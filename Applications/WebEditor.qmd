---
title: "openEO Web Editor"
image: _images/webeditor/joblogs.png
---

The openEO Web Editor is a web-based graphical user interface (GUI) that allows users to interact with the openEO API and perform various tasks related to Earth observation data processing. It provides a user-friendly interface for users who are not familiar with a programming language to carry out several Earth Observation data processing tasks, such as querying available data, defining processing workflows, executing processes, and visualising the results. It allows users to build complex processing chains by connecting different processing steps as building blocks and provides options to specify parameters and input data for each step. 

In short, the openEO Web Editor can act as a simple interface for:


* Data Discovery: User can explore and discover available Earth observation datasets.
* Workflow Creation: User can create an openEO processing workflow from basic building blocks in a drag-and-drop interface.
* Workflow Execution: Once User have defined their processing workflow and configured the parameters, User can execute the workflow using the Web Editor. 
* Result Visualization: User can explore the output data on interactive maps, generate charts and graphs 
* Job Management: In the Web Editor, users can monitor processing jobs, view job histories, and access the generated results.

The openEO Web Editor can be accessed via [https://openeo.dataspace.copernicus.eu/](https://openeo.dataspace.copernicus.eu/){target="_blank"}. Even without logging in, users have the ability to retrieve information on available collections, processes, User Defined Functions(UDF) Runtimes, and the options for exporting files. Additionally, users can create openEO process graphs, however, log in is necessary to execute them.

## Getting Started

Upon initial access to the provided link, users are presented with the following screen which is further explained below in refernce to the given numbering:

![](_images/webeditor/webeditor.png)

1. **Service Offering**
   
    The sidebar offers users the ability to navigate through the available collections, processes, UDF Runtimes and Export file formats. At the top of the sidebar, there is a search feature that allows for direct searching. 

    Within the *Collections* section, users can access a comprehensive list of data collections available in the backend through openEO. Clicking on any of these collections will bring up a detailed metadata window.

    Under the *Processes* section, users can find a comprehensive list of openEO processes specifically designed for Earth Observation processing. These processes operate on individual values within an array, accepting and returning a single value.

    The *UDF Runtimes* section provides information on the available environments or platforms where User Defined Functions (UDFs) can be executed. Currently, the python runtime is available during this stage of development.

    In the *Export File Formats* section, users are guided on the supported output formats within openEO. Clicking on each format provides a detailed summary of its associated parameters.

2. **Help**
    
    The *Help* icon at the top of the screen provides a short tour of the main sections of the editor. 

3. **Wizard**

    The *Wizard* is an experimental feature designed to simplify the creation of openEO processes for common use cases.

4. **Server**

    The Server icon will pop up a window giving the user detailed information on the server used for processing the created processes. 

5. **Guest**

    When clicked on, *Guest* the dropdown will provide an option to log in. The profile will be updated with the username when logged in. 

6. **Features**

    The basic functionalities that can be handy when creating the processes in openEO Web Editor is available in this row. These functionalities includes creating a new script, importing processes from external sources, exporting in another programming language, validating processes on the server side, editing process metadata, adding parameters, etc. 

7. **Process Editor**
   
   The *Process Editor* tab is used to work in "**Visual Model**" mode, where processing chains can be created simply by adding collections and processes and connecting them. The "**Code**" tab allows viewing the generated JSON process of the workflow as a process graph.

   The area on it is right will later be used for previewing collections or inspecting the results of batch jobs, web services or other computations. It will also be used to display log messages, if available.

8.  **Log in**

    As previously mentioned, it is necessary to log in to interact with the server. A new window will appear when attempting to log in, as demonstrated below. While other options are sometimes available, the recommended authentication choice is the "Copernicus Data Space Ecosystem". For further information regarding various authentication methods or to seek assistance, click on the "help" option at the top or contact us.

    <centre><img src="_images/webeditor/editor_login.PNG"  width="80%" height="60%"></centre>
    

## Create a workflow

Based on their applications user can build their model by simple drag and drop method. Some processes may necessitate input parameters, which must be carefully considered. As an illustration, we present a simple case of creating a workflow to calculate NDVI using the Sentinel 2 L2A collection. Three main steps involved in using openEO for Earth Observation data processing is shown below. 

1. Load Collection 
   
    a. To start a task within the openEO web editor, the first step is to search for the necessary collections for analysis. Therefore, verifying that the required collections exist within the openEO database is important. This can be done by exploring or searching the list of available collections from the sidebar of the interface.
    In our example, we want to calculate the Normalized Difference Vegetation Index (NDVI), so the Sentinel 2 L2A collection will be used. So the next step is to drag and drop it into the Process Editor for further operations.
        
    ![](_images/webeditor/drag_collection.png)


    b. Once a collection is loaded, several parameters need to be specified, including the area of interest, temporal extent, and selection of bands. Clicking on `load_collection` opens a window where these parameters can be defined for subsequent processing.
    
        To specify the area of interest, users can choose between generating a bounding box or importing their spatial extent by dragging and dropping GeoJSON or KML files onto the map view. While this example demonstrates the use of a bounding box, it is suggested to experiment with a suitably compact area for testing purposes. Additionally, there is an option labeled "No filter", which includes all data in the datacube.

    ![](_images/webeditor/define_bbox.png)

        Another parameter to consider is the temporal extent, which allows users to restrict the loaded data to a specified time window. It is encouraged to choose a timeframe of 1-2 weeks for testing purposes.

    ![](_images/webeditor/define_temporal.png)

        In our case, for NDVI calculation, we have specifically chosen the Red band (B04) and the Near-Infrared (NIR) band (B08). 
        
    ![](_images/webeditor/define_bands.png)

2. Apply Processes
    
    The next step involves applying essential openEO processes, ranging from straightforward mathematical operations to more complex tasks such spatial or temporal aggregations. 

    In this task, we'll using a specific openEO process called `reduce_dimension` two times to simplify our data cube. First we deal with the various bands and then reduce the temporal dimension.
            
    ![](_images/webeditor/reduce_dimension.png)

    In the initial process, the `reduce_dimension` algorithm is utilised to reduce the band dimension after executing a series of addition, subtraction, and division operations necessary for the NDVI calculation.

    <centre><img src="_images/webeditor/reduce_bands.png"  width="80%" height="60%"></centre>

    Following this, with the same `reduce_dimension` algorithm we eliminate the temporal dimension by selecting the maximum value using the max function.
            
    <centre><img src="_images/webeditor/temporal_reducer.png"  width="80%" height="60%"></centre>


3. Select a format

    As a final step in the workflow creation is to select the output format. 
        
    ![](_images/webeditor/save_process.png)

    Since our workflow eliminated the temporal dimension, we can keep things simple and just save the result as a GeoTiff.

    ![](_images/webeditor/save_as_gtiff.png)


## Execute the workflow

To complete the data analysis process, the final step involves executing the created workflow. This can be done in two ways: synchronously or through batch job-based method. Synchronous method allows the user to download the data directly, whereas batch job-based method enables the user to execute process as a batch. The choice of method depends on the user's preference and the size of the dataset. 

![](_images/webeditor/execute_jobs.png)

In the above figure, the red box includes the two methods possible for executing the process. In this example, I used the synchronus method by directly clicking on *Run now*, which popped up a box in the bottom right corner. 

Once the execution process is completed, the result is automatically saved locally. It can also be visualised in the parallel window as shown in the image below:

![](_images/webeditor/webeditor_result.PNG)


Furthermore, if a Batch Job has been created, its actions can be monitored from the same window.


## Data Download using Wizard

The Wizard feature at the top navigation bar allows easy creation of process graphs for common, basic use cases without having to drag and drop processes as done earlier. 

:::{callout-warning}

This feature is experimental and it is not guaranteed that the generated process graphs are fully functional.

:::

At the time of this documentation release, two cases are available through the Wizard feature: direct downloading of data for a selected area and downloading computed spectral indices as shown in the figure below:

![](_images/webeditor/wizard.png)

User can select the preferred case and click on the *Next* button to proceed. The next window will allow the user to define the area of interest, temporal extent, and the collection to be used.
This method makes the task considerably more straightforward than the previously mentioned workflow creation approach. 

## Monitor the workflow

When a batch job is created, openEO's logs feature can help with *monitoring and debugging* of workflows. The back-end typically uses this to dump information during data processing that may be relevant for the user (e.g. warnings, resource stats, â€¦). Like many other processes, job logs can be visualized programmatically as well as in the web editor. 

As shown in the following image, users have the option to access the job logs by clicking on the icon located next to the job ID at the bottom of the interface.

![](./_images/webeditor/joblist.png)

When clicking on it, a pane emerges on the right, as shown below:

![](./_images/webeditor/joblogs.png)

Moreover, users can utilize openEO processes like `inspect`. This allows logging of custom information to be displayed in the job logs.
