[
  {
    "objectID": "Home.html",
    "href": "Home.html",
    "title": "Welcome to the Copernicus Data Space Ecosystem documentation portal",
    "section": "",
    "text": "Welcome to the Copernicus Data Space Ecosystem documentation portal\n Here you can explore our detailed documentation and learn more about the available data, APIs and applications.\nThe ecosystem will be continuously upgraded over the upcoming months, see the timelines in the evolution roadmap. Our documentation will be updated accordingly.\n\nIn this documentation, you can find more information on:\n\nData providing you with details about the available Earth Observation data and products.\nAPIs helping you to find the right interfaces to access catalogs, list collections and process data.\nApplications reducing your efforts to search, visualize, modify and download images in an easy and user-friendly way. \n\nQuick answers can be found in our FAQ.\nIf you have questions that are not answered on this portal, please contact our Support."
  },
  {
    "objectID": "cdse_doc.html",
    "href": "cdse_doc.html",
    "title": "Welcome to the Copernicus Data Space Ecosystem documentation portal",
    "section": "",
    "text": "Welcome to the Copernicus Data Space Ecosystem documentation portal\n Here you can explore our detailed documentation and learn more about the available data, APIs and applications.\nThe ecosystem will be continuously upgraded over the upcoming months, see the timelines in the evolution roadmap. Our documentation will be updated accordingly.\n\nIn this documentation, you can find more information on:\n\nData providing you with details about the available Earth Observation data and products.\nAPIs helping you to find the right interfaces to access catalogs, list collections and process data.\nApplications reducing your efforts to search, visualize, modify and download images in an easy and user-friendly way. \n\nQuick answers can be found in our FAQ.\nIf you have questions that are not answered on this portal, please contact our Support."
  },
  {
    "objectID": "Applications/Browser.html",
    "href": "Applications/Browser.html",
    "title": "Documentation",
    "section": "",
    "text": "The Browser is a web browser application that allows you to easily search, visualize, modify and download imagery from the Sentinel satellites. You can access the Browser at:\nhttps://dataspace.copernicus.eu/browser/\nCurrently you need a free account to use the Browser. To register for a free account, click here to the browser. A new window will open where you can click on New user? Click here to create an account and access the data. Once you have created the account, you will automatically be logged in to the Browser. Remember to save your login credentials for the next time you want to log in to the Browser.\n Fig 1: Browser start screen\nThe Browser window is divided into three parts:\n\nThe sidebar on the left side of the screen. Here you can set the parameters to search for, visualize and download data.\nThe map in the middle of the screen. Here you can zoom in and out and move around to find the place you are interest in. In this area you will see visualized satellite imagery or geometries of the products, that are the result of your search.\nThe toolbar on the right side of the screen. Here you find various tools (e.g., for measuring or downloading images) with which you can work with the data displayed on the map."
  },
  {
    "objectID": "Applications/Browser.html#about-the-browser",
    "href": "Applications/Browser.html#about-the-browser",
    "title": "Documentation",
    "section": "",
    "text": "The Browser is a web browser application that allows you to easily search, visualize, modify and download imagery from the Sentinel satellites. You can access the Browser at:\nhttps://dataspace.copernicus.eu/browser/\nCurrently you need a free account to use the Browser. To register for a free account, click here to the browser. A new window will open where you can click on New user? Click here to create an account and access the data. Once you have created the account, you will automatically be logged in to the Browser. Remember to save your login credentials for the next time you want to log in to the Browser.\n Fig 1: Browser start screen\nThe Browser window is divided into three parts:\n\nThe sidebar on the left side of the screen. Here you can set the parameters to search for, visualize and download data.\nThe map in the middle of the screen. Here you can zoom in and out and move around to find the place you are interest in. In this area you will see visualized satellite imagery or geometries of the products, that are the result of your search.\nThe toolbar on the right side of the screen. Here you find various tools (e.g., for measuring or downloading images) with which you can work with the data displayed on the map."
  },
  {
    "objectID": "Applications/Browser.html#visualization",
    "href": "Applications/Browser.html#visualization",
    "title": "Documentation",
    "section": "Visualization",
    "text": "Visualization\nYou can find the VISUALIZE tab in the upper left corner of the sidebar (selected by default). The VISUALIZE tab will allow you to easily visualize satellite imagery on the map. Change or modify your visualization with just a few clicks.\n\nVisualizing data\nIn order to visualize data on the map, you need to zoom in to your area of interest. You can do this either with the mouse wheel or with the location search in the upper right corner.\nLet’s try to visualize the latest Sentinel-2 L2A imagery over Italy.\n\nEither zoom to Italy with the mouse wheel or type Italy in the search box in the upper right corner.\nIn the sidebar, a maximum cloud coverage of 30% and the product type Sentinel-2 L2A are already preselected. To visualize the latest available data with cloud coverage below 30% click on the Show latest date button.\n\n\nFig 2: VISUALIZE tab with show latest date button and Sentinel-2 L2A collection highlighted\nYou can now see the latest data over Italy on the map. Depending on the latest data available you will see data from one or more orbits (stripes of images on the map).\n\nModifying and Changing a Visualization\nIf you want to improve how the data is displayed on the map, you can modify the visualization by clicking on Show effects and advanced options at the bottom of the sidebar. Change the Gain/Gamma values, the values of the R/G/B colour channels, specify which sampling method is used for the visualization (Layer default, Bilinear, Bicubic, Nearest) or click on Reset to reset all changes made. To return to the visualization layers overview, click on Show visualizations.\nTo visualize different Sentinel-2 band combinations, either use one of the prepared options from the list of layers (e.g., NDVI for the Normalized Difference Vegetation Index using the Sentinel bands B4 and B8) or click Custom at the bottom of the layers list.\n\nFig 3: Custom Layers option with Composite Index and Custom script highlighted\nHere you can create a custom R/G/B composite or Index (band ratio, normalized difference index) by dragging and dropping the Sentinel-2 bands into the appropriate circles or use the Custom script functionality to insert a piece of JavaScript code.\n\n\nChanging the Data Collection\nYou can switch visualizing between different data collections by clicking on the arrow next to the Data Collections section in the Visualization tab. Once you click on the arrow as seen in Fig. 4, you will be able to see a drop-down menu with a list of the satellite data that is available. Let us try to visualize Sentinel-3 data of the same location and date as that of the Sentinel-2 data in Visualizing data section.\n\nClick on the drop-down arrow on the right next to Pins icon.\nClick on the drop-down arrow next to Sentinel-2 and select Sentinel-3.\nYou can select the product you want to visualize. To visualize the Brightness temperature, select Sentinel-3 SLSTR L1B. You can see the predefined layers that can be visualized and click on the green button to Show latest date.\n\nAt the moment, the Data Collections available for visualization are Sentinel-2 (L1C and L2A), Sentinel-3 (OLCI Level-1 EFT, SLSTR Level-1 RBT) and Sentinel-5P.\n\nFig 4: Changing Data Collection from Visualization tab directly\n\n\nComparing Visualizations\nTo compare two (or more) visualizations you must add them to the compare panel. You can add a visualization to the compare panel by clicking on the Add to compare button in each visualization layer (see Fig. 4). When you have added all the layers you want to compare to the compare panel, you can switch to it by clicking on the compare icon (  ). In the compare panel you can choose between a Split and an Opacity mode. With the Split mode you can compare two images side by side. With the Opacity mode you can compare two (or more) visualizations on top of each other.\n\nFig 5: Add to compare and compare icon\n\n\nSaving Pins\nTo save a visualization for future viewing, you can save it as a pin by clicking on ( ) next to the Layer name and clicking on Add to Pins. You can find the saved pins by clicking on the ( ) icon. If you wish to compare saved pins, you can add them to the compare panel as explained in the previous section. If you have multiple pins saved and want to compare them altogether, you can directly go to the compare panel and add all the pins to compare by clicking on ( ). Another feature of the Browser is that you can export pins as a JSON file and import previously exported pins as well.\n\nFig 6: Add to pins and Pins icon\n\n\n\nProduct Search for Current Visualization\nWhen you are visualizing data (chapter Visualizing data), you can easily find the products associated with the data you see on the map. The product allows you to inspect the full metadata and easily download the raw data. To find connected products, just click the Find products for current view button in the sidebar (under the Show latest date button).\n\nFig 7: Find products for current view button position in the sidebar.\n\n\n3D Visualization\nWith the 3D visualization tool, users can also visualize the terrain. To obtain a 3D visualization, you need to first select a layer to view and then click on the  icon. You can move forward, backward, left, or right by right clicking on the pan console (labelled 1 in the red box in Fig. 8) and rotate around a point by right clicking on the camera console (labelled 2 in the red box in Fig. 8). The viewing angle can be adjusted by scaling vertically and panning in all directions. You can further explore the area by adjusting the sun projected shadows and the shading parameters of the scene in the settings (labelled as box 3 and 4 respectively in Fig. 8). This 3D view can also be downloaded as a PNG or JPEG file. Let us try visualizing Mont Blanc, the highest peak in the Alps.\n\nFollow the steps mentioned in Visualizing data chapter to visualize Mont Blanc and select the “True Color” visualization.\nClick on the  icon placed at the right of the screen.\nYou can navigate around the visualization either with your mouse, keyboard or directly on the map by following the instructions mentioned in the “Help” section (click on the ( ) icon).\nClick on the Settings icon ( ). Set the Vertical terrain scaling to 150% by moving the slider.\nTo adjust shadows, click on the Parameters next to Sun projected shadows toggle switch.\nTo adjust Shading parameters, click on Edit and modify the Ambient factor, Diffuse factor, Specular factor, and Specular power.\nYou can Reset values at any point to return to the default settings.\n\n Fig 8: 3D visualization in the Browser with pop-up Settings windows on the right"
  },
  {
    "objectID": "Applications/Browser.html#product-search",
    "href": "Applications/Browser.html#product-search",
    "title": "Documentation",
    "section": "Product Search",
    "text": "Product Search\nWith the product search you can find products from four Sentinel missions (Sentinel-1, Sentinel-2, Sentinel-3, Sentinel-5p) and the sensors on board these satellites (C-SAR, MSI, OLCI, SRAL, SLSTR, SYNERGY). You can explore the metadata for each of those products, download the raw data or visualize the data on the map (currently only Sentinel-2 L1C and L2A are supported, but more data sources will be supported here in the future).\nThe SEARCH tab is located in the sidebar next to the VISUALIZE tab (see Fig. 9).\n\nFig 9: SEARCH tab with different Data Sources, Time range and Search button\n\nHow to find a Product\nTo find products you can either use the keyword search (text input) or select one or more data sources using the checkboxes. To find products for a specific time range only, set the from/to date in the date input boxes. For example, let us find the latest Sentinel-2 L2A image over Italy for the beginning of 2023.\n\nZoom in on Italy on the map with the scroll wheel of your mouse.\nSelect Sentinel-2 &gt; MSI (selected by default) &gt; L2A.\nSet the Time Range to reflect two weeks (e.g., 2023-01-02, 2023-01-16)\nPress the Search button\n\n Fig 10: SEARCH tab with L2A collection selected and map centred on Rome (Italy)\nYou will now see the first 50 search results for your search settings (Sentinel L2A data over Italy for a time range of 2 weeks) in the sidebar and on the map. To load the next 50 results, click on the Load more button at the end of the list in the sidebar. You can view the metadata of a product in the sidebar or by selecting a product on the map. In both cases you can:\n\nDirectly view the basic metadata (preview image (available for most Sentinel-2 L1C, L2A, Sentinel-3 SLSTR and Sentinel-3 OLCI products), name, mission, instrument, acquisition time)\nView the full metadata by clicking on the product info button ( ) in the results (full metadata)\n\n\nAdditional Filters\nTo get more suitable results, you can also select or choose additional filters as shown in Figure 11. 1. Select the Data Source and the appropriate instrument/ processing level. 2. Click on the Filter button and set the filtering parameters. 3. Press the Search button. Here, you can choose various parameters depending on the chosen Data Source. For example, you can see the filter parameters for Sentinel-1 in Figure 11, letting you filter the results based on satellite platform, orbit direction, relative orbit number, acquisition mode, Beam ID and polarization.\n\nFig 11: Data filters and parameters\n\n\nVisualize the search result\nOnce you have found a product, you can visualize the results in two ways: either by directly selecting the viszualize button (  ) in the sidebar or by selecting the visualize button in the results panel on the map. You can open the results panel by clicking on one of the displayed tile footprints on the map.\n Fig 12: Product metadata and visualize button\n\n\n\nHow to download a Product\nWhen you have found a product (see How to find a Product) that you would like to download, you can do so by clicking click on the download icon (  ) for the desired product in the results (in the sidebar or in the results panel on the map after selecting a product). After you click the button, a progress bar will appear below the product to indicate the status of your download. If you have started a download by mistake, you can cancel it by clicking on the “x” below the download button.\nYou can continue to use the app as normal while a product is being downloaded.\n\nFig 13: Product download (in progress) with Download product and cancel button highlighted"
  },
  {
    "objectID": "Applications/Browser.html#tools",
    "href": "Applications/Browser.html#tools",
    "title": "Documentation",
    "section": "Tools",
    "text": "Tools\nThe Browser has several tools to help you better understand the data on the map and prepare it for sharing with others. These tools can be found in the upper right corner of the Browser. They can help you select the Area of Interest, measure, download the image, create a timelapse if you want to observe the area over a longer period of time, or analyse the statistics of an index (e.g., the NDVI).\n\nArea/Point of Interest\nUse the Area of Interest (AOI) tool to draw a rectangular or polygonal area of interest by clicking on the  icon in the upper right corner of the browser. You can also upload a KML/KMZ, GPX, WKT (in EPSG:4326) or GEOJSON/JSON file to create an AOI.\nUse the  icon to mark a location and re-centre to the Point of Interest(POI)\n\n\nMeasure\nYou can use the Measure tool by clicking on the  icon to get the distance and area measurements. To measure the distance between two points, simply click on the start and end points on the map, to measure the area, draw a polygon (areas can also be measured using the AOI drawing, as described in Area/Point of Interest).\n\n\nImage Download\nThere are three different download options. You can switch between the options using the tabs at the top of the pop-up window. Each option contains a preview of the data at the bottom. When you are satisfied with your download settings, you will find the  button below the preview:\n\nBasic\n\nYou can use the Show Captions toggle switch to add data source, date, zoom scale and branding information to the exported images.\nYou can also use the Add Map Overlays toggle switch to add place labels, streets and political boundaries to the image or the Show Legend toggle switch to add the legend data.\nYou can use the Crop to AOI toggle switch to crop the image to the bounds of area of interest, if drawn previously.\nIf you want to download the entire image but highlight the AOI, it can be done by enabling the Draw AOI Geometry.\nUse the textbox to add a short description to the exported image.\nChoose between two image formats (JPG, PNG).\nA preview of the image that will be downloaded is displayed under Preview. Previews are available only when you zoom in enough.\n\nAnalytical\n\nAfter preparing the data for download, click the  button to download the image in JPG, PNG, KMZ or GeoTIFF format.\nChoose between different image formats, resolutions and coordinate systems before downloading the image. You can also attach a logo.\nIn the Analytical panel, you can select multiple layers (Visualized/Raw) and download them all in a single ZIP file.\n\nHigh-res print\n\nPrepare the selected visual for high-resolution printing by manually selecting a format, size and DPI. Add captions, legends and descriptions as needed.\n\n\n\n\nTimelapse\nTimelapses are a very popular and useful tool to show how a certain location on Earth changed through time. Using the timelapse tool you can create your own visualization of changes through time and export it as .GIF or .MPEG4 to share it with others online. Let’s create a timelapse of the deforestation in the Brazil from 2018 – 2022.\n\nGo to: https://sentinelshare.page.link/osH4\nClick on the timelapse icon (  ) and click on the play button in the middle of the screen. This opens a pop-up window to create a timelapse.\nChange the settings on the left side to:\n\nDates 2018-01-01 – 2022-12-31\nSelect 1 image per: month Alternatively, you can select only certain months in a year using the filter by months option. Click on Search to see all the results.\n\nIn the Visualizations set the Min. tile coverage to 100% and the Max. cloud coverage to 2% and manually deselect the images from the 2022-05-30 (slightly cloudy) and the 2022-09-07 (blurry).\nOnce you have the list of images you want to display in the timelapse, select the speed, and transition to prepare your timelapse.\nClick on the play button to check the result and download the animation as a GIF-file using the Download button for further use online/offline.\n\n Fig 14: Browser timelapse tool with settings highlighted\n\nHistogram\nWith the Histogram tool you can display statistical data (the distribution of values) for specific layers by clicking on the  icon. The histogram is calculated for the data within your AOI, if defined or otherwise for the whole screen. This tool currently only works for index layers (e.g., the NDVI).\n\nFig. 15: Example of a distribution plot of NDVI values"
  },
  {
    "objectID": "Applications/WebEditor.html",
    "href": "Applications/WebEditor.html",
    "title": "openEO Web Editor",
    "section": "",
    "text": "The openEO Web Editor is a web-based graphical user interface (GUI) that allows users to interact with the openEO API and perform various tasks related to Earth observation data processing. It provides a user-friendly interface for users who are not familiar with a programming language to carry out several Earth Observation data processing tasks, such as querying available data, defining processing workflows, executing processes, and visualising the results. It allows users to build complex processing chains by connecting different processing steps as building blocks and provides options to specify parameters and input data for each step.\nThe openEO Web Editor can be accessed via https://openeo.dataspace.copernicus.eu/. Even without logging in, users have the ability to retrieve information on available collections, processes, User Defined Functions(UDF) Runtimes, and the options for exporting files. Additionally, users can create openEO process graphs, however, log in is necessary to execute them."
  },
  {
    "objectID": "Applications/WebEditor.html#getting-started",
    "href": "Applications/WebEditor.html#getting-started",
    "title": "openEO Web Editor",
    "section": "Getting Started",
    "text": "Getting Started\nUpon initial access to the provided link, users are presented with the following screen which is further explained below in refernce to the given numbering:\n\n\nService Offering\nThe sidebar offers users the ability to navigate through the available collections, processes, UDF Runtimes and Export file formats. At the top of the sidebar, there is a search feature that allows for direct searching.\nWithin the Collections section, users can access a comprehensive list of data collections available in the backend through openEO. Clicking on any of these collections will bring up a detailed metadata window.\nUnder the Processes section, users can find a comprehensive list of openEO processes specifically designed for Earth Observation processing. These processes operate on individual values within an array, accepting and returning a single value.\nThe UDF Runtimes section provides information on the available environments or platforms where User Defined Functions (UDFs) can be executed. Currently, the python runtime is available during this stage of development.\nIn the Export File Formats section, users are guided on the supported output formats within openEO. Clicking on each format provides a detailed summary of its associated parameters.\nHelp\nThe Help icon at the top of the screen will provide you with a short tour of the main section of the editor.\nWizard\nThe Wizard is an experimental feature that will help you to create openEO processes in a simple way for some common use cases.\nServer\nThe Server icon will pop up a window giving the user detailed information on the server used for processing the created processes.\nGuest\nThe Guest naming will be replaced with your username when logged in. The dropdown will provide with an option to Log in.\nFeatures\nThe basic functionalities that can be handy when creating the processes in openEO Web Editor is available in this row. These functionalities includes creating a new script, importing processes from external sources, exporting in another programming language, validating processes on the server side, editing process metadata, adding parameters, etc.\nProcess Editor\nThis is the editor for the processes. We recommend to work in “Visual Model” mode, where you can create processing chains simply by adding collections and processes and connecting them with each other. The “Code” mode allows to see the generated JSON process, which is usually only needed if you want to run the process using another client library such as Python or R.\nThe area on it’s right will later be used for previewing collections or inspecting the results of batch jobs, web services or other computations. It will also be used to display log messages, if available.\nLog in\nAs previously mentioned, it is necessary to log in to interact with the server. A new window will appear when attempting to log in, as demonstrated below. While other options are sometimes available, the recommended authentication choice is the “Copernicus Data Space Ecosystem”. For further information regarding various authentication methods or to seek assistance, you can always click on the “help” option at the top or contact us."
  },
  {
    "objectID": "Applications/WebEditor.html#create-a-workflow",
    "href": "Applications/WebEditor.html#create-a-workflow",
    "title": "openEO Web Editor",
    "section": "Create a workflow",
    "text": "Create a workflow\nBased on their applications user can build their model by simple drag and drop method. Some processes may necessitate input parameters, which must be carefully considered. As an illustration, we present a simple case of creating a workflow to calculate NDVI using the Sentinel 2 L2A collection. Three main steps involved in using openEO for Earth Observation data processing is shown below.\n\nLoad Collection\nIn order to load the required collection make sure it is available by searching in the sidebar. Once you find your collection you can simply drag and drop it for carrying out further actions. In the following clip, you can observe the sequential actions are taken to accomplish the following tasks: choosing a collection of interest, defining the spatial and temporal boundaries, and filtering the necessary bands for subsequent processing. Specifically, for calculating the NDVI, the Red band (B04) and Near-Infrared (NIR) band (B08) have been selected.\n\n\n\nApply Processes\nEventually, the next step involves implementing essential processes, ranging from straightforward operations like adding bands to more complex tasks such as importing or defining user-defined functions (UDFs). In the following clip, a reduce_dimension() process is employed to eliminate the temporal dimension by selecting the maximum value. The same process is utilised to reduce the band dimension after executing a series of addition, subtraction, and division operations necessary for the NDVI calculation.\n\n\n\nSelect a format\nAs a final step in the workflow creation, the following clip demonstrates selecting the output format. Since our application involves simple NDVI calculation, we want to save it as a GeoTiff."
  },
  {
    "objectID": "Applications/WebEditor.html#execute-the-workflow",
    "href": "Applications/WebEditor.html#execute-the-workflow",
    "title": "openEO Web Editor",
    "section": "Execute the workflow",
    "text": "Execute the workflow\nTo complete the data analysis process, the final step involves executing the created workflow. This can be done in two ways: synchronously or through batch job-based method. Synchronous method allows the user to download the data directly, whereas batch job-based method enables the user to execute process as a batch. The choice of method depends on the user’s preference and the size of the dataset.\n\nIn the above figure, the red box includes the two methods possible for executing the process. In this example, I used the synchronus method by directly clicking on Run now, which popped up a box in the bottom right corner.\nOnce the execution process is completed, the result is automatically saved locally. It can also be visualised in the parallel window as shown in the image below:\n\nFurthermore, if you have created Batch Job, you can monitor its action from the same window."
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html",
    "href": "Applications/PlazaDetails/ExecuteService.html",
    "title": "Execute a service",
    "section": "",
    "text": "Services can be executed through the tools that are provided by the different orchestrators. The table below shows a short summary of the different tools that are available for each orchestrator.\n\n\n\n\n\n\nopenEO\n\n\n\n\nOnline user interface - web editor  Client Libraries (JavaScript, Python, R) API\n\n\n\nThere are several ways to discover how a service can be executed. When publishing a service on the openEO algorithm plaza, a service provider can choose to provide the following information in the service details:\n\nAn executable link which redirects the user to the online orchestrator’s user interface. If this is the case, an Access service button will appear when opening an openEO algorithm plaza service.\nSample code in the service description on how to execute a service.\n\n\n\nBoth orchestrators provide an online user interface where users can execute services directly in a web browser. Through these graphical user interfaces, users can execute, link, and configure different services. More information on the usage of the online applications is presented in the table below.\n\n\n\nopenEO\n\n\n\n\nAccess\n\n\nDocumentation\n\n\n\n\n\n\nopenEO provides client libraries to support the creation and execution of JavaScript, Python and R services. The full client libraries documentation is available on the official openEO support pages:\n\nJavaScript\nPython\nR\n\nThe following example shows a code sample on how to execute a service through the openEO Python Client.\nimport openeo\n\n# Setup parameters\naoi = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [\n                5.179324150085449,\n                51.2498689148547\n            ],\n            [\n                5.178744792938232,\n                51.24672597710759\n            ],\n            [\n                5.185289382934569,\n                51.24504696935156\n            ],\n            [\n                5.18676996231079,\n                51.245342479161295\n            ],\n            [\n                5.187370777130127,\n                51.24918393390799\n            ],\n            [\n                5.179324150085449,\n                51.2498689148547\n            ]\n        ]\n    ]\n}\ndate = '2020-06-01'\n\n# Setup connection with OpenEO\neoconn = openeo.connect(\"https://openeo.vito.be\").authenticate_oidc(\"egi\")\n\n# Create a processing graph from the BIOMASS process using an active openEO connection\ntaskmap = eoconn.datacube_from_process(\"taskmap_generate\", namespace=\"https://openeo.vito.be/openeo/1.0/processes/u:EOplaza_tps/taskmap_generate\", aoi=aoi,\n                                       date=date)\n\n# Execute the openEO request as a batch job\ntaskmap_job = taskmap.save_result(format='gtiff').send_job()\ntaskmap_job.start_and_wait().get_results()\nTo execute a service from the openEO algorithm plaza through one of the OpenEO client libraries, it is important to use the datacube_from_process function. This accepts the ID and namespace of the service. Both are made available in the service description on the openEO algorithm plaza. The full documentation on using the function is available on the official openEO documentation.\nMore examples are available in the openEO GitHub repository.\n\n\n\nBoth openEO provide a fully documented API as a more advanced way to integrate features of both orchestrators in any existing application or workflow. These APIs can also be used to execute openEO algorithm plaza services. The documentation of these services is available at:\n\n\n\nopenEO\n\n\n\n\nDocumentation"
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html#online-user-interface",
    "href": "Applications/PlazaDetails/ExecuteService.html#online-user-interface",
    "title": "Execute a service",
    "section": "",
    "text": "Both orchestrators provide an online user interface where users can execute services directly in a web browser. Through these graphical user interfaces, users can execute, link, and configure different services. More information on the usage of the online applications is presented in the table below.\n\n\n\nopenEO\n\n\n\n\nAccess\n\n\nDocumentation"
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html#client-libraries",
    "href": "Applications/PlazaDetails/ExecuteService.html#client-libraries",
    "title": "Execute a service",
    "section": "",
    "text": "openEO provides client libraries to support the creation and execution of JavaScript, Python and R services. The full client libraries documentation is available on the official openEO support pages:\n\nJavaScript\nPython\nR\n\nThe following example shows a code sample on how to execute a service through the openEO Python Client.\nimport openeo\n\n# Setup parameters\naoi = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [\n                5.179324150085449,\n                51.2498689148547\n            ],\n            [\n                5.178744792938232,\n                51.24672597710759\n            ],\n            [\n                5.185289382934569,\n                51.24504696935156\n            ],\n            [\n                5.18676996231079,\n                51.245342479161295\n            ],\n            [\n                5.187370777130127,\n                51.24918393390799\n            ],\n            [\n                5.179324150085449,\n                51.2498689148547\n            ]\n        ]\n    ]\n}\ndate = '2020-06-01'\n\n# Setup connection with OpenEO\neoconn = openeo.connect(\"https://openeo.vito.be\").authenticate_oidc(\"egi\")\n\n# Create a processing graph from the BIOMASS process using an active openEO connection\ntaskmap = eoconn.datacube_from_process(\"taskmap_generate\", namespace=\"https://openeo.vito.be/openeo/1.0/processes/u:EOplaza_tps/taskmap_generate\", aoi=aoi,\n                                       date=date)\n\n# Execute the openEO request as a batch job\ntaskmap_job = taskmap.save_result(format='gtiff').send_job()\ntaskmap_job.start_and_wait().get_results()\nTo execute a service from the openEO algorithm plaza through one of the OpenEO client libraries, it is important to use the datacube_from_process function. This accepts the ID and namespace of the service. Both are made available in the service description on the openEO algorithm plaza. The full documentation on using the function is available on the official openEO documentation.\nMore examples are available in the openEO GitHub repository."
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html#api",
    "href": "Applications/PlazaDetails/ExecuteService.html#api",
    "title": "Execute a service",
    "section": "",
    "text": "Both openEO provide a fully documented API as a more advanced way to integrate features of both orchestrators in any existing application or workflow. These APIs can also be used to execute openEO algorithm plaza services. The documentation of these services is available at:\n\n\n\nopenEO\n\n\n\n\nDocumentation"
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceProviderGuide.html",
    "href": "Applications/PlazaDetails/ServiceProviderGuide.html",
    "title": "Guide for Third Party Service Providers (TPS)",
    "section": "",
    "text": "Below you can find more information on the following topics.\n\nCreate your account\nSigning in\nManage your organisation\nManage your services\nManage your profile\nManage your billing information\nCheck execution statistics"
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html",
    "href": "Applications/PlazaDetails/ManageBilling.html",
    "title": "Manage your billing information",
    "section": "",
    "text": "During the execution of our openEO algorithm plaza services, credits will be deducted for each execution. You can manage your credits directly on the openEO algorithm plaza by clicking the Billing menu item. This redirects to the billing page where you can see:\n\nAn overview of your current credit score\nA Call to Action (CTA) button to top up your credits\nA selection menu to select a subscription plan\nAn overview of your financial transactions\n\n\n\nTo visualize available credits in your account, first, you must sign in. If you don’t have login credentials, please Register.\nOnce logged in, click on the Billing tab that leads to a page showing your available credits, followed by additional information on subscription.\n\nThe credits that are shown are shared amongst your organization. If you are a member of multiple organizations, navigate to the profile page to change your Billing Organization.\n\n\n\n\n\nCredits are deducted based on the chosen services and spatial extent. The amount will vary depending on the processing complexity and time required for each type of service. Detailed examples of some well-known services and how they fit into the 1000 free credits can further be found here.\nMoreover, every user is provided with 1000 credits each month, with which they can execute multiple services.\n\n\n\nBased on the required credits for executing a service, if you think your available credits are insufficient, there are two ways you can replenish the credits available in your account. You can purchase them as a one-time purchase or buy a subscription.\n\nPurchase Credits\nYou can add/purchase a limited credit amount through a one-time payment by clicking on Add credits button next to the credit score. After choosing among the different credit packs, you are redirected to a payment service to continue payment.\n\nCredits packs will be made available soon.\n\nOnce we receive the payment, your credits will be updated.\nCredit Subscription\nThe other way is by selecting one of the available subscription plans. Once you click on the “Start subscription” button, you will be redirected to the payment page for your selected subscription plan, where you can provide the payment details for recurring payments.\n\nSubscriptions will be made available soon.\n\nAt any time, you can change or cancel an active subscription. The current credits will be kept, and you will receive a new amount after the successful payment of the new subscription plan.\n\n\n\n\nIf you want to request a statement regarding your credit expenditure, you can create a ticket with your username, email, and the time interval for the requested information."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html#monitor-available-credits",
    "href": "Applications/PlazaDetails/ManageBilling.html#monitor-available-credits",
    "title": "Manage your billing information",
    "section": "",
    "text": "To visualize available credits in your account, first, you must sign in. If you don’t have login credentials, please Register.\nOnce logged in, click on the Billing tab that leads to a page showing your available credits, followed by additional information on subscription.\n\nThe credits that are shown are shared amongst your organization. If you are a member of multiple organizations, navigate to the profile page to change your Billing Organization."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html#credits-strength",
    "href": "Applications/PlazaDetails/ManageBilling.html#credits-strength",
    "title": "Manage your billing information",
    "section": "",
    "text": "Credits are deducted based on the chosen services and spatial extent. The amount will vary depending on the processing complexity and time required for each type of service. Detailed examples of some well-known services and how they fit into the 1000 free credits can further be found here.\nMoreover, every user is provided with 1000 credits each month, with which they can execute multiple services."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html#adding-credits",
    "href": "Applications/PlazaDetails/ManageBilling.html#adding-credits",
    "title": "Manage your billing information",
    "section": "",
    "text": "Based on the required credits for executing a service, if you think your available credits are insufficient, there are two ways you can replenish the credits available in your account. You can purchase them as a one-time purchase or buy a subscription.\n\nPurchase Credits\nYou can add/purchase a limited credit amount through a one-time payment by clicking on Add credits button next to the credit score. After choosing among the different credit packs, you are redirected to a payment service to continue payment.\n\nCredits packs will be made available soon.\n\nOnce we receive the payment, your credits will be updated.\nCredit Subscription\nThe other way is by selecting one of the available subscription plans. Once you click on the “Start subscription” button, you will be redirected to the payment page for your selected subscription plan, where you can provide the payment details for recurring payments.\n\nSubscriptions will be made available soon.\n\nAt any time, you can change or cancel an active subscription. The current credits will be kept, and you will receive a new amount after the successful payment of the new subscription plan."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html#request-for-statement",
    "href": "Applications/PlazaDetails/ManageBilling.html#request-for-statement",
    "title": "Manage your billing information",
    "section": "",
    "text": "If you want to request a statement regarding your credit expenditure, you can create a ticket with your username, email, and the time interval for the requested information."
  },
  {
    "objectID": "Applications/PlazaDetails/UserGuide.html",
    "href": "Applications/PlazaDetails/UserGuide.html",
    "title": "Guide for openEO plaza algorithm users",
    "section": "",
    "text": "Below you can find more information on the following topics:\n\nOverview\nCreate your account\nSigning in\nManage your Profile\nManage your billing information\nExecute a service\nCheck execution statistics"
  },
  {
    "objectID": "Applications/PlazaDetails/SignIn.html",
    "href": "Applications/PlazaDetails/SignIn.html",
    "title": "Signing In",
    "section": "",
    "text": "You arrive at this page by being unauthenticated and clicking on the Sign In navigation option. Through this flow, any user can login into their registered account after they have successfully validated their email address through the link sent to their email."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html",
    "href": "Applications/PlazaDetails/ManageOrg.html",
    "title": "Manage your organization",
    "section": "",
    "text": "Organisations are core elements of the openEO algorithm plaza Portal, as they are the entities that relate users, accesses, services, data, etc. One can think of an organisation as a company in most cases, although users can be a one-man organisation. By default, when a registration is made through the Portal, an organisation is always created with the user that made the registration as the sole user, even if unnamed and with no data. In a user’s Profile page, they can click on the Organisation option in sub-navigation and arrive at the Organisation page, where they can view and edit the organisation’s details, such as:\n\nOrganisation name (mandatory)\nOrganisation Identity registration (optional)\nOrganisation Avatar / logo URL (optional)\nOrganisation description (optional)\nOrganisation website (optional)\nTerms of use URL (optional) and other “useful links” e.g., Terms of Service, Privacy, YouTube, and Support URLs\nUpdate button, disabled by default\n\n\n\n\nYou have arrived here after triggering the Invite User flow through the team screen. You can see a content block to add a new user that contains:\n\nEmail address (Mandatory)\nName (Optional)\nRole dropdown (Admin, Developer, etc.), defaulting as Developer\nSubmit button\n\nYou can fill out the fields accordingly and submit the form to invite the new User to your Team and expect a success / error feedback message upon sending it. The form should also disappear after successful submission. You can see the newly invited user in the user list, however, without a Role dropdown and clearly flagged with an “Invitation Pending” message."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html#provide-your-organisation-details",
    "href": "Applications/PlazaDetails/ManageOrg.html#provide-your-organisation-details",
    "title": "Manage your organization",
    "section": "",
    "text": "Organisations are core elements of the openEO algorithm plaza Portal, as they are the entities that relate users, accesses, services, data, etc. One can think of an organisation as a company in most cases, although users can be a one-man organisation. By default, when a registration is made through the Portal, an organisation is always created with the user that made the registration as the sole user, even if unnamed and with no data. In a user’s Profile page, they can click on the Organisation option in sub-navigation and arrive at the Organisation page, where they can view and edit the organisation’s details, such as:\n\nOrganisation name (mandatory)\nOrganisation Identity registration (optional)\nOrganisation Avatar / logo URL (optional)\nOrganisation description (optional)\nOrganisation website (optional)\nTerms of use URL (optional) and other “useful links” e.g., Terms of Service, Privacy, YouTube, and Support URLs\nUpdate button, disabled by default"
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html#invite-team-members",
    "href": "Applications/PlazaDetails/ManageOrg.html#invite-team-members",
    "title": "Manage your organization",
    "section": "",
    "text": "You have arrived here after triggering the Invite User flow through the team screen. You can see a content block to add a new user that contains:\n\nEmail address (Mandatory)\nName (Optional)\nRole dropdown (Admin, Developer, etc.), defaulting as Developer\nSubmit button\n\nYou can fill out the fields accordingly and submit the form to invite the new User to your Team and expect a success / error feedback message upon sending it. The form should also disappear after successful submission. You can see the newly invited user in the user list, however, without a Role dropdown and clearly flagged with an “Invitation Pending” message."
  },
  {
    "objectID": "Applications/PlazaDetails/Overview.html",
    "href": "Applications/PlazaDetails/Overview.html",
    "title": "Overview",
    "section": "",
    "text": "Being an online Application Programming Interface (API) and integrations, openEO algorithm plaza provides a self-service portal through which customers, internal staff, and external providers can interact, publish, and use integrations easily in one place. In general, because EO user and service provider platforms aggregate services and integrations from a range of providers, the selection is usually wider, and availability is higher than in vendor-specific online portals. As an authenticated user using the openEO algorithm plaza, you should be able to view the advertised services.\n\nYou will see:\n\nA main list of all the services, ordered by popularity, paginated.\nA text filter bar to filter through the existing services.\nAttribute filtering (publisher, category, type).\n\nEach service will be visually represented on a card by:\n\nA logo\nThe service’s title\nThe service’s short description\nThe service’s maturity level\n\nYou can click on each service and be redirected to the service’s detail page.\n\n\n\n\nYou arrive at the services overview after having logged in. Alternatively, you can access this overview by clicking ‘Dashboard’ –&gt; ‘Catalogue’ Per service, some brief information about its organisation and a list of other services that this organisation has published to the openEO algorithm plaza is available. You can click on any of the services listed as part of this organisation and be redirected to the service detail."
  },
  {
    "objectID": "Applications/PlazaDetails/Overview.html#service-publishers",
    "href": "Applications/PlazaDetails/Overview.html#service-publishers",
    "title": "Overview",
    "section": "",
    "text": "You arrive at the services overview after having logged in. Alternatively, you can access this overview by clicking ‘Dashboard’ –&gt; ‘Catalogue’ Per service, some brief information about its organisation and a list of other services that this organisation has published to the openEO algorithm plaza is available. You can click on any of the services listed as part of this organisation and be redirected to the service detail."
  },
  {
    "objectID": "Applications/PlazaDetails/Overview.html#service-details-view",
    "href": "Applications/PlazaDetails/Overview.html#service-details-view",
    "title": "Overview",
    "section": "Service details view",
    "text": "Service details view\n\nAs a user, you want to know about a specific service. You arrive at this page by clicking on a service from the openEO algorithm plaza’s main page.\n\nAs an authenticated user that is visualizing the details of a specific service, you can see:\n\nA logo\nA list of features\nA description\nThe owner (organisation)\nA list of other services from the organisation\n\nYou can click on the organisation’s page (“publisher page”) and be redirected to the organisation’s page, listing all the available openEO algorithm plaza services from this organisation."
  },
  {
    "objectID": "Roadmap/AppTable.html",
    "href": "Roadmap/AppTable.html",
    "title": "Applications",
    "section": "",
    "text": "Open Services\nType\nJan-23\nMar-23\nApr-23\nJul-23\nNov-23\n\n\n\n\nIdentity service\nUser Registration and identity management\nStart of registration of users allowing to access first free services on CDE. Management of user and organization.\n\n\nFull functionality, access to all integrated applications with SSO.\n\n\n\nBrowser\nCopernicus Data Space Ecosystem Browser\nAvailable for registered users, visualisation limited to Sentinel-2 L1C/L2A, simple querying capabilities\nVisualisation of Sentinel-1 GRD added.\nAvailable also for non-registered users, with limited functionality.\nAdvanced querying capabilities.\nVisualization of Sentinel 3 and Sentinel 5p.\nVisualisation support extented to additional data collections.\nVisualisation support extended to Landsat Collection 2 and MODIS.\n\n\nData Workspace\n\n\nAvailable for registered users.\nAvailable, supporting on-demand services.\n\n\n\nopenEO Web Editor\n\n\n\nAvailable, supporting Sentinel-1 GRD, Sentinel-2 L1C/L2A, Sentinel-3 OLCI Level 1 and Sentinel-5p NTC Level 2\nAdditional data collections available.\n\n\nJupyterLab\n\n\n\nAvailable\n\n\n\nWeb Portal\nWeb portal\nLanding page available with road map, registration, browser, documentation, news section\n\nContent on additional data, services and documentation (STAC, S3, OGC and Sentinel Hub APIs, traceability service and on demand)\nNew data, services and documentation (marketplace, user forum, Jupyter lab, processing APIs)\nAdditional information and CTA to new data and services\n\n\nPublic dashboard\n\n\n\nAvailable with all relevant metrics\n\n\n\nHelpdesk\nService desk\nMail support\n\nWeb form in web portal\n\n\n\n\nUser forum\n\n\n\nAvailable\n\n\n\nMarketplace\nEO Marketplace\n\n\n\nIntegration into web portal. Provision of engineering support on Marketplace services\n\n\n\n\n\n\n\n\nThird Party Services\nType\nJan-23\nMar-23\nApr-23\nJul-23\nNov-23\n\n\n\n\nInfrastructure as a Service (IaaS)\nCloud Ferro IaaS\nReady to use\n\n\n\n\n\n\nT-System Open Telekom Cloud IaaS\nReady to use"
  },
  {
    "objectID": "Roadmap/DataTable.html",
    "href": "Roadmap/DataTable.html",
    "title": "Data",
    "section": "",
    "text": "Open Data\nType\nJan-23\nApr-23\nJul-23\nOct-23\nNov-23\n\n\n\n\nSentinel-1\nUser Level Data\nSee here\nSee here\nSee here\n\n\n\n\nEngineering data\n\n\n\nWorld: Last 2: weeks IAD\n\n\n\nAuxiliary data\n\n\n\nFull archive\n\n\n\nSentinel-2\nUser Level Data\nSee here\nSee here\nSee here\n\n\n\n\nEngineering data\n\n\n\nWorld: Last 2: weeks IAD\n\n\n\nAuxiliary data\n\n\n\nFull archive\n\n\n\nSentinel-3\nUser Level Data\nSee here\nSee here\nSee here\n\n\n\n\nEngineering data\n\n\n\nWorld: Last 2: weeks IAD\n\n\n\nAuxiliary data\n\n\n\nFull archive\n\n\n\nsentinel-5P\nUser Level Data\nSee here\nSee here\nSee here\n\n\n\n\nEngineering data\n\n\n\nWorld: Last 2: weeks IAD\n\n\n\nAuxiliary data\n\n\n\nFull archive\n\n\n\nPOD\nAuxiliary data\n\n\n\nFull archive\n\n\n\nCopernicus contributing mission\nDEM\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nVHR\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nVHR Urban Atlas\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nOptical HR\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nOptical HR2\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nOptical MR\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nSAR\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nComplementary open data\nSMOS\n\n\nMIRAS\n\n\n\n\nEnvisat\n\n\nMERIS, ASAR\n\n\n\n\nCAMS\n\n\nCopernicus Atmosphere Monitoring Service\n\n\n\n\nCEMS\n\n\nCopernicus Emergency Management Service\n\n\n\n\nCLMS\n\n\nCopernicus Land Monitoring Service\n\n\n\n\nCMEMS\n\n\nCopernicus Marine Service\n\n\n\n\nS2GLC\n\n\nHigh resolution Land Cover Map of Europe\n\n\n\n\nESA WorldCover\n\n\nHigh resolution Land Cover Map of the world for 2020 and 2021, in COG\n\n\n\n\n\n\n\n\n\nThird Party Service Data\nType\nJan-23\nApr-23\nJul-23\nOct-23\nNov-23\n\n\n\n\nCreodias commercial offer\nAirbus Pleiades\n\n\nAvailable to users from selected countries, payable.\n\n\n\n\nAirbus Spot 6/7\n\n\nAvailable to users from selected countries, payable.\n\n\n\n\nWorldview\n\n\nAvailable to users from selected countries, payable.\n\n\n\n\nPlanetScope\n\n\nPayable, \"Area under management\" model\n\n\n\n\nPlanet SkySat\n\n\nPayable\n\n\n\n\nKompsat \n\n\nPayable"
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical/Examples.html",
    "href": "APIs/SentinelHub/BatchStatistical/Examples.html",
    "title": "Examples of Batch Statistical Workflow",
    "section": "",
    "text": "The requests below are written in Python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical/Examples.html#create-a-batch-statistical-request",
    "href": "APIs/SentinelHub/BatchStatistical/Examples.html#create-a-batch-statistical-request",
    "title": "Examples of Batch Statistical Workflow",
    "section": "Create a batch statistical request",
    "text": "Create a batch statistical request\nThis request defines which data is requested and how it will be processed. In this example we'll get the statistics for a single band on a given day. To create a batch statistical request replace the input.features.s3.url field for the actual path to the GeoPackage features and the output.s3.url field for the desired path where the output data will be processed.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nrequest_payload = {\n  \"input\": {\n  \"features\":{\n      \"s3\": {\n          \"url\": \"s3://&lt;my-bucket&gt;/&lt;path-to-geopackage&gt;\",\n          \"accessKey\": \"&lt;my-s3-access-key&gt;,\n          \"secretAccessKey\": \"&lt;my-secret-access-key&gt;\n      }\n  },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastCC\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-06-01T00:00:00Z\",\n            \"to\": \"2020-07-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P30D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  },\n  \"output\": {\n      \"s3\": {\n          \"url\": \"s3://&lt;my-bucket&gt;/&lt;path&gt;\",\n          \"accessKey\": \"&lt;my-s3-access-key&gt;,\n          \"secretAccessKey\": \"&lt;my-secret-access-key&gt;\n      }\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n   'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch\"\n\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=request_payload)\n\nrequest_id = response.json()['id']\nNote that in the above example we're specifying an accessKey and secretAccessKey, so Sentinel Hub can read and write to the user's bucket. You can find more details about this under the AWS access section.\nYou can download an example of a valid .gpkg (GeoPackage) file by clicking here.\n\nGet information about a batch statistical request\nresponse = oauth.request(\"GET\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}\")\n\nresponse.json()\n\n\nGet status information about a batch statistical request\nresponse = oauth.request(\"GET\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}/status\")\n\nresponse.json()\n\n\nRequest analysis of a batch statistical request (ANALYSIS)\nresponse = oauth.request(\"POST\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}/analyse\")\n\nresponse.status_code\n\n\nRequest the start of a batch statistical request (START)\nresponse = oauth.request(\"POST\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}/start\")\n\nresponse.status_code\n\n\nStop a batch statistical request (STOP)\nresponse = oauth.request(\"POST\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}/stop\")\n\nresponse.status_code"
  },
  {
    "objectID": "APIs/SentinelHub/Catalog/Examples.html",
    "href": "APIs/SentinelHub/Catalog/Examples.html",
    "title": "Catalog API examples",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCatalog API Entry page\nCatalog API Entry page with link to other catalog API endpoints and available collections.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/\"\nresponse = oauth.get(url)\n\n\nList collections\nList all available collections. The list will include deployment specific collections and collections available to users through BYOC, Batch or Third Party Data Import functionalities.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections\"\nresponse = oauth.get(url)\n\n\nSentinel 2 L1C collection\nList single collection, in this case Sentinel 2 L1C collection.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections/sentinel-2-l1c/\"\nresponse = oauth.get(url)\n\n\nSimple GET search\nSimple version of search available via GET request is also available. The only query parameters that can be specified in this simpler version are: bbox, datetime, collections, limit and next.\nquery = {\n    \"bbox\": \"13,45,14,46\",\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": \"sentinel-1-grd\",\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.get(url, params=query)\n\n\nSimple POST search\nThe same parameters can also be specified a POST request, query parameters need to be specified as json formatted body and sent to server like:\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSimple POST search with pagination\nnext token can be specified in the request to get back the next page of results.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"next\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with GeoJSON\nInstead of bbox it is possible to add intersects attribute, which can be any type of GeoJSON object (Point, LineString, Polygon, MultiPoint, MultiPolygon).\ndata = {\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"intersects\": {\n        \"type\": \"Point\",\n        \"coordinates\": [\n            13,\n            45,\n        ],\n    },\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Filter\nfilter object can be used to instruct server to only return a specific subset of data.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"filter\": \"sat:orbit_state='ascending'\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nGet Filter parameters for collection\nList all available filter parameters represented as JSON Schema.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections/sentinel-1-grd/queryables\"\nresponse = oauth.get(url)\n\n\nSearch with Fields: No fields\nDefault outputs from the server can be quite verbose for some collections. By default, all available item properties are included in the response.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Empty fields\nfields attribute can be specific to return less information. When fields object is empty only a default set of properties is included: id, type, geometry, bbox, links, assets.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Include\nBy specifying additional attributes in the include list, those attributes are added to the output along with the default ones.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {\"include\": [\"properties.gsd\"]},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Exclude\nexlude list can be used to exclude even the default ones from the output.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {\"exclude\": [\"properties.datetime\"]},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with distinct\nUsing distinct it is possible to get some overview of the data available inside the specified query. For example specifying date as an option will return a list of dates where data is available.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-01T00:00:00Z/2020-01-01T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 100,\n    \"distinct\": \"date\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\nOr see different Sentinel 1 instrument modes used.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-01T00:00:00Z/2020-01-01T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 100,\n    \"distinct\": \"sar:instrument_mode\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch on BYOC/BATCH collections\nYou can search for features on your own BYOC or Batch collections. The functionality described above regarding GET and POST search is the same. The only difference is that you have to specify the collection id with the appropriate prefix on collections parameter (e.g: byoc-&lt;your-collection-id&gt; for byoc or batch-&lt;your-collection-id&gt; for batch). Remember that you will have to use the appropriate deployment endpoint depending on where your collection is hosted.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"byoc-&lt;byoc-collection-id&gt;\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\nOr using GET simple search endpoint:\nquery = {\n    \"bbox\": \"13,45,14,46\",\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": \"batch-&lt;batch-collection-id&gt;\",\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.get(url, params=query)"
  },
  {
    "objectID": "APIs/SentinelHub/Batch/Crs.html",
    "href": "APIs/SentinelHub/Batch/Crs.html",
    "title": "CRS",
    "section": "",
    "text": "Find the list of supported CRSs here.\nThe area of interest can be defined in any of these CRSs but the CRS of the output of batch API is defined with selected tiling grid."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html",
    "href": "APIs/SentinelHub/OGC/WMS.html",
    "title": "Web Mapping Service",
    "section": "",
    "text": "The Sentinel Hub WMS service conforms to the WMS standard. It not only provides access to raw satellite data but also to processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMS, help you understand the structure, show you how to run the requests in different environments and how it can be integrated with QGIS, ArcGIS and web applications.\nIt is possible to obtain multiple separate instances (which act as separate WMS services) each with their own configuration and list of layers which will likely be useful to advanced users.\nThe base URL for the WMS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;\nFor example, a GetCapabilities request can be done by changing the &lt;INSTANCE_ID&gt; to your provided instance ID and opening the following URL:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetCapabilities\nSome of the most common provided products:\n\nTRUE_COLOR - a brightened RGB image\nFALSE_COLOR - uses near-infrared instead of the blue band\nNDVI - Normalized Difference Vegetation Index\nEVI - Enhanced Vegetation Index\n\nList of all available products.\nThe service supports standard WMS requests: GetMap, GetCapabilities, GetFeatureInfo, and also some custom requests. Supported WMS versions are 1.1.1 and 1.3.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nFor a list of supported coordinate reference systems check the GetCapabilities result."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html#wms-request",
    "href": "APIs/SentinelHub/OGC/WMS.html#wms-request",
    "title": "Web Mapping Service",
    "section": "",
    "text": "The Sentinel Hub WMS service conforms to the WMS standard. It not only provides access to raw satellite data but also to processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMS, help you understand the structure, show you how to run the requests in different environments and how it can be integrated with QGIS, ArcGIS and web applications.\nIt is possible to obtain multiple separate instances (which act as separate WMS services) each with their own configuration and list of layers which will likely be useful to advanced users.\nThe base URL for the WMS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;\nFor example, a GetCapabilities request can be done by changing the &lt;INSTANCE_ID&gt; to your provided instance ID and opening the following URL:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetCapabilities\nSome of the most common provided products:\n\nTRUE_COLOR - a brightened RGB image\nFALSE_COLOR - uses near-infrared instead of the blue band\nNDVI - Normalized Difference Vegetation Index\nEVI - Enhanced Vegetation Index\n\nList of all available products.\nThe service supports standard WMS requests: GetMap, GetCapabilities, GetFeatureInfo, and also some custom requests. Supported WMS versions are 1.1.1 and 1.3.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nFor a list of supported coordinate reference systems check the GetCapabilities result."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html#wms-url-parameters",
    "href": "APIs/SentinelHub/OGC/WMS.html#wms-url-parameters",
    "title": "Web Mapping Service",
    "section": "WMS URL Parameters",
    "text": "WMS URL Parameters\nStandard common WMS URL parameters (parameter names are case insensitive, values are case sensitive):\n\n\n\nWMS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WMS\".\n\n\nVERSION\nWMS version standard. Optional, default: \"1.3.0\". Supported values: \"1.1.1\" and \"1.3.0\".\n\n\nREQUEST\nWhat is requested, valid values: GetMap, GetFeatureInfo, GetCapabilities or a custom request's name. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WMS URL parameters, the WMS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetMap request URL parameters:\n\n\n\nWMS parameter\nInfo\n\n\n\n\nBBOX\nSpecifies the bounding box of the requested image. Coordinates must be in the specified coordinate reference system. The four coordinates representing the top-left and bottom-right of the bounding box must be separated by commas. Required. Example: BBOX=-13152499,4038942,-13115771,4020692\n\n\nCRS\n(when VERSION 1.3.0 or higher) the coordinate reference system in which the BBOX is specified and in which to return the image. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nSRS\n(when VERSION 1.1.1 or lower) the coordinate reference system in which the BBOX is specified and in which to return the image. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values.\n\n\nWIDTH\nReturned image width in pixels. Required, unless RESX is used. If WIDTH is used, HEIGHT is also required.\n\n\nHEIGHT\nReturned image height in pixels. Required, unless RESY is used. If HEIGHT is used, WIDTH is also required.\n\n\nRESX\nReturned horizontal image resolution in UTM units (if m is added, e.g. 10m, in metrical units). (optional instead of WIDTH). If used, RESY is also required.\n\n\nRESY\nReturned vertical image resolution in UTM units (if m is added, e.g. 10m, in metrical units). (optional instead of HEIGHT). If used, RESX is also required.\n\n\nLAYERS\nThe preconfigured layer (image) to be returned. You must specify exactly one layer and optionally add additional overlays. Required. Example: LAYERS=TRUE_COLOR,OUTLINE\n\n\nEXCEPTIONS\nThe exception format. Optional, default: \"XML\". Supported values: \"XML\", \"INIMAGE\", \"BLANK\" (all three for version &gt;= 1.3.0), \"application/vnd.ogc.se_xml\", \"application/vnd.ogc.se_inimage\", \"application/vnd.ogc.se_blank\" (all three for version &lt; 1.3.0).\n\n\n\nStandard GetFeatureInfo request URL parameters:\n\n\n\nWMS parameter\nInfo\n\n\n\n\nBBOX\nSpecifies the bounding box of the area which contains the queried point. Coordinates are in the specified CRS/SRS. Four coordinates representing the top-left and bottom-right of the bounding box must be separated by comma. Required. Example: BBOX=-13152499,4038942,-13115771,4020692\n\n\nCRS\n(when VERSION 1.3.0 or higher) the coordinate reference system in which the BBOX is specified. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nSRS\n(when VERSION 1.1.1 or lower) the coordinate reference system in which the BBOX is specified. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nWIDTH\nThe image-space width containing the queried point, in pixels. Required.\n\n\nHEIGHT\nThe image-space height containing the queried point, in pixels. Required.\n\n\nINFO_FORMAT\nThe output format of the feature info content. Check GetCapabilities for a list of supported formats.\n\n\nRESY\nThe layers for which the feature info is requested.\n\n\nI and J\n(when VERSION 1.3.0 or higher) The X and Y coordinates in the output image space in pixels of the feature queried.\n\n\nX and Y\n(when VERSION 1.1.1 or lower) The X and Y coordinates in the output image space in pixels of the feature queried."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html",
    "href": "APIs/SentinelHub/OGC/WFS.html",
    "title": "Web Feature Service",
    "section": "",
    "text": "The Sentinel Hub WFS (Web Feature Service) service conforms to the WFS standard. It provides access to the geometric (vector) metadata about the available data collection tiles. As with the WMS service, WFS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WFS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WFS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;\nThe service supports many vector formats, including GML, XML, JSON and also raw HTML and plain text. Check GetCapabilities for a list of all supported formats. It supports WFS version 2.0.0."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html#wfs-request",
    "href": "APIs/SentinelHub/OGC/WFS.html#wfs-request",
    "title": "Web Feature Service",
    "section": "",
    "text": "The Sentinel Hub WFS (Web Feature Service) service conforms to the WFS standard. It provides access to the geometric (vector) metadata about the available data collection tiles. As with the WMS service, WFS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WFS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WFS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;\nThe service supports many vector formats, including GML, XML, JSON and also raw HTML and plain text. Check GetCapabilities for a list of all supported formats. It supports WFS version 2.0.0."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html#wfs-url-parameters",
    "href": "APIs/SentinelHub/OGC/WFS.html#wfs-url-parameters",
    "title": "Web Feature Service",
    "section": "WFS URL Parameters",
    "text": "WFS URL Parameters\nStandard common WFS URL parameters (parameter names are case insensitive):\n\n\n\nWFS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WFS\".\n\n\nVERSION\nWFS version standard. Optional, default: \"2.0.0\". Supported values: \"2.0.0\".\n\n\nREQUEST\nWhat is requested, valid values: DescribeFeatureType, GetFeature or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WFS URL parameters, the WFS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetFeature request URL parameters:\n\n\n\nWFS parameter\nInfo\n\n\n\n\nTYPENAMES\nMore information found below.\n\n\nMAXFEATURES\nThe maximum number of features to be returned by a single request. Default value: 100. Valid range: 0..100.\n\n\nBBOX\nThe bounding box area for which to return the features.\n\n\nSRSNAME\nThe CRS in which the BBOX is specified.\n\n\nFEATURE_OFFSET\nOffset controls the starting point within the returned features.\n\n\nOUTPUTFORMAT\nThe MIME format of the returned features.\n\n\n\nStandard DescribeFeatureType request URL parameters:\n\n\n\nWFS parameter\nInfo\n\n\n\n\nTYPENAMES\nMore information found below.\n\n\nOUTPUTFORMAT\nThe MIME format of the returned features.\n\n\n\n\nTypenames\n\n\n\nData collection\nTYPENAMES for AWS services\n\n\n\n\nSENTINEL-2 L1C\nDSS1\n\n\nSENTINEL-2 L2A\nDSS2\n\n\nSENTINEL-1 IW\nDSS3\n\n\nSENTINEL-1 EW\nDSS3\n\n\nSENTINEL-1 EW SH\nDSS3\n\n\nSENTINEL 3 OLCI\nDSS8\n\n\nSENTINEL 3 SLSTR\nDSS9\n\n\nSENTINEL 5P\nDSS7\n\n\nLANDSAT 8 L1 (from Collection 2)1\nDSS12\n\n\nLANDSAT 8 L2 (from Collection 2)\nDSS13\n\n\nLANDSAT 4-5 TM Level 1\nDSS15\n\n\nLANDSAT 4-5 TM Level 2\nDSS16\n\n\nLANDSAT 7 ETM Level 1\nDSS17\n\n\nLANDSAT 7 ETM Level 2\nDSS18\n\n\nLANDSAT 1-5 MSS Level 1\nDSS14\n\n\nHarmonized Landsat Sentinel\nDSS21\n\n\nLANDSAT 72\n/\n\n\nLANDSAT 53\n/\n\n\nMODIS\nDSS5\n\n\nENVISAT MERIS\n/\n\n\nBYOC\nbyoc-&lt;collectionId&gt;\n\n\nBATCH\nbatch-&lt;collectionId&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html#footnotes",
    "href": "APIs/SentinelHub/OGC/WFS.html#footnotes",
    "title": "Web Feature Service",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that Landsat 8 Level 1 from collection 1, known as L8L1C with a typename DSS6, has been deprecated and removed↩︎\nNote that Landsat 5 is a different collection than the Landsat 4-5TM. The former is only supported in OGC, while the↩︎\nNote that Landsat 5 is a different collection than the Landsat 4-5TM. The former is only supported in OGC, while the↩︎"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html",
    "href": "APIs/SentinelHub/OGC/WCS.html",
    "title": "Web Coverage Service",
    "section": "",
    "text": "The Sentinel Hub WCS (Web Coverage Service) service conforms to the WCS standard. Provides access to the same bands product and additional informational layers as the WMS service except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. In addition to raster products, the WCS service can also return the vector features of the Sentinel-2 tiles' metadata. As with the WMS service, WCS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WCS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WCS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request (with addition of vector output formats, when \"TILE\" is selected as the COVERAGE) and supports the standard WCS requests: GetCoverage, DescribeCoverage and GetCapabilities. It supports WCS versions 1.0.0 and 1.1.2."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html#wcs-request",
    "href": "APIs/SentinelHub/OGC/WCS.html#wcs-request",
    "title": "Web Coverage Service",
    "section": "",
    "text": "The Sentinel Hub WCS (Web Coverage Service) service conforms to the WCS standard. Provides access to the same bands product and additional informational layers as the WMS service except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. In addition to raster products, the WCS service can also return the vector features of the Sentinel-2 tiles' metadata. As with the WMS service, WCS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WCS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WCS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request (with addition of vector output formats, when \"TILE\" is selected as the COVERAGE) and supports the standard WCS requests: GetCoverage, DescribeCoverage and GetCapabilities. It supports WCS versions 1.0.0 and 1.1.2."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html#wcs-url-parameters",
    "href": "APIs/SentinelHub/OGC/WCS.html#wcs-url-parameters",
    "title": "Web Coverage Service",
    "section": "WCS URL Parameters",
    "text": "WCS URL Parameters\nStandard common WCS URL parameters (parameter names are case insensitive):\n\n\n\nWCS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WCS\".\n\n\nVERSION\nWCS version standard. Optional, default: \"1.1.2\". Supported values: \"1.0.0\" and \"1.1.2\".\n\n\nREQUEST\nWhat is requested, valid values: GetCoverage, DescribeCoverage or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WCS URL parameters, the WCS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetCoverage request URL parameters:\n\n\n\nWCS parameter\nInfo\n\n\n\n\nCOVERAGE\nThe preconfigured (in the instance) layer for which to generate the output image, or \"TILE\" to return the vector format features.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values.\n\n\n\nStandard DescribeCoverage request URL parameters:\n\n\n\nWCS parameter\nInfo\n\n\n\n\nComing soon..."
  },
  {
    "objectID": "APIs/SentinelHub/OGC.html",
    "href": "APIs/SentinelHub/OGC.html",
    "title": "OGC service",
    "section": "",
    "text": "Our OGC services offer the access to the Sentinel Hub functionalists via interfaces, which conform to the Open Geospatial Consortium (OGC) standards: WMS, WCS, WFS, and WMTS.\nUsing the OGC services you can avoid the complexities of preprocessing of satellite data. No need to download the data, no dealing with the JP2 format, no re-projecting, or mosaicking. No need for large storage volumes and lots of processing power. Simply add a new data collection in your GIS application (ArcGIS, QGIS, OpenLayers, Google Earth or any other app supporting standard services) and start using the data right away! Find more information on:\n\nWMS - Web Mapping Service\nWCS - Web Coverage Service\nWFS - Web Feature Service\nWMTS - Web Mapping Tile Service\n\n\nConfiguration Instance and Authentication\nTo use any of our OGC services you will need a \"configuration instance\" (or shortly \"instance\"). A configuration instance defines which layers are part of your OGC service, how the data shall be processed and visualized for each of these layers, and its id is used to authenticate your OGC requests. You can create a configuration instance using our Configuration API or in the Sentinel Hub Dashboard in the \"Configuration Utility\" tab. \"Simple WMS Instance\" is a pre-created configuration instance, which comes with your Sentinel Hub account and you can use its id (\"9d559...\" in the example below but yours will have a different id) to run the OGC examples.\n\n\n\nTutorials and Other Related Materials\nTo get you started, we have prepared a webinar on OGC API with QGIS integration, explaining the structure of OGC requests, how to run them in web browser, Postman and Python and integrate them into your own GIS. November 4, 2020"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html",
    "href": "APIs/SentinelHub/Evalscript/V3.html",
    "title": "Evalscript V3",
    "section": "",
    "text": "Start your evalscript with //VERSION=3 so the system will interpret it as such.\nFor evalscript V3 you need to specify two functions (described in detail below):\nThis is an example of a simple V3 evalscript which returns a true color image:"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#setup-function",
    "href": "APIs/SentinelHub/Evalscript/V3.html#setup-function",
    "title": "Evalscript V3",
    "section": "setup function",
    "text": "setup function\nThis function is required as it sets up the input and output settings.\n\nSpecifics\nSetup needs to return a javascript object with the following properties:\n\ninput - an array of strings representing band names or an array of input objects.\noutput - a single output object or an array of output objects.\nmosaicking (optional) -  defines input sample preparation, see mosaicking. Defaults to SIMPLE.\n\n\nInput object properties\n\nbands - an array of strings representing band names\nunits (optional) - a string (all bands will use this unit) or an array of strings listing the units of each band. For a description of units see the documentation of the collection you are querying. Defaults to the default units for each band.\nmetadata (optional) - an array of strings representing properties which can be added to the metadata. Options:\n\n\"bounds\" - specifying this will add dataGeomtery and dataEnvelope to tiles\n\n\n\n\nOutput object properties\n\nid (optional) - any string of your choosing. Must be unique if multiple output objects are defined. Defaults to default.\nbands - the number of bands in this output.\nsampleType (optional) - sets the SampleType constant defining the returned raster sample type. Defaults to AUTO.\nnodataValue (optional) - sets the GDAL nodata metadata tag to the specified value. Only applicable for tiff files.\n\nNote that the number of bands represent the number of components in the output image. JPEG and PNG, for example, can only support 1 or 3 color components (plus an alpha channel for PNG, if set). The sampleType also needs to be compatible with the output raster format.\n\n\nMosaicking\nMosaicking defines how the source data is mosaicked. Not all collections support all these mosaicking types as it depends on how the source data is distributed. See the collection information pages to determine which ones are supported. It is a constant which is specified by a string. To use, for example, set: mosaicking: \"SIMPLE\".\n\nSIMPLE (default) - the simplest method, it flattens the mosaicked image so only a single sample is passed to evaluation. \nORBIT - the mosaicked image is flattened for each orbit so that there is only one sample per pixel per orbit. Multiple samples can therefore be present if there is more than one orbit for the selected time range at the pixel location.\nTILE - this is essentially the unflattened mosaic. It contains all data available for the selected time range. Multiple samples can be present as each sample comes from a single scene. What a scene is is defined by the datasource. \n\n\n\n\n\n\n\nNote\n\n\n\nORBIT mosaicking currently does not work exactly as described but generates a single scene for each day containing satellite data. For most requests this should not be an issue, however high latitude regions may have more than one acquisition per day. For these consider using TILE mosaicking if getting all available data is paramount. This will be corrected in future releases.\n\n\n\n\nSampleType\nSampleType defines the sample type of the output raster. This needs to be compatible with the raster format (e.g. JPEG cannot be FLOAT32). It is a constant which is specified by a string. To use, for example, set: sampleType: \"AUTO\".\n\nINT8 - signed 8-bit integer (values should range from -128 to 127)\nUINT8 - unsigned 8-bit integer (values should range from 0 to 255)\nINT16 - signed 16-bit integer (values should range from -32768 to\n\n\n\nUINT16 - unsigned 16-bit integer (values should range from 0 to\n\n\n\nFLOAT32 - 32-bit floating point (values have effectively no limits)\nAUTO (default) - values should range from 0-1, which will then automatically be stretched from the interval [0, 1] to [0, 255] and written into an UINT8 raster. Values below 0 and above 1 will be clamped to 0 and 255, respectively. This is the default if sampleType is not set in the output object.\n\nHandling SampleType in an Evalscript\nIt is the responsibility of the evalscript to return the values in the interval expected for the chosen sampleType. For integer SampleTypes, any floating point values will be rounded to the nearest integer and clamped to the value range of the SampleType. There is no need to do this yourself. For example, in case of UINT8 output, a value of 40.6 will be saved as 41, and a value of 310 will be saved as 255. If no sampleType is specified, AUTO is selected and the evalscript should return values ranging from 0-1. This is convenient as handling reflectance (e.g. Sentinel-2) data can be more intuitive.\n\n\n\nExamples\nThis simple Sentinel-2 setup() function gets bands B02, B03, B04 and returns (UINT16) 16 bit unsigned raster values.\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"B02\", \"B03\", \"B04\"], // this sets which bands to use\n      units: \"DN\" // here we optionally set the units. All bands will be in this unit (in this case Digital numbers)\n    }],\n    output: { // this defines the output image type\n      bands: 3, // the output of this evalscript will have RGB colors\n      sampleType: \"UINT16\" // raster format will be UINT16\n    }\n  };\n}\nThis Sentinel-2 setup() function gets bands B02, B03, B04 and returns a single raster with 8-bit integer values. To return values in the correct interval for the UINT8 sampleType, the evaluatePixel() function multiplies the reflectance values by 255. A true color image is returned.\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"B02\", \"B03\", \"B04\"], // this sets which bands to use\n    }],\n    output: {\n      bands: 3,\n      sampleType: \"UINT8\" // raster format will be UINT8\n    }\n  };\n}\nfunction evaluatePixel(sample) {\n  return [sample.B04 * 255, sample.B03 * 255, sample.B02 * 255]; // bands need to be multiplied by 255\n}\nIn case of UINT16, the multiplication factor in evaluatePixel() would be 65535 instead of 255.\nThe following example uses bands with different units and produces two rasters:\nfunction setup() {\n    return {\n      input: [{\n          bands: [\"B02\", \"B03\", \"B04\", \"B08\"],\n          units: [\"reflectance\", \"reflectance\", \"reflectance\", \"DN\"] // B08 will be in digital numbers, the rest reflectance\n      }],\n      output: [{ // this is now an array since there are multiple output objects\n          id: \"rgb\"\n          bands: 3\n      }, {\n          id: \"falseColor\"\n          bands: 3\n      }]\n    }\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#evaluatepixel-function",
    "href": "APIs/SentinelHub/Evalscript/V3.html#evaluatepixel-function",
    "title": "Evalscript V3",
    "section": "evaluatePixel function",
    "text": "evaluatePixel function\nThe evaluatePixel function is a mapping which maps the input bands in their input units to the values in the output raster(s). The function is executed once for each output pixel.\n\nParameters\nThe evaluatePixel function has five positional parameters:\nfunction evaluatePixel(samples, scenes, inputMetadata, customData, outputMetadata)\nThe first two parameters can be objects or arrays depending on requested mosaicking as explained below. They are additionally changed for data fusion requests, which is documented separately here. The remaining parameters are always objects.\n\nsamples\n\nWhen mosaicking is SIMPLE:\n\nsamples - an object containing the band values of the single mosaicked sample, in the specified units, as its properties. The property names equal the names of all the input bands, pixel values of a band can be accessed as e.g. samples.B02.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen using mosaicking SIMPLE we usually call this parameter sample in our examples to emphasize that it is an object and not an array.\n\n\n\nWhen mosaicking is TILE or ORBIT:\n\nsamples - an array of samples as defined in the SIMPLE case. None1, one or multiple samples can therefore be present depending on how many orbits/tiles there are for the selected time range and area of interest. Pixel values of a band can be accessed for each sample as an item of the array, e.g. samples[0].B02.\n\n\n\n\nscenes\n\nWhen mosaicking is SIMPLE:\n\nscenes object is empty.\n\nWhen mosaicking is ORBIT:\n\nscenes - an object containing a property orbits. scenes.orbits is an array of objects, where each of them contains metadata for one orbit (day). The length of scenes.orbits array is always the same as the length of samples array. A property, for example dateFrom, can be accessed as scenes.orbits[0].dateFrom. Each object's properties include:\n\ndateFrom (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. Together with orbits.dateTo it represents the time interval of one day. All tiles acquired on this day are mosaicked into this scene.\ndateTo (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. Together with orbits.dateFrom it represents the time interval of one day. All tiles acquired on this day are mosaicked into this scene.\ntiles (array) - an array of metadata for each tile used for mosaicking of this orbit. Each element has the same properties as elements of scenes.tiles (listed just below for mosaicking TILE).\n\n\nWhen mosaicking is TILE:\n\nscenes - an object containing a property tiles. scenes.tiles is an array of objects, where each of them contains metadata for one tile. The length of scenes.tiles array is always the same as the length of samples array. A property, for example cloudCoverage, can be accessed as scenes.tiles[0].cloudCoverage. Which properties are available for each tiles element depends on requested data and is documented in the \"Scenes Object\" chapter for each data collection, e.g. here for Sentinel-2 L1C. All possible properties are:\n\ndate (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. It represents a date when the tile was acquired.\ncloudCoverage (number) - Estimated percentage of pixels covered by clouds in the tile. This field is not available for all data collections. A value 2.09 means that 2.09% of pixels in the tile are cloudy.\ndataPath (string) - Path to where the tile is stored on a cloud. For example \"s3://sentinel-s2-l2a/tiles/33/T/VM/2020/9/15/0\".\ntileOriginalId (string) - Original filename of the tile or (in case of Sentinel-3 and -5p) a relative path containing the original filename. For example \"S2A_OPER_MSI_L2A_TL_VGS2_20200915T130644_A027332_T33TVM_N02.14\".\ndataGeometry (geojson - like object, see example) - an optional property, added only when requested. Represents a geometry of data coverage within the tile.\ndataEnvelope (geojson - like object, see example) - an optional property, added only when requested. Represents a bbox of dataGeometry.\nshId (number) - Sentinel Hub internal identifier of the tile. For example 11583048.\n\n\n\nNOTE 1: Objects may contain also fields prefixed by __ (double underscore). Such fields are used internally by Sentinel Hub services. Evalscripts should not make use of them because they can be changed or removed at any time and must never modify or delete such fields. Doing so may cause your request to fail or return incorrect results.\nNOTE 2: In the first implementation, scenes was an array of objects, where each of them contained metadata for one orbit or tile (depending on selected mosaicking). It was possible to access metadata as e.g. scenes[0].date. This approach is now deprecated and we strongly advise to use scenes as described above.\n\n\ninputMetadata\ninputMetadata is an object containing metadata used for processing by Sentinel Hub. Its properties are:\n\nserviceVersion - the version of Sentinel Hub which was used for processing.\nnormalizationFactor - the factor used by Sentinel Hub to convert digital numbers (DN) to reflectance using REFLECTANCE = DN * normalizationFactor. This is useful when requesting bands for which both units - DN and REFLECTANCE - are supported.\n\n\n\ncustomData\ncustomData is an object reserved for possible future use.\n\n\noutputMetadata\noutputMetadata is an object which can be used to output any user defined metadata including passing scenes objects, user defined thresholds or ids of original tiles used for processing. It contains:\n\nuserData - is a property to which you can assign a generic object that can contain any data. This can be pushed to the API response by adding a userdata identified output response object to your API request (see this for details or an example here).\n\n\n\n\nReturns\nThe evaluatePixel function can return:\n\nAn object whose keys are the output ids and its values are arrays of numbers. The length of the array is bound by the output object bands number and the values by sampleType.\nAn array of numbers with the same rules as above. This option can be used only when a single image output is defined.\nNothing; the return statement is not specified. This is useful when only information in outputMetadata.userData is needed.\n\n\nInput Units and Output Values\nThe values of each sample is the units specified in the input object. See the input object documentation for more information. How the output values are written to the output raster depends on the sample type. AUTO will stretch values in the interval [0, 1] to [0, 255] and then write those values into an UINT8 raster. The remaining sample types expect values within the range of the sample format.\n\n\n\nExamples\nExample evaluatePixel script returns a simple True Color image based on bands B04, B03, B02:\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02];\n}\nWhen we have multiple outputs in the setup function we can provide them as such:\nfunction evaluatePixel(sample) {\n  return {\n    trueColor: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n    falseColor: [2.5 * sample.B08, 2.5 * sample.B04, 2.5 * sample.B03]\n  };\n}\nCalculate the average value of band B04 when using ORBIT or TILE mosaicking:\nfunction evaluatePixel(samples) {\n  var sum = 0;\n  var nonZeroSamples = 0;\n  for (var i = 0; i &lt; samples.length; i++) {\n    var value = samples[i].B04;\n    if (value != 0) {\n      sum += value;\n      nonZeroSamples++;\n    }\n  }\n  return [sum / nonZeroSamples];\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#updateoutput-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#updateoutput-function-optional",
    "title": "Evalscript V3",
    "section": "updateOutput function (optional)",
    "text": "updateOutput function (optional)\nThis function can be used to adjust the number of output bands. This is useful, for example, to request all observations in a given time period as bands of an output file. The function is executed after the setup and preProcessScenes functions but before the evaluatePixel.\n\nParameters\n\noutput - an object containing ids of all outputs and their number of bands as specified in the setup function (Note: This is not the same object as output in the setup function.). The number of bands of each output is stored under output.&lt;output id&gt;.bands where &lt;output id&gt; is equal to values in the setup.output object. For example:\n\n{\n    \"default\": {\n        \"bands\": 2\n    },\n    \"my_output\": {\n        \"bands\": 3\n    }\n}\n\ncollection - an object containing one array per requested data collection. The length of each array equals the number of scenes available for processing. If only one data collection is requested, use collection.scenes.length to get the number of available scenes. For data fusion requests, use collection.&lt;data collection identifier&gt;.scenes.length. Each element in an array has a property:\n\ndate (type Date) - the date when the corresponding scene was acquired.\n\n\n\n\nReturns\nThis function updates the number of output bands and does not return anything.\n\n\nExample\nSuppose we request sentinel-2-l1c data from January 2020 with a maximum of 50% cloud coverage. All of this is specified in the body of a request. We would then like to return all available scenes as bands of an output file. Since we generally do not know how many scenes are available, we can not set the number of output bands directly in a setup function. Using the updateOutput function we can get the number of available scenes from collection and assign it as the value of output.&lt;output id&gt;.bands:\n//VERSION=3\nfunction setup() {\n    return {\n        input: [{\n                bands: [\"B02\"],\n            }\n        ],\n        output: [{\n                id: \"my_output\",\n                bands: 1,\n                sampleType: SampleType.UINT16\n            }\n        ],\n        mosaicking: Mosaicking.ORBIT\n    }\n}\n\nfunction updateOutput(output, collection) {\n    output.my_output.bands = collection.scenes.length\n}\n\nfunction evaluatePixel(samples) {\n    var n_scenes = samples.length\n    let band_b02 = new Array(n_scenes)\n\n    // Arrange values of band B02 in an array\n    for (var i = 0; i &lt; n_scenes; i++){\n        band_b02[i] = samples[i].B02\n    }\n\n    return {\n        my_output: band_b02\n    }\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#updateoutputmetadata-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#updateoutputmetadata-function-optional",
    "title": "Evalscript V3",
    "section": "updateOutputMetadata function (optional)",
    "text": "updateOutputMetadata function (optional)\nThis function is optional and if present is called at the end of evalscript evaluation. It provides a convenient way to forward information pertaining to the returned data as a whole (as opposed to evaluatePixel which is run for each pixel) into an output object. Do this by assigning any object you require to the userData property of the outputMetadata parameter.\n\nParameters\nThese are the full parameters of the updateOutputMetadata function:\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata)\nSee description of parameters in the \"evaluatePixel function\" chapter:\n\nscenes - scenes\ninputMetadata - inputMetadata\noutputMetadata - outputMetadata"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#preprocessscenes-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#preprocessscenes-function-optional",
    "title": "Evalscript V3",
    "section": "preProcessScenes function (optional)",
    "text": "preProcessScenes function (optional)\n\n\n\n\n\n\nNote\n\n\n\nThis function shall be used instead of filterScenes function.\n\n\nThis function is optional, and if present is called at the beginning of the script evaluation before the actual satellite data is processed. Use it when mosaicking is set to ORBIT or TILE. It provides additional filtering functionality for scenes, after the constraints set in the request parameters are already applied. This is useful, for example, to reduce the number of scenes needed, thereby reducing processing time and the number of processing units for the request.\n\nParameters\nThese are the full parameters of the preProcessScenes function:\nfunction preProcessScenes(collections)\n\ncollections\ncollections is an object, which contains different properties depending on which mosaicking option is selected.\n\nIf mosaicking is ORBIT, collections contains:\n\nfrom (type Date) - the value given as timeRange.from in the body of the request, representing the start of the search interval\nto (type Date) - the value given as timeRange.to in the body of the request, representing the end of the search interval\nscenes.orbits - corresponds to scenes.orbits as described for evalautePixel function and mosaicking ORBIT here but it doesn't contain tiles.\n\nIf mosaicking is TILE, collections contains:\n\nscenes.tiles - corresponds to scenes.tiles as described for evalautePixel function and mosaicking TILE here.\n\n\n\n\n\nReturns\nThe preProcessScenes function must return an objects of the same type as collections. Most often, a sub-set of the input collections will be returned, e.g. to keep only the data acquired before 1.2.2019:\nfunction preProcessScenes(collections){\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (scene) {\n        return new Date(scene.dateFrom) &lt; new Date(\"2019-02-01T00:00:00Z\")\n    });\n    return collections\n}\n\n\nExamples\n\nFilter scenes by particular days\nIn this example, we use preProcessScenes function to select images acquired on two particular dates within the requested timeRange. This example was taken (and adopted) from the evalscript for delineation of burned areas, based on the comparison of Sentinel-2 images acquired before (i.e. on \"2017-05-15\") and after (i.e. on \"2017-06-24\") the event.\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    var allowedDates = [\"2017-05-15\", \"2017-06-24\"]; //before and after Knysna fires\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var orbitDateFrom = orbit.dateFrom.split(\"T\")[0];\n        return allowedDates.includes(orbitDateFrom);\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    var allowedDates = [\"2017-05-15\", \"2017-06-24\"]; //before and after Knysna fires\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (tile) {\n        var tileDate = tile.date.split(\"T\")[0];\n        return allowedDates.includes(tileDate);\n    })\n    return collections\n}\n\n\n\nFilter scenes by time interval\nHere, we filter out (= remove) all the scenes acquired between the two selected dates, which both fall within the requested time range.\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        return (new Date(orbit.dateFrom) &lt; new Date(\"2019-01-31T00:00:00Z\")) ||\n               (new Date(orbit.dateFrom) &gt;= new Date(\"2019-06-01T00:00:00Z\"))\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (tile) {\n        return (new Date(tile.date) &lt; new Date(\"2019-01-31T00:00:00Z\")) ||\n               (new Date(tile.date) &gt;= new Date(\"2019-06-01T00:00:00Z\"))\n    })\n    return collections\n}\n\n\n\nSpecify the number of months taken into account\nValues of timeRange.from and timeRange.to parameters as given in the request, are available in the preProcessScenes function as collections.to and collections.from, respectively. Mosaicking must be ORBIT to use these parameters. They can be used to e.g. filter out scenes acquired more than 3 months before the given to date and time.\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var orbitDateFrom = new Date(orbit.dateFrom)\n        return orbitDateFrom.getTime() &gt;= (collections.to.getTime()-3*31*24*3600*1000);\n    })\n    return collections\n}\nThe 3*31*24*3600*1000 represents the 3 months converted to milliseconds. This is needed, so that a 3-month time span can be compared to scene.dateFrom and collections.to, which are all returned as milliseconds since 1970-1-1 by the getTime() function. Note: The result is the same as if the timeRange.from parameter in the body of the request is set to 3 months prior to the timeRange.to.\n\n\nSelect one image per month\nIn this example, we filter the available scenes, so that only the first scene acquired in each month is sent to the evaluatePixel function:\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits.sort(function (s1, s2) {\n            var date1 = new Date(s1.dateFrom);\n            var date2 = new Date(s2.dateFrom);\n            return date1 - date2}) // sort the scenes by dateFrom in ascending order\n\n    firstOrbitDate = new Date(collections.scenes.orbits[0].dateFrom)\n    var previousOrbitMonth = firstOrbitDate.getMonth() - 1\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var currentOrbitDate = new Date(orbit.dateFrom)\n        if (currentOrbitDate.getMonth() != previousOrbitMonth){\n            previousOrbitMonth = currentOrbitDate.getMonth();\n            return true;\n        } else return false;\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    collections.scenes.tiles.sort(function (s1, s2) {\n            var date1 = new Date(s1.date);\n            var date2 = new Date(s2.date);\n            return date1 - date2}) // sort the scenes by dateFrom in ascending order\n\n    firstTileDate = new Date(collections.scenes.tiles[0].date)\n    var previousTileMonth = firstTileDate.getMonth() - 1\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (scene) {\n        var currentTileDate = new Date(scene.date)\n        if (currentTileDate.getMonth() != previousTileMonth){\n            previousTileMonth = currentTileDate.getMonth();\n            return true;\n        } else return false;\n    })\n    return collections\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#ogc-services-specifics",
    "href": "APIs/SentinelHub/Evalscript/V3.html#ogc-services-specifics",
    "title": "Evalscript V3",
    "section": "OGC services specifics",
    "text": "OGC services specifics\nThere are some specifics when using evalscript V3 with WMS, WTS, WCS services:\n\nThese services return only the default output. Only one image can be returned with each request and it is not possible to request metadata in JSON format.\nTRANSPARENCY and BGCOLOR parameters are ignored. You can use dataMask band in evalscript V3 to handle transparency, as described here.\nBit depth, which is given as the part of a FORMAT parameter (e.g. FORMAT=image/tiff;depth=8) is ignored. You can use sampleType in evalscript V3 to request the bit depth of your choice."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#footnotes",
    "href": "APIs/SentinelHub/Evalscript/V3.html#footnotes",
    "title": "Evalscript V3",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn case samples is an empty array, calling samples[0].B02 will raise an error and it is up to users to handle this in their evalscript.↩︎"
  },
  {
    "objectID": "APIs/SentinelHub/Byoc/Examples.html",
    "href": "APIs/SentinelHub/Byoc/Examples.html",
    "title": "BYOC API examples",
    "section": "",
    "text": "The following API requests are written in Python. To execute them, you need to create an OAuth client as is explained here. The client is named oauth in these examples. The examples are structured in a way to be as separable as possible, however in many cases doing all the steps in each chapter makes sense.\n\nCreating a collection\nTo create a collection with the name &lt;MyCollection&gt; and S3 bucket &lt;MyBucket&gt;:\ncollection = {\n  'name': '&lt;MyCollection&gt;',\n  's3Bucket': '&lt;MyBucket&gt;'\n}\n\nresponse = oauth.post('https://sh.dataspace.copernicus.eu/api/v1/byoc/collections', json=collection)\nresponse.raise_for_status()\nExtracting the collection id from the response:\nimport json\n\ncollection = json.loads(response.text)['data']\ncollection_id = collection['id']\n\n\nCreating a tile\nTo create a tile with the path &lt;MyTile&gt;:\ntile = {\n  'path': '&lt;MyTile&gt;',\n}\n\nresponse = oauth.post(f'https://sh.dataspace.copernicus.eu/api/v1/byoc/collections/{collection_id}/tiles', json=tile)\nresponse.raise_for_status()\nIf your tile has a known sensing time, e.g. October 21, 2019 at 14:51 by UTC time, add this information by using the following payload:\ntile = {\n  'path': '&lt;MyTile&gt;',\n  'sensingTime': '2019-10-21T14:51:00Z'\n}\nIf you want to provide a cover geometry, set it as the value of the coverGeometry field:\ntile = {\n  'path': '&lt;MyTile&gt;',\n  'coverGeometry': &lt;MyCoverGeometry&gt;\n}\nFor information on how to prepare a cover geometry, see Preparing a cover geometry.\nTo extract the tile id from the response:\nimport json\n\ntile = json.loads(response.text)['data']\ntile_id = tile['id']\n\n\nPreparing a cover geometry\nTo obtain a cover geometry automatically, you can use the gdal_trace_outline script which gives you a cover geometry in the WKT format:\nimport subprocess\n\ncommand = f'gdal_trace_outline &lt;MyCOG&gt; -out-cs en -wkt-out wkt.txt'\nsubprocess.run(command, shell=True, check=True)\nOnce complete, transform the geometry into the GeoJSON format:\nfrom osgeo import ogr\nimport json\n\nf = open('wkt.txt')\ngeom = ogr.CreateGeometryFromWkt(f.read())\ncover_geometry = json.loads(geom.ExportToJson())\nIf the CRS is something other than WGS84, make sure to set its URN &lt;CrsUrn&gt; under crs.properties.name. For example urn:ogc:def:crs:EPSG::32633 for EPSG:32633.\ncover_geometry['crs'] = {\n  'properties': {\n    'name': '&lt;CrsUrn&gt;'\n  }\n}\nTo obtain the URN automatically from a raster file you can use the following Python scriptget_crn_urn.py.\n\n\nChecking the tile ingestion status\nTo check the ingestion status of the tile, first get the tile:\nresponse = oauth.get(f'https://sh.dataspace.copernicus.eu/api/v1/byoc/collections/{collection_id}/tiles/{tile_id}')\nresponse.raise_for_status()\nThen extract its status from the response:\nimport json\n\ntile = json.loads(response.text)['data']\nstatus = tile['status']\n\nif status == 'INGESTED':\n  print('Tile ingested')\nelif status == 'FAILED':\n  print('Tile failed to ingest')\nelse:\n  print(status)\nTo check why a tile failed to ingest:\nprint(tile['additionalData']['failedIngestionCause'])\n\n\nListing tiles\nTiles are paginated and to traverse all pages use the link from response that points to the next page, which is located at links.next. By default, you get back 100 tiles per page, but you can change this using the query parameter count, however it cannot be more than 100.\nimport time\n\nurl = f'https://sh.dataspace.copernicus.eu/api/v1/byoc/collections/{collection_id}/tiles'\n\nwhile url is not None:\n  response = oauth.get(url)\n  response.raise_for_status()\n\n  output = response.json()\n  tiles = output['data']\n  links = output['links']\n\n  for tile in tiles:\n    print(tile['path'])\n\n  # sets url to None if there's no link to the next set of tiles\n  url = links.get('next', None)\n\n  # waits a bit before fetching the next set\n  time.sleep(0.1)"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript.html",
    "href": "APIs/SentinelHub/Evalscript.html",
    "title": "Evalscript (custom script)",
    "section": "",
    "text": "An evalscript (or \"custom script\") is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return. It is a required part of any process, batch processing or OGC request.\nEvalscripts can use any JavaScript function or language structures, along with certain utility functions we provide for your convenience. For running evalscripts we use the Chrome V8 JavaScript engine.\nIn the Evalscript V3 section you will find a technical documentation with detailed explanations of parameters and functions you can use in your evalscripts.\n\nExamples\nExamples of various evalscritps can be found on our Custom Scripts Repository.\n\n\nTutorials and Other Related Materials\n\nA PDF tutorial on writing simple evalscripts for beginners: Custom scripts tutorial\nA webinar on writing evalscripts for beginners: Custom Scripts, September 28, 2020\nA webinar on multi-temporal scripts and data fusion: Multi-temporal Scripts and Data Fusion, March 3, 2021\nA blog on good scripting practices: Custom Scripts: Faster, Cheaper, Better!, November 18, 2019\nA blog post on color maps: PUCK - Perceptually Uniform Color Maps in Satellite Imagery, January 28, 2021\nA blog post on sampleType: SampleType: what’s all the fuss about?, February 15, 2022\nMore blog posts and useful links can be found on our Sentinel Hub website."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/RateLimiting.html",
    "href": "APIs/SentinelHub/Overview/RateLimiting.html",
    "title": "Rate limiting",
    "section": "",
    "text": "In order to ensure the stability of the system and to guarantee good performance for all users we have to protect it against deliberate attacks or runaway scripts. Every request which reaches our system will therefore go through a rate limiting filter. As long as the agreed upon rate limiting policies are conformed to, responses by our services shall be delivered in timely fashion. On the other hand, requests which violate any of the agreed upon policies will be responded to with a HTTP 429 response.\nWe are able to adjust rate limit policies for each individual user so do contact our Support for specific requirements.\n\nRate limiting policy\nA rate limiting policy defines either how many processing units or HTTP requests can be used per given time period or in total. Both processing units and requests are rate limited and the level of rate limiting depends on your account (see pricing plans).\nAn API is usually protected by multiple rate limiting policies. For example, Processing API has both a processing unit and request rate limiting policies. To conform to the rate limiter, all rate limiting policies have to be satisfied. For example, lets say you have a policy of 100 requests per minute and a policy of 100 processing units per minute. By issuing 100 requests from each every request is valued at 2 processing units in one minute, only 50 requests will pass, all others will fail with HTTP status 429. Even though you have a limit of 100 requests per minute, 50 requests would violate the 100 processing units per minute policy and thus be rate limited.\nUnused processing units and requests do not accumulate. If you have a rate limit policy with 100 request per minute and you don't consume any request for a longer period you are still able to do just 100 requests within the next minute.\n\n\nRate limiting ramp up\nFor all SH subscriptions, the rate limiting is configured also on a \"per minute\" basis (i.e. 600 requests per minute and 1000 processing units per minute for the Enterprise S subscription). For optimal performance, it is best to spread this number of requests over a whole minute, i.e. to send one request every 0.1 seconds. As we understand that this might be difficult to do, we allow some variation from this optimum. However, if you will burst the full number of requests at once, some of them will be rate limited. For such requests, we recommend that you simply resend them - the process should reach the optimal level in a few minutes.\n\n\nResponse Headers\nAll requests going through rate limiting include headers to allow for programmatic adaption to Rate Limiting:\n\nRetry-After: Time in milliseconds until the next request is available.\n\n\nExample:\n\nResponse code and message\n{\n  \"status\": 429,\n  \"reason\": \"Too Many Requests\",\n  \"message\": \"You have exceeded your rate limit\",\n  \"code\": \"RATE_LIMIT_EXCEEDED\"\n}\n\n\nResponse header\n{\n  \"Date\": \"Tue, 16 Aug 2022 13:15:02 GMT\",\n  \"retry-after\": \"3398\",\n  ...\n}\nThe HTTP status code in this example is 429 meaning that the request was rate limited. The value of the Retry-After header is 3398, which means that next request will be available in 3398 ms.\n\n\n\n\nTry it out\nWe have set up a test user with two very restrictive rate limiting policies:\n\n10 requests per minute and\n10 processing units per minute\n\nYou can use its instance (for OGC requests) or Oauth client credentials (for API requests) to test how our rate limiting works and for integration purposes.\nAn example of a WMS request using the test user's instance:\n\n[https://services.sentinel-hub.com/ogc/wms/7702fda8-f583-4ae0-a581-1b34e7a6d350](https://services.sentinel-hub.com/ogc/wms/7702fda8-f583-4ae0-a581-1b34e7a6d350){target=“_blank”}?\n\nThe test user's Oauth client credentials below can be used to get an access token, which can then be included in header of a process API requests (for examples of requests see here):\n\nClient id: fa02a066-fc80-4cb4-af26-aae0af26cbf1 Client secret: rate_limit_secret\n\nNote that many people may be using it at the same moment so there is a chance that it will be over the limit more or less all the time. Its purpose is to evaluate response headers anyway.\n\n\nTips to Avoid Being Rate Limited\n\nCaching\nStore API responses that you expect to use a lot. For example, don’t call same requests on every page load but try to store responses in local storage.\n\n\nRequest only what you need\nBe defensive in fetching and try to request only the data that you actually need.\n\n\nExponential backoff\nWhen your limits have been exceeded, we recommend implementing retries with a exponential backoff. An exponential backoff means that you wait for exponentially longer intervals between each retry of a single failing request."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html",
    "title": "Processing Unit definition",
    "section": "",
    "text": "⚠ Costs marked with ** are not yet applied. These will come in effect by September 1st 2023."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#general-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#general-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "title": "Processing Unit definition",
    "section": "General data processing - applicable to Process API, OGC API, Statistical API",
    "text": "General data processing - applicable to Process API, OGC API, Statistical API\nEach request costs a proportional amount of processing unit(s), depending on what data and processing is requested. One processing unit (PU) is defined as a request for:\n\nan output (image) size of 512 x 512 pixels,\n3 collection input bands,\none data sample per pixel (see sample),\nan output (image) format not exceeding 16 bits per pixel,\nwithout additional processing (e.g. orthorectification) applied,\n\nIn addition to this:\n\nMinimal cost of a request is\n\n0.005 PU for Process API and OGC API,\n0.01 PU for Statistical API.\n\nThe number of remaining processing units is reduced only when a request successfully executes, i.e. when the response code is 2XX.\n\n\"Multiplication factors\" are used to calculate how many processing units are required for each request. The definition of 1 processing unit and the calculation rules are summarized in the following tables:\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\nArea of interest\n512 x 512 px\nThe multiplication factor is calculated by dividing requested input size (BBOX) by 512 x 512 (pixel size depends on the user-defined resolution of the request execution).  The minimum value of this multiplication factor is 0.01. This corresponds to an area of 0.25 km^2 for Sentinel-2 data at 10 m spatial resolution.\n\n\nNumber of input bands\n3\nThe multiplication factor is calculated by dividing the requested number of input bands by 3. An exception is requesting dataMask which is not counted, unless it is the only band included.\n\n\nOutput format\n8 bit or 16 bit TIFF/JPG/PNG\nRequesting 32 bit float TIFF will result in a multiplication factor of 2 due to larger memory consumption and data traffic.  Requesting application/octet-stream will result in a multiplication factor of 1.4 due to additional integration costs (This is used for integration with external tools such as xcube.).\n\n\nNumber of data samples\n1\nThe multiplication factor equals the number of data samples per pixel.\n\n\nData fusion\nN/A\nThe multiplication is only applied when data fusion is used. Multiplication factor is calculated as a sum of all collections within the same endpoint location and twice the sum of all remote collections, i.e. count(local_collections) + 2x count(remote_collections). Example: data fusion request executed on services.sentinel-hub.com endpoint, which includes Sentinel-2 L1C, Sentinel-2 L2A and Landsat-9 would have a multiplication factor of 4 (1 + 1 + 2)."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#sentinel-1-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#sentinel-1-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "title": "Processing Unit definition",
    "section": "Sentinel-1 data processing - applicable to Process API, OGC API, Statistical API",
    "text": "Sentinel-1 data processing - applicable to Process API, OGC API, Statistical API\nIn addition to General data processing rules defined above, the following optional multiplicators apply as well:\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\nOrthorectification\nN/A\nRequesting orthorectification will result in a multiplication factor of 2 due to additional processing requirements .\n\n\nRadiometric Terrain Correction\nN/A\nRequesting radiometric terrain correction will result in a multiplication factor of 2.5 due to additional processing requirements. The orthorectification factor is not additionally applied as it is a prerequisite.\n\n\nSpeckle Filtering\nN/A\nRequesting speckle filtering will result in a multiplication factor of 2 due to additional processing requirements."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-querying---applicable-to-catalog-api-ogc-wfs",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-querying---applicable-to-catalog-api-ogc-wfs",
    "title": "Processing Unit definition",
    "section": "Data querying - applicable to Catalog API, OGC WFS",
    "text": "Data querying - applicable to Catalog API, OGC WFS\nEach request costs a proportional amount of processing unit(s) depending on what data and processing is requested. One processing unit (PU) is defined as a request for:\n\narea of 1000 x 1000 km\ntime period up to one month\n\nIn addition to this:\n\nMinimal cost of a request is 0.01 PU.\nMaximal cost of a request is 1 PU.\nThe number of remaining processing units is reduced only when a request successfully executes, i.e. when the response code is 2XX.\n\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\nArea of interest\n1 000 000 km2\nThe multiplication factor is calculated by dividing requested input area of interest (BBOX) by 1 000 000.The minimum value of this multiplication factor is 0.01. This corresponds to an area of 10 000 km2\n\n\nTime period\n1 month\nThe multiplication factor is calculated by ceiling requested time period in months."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-processing-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-processing-api",
    "title": "Processing Unit definition",
    "section": "Batch Processing API",
    "text": "Batch Processing API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\nMinimal cost of a request is 100 PU.\nProcessing with batch processing API will result in a multiplication factor of 1/3. Thus, three times more data can be processed comparing to process API for the same amount of PUs.\n** When data is delivered to a bucket in other region within the same system (i.e. CDAS, AWS) there is additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#asynchronous-processing-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#asynchronous-processing-api",
    "title": "Processing Unit definition",
    "section": "Asynchronous Processing API",
    "text": "Asynchronous Processing API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\nMinimal cost of a request is 10 PU.\n** When data is delivered to a bucket in other region within the same system (i.e. CDAS, AWS) there is an additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-statistical-api",
    "title": "Processing Unit definition",
    "section": "Batch Statistical API",
    "text": "Batch Statistical API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\nMinimal cost of a request is 100 PU.\n** When data is delivered to a bucket in other region within the same system (i.e. CDAS, AWS) there is an additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#third-party-data-order---applicable-to-third-party-data-import-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#third-party-data-order---applicable-to-third-party-data-import-api",
    "title": "Processing Unit definition",
    "section": "Third party data order - applicable to Third Party Data Import API",
    "text": "Third party data order - applicable to Third Party Data Import API\n\n** Each search request costs 1 PU.\n** Each thumbnail request costs 1 PU.\n** Each created order/subscription costs 5 PU.\n** Each processed order delivery costs 5 PU.\n** Each processed subscription delivery costs 2 PU."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-ingestion---applicable-to-bring-your-own-cog-api-and-zarr-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-ingestion---applicable-to-bring-your-own-cog-api-and-zarr-api",
    "title": "Processing Unit definition",
    "section": "Data ingestion - applicable to Bring your own COG API and Zarr API",
    "text": "Data ingestion - applicable to Bring your own COG API and Zarr API\n\nEach request to BYOC or Zarr API costs 1 PU.\nUsage of your BYOC and Zarr collections is billed the same as usage of public collections."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#request-cost-calculation-examples",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#request-cost-calculation-examples",
    "title": "Processing Unit definition",
    "section": "Request cost calculation examples",
    "text": "Request cost calculation examples\n\nSentinel-1 change detection\nAn example of calculation of processing units for a Sentinel-1 change detection request (e.g. comparison of two time slices) is presented in the table below.\n\n\n\nParameter\nQuantity\nMultiplication factor\nDetails\n\n\n\n\nOutput size (width x height)\n1024 x 1024 px\nx 4\nThe requested output size is 1024 x 1024 px which is 4 times larger than the output size for one PU (512 x 512 px). Hence the multiplication factor is 4.\n\n\nNumber of input bands\n4\nx 4/3\n4 input bands are requested, which is 4/3 times more than 3 input bands, which are included in one PU. The multiplication factor is thus 4/3.\n\n\nOutput format\n32-bit float\nx 2\nThe requested 32 bit float TIFF has a multiplication factor of 2.\n\n\nNumber of data samples\n2\nx 2\n2 data samples (one for each time slice) were requested for each pixel. Thus the multiplication factor is 2.\n\n\nOrthorectification\nYes\nx 2\nOrtorectification is requested, which results in a multiplication factor of 2.\n\n\n\nTotal\n42.667 processing units\nTo calculate the number of processing units for this request multiply all the individual multiplication factors: 4 x 4/3 x 2 x 2 x 2 = 42.667\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nStatistical API is also a multi-temporal request. The same rules for calculating multiplication factors apply.\n\n\n\n\nNDVI calculation for a parcel\nAn example of calculation of processing units of NDVI value over a 4 hectare large parcel at 10 m spatial resolution is presented in the table below.\n\n\n\nParameter\nQuantity\nMultiplication factor\nDetails\n\n\n\n\nOutput size (width x height)\n20 x 20 px\nx 0.01\nThe requested output size is 20 x 20 px which is smaller than the minimum area, thus the multiplication factor is 0.01.\n\n\nNumber of input bands\n2\nx 2/3\n2 input bands are requested, thus the multiplication factor is 2/3.\n\n\nOutput format\n16-bit tiff\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\nNumber of data samples\n1\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\nOrthorectification\nNo\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\n\nTotal\n0.0067 processing units\nTo calculate the number of processing units for this request multiply all the individual multiplication factors:  0.01 x 2/3 x 1 x 1 = 0.0067"
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html",
    "href": "APIs/SentinelHub/Statistical.html",
    "title": "Statistical API",
    "section": "",
    "text": "The Statistical API (or shortly \"Stats API\") enables you to get statistics calculated based on satellite imagery without having to download images. In your Statistical API request, you can specify your area of interest, time period, evalscript and which statistical measures should be calculated. The requested statistics are returned in the API response. Using Statistical API you can calculate the percentage of cloudy pixels for a given area of interest and time period, or calculate mean, standard deviation, and histogram of band values for a parcel in a given time period. Find more examples here.\nTo familiarise yourself with the Statistical API, we recommend checking the Requests builder, our API reference and our Statistical API webinar."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#general-approach",
    "href": "APIs/SentinelHub/Statistical.html#general-approach",
    "title": "Statistical API",
    "section": "General approach",
    "text": "General approach\nBased on parameters specified by users in requests (e.g. area of interest, time range, evalscript) the Statistical API processes satellite data in a similar way as Processing API. Instead of returning images, it calculates requested statistics and returns the results in a json format."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#statistical-api-and-evalscript",
    "href": "APIs/SentinelHub/Statistical.html#statistical-api-and-evalscript",
    "title": "Statistical API",
    "section": "Statistical API and evalscript",
    "text": "Statistical API and evalscript\nAll general rules for building evalscripts apply. However, there are some specifics when using evalscripts with the Statistical API:\n\nThe evaluatePixel() function must, in addition to other output, always return also dataMask output. This output defines which pixels are excluded from calculations. For more details and an example, see here.\nThe default value of sampleType is FLOAT32.\nThe output.bands parameter in the setup() function can be an array. This makes it possible to specify custom names for the output bands and different output dataMask for different outputs, see this example."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#apis-features",
    "href": "APIs/SentinelHub/Statistical.html#apis-features",
    "title": "Statistical API",
    "section": "API's features",
    "text": "API's features\n\nSplit requested timeRange into multiple time intervals\nThe Statistical API supports requesting statistics for multiple time intervals with only one request. For example, requesting the aggregationInterval and timeRange as:\n...\n\"timeRange\": {\n    \"from\": \"2020-06-01T00:00:00Z\",\n    \"to\": \"2020-07-31T00:00:00Z\"\n    },\n\"aggregationInterval\": {\n    \"of\": \"P10D\"\n}\n...\nreturns the requested statistics calculated for multiple 10-day intervals, see this example. The aggregation intervals should be at least one day long (e.g. \"P5D\", \"P30D\"). You can only use period OR time designator not both.\nIf a timeRange is not divisible by an aggregationInterval, the last (\"not full\") time interval will be dismissed by default (SKIP option). The user can instead set the lastIntervalBehavior to SHORTEN (shortens the last interval so that it ends at the end of the provided time range) or EXTEND (extends the last interval over the end of the provided time range so that all the intervals are of equal duration).\nNote that the data is mosaicked for each of the time intervals (as defined with the mosaicking parameter in an evalscript) before the statistics are calculated. To calculate statistics over time (for example, the maximum NDVI value in a month), you should set mosaicking to ORBIT or TILE and calculate the required value in an evalscript, see this example. If you use mosaicking SIMPLE, one mosaicked output for each time interval is a basis for calculating statistics.\n\n\nHistogram\nRequesting histograms is optional. A variety of histogram customisations are available. Users can specify:\n\nnumber of bins nBins or\nwidth of bins binWidthor\narbitrary bins.\n\nThis example demonstrates all three options.\n\n\nPercentile calculations\nIt is possible to get values for any percentile. For example, to get values for 33%, 75%, and 90% percentile, add the \"percentiles\" parameter to your requests as:\n...\n{\n  \"percentiles\": {\n    \"k\": [33, 75, 90]\n  }\n}\n...\nSee also this example.\n\n\nExclude pixels from calculations (dataMask output)\nIt is possible to exclude certain pixels from the calculation of the statistics. The most common use cases are excluding no data and cloudy pixels.\nWith the Statistical API, this is achieved by defining a special output called \"dataMask\". This output should have value \"0\" assigned for the pixels that should be excluded from the calculations, and a value of \"1\" elsewhere. The values of the \"dataMask\" output are defined by the user in an evalscript. An illustrative example is excluding water pixels from statistics of NDVI, see this example.\nNote that the Statistical API does not automatically exclude the no data pixels from calculating the statistics. We recommend that you always exclude those unless there is a good reason not to. This is especially important when you are requesting statistics for a polygon, as it will ensure that pixels outside of the polygon (and inside of the bounding box) are excluded. To exclude no data pixels you need to pass input dataMask band to the dataMask output, e.g.:\nfunction evaluatePixel(samples) {\n    return {\n        ...,\n        dataMask: [samples.dataMask]\n        }\n}\nAll evalscripts in the examples here exclude no data pixels.\n\n\nMultiple outputs and multi bands outputs\nStatistics can be requested for multiple outputs. This is useful when we need to use different dataMasks or different sampleTypes for each output. Additionally, each output can have multiple bands. It is possible to request different statistics for each band and for each output. This example demonstrates how to do all this.\n\n\nExamples\nExamples of Statistical API\n\n\nTutorials and Other Related Materials\n\nTo get you started, we created a detailed beginner webinar on statistical API, where you can learn how to get statistics for your data, how to manipulate the evalscript to return several outputs, each with its own statistical information, how to make use of powerful aggregations, exclude pixels from the calculation, make custom histograms and visualize your statistics in Python."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical/Examples.html",
    "href": "APIs/SentinelHub/Statistical/Examples.html",
    "title": "Examples of Statistical API",
    "section": "",
    "text": "The requests below are written in Python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples. Jupyter notebook with all examples can be downloaded here.\n\nStatistics for one single-band output on a given day\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        },\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-04T00:00:00Z\",\n            \"to\": \"2020-07-05T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-04T00:00:00Z',\n    'to': '2020-07-05T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nStatistics, histogram and percentiles for one single-band output\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        },\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-04T00:00:00Z\",\n            \"to\": \"2020-07-05T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  },\n  \"calculations\": {\n    \"default\": {\n      \"histograms\": {\n        \"default\": {\n          \"nBins\": 5,\n          \"lowEdge\": 0.0,\n          \"highEdge\": 0.3\n        }\n      },\n      \"statistics\": {\n        \"default\": {\n          \"percentiles\": {\n            \"k\": [ 33, 50, 75, 90 ]\n          }\n        }\n      }\n    }\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-04T00:00:00Z',\n    'to': '2020-07-05T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.09709999710321426,\n         '50.0': 0.10360000282526016,\n         '75.0': 0.11940000206232071,\n         '90.0': 0.16040000319480896}},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.06, 'count': 0},\n         {'lowEdge': 0.06, 'highEdge': 0.12, 'count': 2458},\n         {'lowEdge': 0.12, 'highEdge': 0.18, 'count': 558},\n         {'lowEdge': 0.18, 'highEdge': 0.24, 'count': 177},\n         {'lowEdge': 0.24, 'highEdge': 0.3, 'count': 44}],\n        'overflowCount': 3,\n        'underflowCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nStatistics for one single-band output for two months with 10 days aggregation period\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-06-01T00:00:00Z\",\n            \"to\": \"2020-07-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P10D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-06-01T00:00:00Z',\n    'to': '2020-06-11T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.7892000079154968,\n        'max': 0.8303999900817871,\n        'mean': 0.804223583473102,\n        'stDev': 0.0067066009561434865,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-06-11T00:00:00Z', 'to': '2020-06-21T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.016300000250339508,\n        'max': 0.5956000089645386,\n        'mean': 0.06240126554233315,\n        'stDev': 0.06266500670629409,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-06-21T00:00:00Z', 'to': '2020-07-01T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.026000000536441803,\n        'max': 0.43799999356269836,\n        'mean': 0.06872379640174772,\n        'stDev': 0.056520330692016944,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-01T00:00:00Z', 'to': '2020-07-11T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-11T00:00:00Z', 'to': '2020-07-21T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.017400000244379044,\n        'max': 0.4187999963760376,\n        'mean': 0.062194598779473156,\n        'stDev': 0.06317700445712106,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-21T00:00:00Z', 'to': '2020-07-31T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.13920000195503235,\n        'max': 0.4927999973297119,\n        'mean': 0.3146395680115182,\n        'stDev': 0.054700527707146035,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nPercentage of cloudy pixels for selected area of interest\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"CLM\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"data\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        data: [samples.CLM],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"bbox\": [\n          413307.629466,\n          4957434.513693,\n          415152.151806,\n          4958814.807431\n        ],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-11-01T00:00:00Z\",\n            \"to\": \"2020-12-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n   'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-11-01T00:00:00Z',\n    'to': '2020-11-02T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 1.0,\n        'max': 1.0,\n        'mean': 1.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-11-06T00:00:00Z', 'to': '2020-11-07T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.0,\n        'mean': 0.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-11-11T00:00:00Z', 'to': '2020-11-12T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.0,\n        'mean': 0.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-11-21T00:00:00Z', 'to': '2020-11-22T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.0,\n        'mean': 0.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-11-26T00:00:00Z', 'to': '2020-11-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 1.0,\n        'mean': 0.31253938248267044,\n        'stDev': 0.46352833449533853,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-01T00:00:00Z', 'to': '2020-12-02T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 1.0,\n        'mean': 0.2800882167611853,\n        'stDev': 0.44904210002261963,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-06T00:00:00Z', 'to': '2020-12-07T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 1.0,\n        'max': 1.0,\n        'mean': 1.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-11T00:00:00Z', 'to': '2020-12-12T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 1.0,\n        'mean': 0.9844439193446739,\n        'stDev': 0.12375010711094206,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-16T00:00:00Z', 'to': '2020-12-17T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 1.0,\n        'max': 1.0,\n        'mean': 1.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-21T00:00:00Z', 'to': '2020-12-22T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 1.0,\n        'max': 1.0,\n        'mean': 1.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-26T00:00:00Z', 'to': '2020-12-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 1.0,\n        'mean': 0.1512287334593577,\n        'stDev': 0.35827168969322143,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\ndates_without_clouds = [(data[\"interval\"], int(100 * data[\"outputs\"][\"data\"]['bands']['B0']['stats']['mean']) ) for data in sh_statistics[\"data\"]]\n\nfor item in dates_without_clouds:\n    print( item )\n({'from': '2020-11-01T00:00:00Z', 'to': '2020-11-02T00:00:00Z'}, 100)\n({'from': '2020-11-06T00:00:00Z', 'to': '2020-11-07T00:00:00Z'}, 0)\n({'from': '2020-11-11T00:00:00Z', 'to': '2020-11-12T00:00:00Z'}, 0)\n({'from': '2020-11-21T00:00:00Z', 'to': '2020-11-22T00:00:00Z'}, 0)\n({'from': '2020-11-26T00:00:00Z', 'to': '2020-11-27T00:00:00Z'}, 31)\n({'from': '2020-12-01T00:00:00Z', 'to': '2020-12-02T00:00:00Z'}, 28)\n({'from': '2020-12-06T00:00:00Z', 'to': '2020-12-07T00:00:00Z'}, 100)\n({'from': '2020-12-11T00:00:00Z', 'to': '2020-12-12T00:00:00Z'}, 98)\n({'from': '2020-12-16T00:00:00Z', 'to': '2020-12-17T00:00:00Z'}, 100)\n({'from': '2020-12-21T00:00:00Z', 'to': '2020-12-22T00:00:00Z'}, 100)\n({'from': '2020-12-26T00:00:00Z', 'to': '2020-12-27T00:00:00Z'}, 15)\n\n\nBasic statistics of NDVI with water pixels excluded (custom output dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"data\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\n\nfunction evaluatePixel(samples) {\n    let ndvi = (samples.B08 - samples.B04)/(samples.B08 + samples.B04)\n\n    var validNDVIMask = 1\n    if (samples.B08 + samples.B04 == 0 ){\n        validNDVIMask = 0\n    }\n\n    var noWaterMask = 1\n    if (samples.SCL == 6 ){\n        noWaterMask = 0\n    }\n\n    return {\n        data: [ndvi],\n        // Exclude nodata pixels, pixels where ndvi is not defined and water pixels from statistics:\n        dataMask: [samples.dataMask * validNDVIMask * noWaterMask]\n    }\n}\n\"\"\"\n\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"geometry\": {\n          \"type\": \"Polygon\",\n          \"coordinates\": [\n            [\n              [\n                458085.878866,\n                5097236.833044\n              ],\n              [\n                457813.834156,\n                5096808.351383\n              ],\n              [\n                457979.897062,\n                5096313.767184\n              ],\n              [\n                458146.639373,\n                5096405.411294\n              ],\n              [\n                458085.878866,\n                5097236.833044\n              ]\n            ]\n          ]\n        },\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastCC\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n        \"from\": \"2020-01-01T00:00:00Z\",\n        \"to\": \"2020-12-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P30D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-01-01T00:00:00Z',\n    'to': '2020-01-31T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.24306687712669373,\n        'max': 0.6244725584983826,\n        'mean': 0.4123224201824293,\n        'stDev': 0.055874589607421886,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-01-31T00:00:00Z', 'to': '2020-03-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.2451941967010498,\n        'max': 0.4233206510543823,\n        'mean': 0.3160828609431641,\n        'stDev': 0.0280772593636271,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-01T00:00:00Z', 'to': '2020-03-31T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.4236144721508026,\n        'max': 0.8021259307861328,\n        'mean': 0.5844831434836089,\n        'stDev': 0.05766820795482124,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-31T00:00:00Z', 'to': '2020-04-30T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.4647541046142578,\n        'max': 0.8266128897666931,\n        'mean': 0.6615912824901472,\n        'stDev': 0.05539347152437238,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-04-30T00:00:00Z', 'to': '2020-05-30T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.1761743128299713,\n        'max': 0.870899498462677,\n        'mean': 0.6880682412526884,\n        'stDev': 0.18833356676740057,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-05-30T00:00:00Z', 'to': '2020-06-29T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.6883189082145691,\n        'max': 0.8775584697723389,\n        'mean': 0.8230951517303176,\n        'stDev': 0.026851310273968688,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-06-29T00:00:00Z', 'to': '2020-07-29T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.8124191164970398,\n        'max': 0.9270430207252502,\n        'mean': 0.8977047195274247,\n        'stDev': 0.01321883825220214,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-07-29T00:00:00Z', 'to': '2020-08-28T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.750795304775238,\n        'max': 0.8925060033798218,\n        'mean': 0.8437445996058478,\n        'stDev': 0.017705930134783242,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-08-28T00:00:00Z', 'to': '2020-09-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.7094070315361023,\n        'max': 0.8823529481887817,\n        'mean': 0.8138526516467535,\n        'stDev': 0.020639924263070358,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-09-27T00:00:00Z', 'to': '2020-10-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.6416097283363342,\n        'max': 0.8256189227104187,\n        'mean': 0.7368144742384923,\n        'stDev': 0.02884084473079313,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-10-27T00:00:00Z', 'to': '2020-11-26T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.5131579041481018,\n        'max': 0.9108409285545349,\n        'mean': 0.6912739742345253,\n        'stDev': 0.06273793790576106,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-11-26T00:00:00Z', 'to': '2020-12-26T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': -0.01446416787803173,\n        'max': 0.015364916995167732,\n        'mean': 0.0018048733875211391,\n        'stDev': 0.004322122712106793,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}}],\n 'status': 'OK'}\n\n\nStatistics of maximum monthly NDVI for a parcel in 2020\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    mosaicking: \"ORBIT\",\n    output: [\n      {\n        id: \"data\",\n        bands: [\"monthly_max_ndvi\"]\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\n\nfunction evaluatePixel(samples) {\n    var max = 0;\n    var hasData = 0;\n    for (var i=0;i&lt;samples.length;i++) {\n      if (samples[i].dataMask == 1 && samples[i].SCL != 6 && samples[i].B04+samples[i].B08 != 0 ){\n        hasData = 1\n        var ndvi = (samples[i].B08 - samples[i].B04)/(samples[i].B08 + samples[i].B04);\n        max = ndvi &gt; max ? ndvi:max;\n      }\n    }\n\n    return {\n        data: [max],\n        dataMask: [hasData]\n    }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"geometry\": {\n          \"type\": \"Polygon\",\n          \"coordinates\": [\n            [\n              [\n                458085.878866,\n                5097236.833044\n              ],\n              [\n                457813.834156,\n                5096808.351383\n              ],\n              [\n                457979.897062,\n                5096313.767184\n              ],\n              [\n                458146.639373,\n                5096405.411294\n              ],\n              [\n                458085.878866,\n                5097236.833044\n              ]\n            ]\n          ]\n        },\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastCC\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-01-01T00:00:00Z\",\n            \"to\": \"2021-01-01T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1M\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n   'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-01-01T00:00:00Z',\n    'to': '2020-02-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.4755639135837555,\n        'max': 0.881286084651947,\n        'mean': 0.6396090604381046,\n        'stDev': 0.06844923487502963,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-02-01T00:00:00Z', 'to': '2020-03-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.3580246865749359,\n        'max': 0.8721038103103638,\n        'mean': 0.5956351390500386,\n        'stDev': 0.07367438999713516,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-01T00:00:00Z', 'to': '2020-04-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.4486735761165619,\n        'max': 0.8021259307861328,\n        'mean': 0.5871563556072766,\n        'stDev': 0.057052289003643133,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-04-01T00:00:00Z', 'to': '2020-05-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7103235721588135,\n        'max': 0.9151291251182556,\n        'mean': 0.8202670164519443,\n        'stDev': 0.029936259510749567,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-05-01T00:00:00Z', 'to': '2020-06-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7955418825149536,\n        'max': 0.9187881350517273,\n        'mean': 0.8889340774162204,\n        'stDev': 0.013139359632348635,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-06-01T00:00:00Z', 'to': '2020-07-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.6883189082145691,\n        'max': 0.8775584697723389,\n        'mean': 0.8258738168990016,\n        'stDev': 0.025802682912912194,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-07-01T00:00:00Z', 'to': '2020-08-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.8329545259475708,\n        'max': 0.9370484948158264,\n        'mean': 0.9037947789513383,\n        'stDev': 0.01278601507445675,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-08-01T00:00:00Z', 'to': '2020-09-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.750795304775238,\n        'max': 0.8925060033798218,\n        'mean': 0.843880225772972,\n        'stDev': 0.017580399946741675,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-09-01T00:00:00Z', 'to': '2020-10-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7121148109436035,\n        'max': 0.8823529481887817,\n        'mean': 0.8138710224835326,\n        'stDev': 0.02056652680651673,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-10-01T00:00:00Z', 'to': '2020-11-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.6416097283363342,\n        'max': 0.8256189227104187,\n        'mean': 0.7368144742384923,\n        'stDev': 0.02884084473079313,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-11-01T00:00:00Z', 'to': '2020-12-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.5424679517745972,\n        'max': 0.9108409285545349,\n        'mean': 0.7069293897671695,\n        'stDev': 0.05380689467103403,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-12-01T00:00:00Z', 'to': '2021-01-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.0683102235198021,\n        'max': 0.23551543056964874,\n        'mean': 0.1444664227123698,\n        'stDev': 0.027443079533455306,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}}],\n 'status': 'OK'}\n\n\nMultiple outputs with different dataMasks, multi-band output with custom bands' names and different histogram types\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_my_bands\",\n        bands: [\"only_band_B04\", \"only_band_B08\"],\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"output_my_indices\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"output_scl\",\n        bands: 1,\n        sampleType: \"UINT8\"\n      },\n      {\n        id: \"dataMask\",\n        bands: [\"output_my_bands\", \"output_my_indices\"]\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    let ndvi = (samples.B08 - samples.B04)/(samples.B08 + samples.B04)\n\n    var validNDVIMask = 1\n    if (samples.B08 + samples.B04 == 0 ){\n        validNDVIMask = 0\n    }\n\n    var noWaterMask = 1\n    if (samples.SCL == 6 ){\n        noWaterMask = 0\n    }\n\n    return {\n        output_my_bands: [samples.B04, samples.B08],\n        output_my_indices: [ndvi],\n        output_scl: [samples.SCL],\n        dataMask: [samples.dataMask, samples.dataMask * noWaterMask * validNDVIMask]\n    }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n      \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n      }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-01T00:00:00Z\",\n            \"to\": \"2020-07-15T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P5D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 20,\n    \"resy\": 20\n  },\n  \"calculations\": {\n    \"output_my_bands\": {\n      \"histograms\": {\n        \"only_band_B08\": {\n          \"nBins\": 3,\n          \"lowEdge\": 0.0,\n          \"highEdge\": 0.3\n        }\n      },\n      \"statistics\": {\n        \"only_band_B04\": {\n          \"percentiles\": {\n            \"k\": [33, 66,100],\n          }\n        }\n      }\n    },\n    \"output_scl\": {\n      \"histograms\": {\n        \"default\": {\n          \"bins\": [0,1,2,3,4,5,6,7,8,9,10,11]\n        }\n      }\n    },\n    \"default\": {\n      \"histograms\": {\n        \"default\": {\n          \"binWidth\": 0.05,\n          \"lowEdge\": 0.0\n        }\n      }\n    }\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-01T00:00:00Z',\n    'to': '2020-07-06T00:00:00Z'},\n   'outputs': {'output_my_bands': {'bands': {'only_band_B04': {'stats': {'min': 0.0803999975323677,\n        'max': 0.2939999997615814,\n        'mean': 0.11451061716602186,\n        'stDev': 0.032769790113614555,\n        'sampleCount': 810,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.09719999879598618,\n         '66.0': 0.11169999837875366,\n         '100.0': 0.2939999997615814}}},\n      'only_band_B08': {'stats': {'min': 0.0860000029206276,\n        'max': 0.34290000796318054,\n        'mean': 0.16518679009175594,\n        'stDev': 0.07128630441809644,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0,\n          'highEdge': 0.09999999999999999,\n          'count': 199},\n         {'lowEdge': 0.09999999999999999,\n          'highEdge': 0.19999999999999998,\n          'count': 270},\n         {'lowEdge': 0.19999999999999998, 'highEdge': 0.3, 'count': 332}],\n        'overflowCount': 9,\n        'underflowCount': 0}}}},\n    'output_scl': {'bands': {'B0': {'stats': {'min': 8.0,\n        'max': 10.0,\n        'mean': 9.75432098765432,\n        'stDev': 0.6555648554361158,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0, 'highEdge': 1, 'count': 0},\n         {'lowEdge': 1, 'highEdge': 2, 'count': 0},\n         {'lowEdge': 2, 'highEdge': 3, 'count': 0},\n         {'lowEdge': 3, 'highEdge': 4, 'count': 0},\n         {'lowEdge': 4, 'highEdge': 5, 'count': 0},\n         {'lowEdge': 5, 'highEdge': 6, 'count': 0},\n         {'lowEdge': 6, 'highEdge': 7, 'count': 0},\n         {'lowEdge': 7, 'highEdge': 8, 'count': 0},\n         {'lowEdge': 8, 'highEdge': 9, 'count': 99},\n         {'lowEdge': 9, 'highEdge': 10, 'count': 1},\n         {'lowEdge': 10, 'highEdge': 11, 'count': 710}],\n        'overflowCount': 0,\n        'underflowCount': 0}}}},\n    'output_my_indices': {'bands': {'B0': {'stats': {'min': -0.04050104320049286,\n        'max': 0.5338308215141296,\n        'mean': 0.14599402473584097,\n        'stDev': 0.15671216615792566,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.05, 'count': 340},\n         {'lowEdge': 0.05, 'highEdge': 0.1, 'count': 71},\n         {'lowEdge': 0.1, 'highEdge': 0.15000000000000002, 'count': 50},\n         {'lowEdge': 0.15000000000000002, 'highEdge': 0.2, 'count': 26},\n         {'lowEdge': 0.2, 'highEdge': 0.25, 'count': 23},\n         {'lowEdge': 0.25, 'highEdge': 0.30000000000000004, 'count': 33},\n         {'lowEdge': 0.30000000000000004,\n          'highEdge': 0.35000000000000003,\n          'count': 64},\n         {'lowEdge': 0.35000000000000003, 'highEdge': 0.4, 'count': 81},\n         {'lowEdge': 0.4, 'highEdge': 0.45, 'count': 53},\n         {'lowEdge': 0.45, 'highEdge': 0.5, 'count': 6},\n         {'lowEdge': 0.5, 'highEdge': 0.55, 'count': 9}],\n        'overflowCount': 0,\n        'underflowCount': 54}}}}}},\n  {'interval': {'from': '2020-07-06T00:00:00Z', 'to': '2020-07-11T00:00:00Z'},\n   'outputs': {'output_my_bands': {'bands': {'only_band_B04': {'stats': {'min': 0.007499999832361937,\n        'max': 0.3788999915122986,\n        'mean': 0.05566148159990979,\n        'stDev': 0.060176196853468686,\n        'sampleCount': 810,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.022700000554323196,\n         '66.0': 0.04439999908208847,\n         '100.0': 0.3788999915122986}}},\n      'only_band_B08': {'stats': {'min': 0.006500000134110451,\n        'max': 0.46369999647140503,\n        'mean': 0.12869839533864502,\n        'stDev': 0.1266643048401008,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0,\n          'highEdge': 0.09999999999999999,\n          'count': 450},\n         {'lowEdge': 0.09999999999999999,\n          'highEdge': 0.19999999999999998,\n          'count': 27},\n         {'lowEdge': 0.19999999999999998, 'highEdge': 0.3, 'count': 254}],\n        'overflowCount': 79,\n        'underflowCount': 0}}}},\n    'output_scl': {'bands': {'B0': {'stats': {'min': 2.0,\n        'max': 9.0,\n        'mean': 5.1716049382715985,\n        'stDev': 1.09834157450977,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0, 'highEdge': 1, 'count': 0},\n         {'lowEdge': 1, 'highEdge': 2, 'count': 0},\n         {'lowEdge': 2, 'highEdge': 3, 'count': 29},\n         {'lowEdge': 3, 'highEdge': 4, 'count': 0},\n         {'lowEdge': 4, 'highEdge': 5, 'count': 235},\n         {'lowEdge': 5, 'highEdge': 6, 'count': 103},\n         {'lowEdge': 6, 'highEdge': 7, 'count': 428},\n         {'lowEdge': 7, 'highEdge': 8, 'count': 13},\n         {'lowEdge': 8, 'highEdge': 9, 'count': 1},\n         {'lowEdge': 9, 'highEdge': 10, 'count': 1},\n         {'lowEdge': 10, 'highEdge': 11, 'count': 0}],\n        'overflowCount': 0,\n        'underflowCount': 0}}}},\n    'output_my_indices': {'bands': {'B0': {'stats': {'min': -0.18976545333862305,\n        'max': 0.858506441116333,\n        'mean': 0.47965881587323095,\n        'stDev': 0.25189343011256504,\n        'sampleCount': 810,\n        'noDataCount': 428},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.05, 'count': 3},\n         {'lowEdge': 0.05, 'highEdge': 0.1, 'count': 3},\n         {'lowEdge': 0.1, 'highEdge': 0.15000000000000002, 'count': 15},\n         {'lowEdge': 0.15000000000000002, 'highEdge': 0.2, 'count': 36},\n         {'lowEdge': 0.2, 'highEdge': 0.25, 'count': 28},\n         {'lowEdge': 0.25, 'highEdge': 0.30000000000000004, 'count': 20},\n         {'lowEdge': 0.30000000000000004,\n          'highEdge': 0.35000000000000003,\n          'count': 17},\n         {'lowEdge': 0.35000000000000003, 'highEdge': 0.4, 'count': 6},\n         {'lowEdge': 0.4, 'highEdge': 0.45, 'count': 9},\n         {'lowEdge': 0.45, 'highEdge': 0.5, 'count': 24},\n         {'lowEdge': 0.5, 'highEdge': 0.55, 'count': 22},\n         {'lowEdge': 0.55, 'highEdge': 0.6000000000000001, 'count': 18},\n         {'lowEdge': 0.6000000000000001, 'highEdge': 0.65, 'count': 32},\n         {'lowEdge': 0.65, 'highEdge': 0.7000000000000001, 'count': 46},\n         {'lowEdge': 0.7000000000000001, 'highEdge': 0.75, 'count': 37},\n         {'lowEdge': 0.75, 'highEdge': 0.8, 'count': 29},\n         {'lowEdge': 0.8, 'highEdge': 0.8500000000000001, 'count': 21},\n         {'lowEdge': 0.8500000000000001, 'highEdge': 0.9, 'count': 2}],\n        'overflowCount': 0,\n        'underflowCount': 14}}}}}}],\n 'status': 'OK'}\n\n\nStatistics for Sentinel-1\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"VV\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_VV\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_VV: [samples.VV],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-1-grd\",\n        \"dataFilter\": {\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-01T00:00:00Z\",\n            \"to\": \"2020-07-10T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P5D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-01T00:00:00Z',\n    'to': '2020-07-06T00:00:00Z'},\n   'outputs': {'output_VV': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.4447733759880066,\n        'mean': 0.046840328479290934,\n        'stDev': 0.05487441687888816,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nStatistics of NDVI using Sentinel-2 L2A as the source of NDVI and Sentinel-1 GRD VV channel as the mask of water bodies\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      // Specify input bands using the \"id\" of datasource set in the payload under data parameter\n      {datasource: \"s2\", bands: [\"B04\", \"B08\", \"dataMask\"]},\n      {datasource: \"s1\", bands: [\"VV\", \"dataMask\"]}\n    ],\n    output: [\n      {\n        id: \"ndvi\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }],\n    mosaicking: \"SIMPLE\"\n  };\n}\n\nfunction evaluatePixel(samples) {\n  let ndvi = (samples.s2[0].B08 - samples.s2[0].B04) / (samples.s2[0].B08+samples.s2[0].B04);\n\n  // Create a mask for invalid ndvi value\n  let validNDVIMask = 1;\n  if (!isFinite(ndvi)) {\n    validNDVIMask = 0;\n  }\n\n  // Create a mask for water\n  // The threshold comes from the result of exploring river flooding during the winter of 2020/21 on the River Severn in the United Kingdom\n  // (https://medium.com/euro-data-cube/exploring-time-and-space-a-guide-to-accessing-analysing-and-visualising-data-in-the-euro-data-e4a46f2bb55b)\n  let noWaterMask = 1;\n  if (toDB(samples.s1[0].VV) &lt;= -20) {\n    noWaterMask = 0;\n  }\n  return {\n      ndvi: [ndvi],\n      // Combine all the masks\n      dataMask: [samples.s2[0].dataMask * samples.s1[0].dataMask * validNDVIMask * noWaterMask]\n  };\n}\n\nfunction toDB(input){\n  return 10 * Math.log(input)/Math.LN10;\n}\n\"\"\"\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [16.72617,47.713689],\n            [16.72617,47.655444],\n            [16.816292,47.655444],\n            [16.816292,47.713689],\n            [16.72617,47.713689]\n          ]\n        ]\n      }\n    },\n    \"data\": [\n      {\n        \"dataFilter\": {},\n        \"id\": \"s2\",\n        \"type\": \"sentinel-2-l2a\"\n      },\n      {\n        \"dataFilter\": {\n          \"resolution\": \"HIGH\",\n          \"acquisitionMode\": \"IW\",\n          \"polarization\": \"DV\"\n        },\n        \"processing\": {\n          \"backCoeff\": \"GAMMA0_TERRAIN\",\n          \"orthorectify\": \"true\",\n          \"demInstance\": \"MAPZEN\",\n          \"speckleFilter\": {\n            \"type\": \"LEE\",\n            \"windowSizeX\": 5,\n            \"windowSizeY\": 5\n          }\n        },\n        \"id\": \"s1\",\n        \"type\": \"sentinel-1-grd\"\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n      \"from\": \"2021-08-08T00:00:00Z\",\n      \"to\": \"2021-08-11T23:59:59Z\"\n    },\n    \"aggregationInterval\": {\n      \"of\": \"P1D\"\n    },\n    \"resx\": 0.00009,\n    \"resy\": 0.00009,\n    \"evalscript\": evalscript\n  },\n  \"calculations\": {\n    \"default\": {}\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2021-08-08T00:00:00Z',\n    'to': '2021-08-09T00:00:00Z'},\n   'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': -0.6206604838371277,\n        'max': 0.8291770815849304,\n        'mean': 0.22080027097811286,\n        'stDev': 0.22071344421516914,\n        'sampleCount': 647647,\n        'noDataCount': 144372}}}}}},\n  {'interval': {'from': '2021-08-10T00:00:00Z', 'to': '2021-08-11T00:00:00Z'},\n   'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': -0.6909090876579285,\n        'max': 0.8982226252555847,\n        'mean': 0.6302106131139007,\n        'stDev': 0.28749024291873476,\n        'sampleCount': 647647,\n        'noDataCount': 220350}}}}}}],\n 'status': 'OK'}"
  },
  {
    "objectID": "APIs/SentinelHub/Overview.html",
    "href": "APIs/SentinelHub/Overview.html",
    "title": "API Overview",
    "section": "",
    "text": "The Sentinel Hub API is a RESTful API interface to various satellite imagery archives. It provides access to raw satellite data, rendered images, statistical analysis and much more.\nThe Sentinel Hub API is annotated via OpenAPI. You can browse reference docs here:\n\nWeb preview\nYAML"
  },
  {
    "objectID": "APIs/SentinelHub/Overview.html#about-sentinel-hub-api",
    "href": "APIs/SentinelHub/Overview.html#about-sentinel-hub-api",
    "title": "API Overview",
    "section": "",
    "text": "The Sentinel Hub API is a RESTful API interface to various satellite imagery archives. It provides access to raw satellite data, rendered images, statistical analysis and much more.\nThe Sentinel Hub API is annotated via OpenAPI. You can browse reference docs here:\n\nWeb preview\nYAML"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/CloudMasks.html",
    "href": "APIs/SentinelHub/UserGuides/CloudMasks.html",
    "title": "Cloud Masks",
    "section": "",
    "text": "Cloud masks and probabilites computed using s2cloudless are available at a fixed resolution of 160m per pixel. Sentinel Hub implements the 10-band version. These are meant as convenience bands with the purpose of speeding up processing. Cloud masks are generated in a very slightly different way than the implementation above but for most applications this should not matter.\nThey are available as Sentinel-2 bands named CLP (cloud probabilities) and CLM (cloud masks) and have the following return values:\n\nCLM: 0 (no clouds), 1 (clouds), 255 (no data)\nCLP: 0–255 (divide by 255 to get to the [0-1] range)\n\nThe CLM no data value of 255 is also returned if a tile has missing CLM and CLP bands, for example due to errors. This ensures that values of 0 and 1 can be used with confidence for each pixel. CLP will in such a case return 0. Consider using CLM alongside CLP in your evalscript if this is an issue.\n\n\nCLP is generated per tile using the s2cloudless product at 160m resolution. Due to the 60m Sentinel-2 bands this means that a perfect match between CLP and s2cloudless is not possible for all requests. In case you require identical data, there are a few constraints which must be met. These are:\n\nrequesting data in the native UTM zone of each tile\nnearest neighbor interpolation\n160m resolution or slightly less (more zoomed out)\nthe request origin is a multiple of 480m away from the tile origin (the top left point of the source tile)\nrequesting a single tile only; no mosaicking (mosaicking violates the previous point)\n\nIf any of these are not met you can expect slight differences. For exact values the s2cloudless product may be used without these constraints, at a cost of requiring more processing time and processing units; for most applications, however, we do not expect this to be necessary.\n\n\n\nRead our blog posts and articles on cloud masks and cloud probabilities:\n\nCloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2 - Our s2cloudless algorithm was validated together with 9 other cloud detection algorithms and it was found to be on the Pareto front in all the test cases. June 1, 2022\nCloud Masks at Your Service, May 5, 2020\nOn cloud detection with multi-temporal data, October 14, 2019\nSentinel Hub Cloud Detector — s2cloudless, January 22, 2018"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/CloudMasks.html#cloud-masks-and-cloud-probabilities",
    "href": "APIs/SentinelHub/UserGuides/CloudMasks.html#cloud-masks-and-cloud-probabilities",
    "title": "Cloud Masks",
    "section": "",
    "text": "Cloud masks and probabilites computed using s2cloudless are available at a fixed resolution of 160m per pixel. Sentinel Hub implements the 10-band version. These are meant as convenience bands with the purpose of speeding up processing. Cloud masks are generated in a very slightly different way than the implementation above but for most applications this should not matter.\nThey are available as Sentinel-2 bands named CLP (cloud probabilities) and CLM (cloud masks) and have the following return values:\n\nCLM: 0 (no clouds), 1 (clouds), 255 (no data)\nCLP: 0–255 (divide by 255 to get to the [0-1] range)\n\nThe CLM no data value of 255 is also returned if a tile has missing CLM and CLP bands, for example due to errors. This ensures that values of 0 and 1 can be used with confidence for each pixel. CLP will in such a case return 0. Consider using CLM alongside CLP in your evalscript if this is an issue.\n\n\nCLP is generated per tile using the s2cloudless product at 160m resolution. Due to the 60m Sentinel-2 bands this means that a perfect match between CLP and s2cloudless is not possible for all requests. In case you require identical data, there are a few constraints which must be met. These are:\n\nrequesting data in the native UTM zone of each tile\nnearest neighbor interpolation\n160m resolution or slightly less (more zoomed out)\nthe request origin is a multiple of 480m away from the tile origin (the top left point of the source tile)\nrequesting a single tile only; no mosaicking (mosaicking violates the previous point)\n\nIf any of these are not met you can expect slight differences. For exact values the s2cloudless product may be used without these constraints, at a cost of requiring more processing time and processing units; for most applications, however, we do not expect this to be necessary.\n\n\n\nRead our blog posts and articles on cloud masks and cloud probabilities:\n\nCloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2 - Our s2cloudless algorithm was validated together with 9 other cloud detection algorithms and it was found to be on the Pareto front in all the test cases. June 1, 2022\nCloud Masks at Your Service, May 5, 2020\nOn cloud detection with multi-temporal data, October 14, 2019\nSentinel Hub Cloud Detector — s2cloudless, January 22, 2018"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Datamask.html",
    "href": "APIs/SentinelHub/UserGuides/Datamask.html",
    "title": "Data Mask",
    "section": "",
    "text": "With evalscript v3 we are now providing full control to you over what is to be returned for image parts (pixels) where there is “no data”. In the setup function, you can request dataMask as an element of the input array and then use it in the evaluatePixel function in the same manner as any other input band.\n\n\ndataMask has value 0 for “no data” pixels and 1 elsewhere.\nBy “no data” pixels we mean:\n\nAll pixels which lay outside of the requested polygon (if specified).\nAll pixels for which no source data was found.\nAll pixels for which source data was found and is explicitly “no data”.\n\nThings to note:\n\nAll “no data” pixels as defined above have a dataMask value of 0. All band values for these pixels are also 0, except for Landsat data collections, where band values for no data pixels are NaN.\n\"No data\" pixels are treated like any other in the evalscript. Their value, namely zero (or NaN in case of Landsat data collections), is applied to your evalscript just like any other other pixel. E.g. return [sample.B04*sample.B03] will return 0 for “no data” pixels, while return [sample.B04/sample.B03] would return \"Infinity\" (if requested sampleType is FLOAT32) due to division by zero (or \"NaN\" for Landsat data collection where the division would be by \"NaN\"). To treat \"no data\" pixels differently, explicitly handle them in your evalscript. See the examples below.\n\n\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1)  {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  } else {\n    return [99, 99, 99]\n  }\n}\n\n\n\n//VERSION=3\nif (dataMask == 1)  {\n  return [2.5 * B04, 2.5 * B03, 2.5 * B02]\n} else {\n  return [99/255, 99/255, 99/255] //normalized with 255 for visualization in EO Browser\n}\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you'd like to use this example, you must set the output.responses.format.type parameter of your process API request to image/png or image/tiff. The png format will automatically interpret the fourth band as transparency.\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 4 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02, sample.dataMask]\n}\n\n\n\n//VERSION=3\nreturn [2.5 * B04, 2.5 * B03, 2.5 * B02, dataMask]"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Datamask.html#datamask---handling-of-pixels-with-no-data",
    "href": "APIs/SentinelHub/UserGuides/Datamask.html#datamask---handling-of-pixels-with-no-data",
    "title": "Data Mask",
    "section": "",
    "text": "With evalscript v3 we are now providing full control to you over what is to be returned for image parts (pixels) where there is “no data”. In the setup function, you can request dataMask as an element of the input array and then use it in the evaluatePixel function in the same manner as any other input band.\n\n\ndataMask has value 0 for “no data” pixels and 1 elsewhere.\nBy “no data” pixels we mean:\n\nAll pixels which lay outside of the requested polygon (if specified).\nAll pixels for which no source data was found.\nAll pixels for which source data was found and is explicitly “no data”.\n\nThings to note:\n\nAll “no data” pixels as defined above have a dataMask value of 0. All band values for these pixels are also 0, except for Landsat data collections, where band values for no data pixels are NaN.\n\"No data\" pixels are treated like any other in the evalscript. Their value, namely zero (or NaN in case of Landsat data collections), is applied to your evalscript just like any other other pixel. E.g. return [sample.B04*sample.B03] will return 0 for “no data” pixels, while return [sample.B04/sample.B03] would return \"Infinity\" (if requested sampleType is FLOAT32) due to division by zero (or \"NaN\" for Landsat data collection where the division would be by \"NaN\"). To treat \"no data\" pixels differently, explicitly handle them in your evalscript. See the examples below.\n\n\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1)  {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  } else {\n    return [99, 99, 99]\n  }\n}\n\n\n\n//VERSION=3\nif (dataMask == 1)  {\n  return [2.5 * B04, 2.5 * B03, 2.5 * B02]\n} else {\n  return [99/255, 99/255, 99/255] //normalized with 255 for visualization in EO Browser\n}\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you'd like to use this example, you must set the output.responses.format.type parameter of your process API request to image/png or image/tiff. The png format will automatically interpret the fourth band as transparency.\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 4 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02, sample.dataMask]\n}\n\n\n\n//VERSION=3\nreturn [2.5 * B04, 2.5 * B03, 2.5 * B02, dataMask]"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S3SLSTR.html",
    "href": "APIs/SentinelHub/Process/Examples/S3SLSTR.html",
    "title": "Examples for S3SLSTR",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nFalse Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                8.558382,\n                41.359678,\n                9.579525,\n                43.055688,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color, resolution (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 250,\n        \"resy\": 250,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nThermal IR fire emission band, gradient visualizer (K)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"F1\"],\n    output: {\n      bands: 3,\n    },\n  }\n}\n\n// Create a Red gradient visualiser from 274-450 K\nvar viz = ColorGradientVisualizer.createRedTemperature(274, 450)\n\nfunction evaluatePixel(sample) {\n  return viz.process(sample.F1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -120.141,\n                37.5282,\n                -119.4131,\n                37.8716,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-08-06T00:00:00Z\",\n                        \"to\": \"2018-08-06T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color and metadata (multi-part GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"INT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n    mosaicking: \"TILE\",\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.tiles }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [sample[0].S3 * 10000, sample[0].S2 * 10000, sample[0].S1 * 10000] //the values are multiplied by 10000 because output sampleType is UINT16\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                8.558382,\n                41.359678,\n                9.579525,\n                43.055688,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bouds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S2\", \"S3\"],\n    output: {\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let NDVI = index(sample.S3, sample.S2)\n  const viz = ColorGradientVisualizer.createWhiteGreen(-0.1, 1.0)\n  return viz.process(NDVI)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                        [\n                            542559.6872296461,\n                            4744749.907737136,\n                        ],\n                        [\n                            550448.1401370098,\n                            4660606.41005859,\n                        ],\n                        [\n                            521523.8128100095,\n                            4570327.449007649,\n                        ],\n                        [\n                            474193.0953658272,\n                            4600128.271102134,\n                        ],\n                        [\n                            461045.67385355436,\n                            4630805.5879641045,\n                        ],\n                        [\n                            453157.22094619065,\n                            4698295.685060439,\n                        ],\n                        [\n                            497858.45408791833,\n                            4741243.928667196,\n                        ],\n                        [\n                            520647.3180425246,\n                            4744749.907737136,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/jpeg\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S2\", \"S3\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: \"INT16\",\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: \"AUTO\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let NDVI = index(sample.S3, sample.S2)\n  const viz = ColorGradientVisualizer.createWhiteGreen(-0.1, 1.0)\n  return {\n    default: [NDVI * 10000],\n    ndvi_image: viz.process(NDVI),\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                        [\n                            542559.6872296461,\n                            4744749.907737136,\n                        ],\n                        [\n                            550448.1401370098,\n                            4660606.41005859,\n                        ],\n                        [\n                            521523.8128100095,\n                            4570327.449007649,\n                        ],\n                        [\n                            474193.0953658272,\n                            4600128.271102134,\n                        ],\n                        [\n                            461045.67385355436,\n                            4630805.5879641045,\n                        ],\n                        [\n                            453157.22094619065,\n                            4698295.685060439,\n                        ],\n                        [\n                            497858.45408791833,\n                            4741243.928667196,\n                        ],\n                        [\n                            520647.3180425246,\n                            4744749.907737136,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nVNIR and SWIR bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      bands: 6,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance or BT values, simply divide the resulting pixel values by 10000.\n  return [\n    10000 * sample.S1,\n    10000 * sample.S2,\n    10000 * sample.S3,\n    10000 * sample.S4,\n    10000 * sample.S5,\n    10000 * sample.S6,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 500,\n        \"resy\": 500,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTIR bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S7\", \"S8\", \"S9\", \"F1\", \"F2\"],\n      },\n    ],\n    output: {\n      bands: 5,\n      sampleType: \"UINT16\",\n    },\n  }\n}\n\nfunction multiplyband(sample) {\n  // Multiply by 100\n  return 100 * sample\n}\n\nfunction evaluatePixel(sample) {\n  // Return the bands multiplied by 100 as integers to save processing units.\n  // To obtain reflectance or BT values, simply divide the resulting pixel values by 100.\n  return [\n    multiplyband(sample.S7),\n    multiplyband(sample.S8),\n    multiplyband(sample.S9),\n    multiplyband(sample.F1),\n    multiplyband(sample.F2),\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 500,\n        \"resy\": 500,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S2L1C.html",
    "href": "APIs/SentinelHub/Process/Examples/S2L1C.html",
    "title": "Examples for S2L1C",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 100,\n        \"resy\": 100,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTIff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue Color, preview mode\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                18.55963134765625,\n                48.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-11T00:00:00Z\",\n                        \"to\": \"2018-11-18T00:00:00Z\",\n                    },\n                    \"previewMode\": \"PREVIEW\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, mosaicking with leastRecent\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-11T00:00:00Z\",\n                        \"to\": \"2018-11-18T00:00:00Z\",\n                    },\n                    \"mosaickingOrder\": \"leastRecent\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    mosaicking: Mosaicking.ORBIT,\n    output: { id: \"default\", bands: 3 },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.orbits }\n}\n\nfunction evaluatePixel(samples) {\n  return [2.5 * samples[0].B04, 2.5 * samples[0].B03, 2.5 * samples[0].B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ]\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-27T00:00:00Z\",\n                        \"to\": \"2018-12-27T23:59:59Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nTrue color multi-part-reponse (different formats and SampleType)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B03\", \"B02\"],\n        units: \"REFLECTANCE\", // default units\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 3,\n        sampleType: \"AUTO\", // default  - scales the output values from input values [0,1] to [0,255].\n      },\n      {\n        id: \"true_color_8bit\",\n        bands: 3,\n        sampleType: \"UINT8\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_16bit\",\n        bands: 3,\n        sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_32float\",\n        bands: 3,\n        sampleType: \"FLOAT32\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return {\n    // output band values are scaled from [0,1] to [0,255]. Multiply by 2.5 to increase brightness\n    default: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n\n    // Multiply input reflectance values by 2.5 to increase brighness and by 255 to return the band values clamped to [0, 255] unsigned 8 bit range.\n    true_color_8bit: [\n      2.5 * sample.B04 * 255,\n      2.5 * sample.B03 * 255,\n      2.5 * sample.B02 * 255,\n    ],\n\n    // Multiply input reflectance values by 2.5 to increase brightness and by 65535 to return the band values clamped to [0, 65535] unsigned 16 bit range.\n    true_color_16bit: [\n      2.5 * sample.B04 * 65535,\n      2.5 * sample.B03 * 65535,\n      2.5 * sample.B02 * 65535,\n    ],\n\n    // Returns band reflectance.\n    true_color_32float: [sample.B04, sample.B03, sample.B02],\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                12.206251,\n                41.627351,\n                12.594042,\n                41.856879,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-06-01T00:00:00Z\",\n                        \"to\": \"2018-08-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/jpeg\"},\n            },\n            {\n                \"identifier\": \"true_color_8bit\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"true_color_16bit\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"true_color_32float\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) return [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) return [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) return [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) return [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) return [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) return [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) return [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) return [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) return [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) return [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) return [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) return [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) return [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) return [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) return [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) return [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) return [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) return [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) return [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) return [0.06, 0.33, 0.04]\n  else return [0, 0.27, 0]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 80,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nExact NDVI values using a floating point GeoTIFF\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  return [ndvi]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI values as INT16 raster\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.INT16, //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  // Return NDVI multiplied by 10000 as integers to save processing units. To obtain NDVI values, simply divide the resulting pixel values by 10000.\n  return [ndvi * 10000]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: SampleType.FLOAT32,\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: SampleType.AUTO,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) image = [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) image = [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) image = [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) image = [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) image = [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) image = [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) image = [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) image = [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) image = [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) image = [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) image = [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) image = [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) image = [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) image = [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) image = [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) image = [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) image = [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) image = [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) image = [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) image = [0.06, 0.33, 0.04]\n  else image = [0, 0.27, 0]\n\n  return {\n    default: [ndvi],\n    ndvi_image: image,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S2L1C raw bands, original data (no harmonization)\nLearn about harmonization here.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B8A\",\n          \"B09\",\n          \"B10\",\n          \"B11\",\n          \"B12\",\n        ],\n        units: \"DN\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 13,\n      sampleType: SampleType.UINT16,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [\n    sample.B01,\n    sample.B02,\n    sample.B03,\n    sample.B04,\n    sample.B05,\n    sample.B06,\n    sample.B07,\n    sample.B08,\n    sample.B8A,\n    sample.B09,\n    sample.B10,\n    sample.B11,\n    sample.B12,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"false\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/DataFusion.html",
    "href": "APIs/SentinelHub/Process/Examples/DataFusion.html",
    "title": "Examples of Data Fusion",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nPan-sharpen Sentinel-3 OLCI with Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s2l1c\",\n        bands: [\"B02\", \"B03\", \"B04\"],\n      },\n      {\n        datasource: \"s3olci\",\n        bands: [\"B04\", \"B06\", \"B08\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  let s3 = samples.s3olci[0]\n  let s2 = samples.s2l1c[0]\n  let amount_s2 = 0.5\n  let gain = 3.0\n  return [\n    gain * (s3.B08 * (1 - amount_s2) + s2.B04 * amount_s2),\n    gain * (s3.B06 * (1 - amount_s2) + s2.B03 * amount_s2),\n    gain * (s3.B04 * (1 - amount_s2) + s2.B02 * amount_s2),\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                7.388827,\n                53.537043,\n                8.35627,\n                53.901102,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s2l1c\",\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-01T00:00:00Z\",\n                        \"to\": \"2020-06-01T23:59:00Z\",\n                    }\n                },\n            },\n            {\n                \"id\": \"s3olci\",\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-01T00:00:00Z\",\n                        \"to\": \"2020-06-01T23:59:00Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 1024,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nReplace clouds in Sentinel-2 images with Sentinel-1 data\nevalscript = \"\"\"\n// VERSION=3\n\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s2l1c\",\n        bands: [\"B02\", \"B03\", \"B04\", \"CLP\"],\n      },\n      {\n        datasource: \"s1grd\",\n        bands: [\"VV\", \"VH\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  var S2L1C = samples.s2l1c[0]\n  var S1 = samples.s1grd[0]\n  let WAT = 25 // Water Threshold for SAR\n  let CLP = S2L1C.CLP / 2.55 // cloud probability in percent\n  let CLPT = 70 // cloud probability threshold in percent\n  if (CLP &gt; CLPT) {\n    if (S1.VV / S1.VH &lt;= WAT) {\n      return [S1.VV * 3.0, S1.VV * 1.1 + S1.VH * 8.75, S1.VH * 1.75]\n    } else {\n      // S1.VV / S1.VH &gt; WAT\n      return [S1.VV * 1, S1.VV * 8, 0.5 + S1.VV * 3 + S1.VH * 2000]\n    }\n  }\n  return [3 * S2L1C.B04, 3 * S2L1C.B03, 3 * S2L1C.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                33.3219,\n                44.7014,\n                33.8073,\n                44.4791,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s2l1c\",\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-05-11T00:00:00Z\",\n                        \"to\": \"2020-05-11T23:59:00Z\",\n                    }\n                },\n            },\n            {\n                \"id\": \"s1grd\",\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-05-11T00:00:00Z\",\n                        \"to\": \"2020-05-11T23:59:00Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 663,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI with Sentinel-1 and Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s1\",\n        bands: [\"VV\", \"VH\"],\n      },\n      {\n        datasource: \"l2a\",\n        bands: [\"B08\", \"B04\", \"SCL\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction toDb(linear) {\n  // Convert the linear backscatter to DB (Filgueiras et al. (2019), eq. 3)\n  return 10 * Math.LN10 * linear\n}\n\nfunction calc_s1_ndvi(sigmaVV, sigmaVH) {\n  // Convert sigma0 to Decibels\n  let vh_Db = toDb(sigmaVH)\n  let vv_Db = toDb(sigmaVV)\n  // Calculate NRPB (Filgueiras et al. (2019), eq. 4)\n  let NRPB = (vh_Db - vv_Db) / (vh_Db + vv_Db)\n  // Calculate NDVI_nc with approach A3 (Filgueiras et al. (2019), eq. 14)\n  let NDVInc = 2.572 - 0.05047 * vh_Db + 0.176 * vv_Db + 3.422 * NRPB\n  return NDVInc\n}\n\n// Create an NDVI visualiser\nvar viz = new ColorMapVisualizer([\n  [0.0, 0xa50026],\n  [0.0, 0xd73027],\n  [0.2, 0xf46d43],\n  [0.3, 0xfdae61],\n  [0.4, 0xfee08b],\n  [0.5, 0xffffbf],\n  [0.6, 0xd9ef8b],\n  [0.7, 0xa6d96a],\n  [0.8, 0x66bd63],\n  [0.9, 0x1a9850],\n  [1.0, 0x006837],\n])\n\nfunction evaluatePixel(samples) {\n  var s1 = samples.s1[0]\n  var s2 = samples.l2a[0]\n\n  // Use the S2-L2A classification to identify clouds\n  if ([7, 8, 9, 10].includes(s2.SCL)) {\n    // If clouds are present use S1 NDVI\n    let s1_ndvi = calc_s1_ndvi(s1.VV, s1.VH) // Calculate S1 NDVI\n    return viz.process(s1_ndvi)\n  } else {\n    // Otherwise use s2 NDVI\n    let ndvi = index(s2.B08, s2.B04) // Calculate S2 NDVI\n    return viz.process(ndvi)\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -100.9204,\n                37.5718,\n                -100.4865,\n                37.864,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s1\",\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-26T00:00:00Z\",\n                        \"to\": \"2019-04-26T23:59:00Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            },\n            {\n                \"id\": \"l2a\",\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-26T00:00:00Z\",\n                        \"to\": \"2019-04-26T23:59:00Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 1024,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nShip detection with Sentinel-1 and Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s2l2a\",\n        bands: [\"B02\", \"B03\", \"B04\", \"B08\"],\n      },\n      {\n        datasource: \"s1grd\",\n        bands: [\"VV\", \"VH\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  var S2L2A = samples.s2l2a[0]\n  var S1 = samples.s1grd[0]\n\n  let ndwi = (S2L2A.B03 - S2L2A.B08) / (S2L2A.B03 + S2L2A.B08)\n  if (ndwi &gt; 0.1) {\n    if (S1.VV &gt; 0.3 || S1.VH &gt; 0.3) {\n      return [1, 1, 1]\n    }\n    return [4 * S2L2A.B04 - 0.2, 4 * S2L2A.B03 - 0.2, 5 * S2L2A.B02 - 0.2]\n  }\n  return [4 * S2L2A.B04 - 0.2, 4 * S2L2A.B03 - 0.2, 4 * S2L2A.B02 - 0.2]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                119.60987091064452,\n                32.176774851931214,\n                119.91474151611328,\n                32.3640132852233,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s1grd\",\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-05-23T00:00:00Z\",\n                        \"to\": \"2020-05-23T23:59:00Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            },\n            {\n                \"id\": \"s2l2a\",\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-05-23T00:00:00Z\",\n                        \"to\": \"2020-05-23T23:59:00Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 742,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nBuilt up areas detection with Sentinel-1 and Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s2l1c\",\n        bands: [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\"],\n      },\n      {\n        datasource: \"s1grd\",\n        bands: [\"VV\", \"VH\"],\n      },\n      {\n        datasource: \"s2l2a\",\n        bands: [\"B02\", \"B03\", \"B04\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(samples) {\n  var S2L1C = samples.s2l1c[0]\n  var S2L2A = samples.s2l2a[0]\n  var S1 = samples.s1grd[0]\n  let ndvi = (S2L1C.B08 - S2L1C.B04) / (S2L1C.B08 + S2L1C.B04)\n  if (ndvi &gt; 0.5) {\n    return [3 * S2L2A.B04, 3 * S2L2A.B03, 3 * S2L2A.B02]\n  }\n  let ndmi = (S2L1C.B08 - S2L1C.B11) / (S2L1C.B08 + S2L1C.B11)\n  if (ndmi &gt; 0) {\n    return [3 * S2L2A.B04, 3 * S2L2A.B03, 4 * S2L2A.B02]\n  }\n  if (S1.VH &gt; 0.2 || S1.VV &gt; 0.2) {\n    return [S1.VH * 5.5, S1.VV, S1.VH * 8]\n  }\n  return [3 * S2L1C.B04 - 0.2, 3 * S2L1C.B03 - 0.2, 3 * S2L1C.B02 - 0.2]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                12.280998229980469,\n                45.40206593659076,\n                12.43274688720703,\n                45.47361429775641,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s2l1c\",\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-12-10T00:00:00Z\",\n                        \"to\": \"2019-12-10T23:59:00Z\",\n                    }\n                },\n            },\n            {\n                \"id\": \"s1grd\",\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-12-10T00:00:00Z\",\n                        \"to\": \"2019-12-10T23:59:00Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            },\n            {\n                \"id\": \"s2l2a\",\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-12-10T00:00:00Z\",\n                        \"to\": \"2019-12-10T23:59:00Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 1024,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFire monitoring with Sentinel-1 and Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\n// Multitemporal forest fire progression monitoring script utilizing a) Sentinel-2 data from 7 September 2019 for the visualization of burned areas\n// and b) Sentinel-1 SAR data to monitor forest fire progression in overcast conditions on 12 September 2019.\n\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s1_t1\",\n        bands: [\"VH\"],\n      }, // S1 data from 7 September 2019 (t1)\n      {\n        datasource: \"s1_t2\",\n        bands: [\"VV\", \"VH\"],\n      }, // S1 data from 12 September 2019 (t2)\n      {\n        datasource: \"l2a_t1\",\n        bands: [\"B03\", \"B04\", \"B08\", \"B11\", \"B12\"],\n      },\n    ], // S2 data from 7 September 2019 (t1)\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  var s1_1 = samples.s1_t1[0] //Assigns S1 data from t1\n  var s1_2 = samples.s1_t2[0] //Assigns S1 data from t2\n  var s2_1 = samples.l2a_t1[0] //Assigns S2 data from t1\n\n  // Calculate indices with S2 data from t1 for Burned Area visualization by Monja Sebela\n  var NDWI = index(s2_1.B03, s2_1.B08)\n  var NDVI = index(s2_1.B08, s2_1.B04)\n  var INDEX = (s2_1.B11 - s2_1.B12) / (s2_1.B11 + s2_1.B12) + s2_1.B08\n\n  // Calculate difference in S1 VH backscatter between second (t2) and first scene (t1) (Belenguer-Plomer et al. 2019)\n  var VH_diff = s1_2.VH - s1_1.VH\n\n  // Set classification threshholds\n  var thr_VH = 0.03\n  var thr_VH_diff = -0.015\n  var thr_VV = 0.2\n\n  if (NDWI &gt; 0.15 || NDVI &gt; 0.35 || INDEX &gt; 0.2) {\n    // If non-burned areas in S2 image from t1\n    if (s1_2.VH &lt; thr_VH && VH_diff &lt; thr_VH_diff) {\n      // are classified as burned in S1 image from t2 via thresholds for VH backscatter and the calculated difference layer\n      return [1, 0, 0] // Return red color\n    } else {\n      return [2.5 * s2_1.B12, 2.5 * s2_1.B08, 2.5 * s2_1.B04] // Else return SWIR composite\n    }\n  } else {\n    if (s1_2.VV &lt; thr_VV) {\n      // Else, if already burnt area is also burned in S1 image from t2\n      return [0.9, 0.9, 0.7] // Return beige color\n    } else {\n      return [0, 0, 1] // Else return blue for areas that are no longer burned in S1 image from t2\n    }\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -59.75738525390625,\n                -19.919130502461016,\n                -58.7274169921875,\n                -19.062117883514652,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"id\": \"l2a_t1\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-09-06T00:00:00Z\",\n                        \"to\": \"2019-09-08T23:59:59Z\",\n                    }\n                },\n            },\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"id\": \"s1_t1\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-09-06T00:00:00Z\",\n                        \"to\": \"2019-09-08T23:59:59Z\",\n                    }\n                },\n            },\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"id\": \"s1_t2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-09-11T00:00:00Z\",\n                        \"to\": \"2019-09-13T23:59:59Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 1024,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nMonitoring low pressure clouds with Sentinel-3 OLCI and Sentinel-5P\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s3olci\",\n        bands: [\"B04\", \"B06\", \"B08\"],\n      },\n      {\n        datasource: \"s5pl2\",\n        bands: [\"CLOUD_TOP_PRESSURE\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nvar minVal = 10000.0\nvar maxVal = 110000.0\nvar diff = maxVal - minVal\nvar limits = [\n  minVal,\n  minVal + 0.125 * diff,\n  minVal + 0.375 * diff,\n  minVal + 0.625 * diff,\n  minVal + 0.875 * diff,\n  maxVal,\n]\nvar colors = [\n  [0, 0, 0.5],\n  [0, 0, 1],\n  [0, 1, 1],\n  [1, 1, 0],\n  [1, 0, 0],\n  [0.5, 0, 0],\n]\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  var S5 = samples.s5pl2[0]\n  var S3 = samples.s3olci[0]\n  var CLOUD_TOP_PRESSURE = S5.CLOUD_TOP_PRESSURE\n\n  if (CLOUD_TOP_PRESSURE &gt; 0) {\n    return colorBlend(CLOUD_TOP_PRESSURE, limits, colors)\n  }\n  return [S3.B08 * 3, S3.B06 * 3, S3.B04 * 3.5]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -154.82,\n                21.96,\n                -135.66,\n                13.56,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s3olci\",\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-07-24T00:00:00Z\",\n                        \"to\": \"2020-07-24T23:59:59Z\",\n                    }\n                },\n            },\n            {\n                \"id\": \"s5pl2\",\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-07-24T00:00:00Z\",\n                        \"to\": \"2020-07-24T23:59:59Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 449,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S1GRD.html",
    "href": "APIs/SentinelHub/Process/Examples/S1GRD.html",
    "title": "Examples for S1GRD",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nS1GRD orthorectified linear gamma0 VV between 0 and 0.5 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\"orthorectify\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified linear gamma0 VV between 0 and 0.5 in approximate real-world 10 m resolution (IW) (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                268574.43,\n                4624494.84,\n                276045.41,\n                4631696.16,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n        },\n        \"data\": [\n            {\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    },\n                    \"resolution\": \"HIGH\",\n                    \"acquisitionMode\": \"IW\",\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"demInstance\": \"COPERNICUS_30\",\n                },\n                \"type\": \"sentinel-1-grd\",\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 10,\n        \"resy\": 10,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified with Copernicus DEM 30 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"demInstance\": \"COPERNICUS_30\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified linear gamma0 VV, ascending orbit direction, GeoTIFF in EPSG:32648 (UTM zone 48N)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1, sampleType: SampleType.FLOAT32 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                699800,\n                1190220,\n                709800,\n                1200220,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32648\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2017-11-15T00:00:00Z\",\n                        \"to\": \"2017-11-15T23:00:00Z\",\n                    },\n                    \"acquisitionMode\": \"IW\",\n                    \"polarization\": \"DV\",\n                    \"orbitDirection \": \"ASCENDING\",\n                },\n                \"processing\": {\n                    \"backCoeff\": \"GAMMA0_ELLIPSOID\",\n                    \"orthorectify\": \"true\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 1000,\n        \"height\": 1000,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nS1GRD orthorectified decibel gamma0 VH between -20 dB and 0 dB (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VH\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [toDb(samples.VH)]\n}\n\n// visualizes decibels from -20 to 0\n\nfunction toDb(linear) {\n  // the following commented out lines are simplified below\n  // var log = 10 * Math.log(linear) / Math.LN10\n  // var val = Math.max(0, (log + 20) / 20)\n  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\"orthorectify\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified decibel gamma0 RGB composite of VV, VH, VV/VH/10 between -20 dB and 0 dB (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\", \"VH\"],\n    output: { id: \"default\", bands: 3 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  var vvdB = toDb(samples.VV)\n  var vhdB = toDb(samples.VH)\n  return [vvdB, vhdB, vvdB / vhdB / 10]\n}\n\n// displays VV in decibels from -20 to 0\n\nfunction toDb(linear) {\n  // the following commented out lines are simplified below\n  // var log = 10 * Math.log(linear) / Math.LN10\n  // var val = Math.max(0, (log + 20) / 20)\n  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\"orthorectify\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD non-orthorectified linear sigma0 VH between 0 and 0.5 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VH\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VH]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"false\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD non-orthorectified Lee speckle filtered decibel gamma0 HH between -20 dB and +10 dB (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"HH\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [toDb(samples.HH)]\n}\n\n// visualizes decibels from -20 to +10\n\nfunction toDb(linear) {\n  var log = (10 * Math.log(linear)) / Math.LN10\n  return Math.max(0, (log + 20) / 30)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                18400000,\n                -11330000,\n                18500000,\n                -11430000,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"acquisitionMode\": \"EW\",\n                    \"timeRange\": {\n                        \"from\": \"2020-09-29T00:00:00Z\",\n                        \"to\": \"2020-09-29T23:59:59Z\",\n                    },\n                },\n                \"processing\": {\n                    \"orthorectify\": \"false\",\n                    \"backCoeff\": \"GAMMA0_ELLIPSOID\",\n                    \"speckleFilter\": {\n                        \"type\": \"LEE\",\n                        \"windowSizeX\": 5,\n                        \"windowSizeY\": 5,\n                    },\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 1000,\n        \"height\": 1000,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified gamma0 two month temporal averaged decibel VV between -20 dB and 0 dB (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\", \"dataMask\"],\n    output: { id: \"default\", bands: 1 },\n    mosaicking: Mosaicking.ORBIT,\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [calculateAverage(samples)]\n}\n\nfunction calculateAverage(samples) {\n  var sum = 0\n  var nValid = 0\n  for (let sample of samples) {\n    if (sample.dataMask != 0) {\n      nValid++\n      sum += toDb(sample.VV)\n    }\n  }\n  return sum / nValid\n}\n\n// visualizes decibels from -20 to 0\n\nfunction toDb(linear) {\n  // the following commented out lines are simplified below\n  // var log = 10 * Math.log(linear) / Math.LN10\n  // var val = Math.max(0, (log + 20) / 20)\n  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-01T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"ASCENDING\",\n                },\n                \"processing\": {\"orthorectify\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD radiometrically terrain corrected linear gamma0 VV between 0 and 0.5 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1095431,\n                5714610,\n                1146158,\n                5754129,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"GAMMA0_TERRAIN\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD radiometrically terrain corrected using Copernicus DEM 30 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1095431,\n                5714610,\n                1146158,\n                5754129,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"GAMMA0_TERRAIN\",\n                    \"demInstance\": \"COPERNICUS_30\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD radiometrically terrain corrected with custom DEM oversampling of 3 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1095431,\n                5714610,\n                1146158,\n                5754129,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"GAMMA0_TERRAIN\",\n                    \"radiometricTerrainOversampling\": 3,\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD radiometrically terrain corrected gamma0 VV and auxiliary data: local incidence angle, scattering area, and shadow mask\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\", \"localIncidenceAngle\", \"scatteringArea\", \"shadowMask\"],\n    output: [\n      { id: \"s1_rtc_VV_area\", bands: 2, sampleType: \"FLOAT32\" },\n      { id: \"s1_rtc_angle_mask\", bands: 2, sampleType: \"UINT8\" },\n    ],\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return {\n    s1_rtc_VV_area: [samples.VV, samples.scatteringArea],\n    s1_rtc_angle_mask: [samples.localIncidenceAngle, samples.shadowMask],\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                565556.94,\n                5048644.47,\n                600656.56,\n                5076658.33,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"GAMMA0_TERRAIN\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 796,\n        \"responses\": [\n            {\n                \"identifier\": \"s1_rtc_VV_area\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"s1_rtc_angle_mask\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})"
  },
  {
    "objectID": "APIs/OData.html",
    "href": "APIs/OData.html",
    "title": "OData",
    "section": "",
    "text": "OData (Open Data Protocol) is a standard that specifies a variety of best practices for creating and using REST APIs. OData makes it possible to build REST-based data services that let Web clients publish and edit resources that are recognized by Uniform Resource Locators (URLs) and described in a data model using straightforward HTTP messages."
  },
  {
    "objectID": "APIs/OData.html#query-structure",
    "href": "APIs/OData.html#query-structure",
    "title": "OData",
    "section": "Query structure",
    "text": "Query structure\nAs a general note, OData query consists of elements which in this documentation are called “options”. Interface supports the following search options:\n\nfilter\norderby\ntop\nskip\ncount\nexpand\n\nSearch options should always be preceded with $ and consecutive options should be separated with &.\nConsecutive filters within filter option should be separated with and or or. Not operator can also be used e.g.:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=not contains(Name,'S2') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:10:00.000Z&$orderby=ContentDate/Start&$top=100\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=not contains(Name,'S2') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:10:00.000Z&$orderby=ContentDate/Start&$top=100\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nc6d30f04-e179-582e-82bb-bf8057a8247a\nS3B_SL_2_WST____20220503T000015_20220503T00031...\napplication/octet-stream\n0\n2022-05-03T01:38:51.200Z\n2022-05-03T02:43:42.265Z\n2022-05-03T02:43:42.265Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_2_WST/2022/05/03/S...\n[]\n{'Start': '2022-05-03T00:00:15.373Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-29.4495 -39.747...\n{'type': 'Polygon', 'coordinates': [[[-29.4495...\n\n\n1\napplication/octet-stream\n6f77dc3e-c918-5b42-911a-e8213eab8929\nS3A_SL_1_RBT____20220503T000040_20220503T00034...\napplication/octet-stream\n0\n2022-05-03T02:05:26.929Z\n2022-05-03T02:06:52.440Z\n2022-05-03T02:06:52.440Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2022/05/03/S...\n[]\n{'Start': '2022-05-03T00:00:39.649Z', 'End': '...\ngeography'SRID=4326;POLYGON ((140.111 -0.07485...\n{'type': 'Polygon', 'coordinates': [[[140.111,...\n\n\n2\napplication/octet-stream\n7f265639-547d-5826-93a5-a1be345add24\nS3A_SL_2_WST____20220503T000040_20220503T00034...\napplication/octet-stream\n0\n2022-05-03T02:29:00.617Z\n2022-05-03T03:38:18.142Z\n2022-05-03T03:38:18.142Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_2_WST/2022/05/03/S...\n[]\n{'Start': '2022-05-03T00:00:39.649Z', 'End': '...\ngeography'SRID=4326;POLYGON ((140.111 -0.07485...\n{'type': 'Polygon', 'coordinates': [[[140.111,...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo accelerate the query performance it is recommended to limit the query by acquisition dates e.g.:\nContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z"
  },
  {
    "objectID": "APIs/OData.html#filter-option",
    "href": "APIs/OData.html#filter-option",
    "title": "OData",
    "section": "Filter option",
    "text": "Filter option\n\nQuery by name\nTo search for a specific product by its exact name:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Name eq 'S1A_IW_GRDH_1SDV_20141031T161924_20141031T161949_003076_003856_634E.SAFE'\n\n\n\nTo search for products containing “S1A” in their names:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nfa40dbce-3518-42b9-96c1-4e4e3bcb4f90\nS1A_20220509T171647__1A__20220427T171622_20220...\napplication/octet-stream\n772471258\n2023-07-19T11:34:47.033Z\n2023-07-19T23:42:56.451Z\n2023-07-20T13:51:20.144Z\nTrue\n\n/eodata/Sentinel-1/SAR/CARD-COH12/2022/05/09/S...\n[{'Value': '3cfd637a4eeceaa9ce9d36a928981663',...\n{'Start': '2022-05-09T17:16:47.869Z', 'End': '...\ngeography'SRID=4326;MULTIPOLYGON (((6.397713 5...\n{'type': 'MultiPolygon', 'coordinates': [[[[6....\n\n\n1\napplication/octet-stream\n9b248a46-b673-51b3-97ac-17c5131ffac0\nS1A_IW_RAW__0SSH_20220503T023424_20220503T0234...\napplication/octet-stream\n0\n2022-05-03T03:55:04.327Z\n2022-05-03T03:58:07.261Z\n2022-05-03T03:58:07.261Z\nTrue\n\n/eodata/Sentinel-1/SAR/RAW/2022/05/03/S1A_IW_R...\n[]\n{'Start': '2022-05-03T02:34:24.449Z', 'End': '...\ngeography'SRID=4326;POLYGON ((12.8671 -68.3681...\n{'type': 'Polygon', 'coordinates': [[[12.8671,...\n\n\n2\napplication/octet-stream\n84a512c0-72b7-5587-ace1-3795c6e88325\nS1A_IW_RAW__0SDV_20220503T002029_20220503T0021...\napplication/octet-stream\n0\n2022-05-03T03:50:08.811Z\n2022-05-03T04:02:26.944Z\n2022-05-03T04:02:26.944Z\nTrue\n\n/eodata/Sentinel-1/SAR/RAW/2022/05/03/S1A_IW_R...\n[]\n{'Start': '2022-05-03T00:20:29.453Z', 'End': '...\ngeography'SRID=4326;POLYGON ((87.3906 55.3996,...\n{'type': 'Polygon', 'coordinates': [[[87.3906,...\n\n\n\n\n\n\n\n\n\n\nAlternatively to contains, endswith and startswith can be used, to search for products ending or starting with provided string.\n\n\nQuery by list\nIn case a user desires to search for multiple products by name in one query, POST method can be used:\nPOST\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products/OData.CSC.FilterList\nRequest body:\n{\n  \"FilterProducts\":\n    [\n     {\"Name\": \"S1A_IW_GRDH_1SDV_20141031T161924_20141031T161949_003076_003856_634E.SAFE\"},\n     {\"Name\": \"S3B_SL_1_RBT____20190116T050535_20190116T050835_20190117T125958_0179_021_048_0000_LN2_O_NT_003.SEN3\"},\n     {\"Name\": \"xxxxxxxx.06.tar\"}\n    ]\n }\nTwo results are returned, as there is no product named xxxxxxxx.06.tar.\n\n\nQuery Collection of Products\nTo search for products within a specific collection:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:11:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:11:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n7e0f9557-d537-56bb-90a1-9b4a746f0f55\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XMQ_2...\napplication/octet-stream\n0\n2022-05-03T03:11:09.519Z\n2022-05-03T03:15:23.316Z\n2022-05-03T03:15:23.316Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-138.24152 80.05...\n{'type': 'Polygon', 'coordinates': [[[-138.241...\n\n\n1\napplication/octet-stream\n9c2fa572-0267-50ca-9d71-3c46881486b7\nS2B_MSIL1C_20220503T000139_N0400_R016_T10XDP_2...\napplication/octet-stream\n0\n2022-05-03T01:43:12.773Z\n2022-05-03T01:47:06.958Z\n2022-05-03T01:47:06.958Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-122.49541 80.01...\n{'type': 'Polygon', 'coordinates': [[[-122.495...\n\n\n2\napplication/octet-stream\n89ed3e3a-0836-585f-a35d-53695cb8b2af\nS2B_MSIL1C_20220503T000139_N0400_R016_T09XWJ_2...\napplication/octet-stream\n0\n2022-05-03T01:42:12.340Z\n2022-05-03T01:45:30.803Z\n2022-05-03T01:45:30.803Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-123.3304 79.985...\n{'type': 'Polygon', 'coordinates': [[[-123.330...\n\n\n\n\n\n\n\n\n\n\nThe following collections are currently available:\n\nCopernicus Sentinel Mission\n\nSentinel1 or SENTINEL-1\nSentinel2 or SENTINEL-2\nSentinel3 or SENTINEL-3\nSentinel5P or SENTINEL-5P\n\nComplementary data\n\nSoil Moisture and Ocean Salinity (SMOS)\nENVISAT- Medium Resolution Imaging Spectrometer (MERIS)\nLandsat5 or Landsat-5\nLandsat7 or Landsat-7\nLandsat8 or Landsat-8\nCopernicus Atmosphere Monitoring Service (CAMS)\nCopernicus Emergency Management Service (CEMS)\nCopernicus Land Monitoring Service (CLMS)\nCopernicus Marine Service (CMEMS)\nAdditional\nVHR Commercial Data\n\n\n\n\nQuery by Publication Date\nTo search for products published between two dates:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate gt 2019-05-15T00:00:00.000Z and PublicationDate lt 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate gt 2019-05-15T00:00:00.000Z and PublicationDate lt 2019-05-16T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nd04a4c2a-30e3-51a6-9706-d3dcf07a1ce6\nS3A_SL_1_RBT____20160429T140836_20160429T14113...\napplication/octet-stream\n0\n2019-03-20T18:25:19.702Z\n2019-05-15T00:01:01.985Z\n2019-05-15T00:01:01.985Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/29/S...\n[]\n{'Start': '2016-04-29T14:08:35.710Z', 'End': '...\ngeography'SRID=4326;POLYGON ((146.907 -55.5281...\n{'type': 'Polygon', 'coordinates': [[[146.907,...\n\n\n1\napplication/octet-stream\n989fd7a2-c67e-55be-ae63-5b911b600878\nS3A_SL_1_RBT____20160427T120458_20160427T12075...\napplication/octet-stream\n0\n2019-03-20T18:11:16.405Z\n2019-05-15T00:01:02.228Z\n2019-05-15T00:01:02.228Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/27/S...\n[]\n{'Start': '2016-04-27T12:04:58.305Z', 'End': '...\ngeography'SRID=4326;POLYGON ((153.039 33.665, ...\n{'type': 'Polygon', 'coordinates': [[[153.039,...\n\n\n2\napplication/octet-stream\nd34281f0-85bd-508a-a3fc-a9bb09d98f79\nS3A_SL_1_RBT____20160426T154708_20160426T15500...\napplication/octet-stream\n0\n2019-03-20T20:54:18.034Z\n2019-05-15T00:01:03.032Z\n2019-05-15T00:01:03.032Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/26/S...\n[]\n{'Start': '2016-04-26T15:47:07.654Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.745 12.6377, ...\n{'type': 'Polygon', 'coordinates': [[[99.745, ...\n\n\n\n\n\n\n\n\n\n\nTo define inclusive interval ge and le parameters can be used:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate ge 2019-05-15T00:00:00.000Z and PublicationDate le 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate ge 2019-05-15T00:00:00.000Z and PublicationDate le 2019-05-16T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nd04a4c2a-30e3-51a6-9706-d3dcf07a1ce6\nS3A_SL_1_RBT____20160429T140836_20160429T14113...\napplication/octet-stream\n0\n2019-03-20T18:25:19.702Z\n2019-05-15T00:01:01.985Z\n2019-05-15T00:01:01.985Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/29/S...\n[]\n{'Start': '2016-04-29T14:08:35.710Z', 'End': '...\ngeography'SRID=4326;POLYGON ((146.907 -55.5281...\n{'type': 'Polygon', 'coordinates': [[[146.907,...\n\n\n1\napplication/octet-stream\n989fd7a2-c67e-55be-ae63-5b911b600878\nS3A_SL_1_RBT____20160427T120458_20160427T12075...\napplication/octet-stream\n0\n2019-03-20T18:11:16.405Z\n2019-05-15T00:01:02.228Z\n2019-05-15T00:01:02.228Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/27/S...\n[]\n{'Start': '2016-04-27T12:04:58.305Z', 'End': '...\ngeography'SRID=4326;POLYGON ((153.039 33.665, ...\n{'type': 'Polygon', 'coordinates': [[[153.039,...\n\n\n2\napplication/octet-stream\nd34281f0-85bd-508a-a3fc-a9bb09d98f79\nS3A_SL_1_RBT____20160426T154708_20160426T15500...\napplication/octet-stream\n0\n2019-03-20T20:54:18.034Z\n2019-05-15T00:01:03.032Z\n2019-05-15T00:01:03.032Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/26/S...\n[]\n{'Start': '2016-04-26T15:47:07.654Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.745 12.6377, ...\n{'type': 'Polygon', 'coordinates': [[[99.745, ...\n\n\n\n\n\n\n\n\n\n\n\n\nQuery by Sensing Date\nTo search for products acquired between two dates:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/Start lt 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/Start lt 2019-05-16T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nb76d70b2-7dd0-5b10-8727-a5979d828f57\nS1B_IW_RAW__0SDV_20190515T000001_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T04:38:19.893Z\n2019-05-15T04:45:10.989Z\n2019-05-15T04:45:10.989Z\nFalse\n\n/eodata/Sentinel-1/SAR/RAW/2019/05/15/S1B_IW_R...\n[]\n{'Start': '2019-05-15T00:00:01.539Z', 'End': '...\ngeography'SRID=4326;POLYGON ((95.0159 66.2881,...\n{'type': 'Polygon', 'coordinates': [[[95.0159,...\n\n\n1\napplication/octet-stream\n8bf7e312-2ea0-5288-abdb-01b1da9cc26b\nS1B_IW_SLC__1SDV_20190515T000004_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T00:00:04.000Z\n2019-05-15T05:39:50.376Z\n2019-05-15T05:39:50.376Z\nFalse\n\n/eodata/Sentinel-1/SAR/SLC/2019/05/15/S1B_IW_S...\n[]\n{'Start': '2019-05-15T00:00:04.536Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.446007 64.201...\n{'type': 'Polygon', 'coordinates': [[[99.44600...\n\n\n2\napplication/octet-stream\n4e4fddce-ad73-5b6c-94fc-04f721d96f94\nS1B_IW_GRDH_1SDV_20190515T000005_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T04:57:32.023Z\n2019-05-15T05:10:44.190Z\n2019-05-15T05:10:44.190Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2019/05/15/S1B_IW_G...\n[]\n{'Start': '2019-05-15T00:00:05.238Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.487076 64.276...\n{'type': 'Polygon', 'coordinates': [[[99.48707...\n\n\n\n\n\n\n\n\n\n\nUsually, there are two parameters describing the ContentDate (Acquisition Dates) for a product - Start and End. Depending on what the user is looking for, these parameters can be mixed, e.g.,:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/End lt 2019-05-15T00:05:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/End lt 2019-05-15T00:05:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nb76d70b2-7dd0-5b10-8727-a5979d828f57\nS1B_IW_RAW__0SDV_20190515T000001_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T04:38:19.893Z\n2019-05-15T04:45:10.989Z\n2019-05-15T04:45:10.989Z\nFalse\n\n/eodata/Sentinel-1/SAR/RAW/2019/05/15/S1B_IW_R...\n[]\n{'Start': '2019-05-15T00:00:01.539Z', 'End': '...\ngeography'SRID=4326;POLYGON ((95.0159 66.2881,...\n{'type': 'Polygon', 'coordinates': [[[95.0159,...\n\n\n1\napplication/octet-stream\n8bf7e312-2ea0-5288-abdb-01b1da9cc26b\nS1B_IW_SLC__1SDV_20190515T000004_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T00:00:04.000Z\n2019-05-15T05:39:50.376Z\n2019-05-15T05:39:50.376Z\nFalse\n\n/eodata/Sentinel-1/SAR/SLC/2019/05/15/S1B_IW_S...\n[]\n{'Start': '2019-05-15T00:00:04.536Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.446007 64.201...\n{'type': 'Polygon', 'coordinates': [[[99.44600...\n\n\n2\napplication/octet-stream\n4e4fddce-ad73-5b6c-94fc-04f721d96f94\nS1B_IW_GRDH_1SDV_20190515T000005_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T04:57:32.023Z\n2019-05-15T05:10:44.190Z\n2019-05-15T05:10:44.190Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2019/05/15/S1B_IW_G...\n[]\n{'Start': '2019-05-15T00:00:05.238Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.487076 64.276...\n{'type': 'Polygon', 'coordinates': [[[99.48707...\n\n\n\n\n\n\n\n\n\n\n\n\nQuery by Geographic Criteria\nTo search for products intersecting the specified polygon:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((12.655118166047592 47.44667197521409,21.39065656328509 48.347694733853245,28.334291357162826 41.877123516783655,17.47086198383573 40.35854475076158,12.655118166047592 47.44667197521409))') and ContentDate/Start gt 2022-05-20T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((12.655118166047592 47.44667197521409,21.39065656328509 48.347694733853245,28.334291357162826 41.877123516783655,17.47086198383573 40.35854475076158,12.655118166047592 47.44667197521409))') and ContentDate/Start gt 2022-05-20T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n0d3b8cf1-01fb-5f7e-820a-1d5442875575\nLC08_L1TP_180031_20220520_20220520_02_RT\napplication/octet-stream\n0\n2022-05-20T08:45:20.510Z\n2022-05-22T08:08:13.816Z\n2022-05-22T08:08:13.816Z\nTrue\n\n/eodata/Landsat-8/OLI_TIRS/L1TP/2022/05/20/LC0...\n[]\n{'Start': '2022-05-20T08:45:20.510Z', 'End': '...\ngeography'SRID=4326;POLYGON ((27.73522 42.821,...\n{'type': 'Polygon', 'coordinates': [[[27.73522...\n\n\n1\napplication/octet-stream\nd3b5fbd9-9ffd-579b-b327-4de3e8502591\nLC08_L2SP_180031_20220520_20220525_02_T1\napplication/octet-stream\n0\n2022-05-20T08:45:20.510Z\n2022-05-27T12:43:58.554Z\n2022-05-27T12:43:58.554Z\nTrue\n\n/eodata/Landsat-8/OLI_TIRS/L2SP/2022/05/20/LC0...\n[]\n{'Start': '2022-05-20T08:45:20.510Z', 'End': '...\ngeography'SRID=4326;POLYGON ((27.73522 42.821,...\n{'type': 'Polygon', 'coordinates': [[[27.73522...\n\n\n2\napplication/octet-stream\n0bfcd52a-1c10-5870-820a-7282032fe8e4\nLC08_L1TP_180031_20220520_20220525_02_T1\napplication/octet-stream\n0\n2022-05-20T08:45:20.510Z\n2022-05-27T15:38:46.726Z\n2022-05-27T15:38:46.726Z\nTrue\n\n/eodata/Landsat-8/OLI_TIRS/L1TP/2022/05/20/LC0...\n[]\n{'Start': '2022-05-20T08:45:20.510Z', 'End': '...\ngeography'SRID=4326;POLYGON ((27.73522 42.821,...\n{'type': 'Polygon', 'coordinates': [[[27.73522...\n\n\n\n\n\n\n\n\n\n\nTo search for products intersecting the specified point:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography%27SRID=4326;POINT(-0.5319577002158441%2028.65487836189358)%27)\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography%27SRID=4326;POINT(-0.5319577002158441%2028.65487836189358)%27)\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n57b778d5-1caa-5731-a0d8-c08ec2881f3a\nLS05_RFUI_TM__GTC_1P_19841212T100352_19841212T...\napplication/octet-stream\n0\n2018-04-01T00:00:00.000Z\n2016-07-09T19:59:41.313Z\n2016-07-09T19:59:41.313Z\nTrue\n\n/eodata/Landsat-5/TM/L1T/1984/12/12/LS05_RFUI_...\n[]\n{'Start': '1984-12-12T10:04:06.279Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-1.9295636 29.80...\n{'type': 'Polygon', 'coordinates': [[[-1.92956...\n\n\n1\napplication/octet-stream\n8a7038bd-5726-5a01-a525-03c120a5f576\nLS05_RFUI_TM__GTC_1P_19841228T100400_19841228T...\napplication/octet-stream\n0\n2018-04-01T00:00:00.000Z\n2016-07-09T20:07:49.022Z\n2016-07-09T20:07:49.022Z\nTrue\n\n/eodata/Landsat-5/TM/L1T/1984/12/28/LS05_RFUI_...\n[]\n{'Start': '1984-12-28T10:04:15.198Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-1.9485325 29.80...\n{'type': 'Polygon', 'coordinates': [[[-1.94853...\n\n\n2\napplication/octet-stream\n0a1b561c-9e68-52db-977c-95a2c1894d40\nLS05_RFUI_TM__GTC_1P_19841110T100341_19841110T...\napplication/octet-stream\n0\n2018-04-01T00:00:00.000Z\n2016-07-09T20:20:01.402Z\n2016-07-09T20:20:01.402Z\nTrue\n\n/eodata/Landsat-5/TM/L1T/1984/11/10/LS05_RFUI_...\n[]\n{'Start': '1984-11-10T10:03:56.077Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-1.9362267 29.80...\n{'type': 'Polygon', 'coordinates': [[[-1.93622...\n\n\n\n\n\n\n\n\n\n\nDisclaimers:\n\nMULTIPOLYGON is currently not supported.\nPolygon must start and end with the same point.\nCoordinates must be given in EPSG 4326\n\n\n\nQuery by attributes\nTo search for products by attributes it is necessary to build a filter with the following structure:\nAttributes/OData.CSC.ValueTypeAttribute/any(att:att/Name eq ‘[Attribute.Name]’ and att/OData.CSC.ValueTypeAttribute/Value eq ‘[Attribute.Value]’)\nwhere\n\nValueTypeAttribute can take the following values:\n\nStringAttribute\nDoubleAttribute\nIntegerAttribute\nDateTimeOffsetAttribute\n\n[Attribute.Name] is the attribute name which can take multiple values, depending on collection (Attachment 1 - Coming soon)\neq before [Attribute.Value] can be substituted with le, lt, ge, gt in case of Integer, Double or DateTimeOffset Attributes\n[Attribute.Value] is the specific value that the user is searching for\n\nTo get products with CloudCover&lt;40% between two dates:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 40.00) and ContentDate/Start gt 2022-01-01T00:00:00.000Z and ContentDate/Start lt 2022-01-03T00:00:00.000Z&$top=10\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 40.00) and ContentDate/Start gt 2022-01-01T00:00:00.000Z and ContentDate/Start lt 2022-01-03T00:00:00.000Z&$top=10\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n13bf9e1e-e9e2-52fb-9274-5430131d3099\nS2B_MSIL1C_20220101T000459_N0301_R130_T52DDF_2...\napplication/octet-stream\n0\n2022-01-01T01:46:51.240Z\n2022-01-01T01:52:04.546Z\n2022-01-01T01:52:04.546Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/01/01/S2B_MSIL...\n[]\n{'Start': '2022-01-01T00:04:59.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((126.22039161156 ...\n{'type': 'Polygon', 'coordinates': [[[126.2203...\n\n\n1\napplication/octet-stream\n38325a36-9439-5488-97b0-765f81435e1a\nS2B_MSIL2A_20220101T000459_N0301_R130_T48CWV_2...\napplication/octet-stream\n0\n2022-01-01T02:36:06.713Z\n2022-06-06T14:26:12.464Z\n2022-06-06T14:26:12.464Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/01/01/S2B_MSIL...\n[]\n{'Start': '2022-01-01T00:04:59.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((108.48785184065 ...\n{'type': 'Polygon', 'coordinates': [[[108.4878...\n\n\n2\napplication/octet-stream\n487c8a1f-3740-5f0c-af8d-6b242922ba26\nS2B_MSIL2A_20220101T000459_N0301_R130_T50CNA_2...\napplication/octet-stream\n0\n2022-01-01T02:39:13.878Z\n2022-06-06T14:26:05.912Z\n2022-06-06T14:26:05.912Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/01/01/S2B_MSIL...\n[]\n{'Start': '2022-01-01T00:04:59.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((116.9992753763 -...\n{'type': 'Polygon', 'coordinates': [[[116.9992...\n\n\n\n\n\n\n\n\n\n\nTo get products with cloudCover&lt; 10% and productType=S2MSI2A and ASCENDING orbitDirection between two dates:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value lt 10.00) and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'orbitDirection' and att/OData.CSC.StringAttribute/Value eq 'ASCENDING') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T04:00:00.000Z&$top=10\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value lt 10.00) and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'orbitDirection' and att/OData.CSC.StringAttribute/Value eq 'ASCENDING') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T04:00:00.000Z&$top=10\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n7e0f9557-d537-56bb-90a1-9b4a746f0f55\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XMQ_2...\napplication/octet-stream\n0\n2022-05-03T03:11:09.519Z\n2022-05-03T03:15:23.316Z\n2022-05-03T03:15:23.316Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-138.24152 80.05...\n{'type': 'Polygon', 'coordinates': [[[-138.241...\n\n\n1\napplication/octet-stream\na3041799-63e6-5b61-a16a-cb5bfabce2aa\nS2B_MSIL2A_20220503T000139_N0400_R016_T09XVJ_2...\napplication/octet-stream\n0\n2022-05-03T03:12:19.810Z\n2022-05-03T03:17:14.301Z\n2022-05-03T03:17:14.301Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-128.50604 79.78...\n{'type': 'Polygon', 'coordinates': [[[-128.506...\n\n\n2\napplication/octet-stream\n716d55e7-ee2a-5985-afed-4ca073864ca9\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XNQ_2...\napplication/octet-stream\n0\n2022-05-03T02:55:20.511Z\n2022-05-03T02:59:59.363Z\n2022-05-03T02:59:59.363Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-135.00116 81.06...\n{'type': 'Polygon', 'coordinates': [[[-135.001...\n\n\n\n\n\n\n\n\n\n\n\n\nOrderby option\nOrderby option can be used to order the products in an ascending (asc) or descending (desc) direction. If asc or desc not specified, then the resources will be ordered in ascending order.\nTo order products by ContentDate/Start in a descending direction:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A_EW_GRD') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T03:00:00.000Z&$orderby=ContentDate/Start desc\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A_EW_GRD') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T03:00:00.000Z&$orderby=ContentDate/Start desc\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n6928b379-4f9a-5473-a12a-7e7e4b83f776\nS1A_EW_GRDM_1SSH_20220503T024410_20220503T0244...\napplication/octet-stream\n0\n2022-05-03T04:06:31.762Z\n2022-05-03T04:11:15.920Z\n2022-05-03T04:11:15.920Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T02:44:10.981Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-105.464699 -67....\n{'type': 'Polygon', 'coordinates': [[[-105.464...\n\n\n1\napplication/octet-stream\n9b4e3124-fa8e-4ea7-b43e-d5f08297ea8c\nS1A_EW_GRDM_1SSH_20220503T024410_20220503T0244...\napplication/octet-stream\n78609172\n2023-05-20T19:44:03.069Z\n2023-05-20T21:45:18.079Z\n2023-05-20T21:45:18.079Z\nTrue\n\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n[{}]\n{'Start': '2022-05-03T02:44:10.981Z', 'End': '...\ngeography'SRID=4326;MULTIPOLYGON (((-103.09848...\n{'type': 'MultiPolygon', 'coordinates': [[[[-1...\n\n\n2\napplication/octet-stream\n2abd9bf9-7a35-4916-8bf5-34727d71da1b\nS1A_EW_GRDM_1SSH_20220503T024310_20220503T0244...\napplication/octet-stream\n164573262\n2023-05-20T19:46:01.280Z\n2023-05-20T21:47:32.929Z\n2023-05-20T21:47:32.929Z\nTrue\n\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n[{}]\n{'Start': '2022-05-03T02:43:10.982Z', 'End': '...\ngeography'SRID=4326;MULTIPOLYGON (((-97.269363...\n{'type': 'MultiPolygon', 'coordinates': [[[[-9...\n\n\n\n\n\n\n\n\n\n\nBy default, if orderby option is not used, the results are not ordered. If orderby option is used, additional orderby by id is also used, so that the results are fully ordered and no products are lost while paginating through the results.\nThe acceptable arguments for this option: ContentDate/Start, ContentDate/End, PublicationDate, ModificationDate, in directions: asc, desc.\n\n\nTop option\nTop option specifies the maximum number of items returned from a query.\nTo limit the number of results:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$top=100\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$top=100\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nfe37ae5f-153b-511c-89b9-dcc059c86489\nS1A_EW_GRDM_1SDH_20220503T033034_20220503T0331...\napplication/octet-stream\n0\n2022-05-03T04:04:31.386Z\n2022-05-03T04:09:06.657Z\n2022-05-03T04:09:06.657Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:30:34.272Z', 'End': '...\ngeography'SRID=4326;POLYGON ((64.757805 76.819...\n{'type': 'Polygon', 'coordinates': [[[64.75780...\n\n\n1\napplication/octet-stream\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\napplication/octet-stream\n0\n2022-05-03T06:04:33.053Z\n2022-05-03T06:09:16.562Z\n2022-05-03T06:09:16.562Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T05:10:20.362Z', 'End': '...\ngeography'SRID=4326;POLYGON ((34.926594 74.394...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n\n\n2\napplication/octet-stream\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\napplication/octet-stream\n0\n2022-05-03T08:54:32.861Z\n2022-05-03T08:59:36.441Z\n2022-05-03T08:59:36.441Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T06:48:00.855Z', 'End': '...\ngeography'SRID=4326;POLYGON ((15.664783 76.959...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n\n\n\n\n\n\n\n\n\n\nThe default value is set to 20.\nThe acceptable arguments for this option: Integer &lt;0,1000&gt;"
  },
  {
    "objectID": "APIs/OData.html#skip-option",
    "href": "APIs/OData.html#skip-option",
    "title": "OData",
    "section": "Skip option",
    "text": "Skip option\nSkip option can be used to skip a specific number of results. Exemplary application of this option would be paginating through the results, however for performance reasons, we recommend limiting queries with small time intervals as a substitute of using skip in a more generic query.\nTo skip a specific number of results:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$skip=23\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$skip=23\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n47921038-e7ca-56d0-9a9a-7192dec36de0\nS1A_EW_GRDM_1SDH_20220503T114448_20220503T1145...\napplication/octet-stream\n0\n2022-05-03T13:00:31.219Z\n2022-05-03T13:07:21.060Z\n2022-05-03T13:07:21.060Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T11:44:48.791Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-62.467339 75.12...\n{'type': 'Polygon', 'coordinates': [[[-62.4673...\n\n\n1\napplication/octet-stream\n35d932b2-715f-521b-9dbe-612d6edc4d1c\nS1A_EW_GRDM_1SDH_20220503T033138_20220503T0332...\napplication/octet-stream\n0\n2022-05-03T04:05:38.338Z\n2022-05-03T04:08:53.811Z\n2022-05-03T04:08:53.811Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:31:38.586Z', 'End': '...\ngeography'SRID=4326;POLYGON ((58.356129 73.551...\n{'type': 'Polygon', 'coordinates': [[[58.35612...\n\n\n2\napplication/octet-stream\n81738432-1e5c-5419-9be9-4aada9160f7c\nS1A_EW_GRDM_1SDH_20220503T033338_20220503T0334...\napplication/octet-stream\n0\n2022-05-03T04:05:37.842Z\n2022-05-03T04:09:03.217Z\n2022-05-03T04:09:03.217Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:33:38.585Z', 'End': '...\ngeography'SRID=4326;POLYGON ((50.733326 66.705...\n{'type': 'Polygon', 'coordinates': [[[50.73332...\n\n\n\n\n\n\n\n\n\n\nThe default value is set to 0.\nWhenever a query results in more products than 20 (default top value), the API provides a nextLink at the bottom of the page:\n\"@OData.nextLink\":\n\nHTTP RequestPython\n\n\nhttp://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A_EW_GRD')+and+ContentDate/Start+gt+2022-05-03T00:00:00.000Z+and+ContentDate/Start+lt+2022-05-03T12:00:00.000Z&$skip=20\n\n\n\n\nCode\njson = requests.get(\"http://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A_EW_GRD')+and+ContentDate/Start+gt+2022-05-03T00:00:00.000Z+and+ContentDate/Start+lt+2022-05-03T12:00:00.000Z&$skip=20\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n01f4c791-29d8-528b-8d91-3de9b76c2f28\nS1A_EW_GRDM_1SDH_20220503T091826_20220503T0919...\napplication/octet-stream\n0\n2022-05-03T11:35:04.805Z\n2022-05-03T11:35:00.341Z\n2022-05-03T11:35:00.341Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T09:18:26.004Z', 'End': '...\ngeography'SRID=4326;POLYGON ((156.800079 -67.9...\n{'type': 'Polygon', 'coordinates': [[[156.8000...\n\n\n1\napplication/octet-stream\na46c4820-96f4-55f7-9ee0-bb897597ad20\nS1A_EW_GRDM_1SDH_20220503T115007_20220503T1150...\napplication/octet-stream\n0\n2022-05-03T12:54:33.343Z\n2022-05-03T12:58:57.927Z\n2022-05-03T12:58:57.927Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T11:50:07.829Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-77.549103 59.06...\n{'type': 'Polygon', 'coordinates': [[[-77.5491...\n\n\n2\napplication/octet-stream\nbf7bec9a-3b52-5923-933c-6167eeae8f23\nS1A_EW_GRDM_1SDH_20220503T114553_20220503T1147...\napplication/octet-stream\n0\n2022-05-03T13:05:39.033Z\n2022-05-03T13:06:05.763Z\n2022-05-03T13:06:05.763Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T11:45:53.092Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-68.278107 71.26...\n{'type': 'Polygon', 'coordinates': [[[-68.2781...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: Integer &lt;0,10000&gt;"
  },
  {
    "objectID": "APIs/OData.html#count-option",
    "href": "APIs/OData.html#count-option",
    "title": "OData",
    "section": "Count option",
    "text": "Count option\nCount option enables users to get the exact number of products matching the query. This option is disabled by default to accelerate the query performance.\nTo get the exact number of products for a given query:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$count=True\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$count=True\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nfe37ae5f-153b-511c-89b9-dcc059c86489\nS1A_EW_GRDM_1SDH_20220503T033034_20220503T0331...\napplication/octet-stream\n0\n2022-05-03T04:04:31.386Z\n2022-05-03T04:09:06.657Z\n2022-05-03T04:09:06.657Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:30:34.272Z', 'End': '...\ngeography'SRID=4326;POLYGON ((64.757805 76.819...\n{'type': 'Polygon', 'coordinates': [[[64.75780...\n\n\n1\napplication/octet-stream\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\napplication/octet-stream\n0\n2022-05-03T06:04:33.053Z\n2022-05-03T06:09:16.562Z\n2022-05-03T06:09:16.562Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T05:10:20.362Z', 'End': '...\ngeography'SRID=4326;POLYGON ((34.926594 74.394...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n\n\n2\napplication/octet-stream\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\napplication/octet-stream\n0\n2022-05-03T08:54:32.861Z\n2022-05-03T08:59:36.441Z\n2022-05-03T08:59:36.441Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T06:48:00.855Z', 'End': '...\ngeography'SRID=4326;POLYGON ((15.664783 76.959...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: True, true, 1, False, false, 0."
  },
  {
    "objectID": "APIs/OData.html#expand-option",
    "href": "APIs/OData.html#expand-option",
    "title": "OData",
    "section": "Expand option",
    "text": "Expand option\nExpand option enables users to see full metadata of each returned result.\nTo see the metadata of the results:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$expand=Attributes\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$expand=Attributes\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\nAttributes\n\n\n\n\n0\napplication/octet-stream\nfe37ae5f-153b-511c-89b9-dcc059c86489\nS1A_EW_GRDM_1SDH_20220503T033034_20220503T0331...\napplication/octet-stream\n0\n2022-05-03T04:04:31.386Z\n2022-05-03T04:09:06.657Z\n2022-05-03T04:09:06.657Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:30:34.272Z', 'End': '...\ngeography'SRID=4326;POLYGON ((64.757805 76.819...\n{'type': 'Polygon', 'coordinates': [[[64.75780...\n[{'@odata.type': '#OData.CSC.StringAttribute',...\n\n\n1\napplication/octet-stream\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\napplication/octet-stream\n0\n2022-05-03T06:04:33.053Z\n2022-05-03T06:09:16.562Z\n2022-05-03T06:09:16.562Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T05:10:20.362Z', 'End': '...\ngeography'SRID=4326;POLYGON ((34.926594 74.394...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n[{'@odata.type': '#OData.CSC.StringAttribute',...\n\n\n2\napplication/octet-stream\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\napplication/octet-stream\n0\n2022-05-03T08:54:32.861Z\n2022-05-03T08:59:36.441Z\n2022-05-03T08:59:36.441Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T06:48:00.855Z', 'End': '...\ngeography'SRID=4326;POLYGON ((15.664783 76.959...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n[{'@odata.type': '#OData.CSC.StringAttribute',...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: Attributes and Assets\n\nExpand assets\nExpand assets allows to list additional assets of a products, including quicklooks:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%20%27SL_2_FRP___%27)&$expand=Assets\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%20%27SL_2_FRP___%27)&$expand=Assets\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\nAssets\n\n\n\n\n0\napplication/octet-stream\n766ef285-4ca4-4767-9984-ed42661e3e35\nS3A_SL_2_FRP____20200821T042815_20200821T04311...\napplication/octet-stream\n77907851\n2020-08-22T08:14:05.178Z\n2023-03-27T13:15:17.110Z\n2023-03-27T13:15:17.110Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_2_FRP___/2020/08/2...\n[{}]\n{'Start': '2020-08-21T04:28:15.129Z', 'End': '...\ngeography'SRID=4326;POLYGON ((76.9487 31.4864,...\n{'type': 'Polygon', 'coordinates': [[[76.9487,...\n[{'Type': 'QUICKLOOK', 'Id': 'f4a87522-dd81-4c...\n\n\n1\napplication/octet-stream\n22a4164c-0f10-40be-b6e9-99b57c8ec4c5\nS3A_SL_2_FRP____20200829T194738_20200829T19503...\napplication/octet-stream\n68116839\n2020-08-30T23:56:14.973Z\n2023-03-27T13:15:21.211Z\n2023-03-27T13:15:21.211Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_2_FRP___/2020/08/2...\n[{}]\n{'Start': '2020-08-29T19:47:38.058Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-163.63 -31.3036...\n{'type': 'Polygon', 'coordinates': [[[-163.63,...\n[{'Type': 'QUICKLOOK', 'Id': '9a58cb8d-1579-42...\n\n\n2\napplication/octet-stream\n59a4cbb8-4a8b-4c44-8bf8-4aefd1b3b39a\nS3A_SL_2_FRP____20200829T200238_20200829T20053...\napplication/octet-stream\n73790765\n2020-08-30T23:43:29.087Z\n2023-03-27T13:15:26.211Z\n2023-03-27T13:15:26.211Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_2_FRP___/2020/08/2...\n[{}]\n{'Start': '2020-08-29T20:02:38.058Z', 'End': '...\ngeography'SRID=4326;MULTIPOLYGON (((180 -81.58...\n{'type': 'MultiPolygon', 'coordinates': [[[[18...\n[{'Type': 'QUICKLOOK', 'Id': '333d5df0-64c7-48...\n\n\n\n\n\n\n\n\n\n\n\n\nQuicklook\nFor example, a quicklook for product S3A_SL_2_FRP____20200821T042815_20200821T043115_20200822T092750_0179_062_033_2340_LN2_O_NT_004.SEN3 with ID of a quicklook f4a87522-dd81-4c40-856e-41d40510e3b6, can be downloaded with the request:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Assets(f4a87522-dd81-4c40-856e-41d40510e3b6)/$value\n\n\n\nDownload link is also available under DownloadLink parameter in Assets."
  },
  {
    "objectID": "APIs/OData.html#product-download",
    "href": "APIs/OData.html#product-download",
    "title": "OData",
    "section": "Product Download",
    "text": "Product Download\nFor downloading products you need an authorization token as only authorized users are allowed to download data products.\nTo get the token you can use the following scripts:\n\ncURL\n\n\ncurl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n  --header 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'grant_type=password' \\\n  --data-urlencode 'username=&lt;LOGIN&gt;' \\\n  --data-urlencode 'password=&lt;PASSWORD&gt;' \\\n  --data-urlencode 'client_id=cdse-public'\n\n\n\nor \n\ncURL\n\n\ncurl -d 'client_id=cdse-public' -d 'username=&lt;LOGIN&gt;' -d 'password=&lt;PASSWORD&gt;' -d 'grant_type=password' 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | python3 -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}'\n\n\n\nAlong with the Access Token you will be returned a Refresh Token, the latter is used to generate a new Access Token without the need to specify Username or Password, this helps to make requests less vulnerable to your credentials being exposed.\nTo re-generate the Access Token from the Refresh Token it can be done with the following request:\n\ncURL\n\n\ncurl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n  --header 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'grant_type=refresh_token' \\\n  --data-urlencode 'refresh_token=&lt;REFRESH_TOKEN&gt;' \\\n  --data-urlencode 'client_id=cdse-public'\n\n\n\n\n\nOnce you have your token, you require a product Id which can be found in the response of the products search: https://catalogue.dataspace.copernicus.eu/odata/v1/Products\nFinally, you can download the product using this script:\n\ncURL\n\n\ncurl -H \"Authorization: Bearer $ACCESS_TOKEN\" 'https://catalogue.dataspace.copernicus.eu/odata/v1/Products(060882f4-0a34-5f14-8e25-6876e4470b0d)/$value' --location-trusted --output /tmp/product.zip\n\n\n\nor\n\nWget\n\n\n!wget  --header \"Authorization: Bearer $ACCESS_TOKEN\" 'http://catalogue.dataspace.copernicus.eu/odata/v1/Products(db0c8ef3-8ec0-5185-a537-812dad3c58f8)/$value' -O example_odata.zip\n\n\n\n\nPython\n\n\nimport requests\nsession = requests.Session()\nsession.headers.update({'Authorization': f'Bearer {access_token}'})\nurl = f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products(db0c8ef3-8ec0-5185-a537-812dad3c58f8)/$value\"\nresponse = session.get(url, allow_redirects=False)\nwhile response.status_code in (301, 302, 303, 307):\n    url = response.headers['Location']\n    response = session.get(url, allow_redirects=False)\n\nfile = session.get(url, verify=False, allow_redirects=True)\n\nwith open(f\"product.zip\", 'wb') as p:\n    p.write(file.content)"
  },
  {
    "objectID": "APIs/Token.html",
    "href": "APIs/Token.html",
    "title": "Copernicus Data Space Ecosystem Token Generation",
    "section": "",
    "text": "In order to download products from CDSE catalogue using OData and OpenSearch API user are required to have an Keycloak token. This token can be generated in both Linux and Window OS using either cURL or python script."
  },
  {
    "objectID": "APIs/Token.html#by-query-with-curl",
    "href": "APIs/Token.html#by-query-with-curl",
    "title": "Copernicus Data Space Ecosystem Token Generation",
    "section": "By query with cURL",
    "text": "By query with cURL\nCURL is a tool to send data to the server using several protocols such as HTTP.\nOn Linux:\nIn this example, the output is being filtered by grep and awk commands to obtain a token. In the Linux operating system it’s being seen as environmental variable KEYCLOAK_TOKEN.\n\ncURL\n\n\nexport KEYCLOAK_TOKEN=$(curl -d 'client_id=cdse-public' \\\n                    -d \"username=&lt;username&gt;\" \\\n                    -d \"password=&lt;password&gt;\" \\\n                    -d 'grant_type=password' \\\n                    'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | \\\n                    python3 -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}')\n\n\n\n\nYou can use following command to print the token:\nprintenv KEYCLOAK_TOKEN\nOn Windows:\n\ncURL\n\n\ncurl -s -X POST https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token -H \"Content-Type: application/x-www-form-urlencoded\" -d \"username=&lt;username&gt;\" -d \"password=&lt;password&gt;\" -d \"grant_type=password\" -d \"client_id=cdse-public\"\n\n\n\n\nFor commands to work you need to replace “&lt;username&gt;” and “&lt;password&gt;” with your Copernicus Data Space Ecosystem login credentials"
  },
  {
    "objectID": "APIs/Token.html#by-python-script",
    "href": "APIs/Token.html#by-python-script",
    "title": "Copernicus Data Space Ecosystem Token Generation",
    "section": "By Python script",
    "text": "By Python script\n\nPython\n\n\n\nimport json\nimport requests\ndef get_keycloak(username: str, password: str) -&gt; str:\n    data = {\n        \"client_id\": \"cdse-public\",\n        \"username\": username,\n        \"password\": password,\n        \"grant_type\": \"password\",\n        }\n    try:\n        r = requests.post(\"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n        data=data,\n        )\n        r.raise_for_status()\n    except Exception as e:\n        raise Exception(\n            f\"Keycloak token creation failed. Reponse from the server was: {r.json()}\"\n            )\n    return r.json()[\"access_token\"]\n        \n\nkeycloak_token = get_keycloak(\"USERNAME\", \"PASSWORD\")\n\n\n\n\nPlease replace the USERNAME and PASSWORD text in the last line of the script with your Copernicus Data Space Ecosystem login credentials.\nIn case you have any questions, please contact our support."
  },
  {
    "objectID": "APIs/Traceability.html",
    "href": "APIs/Traceability.html",
    "title": "Traceability Service",
    "section": "",
    "text": "Traceability Service provides the user with means to track the lifecycle of a data product. It acts as a historian of the product’s lifecycle, collecting the traces of all related events. These traces then can be used to check the integrity of the product, its current whereabouts, its impact on other products or ultimately its inadequacy for continued use in case of obsolescence. Digital signatures on the traces provide users with the ability to verify authenticity and integrity of the traces themselves – this also enables users to detect any alterations of the product during its lifecycle.\nUsers may interact with Traceability API either directly using e.g. curl, or through the open source Traceability command line utility.\nTraceability Service API OpenAPI endpoint documentation: https://trace.dataspace.copernicus.eu/api/docs\nTraceability Service command line utility: https://github.com/eu-cdse/trace-cli\n\n\nInteraction with Traceability Service by using curl command on Linux:\ncurl -X 'GET' 'https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip' -H 'accept: application/json'\nPlease be aware that curl command might have a different syntax on Windows. Please refer to curl official documentation if you have any questions (https://curl.se/docs/manual.html).\n\n\n\nInteraction with Traceability Service directly via the Traceability Service API: https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip"
  },
  {
    "objectID": "APIs/Traceability.html#example",
    "href": "APIs/Traceability.html#example",
    "title": "Traceability Service",
    "section": "",
    "text": "Interaction with Traceability Service by using curl command on Linux:\ncurl -X 'GET' 'https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip' -H 'accept: application/json'\nPlease be aware that curl command might have a different syntax on Windows. Please refer to curl official documentation if you have any questions (https://curl.se/docs/manual.html)."
  },
  {
    "objectID": "APIs/Traceability.html#direct-access",
    "href": "APIs/Traceability.html#direct-access",
    "title": "Traceability Service",
    "section": "",
    "text": "Interaction with Traceability Service directly via the Traceability Service API: https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip"
  },
  {
    "objectID": "APIs/S3.html",
    "href": "APIs/S3.html",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "Access to EO data hosted on object storage is using API compatible with S3.\nS3 is an object storage service with which you can retrieve data over HTTP using REST API.\n\n\n\nTo generate the necessary credentials you must have a registered account on dataspace.copernicus.eu. If you don’t have an account, you can register here.\n\n\n\nIn order to obtain secrets, create a ticket to CDSE support. Our operators will provide you with the appropriate credentials. You must provide in such request the e-mail address of the registered CDSE user for whom the credentials will be generated.\n\n\n\nBelow example assumes the use of a Linux environment.\nHaving the access and secret key together with the endpoint eodata.dataspace.copernicus.eu, you can use any tool to handle access via S3. Below is an example of how to access EO Data using the s3cmd.\nFirst, we recommend to create a configuration file. You can create it with tools like vi/vim or nano:\nvi .s3cfg\nvim .s3cfg\nnano .s3cfg\nCopy the following content to your configuration file, with your access and secret key:\n[default]\naccess_key = &lt;access_key&gt;\nhost_base = eodata.dataspace.copernicus.eu\nhost_bucket = eodata.dataspace.copernicus.eu\nhuman_readable_sizes = False\nsecret_key = &lt;secret_key&gt;\nuse_https = true\ncheck_ssl_certificate = true\nThen you can run any s3cmd command pointing to the previously created configuration file with parameter -c:\ns3cmd -c ~/.s3cfg ls\nBelow is an example of downloading a product from the EO data repository using s3cmd:\ns3cmd -c ~/.s3cfg get s3://eodata/Sentinel-1/SAR/SLC/2016/12/28/S1A_IW_SLC__1SDV_20161228T044442_20161228T044509_014575_017AE8_4C26.SAFE/measurement/s1a-iw2-slc-vv-20161228t044442-20161228t044508-014575-017ae8-005.tiff\nIf the objects in the repository are archives, for example, such as S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE use the –recursive parameter to download whole product."
  },
  {
    "objectID": "APIs/S3.html#object-storage",
    "href": "APIs/S3.html#object-storage",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "Access to EO data hosted on object storage is using API compatible with S3.\nS3 is an object storage service with which you can retrieve data over HTTP using REST API."
  },
  {
    "objectID": "APIs/S3.html#registration",
    "href": "APIs/S3.html#registration",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "To generate the necessary credentials you must have a registered account on dataspace.copernicus.eu. If you don’t have an account, you can register here."
  },
  {
    "objectID": "APIs/S3.html#request-for-secrets",
    "href": "APIs/S3.html#request-for-secrets",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "In order to obtain secrets, create a ticket to CDSE support. Our operators will provide you with the appropriate credentials. You must provide in such request the e-mail address of the registered CDSE user for whom the credentials will be generated."
  },
  {
    "objectID": "APIs/S3.html#example-access-using-s3cmd",
    "href": "APIs/S3.html#example-access-using-s3cmd",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "Below example assumes the use of a Linux environment.\nHaving the access and secret key together with the endpoint eodata.dataspace.copernicus.eu, you can use any tool to handle access via S3. Below is an example of how to access EO Data using the s3cmd.\nFirst, we recommend to create a configuration file. You can create it with tools like vi/vim or nano:\nvi .s3cfg\nvim .s3cfg\nnano .s3cfg\nCopy the following content to your configuration file, with your access and secret key:\n[default]\naccess_key = &lt;access_key&gt;\nhost_base = eodata.dataspace.copernicus.eu\nhost_bucket = eodata.dataspace.copernicus.eu\nhuman_readable_sizes = False\nsecret_key = &lt;secret_key&gt;\nuse_https = true\ncheck_ssl_certificate = true\nThen you can run any s3cmd command pointing to the previously created configuration file with parameter -c:\ns3cmd -c ~/.s3cfg ls\nBelow is an example of downloading a product from the EO data repository using s3cmd:\ns3cmd -c ~/.s3cfg get s3://eodata/Sentinel-1/SAR/SLC/2016/12/28/S1A_IW_SLC__1SDV_20161228T044442_20161228T044509_014575_017AE8_4C26.SAFE/measurement/s1a-iw2-slc-vv-20161228t044442-20161228t044508-014575-017ae8-005.tiff\nIf the objects in the repository are archives, for example, such as S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE use the –recursive parameter to download whole product."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html",
    "href": "APIs/openEO/Python_Client/Python.html",
    "title": "Getting started with the openEO Python client",
    "section": "",
    "text": "This Getting Started guide will just give a small taste of using the openEO Python client library in the context of the Copernicus Data Space Ecosystem. Consult the official openEO Python client library documentation for more in-depth information and a broader coverage of its functionality."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#installation",
    "href": "APIs/openEO/Python_Client/Python.html#installation",
    "title": "Getting started with the openEO Python client",
    "section": "Installation",
    "text": "Installation\n\n\n\n\n\n\nTip\n\n\n\nAs with any Python project, it is recommended to work in some kind of virtual environment (venv, virtualenv, conda, docker, …) to avoid interference with other projects or applications.\n\n\nThe openEO Python client library is available on PyPI and can easily be installed with a tool like pip, for example:\npip instal openeo\nThe client library is also available on Conda Forge and can be easily installed in a conda environment, for example:\nconda install -c conda-forge openeo\n\n\n\n\n\n\nTip\n\n\n\nSee the official openeo installation docs for more details, alternative installation procedures or troubleshooting tips."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#exploring-a-back-end",
    "href": "APIs/openEO/Python_Client/Python.html#exploring-a-back-end",
    "title": "Getting started with the openEO Python client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO back-end of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu. We establish a connection to this back-end as follows:\nimport openeo\n\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\")\nThe Connection object we created here is the central gateway to interact with the back-end:\n\nlist data collections, available processes, file formats and other capabilities of the back-end\nstart building your openEO algorithm from the desired data on the back-end\nexecute and monitor (batch) jobs on the back-end\netc.\n\n\nEO Collections\nEO data in openEO is organized in so-called collections, which are used as the input data for your openEO jobs (see the glossary for more info). Collections can be listed and inspected programmatically:\n# List collections available on the openEO back-end\nconnection.list_collection_ids()\n\n# Get detailed metadata of a certain collection\nconnection.describe_collection(\"SENTINEL2_L2A\")\nHowever, it is often easier to browse collections through the openEO collection listing page or the collection listing sidebar of the openEO Web Editor.\n\n\nopenEO Processes\nProcesses in openEO are operations that can be applied on (EO) data (see the the openEO glossary for more info). For example: calculate the mean of an array, mask out pixels outside a given polygon or calculate spatial aggregations. The output of one process can be used as the input of another process, and by doing so, multiple processes can be connected that way in a larger “process graph”, as illustrated in this conceptual diagram:\n\n\n\n\nflowchart TD\n  load_collection --&gt; NDVI[calculate NDVI]\n  load_collection --&gt; cm[build cloud mask]\n  NDVI --&gt; mask[apply mask]\n  cm --&gt; mask\n  mask --&gt; aggregate_spatial\n  load_geojson[load geometries] --&gt; aggregate_spatial\n  aggregate_spatial --&gt; save_result\n\n\n\n\n\nWhile it is possible to programmatically list and inspect the available processes (e.g. connection.list_processes() with the openEO python client), it is recommended to just consult the process listing page, the process listing sidebar of the openEO Web Editor, or the official openeo.org processes listing."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#authentication",
    "href": "APIs/openEO/Python_Client/Python.html#authentication",
    "title": "Getting started with the openEO Python client",
    "section": "Authentication",
    "text": "Authentication\nBasic metadata about collection and processes, as discussed above is publicly available and does not require being logged in. However, for downloading EO data or running processing workflows, it is necessary to authenticate so that permissions, resource usage, etc. can be managed properly.\n\n\n\n\n\n\nImportant\n\n\n\nMake sure to complete your Copernicus Data Space Ecosystem registration before attempting to do the authentication explained below.\n\n\nOnce properly registered, you will be able to authenticate your connection handle in your Python code with Connection.authenticate_oidc(), just like this:\nconnection.authenticate_oidc()\n\nBy default, the first time you call this authenticate_oidc() method, a URL will be printed. Something like for example:\nVisit https://auth.example.com/device?user_code=EAXD-RQXV to authenticate.\nVisit this URL (click it or copy-paste it into your web browser) and follow the login flow using your Copernicus Data Space Ecosystem credentials.\n\n\n\n\n\n\nTip\n\n\n\nYou can visit this URL with any browser you prefer to complete the login procedure (e.g. on your laptop or smartphone). It does not have to be a browser running on the same machine/network as your Python script/application.\n\n\nOnce the authentication is completed, your Python script will receive the necessary authentication tokens and print\nAuthorized successfully.\nOther times, when you still have valid (refresh) tokens on your system, it will not be necessary to go through the Copernicus Data Space Ecosystem login steps and you will immediately see\nAuthenticated using refresh token.\n\nIn any case, your connection is now authenticated and capable to make download/processing requests.\nA more in-depth discussion of various authentication concepts is available in the openEO Python client documentation."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#working-with-datacube",
    "href": "APIs/openEO/Python_Client/Python.html#working-with-datacube",
    "title": "Getting started with the openEO Python client",
    "section": "Working with Datacube",
    "text": "Working with Datacube\nNow that we know how to discover the capabilities of the back-end and how to authenticate, let’s do some real work and process some EO data in a batch job. We’ll build the desired algorithm by working on so-called “Datacubes”, which is the central concept in openEO to represent EO data.\n\nCreating a Datacube\nThe first step is loading the desired slice of a data collection with Connection.load_collection:\ndatacube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    spatial_extent={\"west\": 5.14, \"south\": 51.17, \"east\": 5.17, \"north\": 51.19},\n    temporal_extent = [\"2021-02-01\", \"2021-04-30\"],\n    bands=[\"B02\", \"B04\", \"B08\"],\n    max_cloud_cover=85,\n)\nThis results in a Datacube object containing the “SENTINEL2_L2A” data restricted to the given spatial extent, the given temporal extend and the given bands .\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can also filter the datacube step by step or at a later stage by using the following filter methods:\ndatacube = datacube.filter_bbox(west=5.14, south=51.17, east=5.17, north=51.19)\ndatacube = datacube.filter_temporal(start_date=\"2021-02-01\", end_date=\"2021-04-30\")\ndatacube = datacube.filter_bands([\"B02\", \"B04\", \"B08\"])\nStill, it is recommended to always use the filters directly in load_collection to avoid loading too much data upfront.\n\n\n\n\n\nApplying processes\nBy applying an openEO process on a datacube, we create a new datacube object that represents the manipulated data. The standard way to do this with the Python client is to call the appropriate Datacube object method. The most common or popular openEO processes have a dedicated Datacube method (e.g. mask, aggregate_spatial, filter_bbox, …). Other processes without a dedicated method can still be applied in a generic way. An on top of that, there are also some convenience methods that implement openEO processes is a compact, Pythonic interface.\nFor example, the min_time method implements a reduce_dimension process along the temporal dimension, using the max process as reducer function:\ndatacube = datacube.max_time()\nThis creates a new datacube (we overwrite the existing variable), where the time dimension is eliminated and for each pixel we just have the minimum value of the corresponding timeseries in the original datacube.\nSee the Python client Datacube API for a more complete listing of methods that implement openEO processes.\n\n\n\n\n\n\nNote\n\n\n\nStill unsure on how to make use of processes with the Python client? Visit the official documentation on working with processes."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#execution",
    "href": "APIs/openEO/Python_Client/Python.html#execution",
    "title": "Getting started with the openEO Python client",
    "section": "Execution",
    "text": "Execution\nIt’s important to note that all the datacube processes we applied up to this point are not actually executed yet, neither locally nor remotely on the back-end. We just built an abstract representation of the algorithm (input data and processing chain), encapsulated in a local Datacube object (e.g. the result variable above). To trigger an actual execution (on the back-end) we have to explicitly send this representation to the back-end.\n\nBatch job execution\nMost of the simple, basic openEO usage examples show synchronous downloading of results. This only works properly if the processing doesn’t take too long and is focused on a smaller area of interest. However, you have to use batch jobs for the heavier work (larger regions of interest, larger time series, more intensive processing).\n# While not necessary, it is also recommended to give your batch job a descriptive title so it’s easier to identify in your job listing.\njob = cube.execute_batch()\n\nThis documentation mainly discusses how to programmatically create and interact with batch job using the openEO Python client library. The openEO API however does not enforce usage of the same tool for each step in the batch job life cycle.\nFor example: if you prefer a graphical, web-based interactive environment to manage and monitor your batch jobs, feel free to switch to an openEO web editor like openeo.dataspace.copernicus.eu/ at any time. After logging in with the same account you use in your Python scripts, you should see your batch jobs listed under the “Data Processing” tab. More information on using openEO web editor is discussed here.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe official openEO Python Client documentation has more information on batch job basics {target=“_blank”} or more detailed batch job (result) management"
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#full-example",
    "href": "APIs/openEO/Python_Client/Python.html#full-example",
    "title": "Getting started with the openEO Python client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the Python client.\nA common task in earth observation is to apply a formula to a number of spectral bands in order to compute an ‘index’, such as NDVI, NDWI, EVI, … In this tutorial we’ll go through a couple of steps to extract EVI (enhanced vegetation index) values and timeseries\nimport openeo\n\n# First, we connect to the back-end and authenticate. \ncon = openeo.connect(\"openeo.dataspace.copernicus.eu\")\ncon.authenticate_oidc()\n\n# Now that we are connected, we can initialize our datacube object with the area of interest \n# and the time range of interest using Sentinel 1 data.\ndatacube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    spatial_extent={\"west\": 5.14, \"south\": 51.17, \"east\": 5.17, \"north\": 51.19},\n    temporal_extent = [\"2021-02-01\", \"2021-04-30\"],\n    bands=[\"B02\", \"B04\", \"B08\"],\n    max_cloud_cover=85,\n)\n\n# By filtering as early as possible (directly in load_collection() in this case), \n# we make sure the back-end only loads the data we are interested in and avoid incurring unneeded costs.\n\n\n#From this data cube, we can now select the individual bands with the DataCube.band() method and rescale the digital number values to physical reflectances:\nblue = sentinel2_cube.band(\"B02\") * 0.0001\nred = sentinel2_cube.band(\"B04\") * 0.0001\nnir = sentinel2_cube.band(\"B08\") * 0.0001\n\n\n# We now want to compute the enhanced vegetation index and can do that directly with these band variables:\nevi_cube = 2.5 * (nir - red) / (nir + 6.0 * red - 7.5 * blue + 1.0)\n\n# Now we can use the compact “band math” feature again to build a binary mask with a simple comparison operation:\n# Select the \"SCL\" band from the data cube\nscl_band = s2_scl.band(\"SCL\")\n# Build mask to mask out everything but class 4 (vegetation)\nmask = (scl_band != 4)\n\n# Before we can apply this mask to the EVI cube we have to resample it, as the “SCL” layer has a “ground sample distance” of 20 meter, while it is 10 meter for the “B02”, “B04” and “B08” bands. We can easily do the resampling by referring directly to the EVI cube.\nmask_resampled = mask.resample_cube_spatial(evi_cube)\n\n# Apply the mask to the `evi_cube`\nevi_cube_masked = evi_cube.mask(mask_resampled)\n\n# Because GeoTIFF does not support a temporal dimension, we first eliminate it by taking the temporal maximum value for each pixel:\nevi_composite = evi_cube.max_time()\n\n# Now we can download this to a local file:\nevi_composite.download(\"evi-composite.tiff\")\nNow, you can inspect the result for the EVI map."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#user-defined-functions",
    "href": "APIs/openEO/Python_Client/Python.html#user-defined-functions",
    "title": "Getting started with the openEO Python client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function. Therefore, you can create a Python function that will be executed at the back-end and functions as a process in your process graph.\nDetailed information about Python UDFs can be found in the official documentation as well as examples in the Python client repository."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#useful-links",
    "href": "APIs/openEO/Python_Client/Python.html#useful-links",
    "title": "Getting started with the openEO Python client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO Python Client Library:\n\nExample scripts\nExample Jupyter Notebooks\nOfficial openEO Python Client Library Documentation\nRepository on GitHub"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/BasicSentinelMerge/sentinel_merge.html",
    "href": "APIs/openEO/openeo-community-examples/python/BasicSentinelMerge/sentinel_merge.html",
    "title": "Creating multi-mission, multi-temporal datacube",
    "section": "",
    "text": "import openeo\n\nThis notebooks shows how to combine timeseries data from two popular missions, Sentinel-1 and Sentinel-2 in a single datacube for further processing. It can be considered a basic template for many use cases.\nThe uses precomputed backscatter if available, and falls back to compute backscatter on the fly, which works globally, but also consumes more credits.\nWe also create 10-daily composites, and apply linear interpolation to avoid gaps. Specific methods may of course require different cloud masking and preprocessing options.\n\nc=openeo.connect(\"openeo.dataspace.copernicus.eu\")\nc.authenticate_oidc()\n\nsentinel2 = c.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent = [\"2022-06-04\", \"2022-08-04\"],\n    bands = [\"B02\", \"B03\", \"B04\",\"SCL\"],\n    max_cloud_cover=95\n)\n\nsentinel2 = sentinel2.process(\n            \"mask_scl_dilation\",\n            data=sentinel2,\n            scl_band_name=\"SCL\",\n            kernel1_size=17, kernel2_size=77,\n            mask1_values=[2, 4, 5, 6, 7],\n            mask2_values=[3, 8, 9, 10, 11],\n            erosion_kernel_size=3)\n\nsentinel2 = sentinel2.aggregate_temporal_period(\"dekad\",reducer=\"median\")\\\n    .apply_dimension(dimension=\"t\", process=\"array_interpolate_linear\")\n\n\nAuthenticated using refresh token.\n\n\nSome openEO backends offer precomputed Sentinel-1 backscatter. We inspect the backend metadata to check if such a collection is available, otherwise we start from raw GRD and compute it on the fly.\n\nS1_collection = \"SENTINEL1_GRD\"\nif \"SENTINEL1_GRD_SIGMA0\" in c.list_collection_ids():\n    S1_collection = \"SENTINEL1_GRD_SIGMA0\"\n\nS1_collection\n\n'SENTINEL1_GRD'\n\n\n\n\nsentinel1 = c.load_collection(\n    S1_collection,\n    temporal_extent = [\"2022-06-04\", \"2022-08-04\"],\n    bands = [\"VV\",\"VH\"]\n)\n\nif S1_collection == \"SENTINEL1_GRD\":\n    sentinel1 = sentinel1.sar_backscatter(\n        coefficient='sigma0-ellipsoid',\n        local_incidence_angle=False,\n        elevation_model='COPERNICUS_30')\n\nsentinel1 = sentinel1.aggregate_temporal_period(\"dekad\",reducer=\"median\")\\\n    .apply_dimension(dimension=\"t\", process=\"array_interpolate_linear\")\n\nNow we can simply combine both cubes. Resampling is performed implicitly if needed, but explicit resampling can also be specified.\n\nmerged = sentinel2.merge_cubes(sentinel1)\n\nThe next block receives the combined Sentinel-1 and Sentinel-2 input, and transforms it using whatever method. This can be for instance a neural network based on PyTorch.\nThis example uses blocks of 128x128 pixels, with an 8 pixel overlap. Sizes for the time and bands dimensions are not specified, which means they will be fully included.\nThe UDF in this example also shows how to print statements to the logging, this is an easy way to get a better sense of the XArray data that is passed in. More information on UDF’s can be found in the documentation.\n\nmy_udf = openeo.UDF(\"\"\"\nfrom openeo.udf import XarrayDataCube\nfrom openeo.udf.debug import inspect\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    inspect(array,level=\"ERROR\",message=\"inspecting input cube\")\n    array.values = 0.0001 * array.values\n    return cube\n\"\"\")\n\nfused = merged.apply_neighborhood(my_udf, size=[\n        {'dimension': 'x', 'value': 112, 'unit': 'px'},\n        {'dimension': 'y', 'value': 112, 'unit': 'px'}\n    ], overlap=[\n        {'dimension': 'x', 'value': 8, 'unit': 'px'},\n        {'dimension': 'y', 'value': 8, 'unit': 'px'}\n    ])\n\n\nspatial_extent = {'west': 4.45, 'east': 4.70, 'south': 51.16, 'north': 51.22, 'crs': 'epsg:4326'}\njob=fused.filter_bbox(spatial_extent).execute_batch(\"result.nc\", title=\"Sentinel composite\", filename_prefix=\"merged_cube\")\n\n0:00:00 Job 'j-beec61e8511149d19cc3b6627a19888a': send 'start'\n0:00:11 Job 'j-beec61e8511149d19cc3b6627a19888a': created (progress N/A)\n0:00:16 Job 'j-beec61e8511149d19cc3b6627a19888a': created (progress N/A)\n0:00:23 Job 'j-beec61e8511149d19cc3b6627a19888a': created (progress N/A)\n0:00:31 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:00:42 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:00:55 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:01:10 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:01:30 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:01:54 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:02:24 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:03:01 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:03:48 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:04:46 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:05:47 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:06:47 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:07:47 Job 'j-beec61e8511149d19cc3b6627a19888a': finished (progress N/A)\n\n\nWhen the job is finished, are downloaded as netCDF and can be inspected using XArray or a desktop viewer like QGis.\n\nimport xarray as xr\nxr.open_dataset(\"result.nc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (t: 7, x: 1762, y: 706)\nCoordinates:\n  * t        (t) datetime64[ns] 2022-06-01 2022-06-11 ... 2022-07-21 2022-08-01\n  * x        (x) float64 6.013e+05 6.013e+05 6.013e+05 ... 6.189e+05 6.189e+05\n  * y        (y) float64 5.676e+06 5.676e+06 5.676e+06 ... 5.669e+06 5.669e+06\nData variables:\n    crs      |S1 ...\n    B02      (t, y, x) float64 ...\n    B03      (t, y, x) float64 ...\n    B04      (t, y, x) float64 ...\n    SCL      (t, y, x) float64 ...\n    VV       (t, y, x) float64 ...\n    VH       (t, y, x) float64 ...\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platform - Geotrellis backend: 0.14.1a1\n    description:  \n    title:        xarray.DatasetDimensions:t: 7x: 1762y: 706Coordinates: (3)t(t)datetime64[ns]2022-06-01 ... 2022-08-01standard_name :tlong_name :taxis :Tarray(['2022-06-01T00:00:00.000000000', '2022-06-11T00:00:00.000000000',\n       '2022-06-21T00:00:00.000000000', '2022-07-01T00:00:00.000000000',\n       '2022-07-11T00:00:00.000000000', '2022-07-21T00:00:00.000000000',\n       '2022-08-01T00:00:00.000000000'], dtype='datetime64[ns]')x(x)float646.013e+05 6.013e+05 ... 6.189e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([601265., 601275., 601285., ..., 618855., 618865., 618875.])y(y)float645.676e+06 5.676e+06 ... 5.669e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5675665., 5675655., 5675645., ..., 5668635., 5668625., 5668615.])Data variables: (7)crs()|S1...crs_wkt :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]]spatial_ref :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]][1 values with dtype=|S1]B02(t, y, x)float64...long_name :B02units :grid_mapping :crs[8707804 values with dtype=float64]B03(t, y, x)float64...long_name :B03units :grid_mapping :crs[8707804 values with dtype=float64]B04(t, y, x)float64...long_name :B04units :grid_mapping :crs[8707804 values with dtype=float64]SCL(t, y, x)float64...long_name :SCLunits :grid_mapping :crs[8707804 values with dtype=float64]VV(t, y, x)float64...long_name :VVunits :grid_mapping :crs[8707804 values with dtype=float64]VH(t, y, x)float64...long_name :VHunits :grid_mapping :crs[8707804 values with dtype=float64]Indexes: (3)tPandasIndexPandasIndex(DatetimeIndex(['2022-06-01', '2022-06-11', '2022-06-21', '2022-07-01',\n               '2022-07-11', '2022-07-21', '2022-08-01'],\n              dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Float64Index([601265.0, 601275.0, 601285.0, 601295.0, 601305.0, 601315.0,\n              601325.0, 601335.0, 601345.0, 601355.0,\n              ...\n              618785.0, 618795.0, 618805.0, 618815.0, 618825.0, 618835.0,\n              618845.0, 618855.0, 618865.0, 618875.0],\n             dtype='float64', name='x', length=1762))yPandasIndexPandasIndex(Float64Index([5675665.0, 5675655.0, 5675645.0, 5675635.0, 5675625.0, 5675615.0,\n              5675605.0, 5675595.0, 5675585.0, 5675575.0,\n              ...\n              5668705.0, 5668695.0, 5668685.0, 5668675.0, 5668665.0, 5668655.0,\n              5668645.0, 5668635.0, 5668625.0, 5668615.0],\n             dtype='float64', name='y', length=706))Attributes: (4)Conventions :CF-1.9institution :openEO platform - Geotrellis backend: 0.14.1a1description :title :\n\n\nYou can also inspect the result in the openEO editor:"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html",
    "href": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html",
    "title": "Usecase showcasing Regional Benchmarking service of Anomaly Identification",
    "section": "",
    "text": "With the OpenEO-based Regional Benchmarking service you can check the crop growth on a field and compare it with a similar fields. It gives you an idea of whether your field is performing better or worse than other fields.\nIn this example, we have compared several fields with similar croptype available in our area of interest. The area of interest is derived as WFS from DLV service filtered by a croptype(here, croptype = ‘Zomergerst’). Nevertheless, if users have their polygons/parcels, they can use them with a note that they should be of similar crop type.\n# importing necessary packages\nimport openeo\nimport rasterio\nfrom rasterio.plot import show\n# Acquire more information about the service\nservice = \"Anomaly_Detection\"\nnamespace = \"vito\"\n\neoconn = openeo.connect('https://openeo.vito.be').authenticate_oidc()\neoconn.describe_process(service, namespace=namespace)\n\nAuthenticated using refresh token.\nAs mentioned earlier, though, in this example, we used parcels from a WFS; these parameters are specific to them. User can use their polygons/parcels based on their requirements.\n# Specific parameters\ncroptype = 'Zomergerst'\n\n# Bounding Box\nwest = 5.17\neast = 5.3\nsouth = 51.1\nnorth = 52.246\n# reading the json file (user can use this function if they have their features stored as json file)\n\nimport json\ndef read_json_str(json_txt: str) -&gt; dict:\n    field = json.loads(json_txt)\n    return field"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#parse-the-data",
    "href": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#parse-the-data",
    "title": "Usecase showcasing Regional Benchmarking service of Anomaly Identification",
    "section": "Parse the data",
    "text": "Parse the data\nHere, we tried in parsing WFS provided by https://lv.vlaanderen.be/en as parcels with their crop types.\n\n# requesting data over a region for a specific crop type\n\nimport urllib\nimport requests\n\nurl = f\"https://geo.api.vlaanderen.be/Landbgebrperc/wfs?service=WFS&request=getfeature&cql_filter=LBLHFDTLT='{croptype}'&outputformat=json&typename=Lbgebrperc&SRSName=urn:x-ogc:def:crs:EPSG:4326\"\nreq = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n\nwfs_request_url = requests.Request('GET', url,headers={'User-Agent': 'Mozilla/5.0'}).prepare().url\ndata = req.json()\n\nBefore proceeding forward, we want to ensure that the filtered data likes in the area of interest. Thus the following cell includes the method to display the parsed data as a dataframe and map.\n\nimport shapely\nimport geopandas as gpd\nfrom shapely.geometry import box\n\n\ndataframe = gpd.GeoDataFrame.from_features(data[\"features\"],crs='EPSG:4326')\narea=dataframe.to_crs(epsg=3857).area\ndataframe=dataframe[area&gt;200]\n\n# filter data within the bounding box\nbbox = box(west,south,east,north)\ndataframe = dataframe[dataframe.within(bbox)]\n\ndataframe = dataframe.head()\n# converting dataframe to geojson string\ngeojson_str = dataframe.to_json()\n\ndataframe\n\n\n\n\n\n\n\n\ngeometry\nUIDN\nOIDN\nALVID\nHFDTLT\nLBLHFDTLT\nGEWASGROEP\nPM\nLBLPM\n\n\n\n\n19\nPOLYGON ((5.17759388 51.13236902, 5.17754339 5...\n4092306\n1228344\n1211525956\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n47\nPOLYGON ((5.24743582 51.10311003, 5.24843201 5...\n1882791\n1021017\n1319447853\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n57\nPOLYGON ((5.17872085 51.17170835, 5.17848342 5...\n4340847\n1667648\n2074973981\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n82\nPOLYGON ((5.21847254 51.27816026, 5.21847592 5...\n4355462\n1639446\n2070875228\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n129\nPOLYGON ((5.2909333 51.20048401, 5.29085554 51...\n4367507\n1523096\n1860308032\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n\n\n\n\n\n\n# plot the polygons\nimport folium\nmap = folium.Map( tiles=\"open street map\", zoom_start=12,location=[51.243,5.18])\npoints = folium.features.GeoJson(dataframe.to_crs('EPSG:4326').to_json())\nmap.add_child(points)\nmap.fit_bounds(map.get_bounds(), padding=(30, 30))\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#apply-anomaly-detection-service",
    "href": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#apply-anomaly-detection-service",
    "title": "Usecase showcasing Regional Benchmarking service of Anomaly Identification",
    "section": "Apply Anomaly Detection service",
    "text": "Apply Anomaly Detection service\n\n#parameters mandatory for this openeo-based service\naoi=read_json_str(geojson_str)\ndate = [\"2020-03-06\", \"2020-06-30\"]\n\n#accessing the openeo service\nanomaly = eoconn.datacube_from_process(service, namespace=namespace, date=date\n                                       , polygon=aoi)\n\n/home/pratixa/.local/lib/python3.6/site-packages/openeo/metadata.py:252: UserWarning: No cube:dimensions metadata\n  complain(\"No cube:dimensions metadata\")\n\n\n\n# synchronous download or batch process\nanomaly.download('RegionalBenchmarking_AD.json')\n\n# # batch processing\n# batch_job = anomaly.create_job(out_format = \"json\", title=\"Croptype\")\n# batch_job.start_and_wait()\n# results = batch_job.get_results()\n# results.download_files()\n\nThe service calculates the CropSAR fAPAR curve for each field and the regional average fAPAR curve calculated from comparable fields in the region during a given time period."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#visualize-and-compare-the-final-result",
    "href": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#visualize-and-compare-the-final-result",
    "title": "Usecase showcasing Regional Benchmarking service of Anomaly Identification",
    "section": "Visualize and compare the final result",
    "text": "Visualize and compare the final result\n\nimport matplotlib.pyplot as plt\nimport json\n\ndata_json = json.load(open('RegionalBenchmarking_AD.json', 'r'))\n\n\nfrom matplotlib.pyplot import figure\nimport matplotlib.dates as mdates\n\nfigure(figsize=(18,9), dpi=300)\nfor i in data_json:\n    x_Axis = [key for key, value in data_json[i].items()]\n    y_Axis = [value for key, value in data_json[i].items()]\n    plt.plot(x_Axis,y_Axis, label = i)\n\nax = plt.gca()\nn = 7  # Keeps every 7th label\n[l.set_visible(False) for (i,l) in enumerate(ax.get_xticklabels()) if i % n != 0]\nplt.xlabel('variable')\nplt.xticks(rotation=90)\nplt.ylabel('value')\nplt.tight_layout()\nplt.legend()\nplt.show()\n\n\n\n\nThrough the visualized curved you can study the croptype behaviour of the field in comparision with the Regional average."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RescaleChunks/rescale_chunks.html",
    "href": "APIs/openEO/openeo-community-examples/python/RescaleChunks/rescale_chunks.html",
    "title": "Rescale RGB image for spatial chunks",
    "section": "",
    "text": "This notebook shows a simple process for rescaling Sentinel 2 RGB images within polygon chunks that also showcases how to use chunk_polygon() with a (User Defined Function) UDF. (To be noted: chunk_polygon are experimental at the moment)\n\n# import necessary packages\nimport openeo\nfrom openeo.api.process import Parameter\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport rasterio\n\n# connect with the backend\neoconn = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nUser can choose among different backend available here to connect to the backend of their choice. Regarding the authentication process OpenID connect (oidc) is recommended, but not always straightforward to use. In cases where you are unable to connect with the backend use basic authentication method explained here.\n\n# function to load geojson file\ndef read_json(path: Path) -&gt; dict:\n    with open(path) as input:\n        field = json.load(input)\n        input.close()\n    return field\n\nTo use the data collection, a user must use the correct backend with the data collection. Then using load_collection, they can specify bands, temporal extent (i.e. interested time interval) and even spatial extent. In this example, we have loaded the entire collection so that process (including UDF) can later be applied to spatial chunks.\n\n# Load your data cube based on your prefernce\n\nS2_cube = eoconn.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent = [\"2022-06-04\", \"2022-08-04\"],\n    bands = [\"B02\", \"B03\", \"B04\"]\n)\n\nHere we tried in presenting a method to create and use UDF as an openEO feature. In a similar manner user can create their own UDF as needed to apply to their data cube. More information on UDF.\n\n# Create a UDF object from inline source code.\nmy_udf = openeo.UDF(\"\"\"\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    array.values = 0.0001 * array.values\n    return cube\n\"\"\")\n\nWe used the chunk_polygon method to apply our UDF over a spatial chunk of the datacube. In the case of a simple process that does not require UDF, you can directly load your spatial extent in the dataset.\nFurthermore, since we loaded our collection for specific time intervals, it can include multiple time dimensions. Thus reduce_dimension applies a reducer to a data cube dimension by collapsing all the pixel values along the time dimension into an output value computed by the reducer.\n\n# apply rescale to chunks of polygon\naoi = read_json(\"cologne_aoi.geojson\")\nrescaled_chunks = S2_cube.chunk_polygon(chunks=aoi,process=my_udf)\n\n# perform time dimension reduction\nRrescaled_chunks = rescaled_chunks.reduce_dimension(dimension=\"t\", reducer=\"mean\")\n\nOnce the process is completed, you can also save it as your process using save_user_defined_process that can later be used for a similar task. Otherwise, you can download the result either by direct download (in case of the small spatial extent with few processing) or perform create a batch job in case it is a heavy task over a large extent.\n\n## download your result either using synchronous method or batch\n# synchronous download\n# rescaled_chunks.download(\"rescaled_test_v1.tiff\")\n# \n# Or perform batch processing if area is comparatively large\nbatch_job = Rrescaled_chunks.create_job(out_format = \"GTiff\", title=\"rescaled_chunks2\")\nbatch_job.start_and_wait()\nresults = batch_job.get_results()\nresults.download_files()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/WorldCereal/WorldCereal.html",
    "href": "APIs/openEO/openeo-community-examples/python/WorldCereal/WorldCereal.html",
    "title": "WorldCereal product download",
    "section": "",
    "text": "This example illustrates the use of openEO for combining and downloading data from the ESA WorldCereal project.\nThis project provides a global map of cereals for 2021 at 10m resolution! It can be used as an important base layer for agriculture use cases. Combined with the power of openEO, you can easily generate agricultural statistics over an area of interest, or use this data as a masking layer in an advanced workflow.\nIn this example, we’ll illustrate a fairly simple case of combining two collections into a single image file.\n\nimport openeo\nc=openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nWe list the available collection id’s to make sure we have the right name.\n\n[col['id'] for col in c.list_collections() if \"WORLDCEREAL\" in col['id']]\n\n['ESA_WORLDCEREAL_ACTIVECROPLAND',\n 'ESA_WORLDCEREAL_IRRIGATION',\n 'ESA_WORLDCEREAL_TEMPORARYCROPS',\n 'ESA_WORLDCEREAL_WINTERCEREALS',\n 'ESA_WORLDCEREAL_MAIZE',\n 'ESA_WORLDCEREAL_SPRINGCEREALS']\n\n\n\nc.describe_collection(\"ESA_WORLDCEREAL_MAIZE\")\n\n\n    \n    \n        \n    \n    \n\n\nIn the following block, we combine two WorldCereal collections into a single output. The formula used here is just an example, and can be made much more complex depending on your use case.\n\nextent = {'west': 3.0, 'south': 50.0, 'east': 4.0, 'north': 51.0, 'crs': 'EPSG:4326'}\ntemporal = ('2020-09-01T00:00:00Z', '2021-12-31T00:00:00Z')\nmaize = c.load_collection(\"ESA_WORLDCEREAL_MAIZE\",\n                         temporal_extent= temporal,\n                         spatial_extent=extent,\n                         bands=[\"classification\"])\nwinter = c.load_collection(\"ESA_WORLDCEREAL_WINTERCEREALS\",\n                         temporal_extent= temporal,\n                         spatial_extent=extent,\n                         bands=[\"classification\"]).apply(lambda x:100*(x+10))\n\ncombined = maize.merge_cubes(winter, overlap_resolver=\"sum\")\n\nWe now have defined what openEO calls a ‘process graph’, but still need to execute it. We will use an ‘asynchronous’ batch job that gets sent to the server, as it can take a longer time to execute.\nWhen finished, this command will automatically download the result from openEO to your local working directory. You can also follow the progress and view results in the openEO web editor.\n\njob = combined.execute_batch(\"worldcereal_combined.nc\")\n\n0:00:00 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': send 'start'\n0:00:22 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:00:28 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:00:35 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:00:43 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:01:18 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:01:31 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:01:47 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:02:06 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:02:30 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:03:00 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:03:54 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': running (progress N/A)\n0:04:42 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': running (progress N/A)\n0:05:40 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': running (progress N/A)\n0:06:41 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': running (progress N/A)\n0:07:41 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': finished (progress N/A)\n\n\n\njob.get_results()"
  },
  {
    "objectID": "APIs/openEO/job_config.html",
    "href": "APIs/openEO/job_config.html",
    "title": "Documentation",
    "section": "",
    "text": "Batch job results are accessible to the user via signed URLs stored in the result assets. Within the platform, these URLs have a validity (expiry time) of 7 days. Within these 7 days, the results of a batch job can be accessed by any person with the URL. Each time a user requests the results from the job endpoint (GET /jobs/{job_id}/results), a freshly signed URL (valid for 7 days) is created for the result assets."
  },
  {
    "objectID": "APIs/openEO/job_config.html#validity-of-signed-urls-in-batch-job-results",
    "href": "APIs/openEO/job_config.html#validity-of-signed-urls-in-batch-job-results",
    "title": "Documentation",
    "section": "",
    "text": "Batch job results are accessible to the user via signed URLs stored in the result assets. Within the platform, these URLs have a validity (expiry time) of 7 days. Within these 7 days, the results of a batch job can be accessed by any person with the URL. Each time a user requests the results from the job endpoint (GET /jobs/{job_id}/results), a freshly signed URL (valid for 7 days) is created for the result assets."
  },
  {
    "objectID": "APIs/openEO/job_config.html#customizing-batch-job-resources",
    "href": "APIs/openEO/job_config.html#customizing-batch-job-resources",
    "title": "Documentation",
    "section": "Customizing batch job resources",
    "text": "Customizing batch job resources\nJobs running on the cloud get assigned a default amount of CPU and memory resources. This may not always be enough for your job, for instance when using UDF’s. Also for very large jobs, you may want to tune your resource settings to optimize for cost.\nThe example below shows how to start a job with all options set to their default values. It is important to highlight that default settings are subject to change by the backend whenever needed.\njob_options = {\n    \"executor-memory\": \"2G\",\n    \"executor-memoryOverhead\": \"1800m\",\n    \"executor-cores\": 1,\n    \"task-cpus\": 1,\n    \"max-executors\": 20,\n    \"driver-memory\": \"2G\",\n    \"driver-memoryOverhead\": \"1G\",\n    \"driver-cores\": 1,\n    \"udf-dependency-archives\": [],\n    \"logging-threshold\": \"info\"\n}\ncube.execute_batch(job_options=job_options)\nThis is a short overview of the various options:\n\nexecutor-memory: memory assigned to your workers, for the JVM that executes most predefined processes\nexecutor-memoryOverhead: memory assigned on top of the JVM, for instance to run UDF’s\nexecutor-cores: number of CPUs per worker (executor). The number of parallel tasks is executor-cores/task-cpus\ntask-cpus: CPUs assigned to a single task. UDF’s using libraries like Tensorflow can benefit from further parallellization on the level of individual tasks.\nexecutor-request-cores: this settings is only relevant for Kubernetes based backends, allows to overcommit CPU\nmax-executors: the maximum number of workers assigned to your job. Maximum number of parallel tasks is max-executors*executor-cores/task-cpus. Increasing this can inflate your costs, while not necessarily improving performance!\ndriver-memory: memory assigned to the spark ‘driver’ JVM that controls execution of your batch job\ndriver-memoryOverhead: memory assigned to the spark ‘driver’ on top of JVM memory, for Python processes.\nlogging-threshold: the threshold for logging, set to ‘info’ by default, can be set to ‘debug’ to generate much more logging\nudf-dependency-archives: an array of urls pointing to zip files with extra dependencies, see below\n\n\nCustom UDF dependencies\nUser defined functions often depend on (specific versions of) libraries or require small auxiliary data files. The UDF specifications do not yet define a standardized manner to provide this other than having the ability of selecting from a predefined set of ‘runtimes’ that than again have a predefined configuration.\nWe solve this via the udf-dependency-archives job option, that allows to specify a list of zip files that should be included in the working directory of the UDF.\nThis enables the following example workflow for Python UDF’s:\n\nCreate a Python ‘virtualenv’ with your dependencies\nBased on the ‘site-packages’ directory of the virtualenv, create a zip file with all dependencies\nUpload the zip to a url that can be reached by the backend.\nIn job options, add \"udf-dependency-archives\": ['https://yourhost.com/myEnv.zip#tmp/mydir'] The #tmp/mydir suffix indicates where you want to unzip your files, relative to the working directory.\nIn your UDF, before trying to import libraries, add your directory to the Python path: sys.path.insert(0, 'tmp/mydir')\nNow your libraries should be loaded before anything else!\n\nKnown limitations:\n\nYour dependencies need to be compatible with the Python version of the backend, currently 3.8.\nYour dependencies need to be compatible with the OS of the backend, currently AlmaLinux 8.\nThe backend has a limited set of Python dependencies that are preloaded, and cannot be changed, such as numpy.\n\n\n\nLearning more\nThe topic of resource optimization is a complex one, and here we just give a short summary. The goal of openEO is to hide most of these details from the user, but we realize that advanced users sometimes want to have a bit more insight, so in the spirit of being open, we give some hints.\nTo learn more about these options, we point to the piece of code that handles this.\nMost memory related options are translated to Apache Spark configuration settings, which are documented here."
  },
  {
    "objectID": "APIs/OpenSearch.html",
    "href": "APIs/OpenSearch.html",
    "title": "OpenSearch Catalog web service",
    "section": "",
    "text": "The OpenSearch catalogue allows you to search through Copernicus data using a standardized web service. The OpenSearch specification can be consulted for technical details of the standard. This web service returns results as GeoJSON feature collections. Each feature in the collection represents an earth observation ‘product’, referencing where the actual data can be found.\nWe remark that this version does not implement the OGC OpenSearch standards, and a migration from other API’s named OpenSearch may require significant modifications. It mainly offers compatibility for existing users of a similar API on the CreoDIAS and Wekeo platforms and with client-side tools and workflows that have implemented support for this API. For new users looking for a more standardized API, a STAC alternative is being developed."
  },
  {
    "objectID": "APIs/OpenSearch.html#using-opensearch-interface-to-query-data-catalogue",
    "href": "APIs/OpenSearch.html#using-opensearch-interface-to-query-data-catalogue",
    "title": "OpenSearch Catalog web service",
    "section": "Using OpenSearch interface to query Data Catalogue",
    "text": "Using OpenSearch interface to query Data Catalogue\nDue to the fact that offset is not a recommended form of searching repository pages, we had to implement a limit to a maximum of 200k. The requests over the limit will be rejected with the code 400. Therefore, we encourage you to limit your inquiries by geographic or temporal area.\nAll queries may be executed as simple HTTP-Get calls by typing the query in the web browser address line, by using any HTTP client, e.g. curl or wget, or from inside of the users’ program. The database is accessible free and anonymously (open for anonymous access for everyone, no authorization is used). It may be accessed both from the internal network (virtual machines in Creodias) and from outside, e.g. your home computer. Note that the actual EO data are restricted to authorized users; only the Data Catalogue is open.\n\nGeneral Rules\nThe queries produce results in JSON format. Base url:\n\nHTTP RequestPython\n\n\nhttp://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?\n\n\n\n\nCode\njson = requests.get(\"http://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\nffc7c4ae-9cdf-56a7-981e-401f2cdd0a53\n{'type': 'Polygon', 'coordinates': [[[22.29859...\n{'collection': 'LANDSAT-5', 'status': 'ONLINE'...\n\n\n1\nFeature\n144c9de3-6c30-5062-8bab-add3d83aa76a\n{'type': 'Polygon', 'coordinates': [[[32.31033...\n{'collection': 'LANDSAT-5', 'status': 'ONLINE'...\n\n\n2\nFeature\nbd33aaca-c7d5-5f00-a005-00450cae37bf\n{'type': 'Polygon', 'coordinates': [[[33.90780...\n{'collection': 'LANDSAT-5', 'status': 'ONLINE'...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMost queries are case-sensitive.\n\n\n\n\nCollections\nThe data are organized in so-called collections corresponding to various satellites. A query may search for data in all collections or in one particular collection only. If only one satellite is in the field of interest, the second approach is faster and more efficient than filtering the general query. For example, to find the ten most recent Sentinel-2 products with cloud cover below 10%, the query should look like:\n\nCLI\n\n\n$ wget -O - \"http://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10\"\n\n\n\nwhile if the collection field is missing in the URL, the products from all the satellites are returned:\n\nCLI\n\n\n$ wget -O - \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10\"\n\n\n\nAs for today the following collections are defined and may be used:\n\nCopernicus Sentinel Mission\n\nSentinel1 or SENTINEL-1\nSentinel2 or SENTINEL-2\nSentinel3 or SENTINEL-3\nSentinel5P or SENTINEL-5P\n\nComplementary data\n\nSoil Moisture and Ocean Salinity (SMOS)\nENVISAT- Medium Resolution Imaging Spectrometer (MERIS)\nLandsat5 or Landsat-5\nLandsat7 or Landsat-7\nLandsat8 or Landsat-8\nCopernicus Atmosphere Monitoring Service (CAMS)\nCopernicus Emergency Management Service (CEMS)\nCopernicus Land Monitoring Service (CLMS)\nCopernicus Marine Service (CMEMS)\nAdditional\nVHR Commercial Data\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote, that collection names vary a bit from satellite names, as they are used in EO Data repository. For example, the collection is named Sentinel2, while in the repository its data are located within /eodata/Sentinel-2/…. branch of the repository tree.\n\n\n\n\nOutput sorting and limiting\nBy default, maximum of 20 products are returned. You may change the limit (beware of long execution time for queries about thousands of products) using the phrase:\n\nmaxRecords=nnn\n\nIf the query is very general and the number of matching products is large, the next pages of products can be retrieved using:\n\npage=nnn\n\nIt is also possible to alter the sequence in which the products are displayed by using a phrase similar to:\n\nsortParam=startDate\n\nThis will sort the output by observation date. The following orderings can be implemented:\n\nstartDate - the date when the observation was made (start)\ncompletionDate - the date when the observation was made (end)\npublished - the date when the product got published in our repository\n\nEeach of these ordering can be be accompanied by:\n\nsortOrder=ascending or sortOrder=descending\n\nFor example the query\n\nHTTP RequestPython\n\n\nhttp://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20\n\n\n\n\nCode\njson = requests.get(\"http://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n010f2ad1-0199-4bd8-850a-215b5c63b0b9\n{'type': 'Polygon', 'coordinates': [[[158.5965...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\n06ccfceb-938e-4bda-beff-3c2acae864b2\n{'type': 'Polygon', 'coordinates': [[[158.5288...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n229dd65c-399d-48bc-a116-14bb0e001742\n{'type': 'Polygon', 'coordinates': [[[157.1876...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\nThe above request will return 20 products from July 2021, whereas the next query will return the next 20:\n\nHTTP RequestPython\n\n\nhttp://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20&page=2\n\n\n\n\nCode\njson = requests.get(\"http://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20&page=2\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\ncdaed6e4-99c3-44db-89e6-efbd21276bef\n{'type': 'Polygon', 'coordinates': [[[156.7053...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\nd2a89e60-4b83-4cb6-a3d7-d926e2b804df\n{'type': 'Polygon', 'coordinates': [[[156.0567...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\nd4e341a1-719f-4297-a6f2-1c5d10098c12\n{'type': 'Polygon', 'coordinates': [[[158.1844...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\n\n\nFormal queries\nThe formal query is invoked as a sequence of sub phrases, separated by &. The result is a conjunction of all sub phrases. It is impossible to use an alternative in the question. The query must be specified as a formal query.\nThe example of formal query - about cloudless (cloud cover lower or equal to 10%) products for a specific location:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2021-06-21T00:00:00Z&completionDate=2021-09-22T23:59:59Z&lon=21.01&lat=52.22\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2021-06-21T00:00:00Z&completionDate=2021-09-22T23:59:59Z&lon=21.01&lat=52.22\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n8eeb4008-c8e9-4ddc-998c-b22f259d5de6\n{'type': 'Polygon', 'coordinates': [[[19.53152...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\n04008903-8704-437b-a8b8-d0942d7fa19c\n{'type': 'Polygon', 'coordinates': [[[22.45053...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\nae2a69fd-1ad2-4b20-b9e9-d36b2ec05806\n{'type': 'Polygon', 'coordinates': [[[21.96038...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\nThe queries are in form param=value or param=[minvalue,maxvalue]. Most of the parameters are common for all collections, but some are specific for some them (e.g. cloudCover applies to optical satellites, but polarisation applies to radar ones), or just single one.\n\n\nGeography and time-frame\nThe common set of parameters are:\n\nstartDate, completionDate - the date limits of the observation. The time may also be specified, e.g. 2021-10-01T21:37:00Z\npublishedAfter, publishedBefore - the date limits when the product was published in our repository\nlon, lat - geographical position, expressed in military style (EPSG:4326, as decimal fraction of degrees, positive for eastern latitude and northern longitude) radius - region of interest, defined as a circle with centre in point determined by the longitude and latitude with radius expressed in meters (it won’t work with point manually selected in EOFinder/Data Explorer)\ngeometry - region of interest, defined as WKT string (POINT, POLYGON, etc.)\nbox - region of interest, defined as the rectangle with given (west,south,east,north) values. It should be defined this way: &box=west,south,east,north\n\nFor example the query can be:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?productType=S2MSI1C&cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=4,51,4.5,52\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?productType=S2MSI1C&cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=4,51,4.5,52\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n5fff7c82-7c4f-50d9-ac21-c1f40855ad74\n{'type': 'Polygon', 'coordinates': [[[4.436811...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\nb2debfff-f569-5a7f-8a30-801ffaebe328\n{'type': 'Polygon', 'coordinates': [[[4.325617...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\ne6c08c26-60a9-59aa-bc7e-222875703aef\n{'type': 'Polygon', 'coordinates': [[[4.064090...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\nor\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=-21,23,-24,15\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=-21,23,-24,15\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\nc5d86632-5263-5a59-b94f-325a3323ea64\n{'type': 'Polygon', 'coordinates': [[[15.98872...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\n95b34e40-fdbc-52b6-98b9-659bcf9f2bae\n{'type': 'Polygon', 'coordinates': [[[14.99980...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n0aeea7ca-875f-5536-8ec0-8a696bf544f5\n{'type': 'Polygon', 'coordinates': [[[-159.774...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\n\n\nVolatile features\nSome terrain-like feature masks are not permanent but describing a single scene only. The most commonly used such feature is cloudiness, or cloudCover, which is defined for most of the products coming from optical sensors. For example:\n\ncloudCover=[0,10]\n\nThis parameter selects only those scenes, which are covered by clouds by no more than 10%.\n\n\n\n\n\n\nCaution\n\n\n\nTo be meaningful, the cloudiness must be provided with each product, while in many products is missing. If the cloudiness is unknown for the scene, it is marked by a value of 0 or -1. cloudCover=0 is therefore ambiguous: it may either mean totally cloudless sky or the cloudy scene for which cloud cover had not been estimated during original data processing.\n\n\n\n\nSatellite features\n\ninstrument - meaningful only for satellites equipped with multiple instruments. The possible values are satellite specific.\nproductType - the actual types possible are specific for every satellite.\nsensorMode - also satellite and sensor specific. E.g. (for Sentinel-1): sensorMode=EW\norbitDirection - ASCENDING or DESCENDING. For most heliosynchronous satellites descending orbits means the day scenes, while ascending means night ones. For many optical satellites (e.g. Sentinel-2) only day scenes are published.\nresolution - expected spatial resolution of the product defined in meters.\nstatus:\n\n\n\nONLINE\nOFFLINE\n\n\nSome additional parameters are strictly satellite-specific, e.g. polarisation, which is defined only for Sentinel-1.\nFor every satellite (collection) its set of query-able parameters may be obtained by a query like:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/describe.xml\n\n\n\n\nCode\nurl = 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/describe.xml'\nresponse = requests.get(url)\n\nroot = ET.fromstring(response.content)\n\nfor child in root:\n    if child.tag.endswith('ShortName') or child.tag.endswith('Description'):\n        print(f\"{child.tag}: {child.text}\")\n\n\n{http://a9.com/-/spec/opensearch/1.1/}ShortName: Sentinel-1\n{http://a9.com/-/spec/opensearch/1.1/}Description: Sentinel-1 Collection\n\n\n\n\n\nThe resulting XML file provides full list of the parameters for the collection, with their very brief descriptions."
  },
  {
    "objectID": "Data/CMEMS.html",
    "href": "Data/CMEMS.html",
    "title": "Copernicus Marine Environment Monitoring Service (CMEMS)",
    "section": "",
    "text": "The Copernicus Marine Environment Monitoring Service (CMEMS) provides open, free, regular and systematic reference data on the blue (physical), white (sea ice), and green (biogeochemical) state of the marine environment, as well as data on variability and dynamics across the global ocean and European seas.\nCopernicus Data Space Ecosystem data catalogue provides resources for water analysis in all dimensions, from local to global and from visible to radar techniques. The CMEMS products available via Copernicus Data Space Ecosystem platform are particularly dedicated to water application.\nTwo main kinds of products are offered by Copernius Data Space Ecosystem: Near Real Time (NRT) and Reprocessed including climate analysis (REP)."
  },
  {
    "objectID": "Data/CMEMS.html#copernicus-marine-environment-monitoring-service-cmems---near-real-time-nrt",
    "href": "Data/CMEMS.html#copernicus-marine-environment-monitoring-service-cmems---near-real-time-nrt",
    "title": "Copernicus Marine Environment Monitoring Service (CMEMS)",
    "section": "Copernicus Marine Environment Monitoring Service (CMEMS) - Near Real Time (NRT)",
    "text": "Copernicus Marine Environment Monitoring Service (CMEMS) - Near Real Time (NRT)\n\nOverview\n\nOffered Data\n\n\nGLO - Global\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nGLOBAL_ANALYSIS_FORECAST_BIO_001_028\n\n\nJan 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/BIO/GLOBAL_ANALYSIS_FORECAST_BIO_001_028/\n\n\nDetails\n\n\n\n\nGLOBAL_ANALYSIS_FORECAST_BIO_001_014\n\n\nDec 2011 - Jan 2021\n\n\n/eodata/CMEMS/NRT/GLO/BIO/GLOBAL_ANALYSIS_FORECAST_BIO_001_014/\n\n\nN/A\n\n\n\n\nCAR (Carbon)\n\n\nINSITU_GLO_CARBON_NRT_OBSERVATIONS_013_049\n\n\nMar 2019 - Dec 2021\n\n\n/eodata/CMEMS/NRT/GLO/CAR/INSITU_GLO_CARBON_NRT_OBSERVATIONS_013_049/\n\n\nN/A\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_GLO_CHL_L3_NRT_OBSERVATIONS_009_032\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/GLO/CHL/OCEANCOLOUR_GLO_CHL_L3_NRT_OBSERVATIONS_009_032/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_CHL_L4_NRT_OBSERVATIONS_009_033\n\n\nJan 2016 - Jan 2022\n\n\n/eodata/CMEMS/NRT/GLO/CHL/OCEANCOLOUR_GLO_CHL_L4_NRT_OBSERVATIONS_009_033/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_GLO_NRT_OBSERVATIONS_013_030\n\n\nFeb 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/GLO/OBS/INSITU_GLO_NRT_OBSERVATIONS_013_030/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_GLO_OPTICS_L3_NRT_OBSERVATIONS_009_030\n\n\nApr 2016 - Sep 2023\n\n\n/eodata/CMEMS/NRT/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L3_NRT_OBSERVATIONS_009_030/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_OPTICS_L4_NRT_OBSERVATIONS_009_083\n\n\nJan 2016 - Jun 2022\n\n\n/eodata/CMEMS/NRT/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L4_NRT_OBSERVATIONS_009_083/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nGLOBAL_ANALYSIS_FORECAST_PHY_001_024\n\n\nAug 2018 - Present\n\n\n/eodata/CMEMS/NRT/GLO/PHY/GLOBAL_ANALYSIS_FORECAST_PHY_001_024/\n\n\nDetails\n\n\n\n\nGLOBAL_ANALYSIS_FORECAST_PHYS_001_015\n\n\nDec 2015 - Jan 2022\n\n\n/eodata/CMEMS/NRT/GLO/PHY/GLOBAL_ANALYSIS_FORECAST_PHYS_001_015/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_NRT_015_001\n\n\nJan 2018 - Mar 2023\n\n\n/eodata/CMEMS/NRT/GLO/PHY/MULTIOBS_GLO_PHY_NRT_015_001/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_NRT_015_003\n\n\nMay 2019 - Aug 2019\n\n\n/eodata/CMEMS/NRT/GLO/PHY/MULTIOBS_GLO_PHY_NRT_015_003/\n\n\nDetails\n\n\n\n\nSEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046\n\n\nApr 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/PHY/SEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_001\n\n\nMar 2005 Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/SI/SEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_001/\n\n\nDetails\n\n\n\n\nSEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_006\n\n\nMar 2010 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/SI/SEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_006/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_GLO_SST_L3S_NRT_OBSERVATIONS_010_010\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/GLO/SST/SST_GLO_SST_L3S_NRT_OBSERVATIONS_010_010/\n\n\nDetails\n\n\n\n\nSST_GLO_SST_L4_NRT_OBSERVATIONS_010_001\n\n\nJan 2007 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/SST/SST_GLO_SST_L4_NRT_OBSERVATIONS_010_001/\n\n\nDetails\n\n\n\n\nSST_GLO_SST_L4_NRT_OBSERVATIONS_010_005\n\n\nSep 2017 - Dec 2022\n\n\n/eodata/CMEMS/NRT/GLO/SST/SST_GLO_SST_L4_NRT_OBSERVATIONS_010_005/\n\n\nN/A\n\n\n\n\nSST_GLO_SST_L4_NRT_OBSERVATIONS_010_014\n\n\nSep 2017 - Dec 2022\n\n\n/eodata/CMEMS/NRT/GLO/SST/SST_GLO_SST_L4_NRT_OBSERVATIONS_010_014/\n\n\nN/A\n\n\n\n\nTS_OA (Real time in-situ observations objective analysis)\n\n\nINSITU_GLO_TS_OA_NRT_OBSERVATIONS_013_002_a\n\n\nJan 2015 - Dec 2022\n\n\n/eodata/CMEMS/NRT/GLO/TS_OA/INSITU_GLO_TS_OA_NRT_OBSERVATIONS_013_002_a/\n\n\nDetails\n\n\n\n\nUV (water velocity)\n\n\nINSITU_GLO_UV_NRT_OBSERVATIONS_013_048\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/GLO/UV/INSITU_GLO_UV_NRT_OBSERVATIONS_013_048/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nGLOBAL_ANALYSIS_FORECAST_WAV_001_023\n\n\nApr 2015 - Aug 2019\n\n\n/eodata/CMEMS/NRT/GLO/WAV/GLOBAL_ANALYSIS_FORECAST_WAV_001_023/\n\n\nN/A\n\n\n\n\nGLOBAL_ANALYSIS_FORECAST_WAV_001_027\n\n\nMay 2017 - Mar 2023\n\n\n/eodata/CMEMS/NRT/GLO/WAV/GLOBAL_ANALYSIS_FORECAST_WAV_001_027/\n\n\nDetails\n\n\n\n\nGLOBAL_ANALYSIS_FORECAST_WAV_001_028\n\n\nAug 2019 - Aug 2019\n\n\n/eodata/CMEMS/NRT/GLO/WAV/GLOBAL_ANALYSIS_FORECAST_WAV_001_028/\n\n\nDetails\n\n\n\n\nSEALEVEL_GLO_WAV_L3_NRT_OBSERVATIONS_008_052\n\n\nJul 2017 - Nov 2018\n\n\n/eodata/CMEMS/NRT/GLO/WAV/SEALEVEL_GLO_WAV_L3_NRT_OBSERVATIONS_008_052/\n\n\nN/A\n\n\n\n\nWAVE_GLO_WAV_L3_SPC_NRT_OBSERVATIONS_014_002\n\n\nApr 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/WAV_SPC/WAVE_GLO_WAV_L3_SPC_NRT_OBSERVATIONS_014_002/\n\n\nDetails\n\n\n\n\nWAVE_GLO_WAV_L3_SWH_NRT_OBSERVATIONS_014_001\n\n\nOct 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/WAV_SWH/WAVE_GLO_WAV_L3_SWH_NRT_OBSERVATIONS_014_001/\n\n\nDetails\n\n\n\n\nWAVE_GLO_WAV_L4_SWH_NRT_OBSERVATIONS_014_003\n\n\nJun 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/WAV_SWH/WAVE_GLO_WAV_L4_SWH_NRT_OBSERVATIONS_014_003/\n\n\nDetails\n\n\n\n\nWIN (Wind)\n\n\nWIND_GLO_WIND_L3_NRT_OBSERVATIONS_012_002\n\n\nJan 2016 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/WIN/WIND_GLO_WIND_L3_NRT_OBSERVATIONS_012_002/\n\n\nDetails\n\n\n\n\nWIND_GLO_WIND_L4_NRT_OBSERVATIONS_012_004\n\n\nJan 2018 - Nov 2021\n\n\n/eodata/CMEMS/NRT/GLO/WIN/WIND_GLO_WIND_L4_NRT_OBSERVATIONS_012_004/\n\n\nDetails\n\n\n\n\n\n\nANT - Antarctic Ocean\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_ANT_SEAICE_L4_NRT_OBSERVATIONS_011_012\n\n\nJan 2011 - Mar 2022\n\n\n/eodata/CMEMS/NRT/ANT/SI/SEAICE_ANT_SEAICE_L4_NRT_OBSERVATIONS_011_012/\n\n\nDetails\n\n\n\n\n\n\nARC - Arctic Ocean\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nARCTIC_ANALYSISFORECAST_BGC_002_004\n\n\nJan 2019 - May 2023\n\n\n/eodata/CMEMS/NRT/ARC/BGC/ARCTIC_ANALYSISFORECAST_BGC_002_004/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_ARC_BGC_HR_L3_NRT_009_201\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/BGC/OCEANCOLOUR_ARC_BGC_HR_L3_NRT_009_201/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_ARC_BGC_HR_L4_NRT_009_207\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/ARC/BGC/OCEANCOLOUR_ARC_BGC_HR_L4_NRT_009_207/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nARCTIC_ANALYSIS_FORECAST_BIO_002_004\n\n\nDec 2011 - Jul 2021\n\n\n/eodata/CMEMS/NRT/ARC/BIO/ARCTIC_ANALYSIS_FORECAST_BIO_002_004/\n\n\nDetails\n\n\n\n\nARCTIC_ANALYSIS_FORECAST_WAV_002_006\n\n\nJul 2019 - Aug 2019\n\n\n/eodata/CMEMS/NRT/ARC/BIO/ARCTIC_ANALYSIS_FORECAST_WAV_002_006/\n\n\nN/A\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_ARC_CHL_L3_NRT_OBSERVATIONS_009_047\n\n\nMar 2016 - Aug 2022\n\n\n/eodata/CMEMS/NRT/ARC/CHL/OCEANCOLOUR_ARC_CHL_L3_NRT_OBSERVATIONS_009_047/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ARC_CHL_L4_NRT_OBSERVATIONS_009_087\n\n\nApr 2016 - Jan 2022\n\n\n/eodata/CMEMS/NRT/ARC/CHL/OCEANCOLOUR_ARC_CHL_L4_NRT_OBSERVATIONS_009_087/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_ARC_NRT_OBSERVATIONS_013_031\n\n\nJan 1990 - Present\n\n\n/eodata/CMEMS/NRT/ARC/OPT/INSITU_ARC_NRT_OBSERVATIONS_013_031/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_ARC_OPTICS_L3_NRT_OBSERVATIONS_009_046\n\n\nMar 2016 - Aug 2022\n\n\n/eodata/CMEMS/NRT/ARC/OPT/OCEANCOLOUR_ARC_OPTICS_L3_NRT_OBSERVATIONS_009_046/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ARC_OPTICS_L4_NRT_OBSERVATIONS_009_089\n\n\nApr 2016 - Jan 2022\n\n\n/eodata/CMEMS/NRT/ARC/OPT/OCEANCOLOUR_ARC_OPTICS_L4_NRT_OBSERVATIONS_009_089/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nARCTIC_ANALYSIS_FORECAST_PHYS_002_001_a\n\n\nOct 2016 - May 2023\n\n\n/eodata/CMEMS/NRT/ARC/PHY/ARCTIC_ANALYSIS_FORECAST_PHYS_002_001_a/\n\n\nDetails\n\n\n\n\nARCTIC_ANALYSISFORECAST_PHY_ICE_002_011\n\n\nNov 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/PHY/ARCTIC_ANALYSISFORECAST_PHY_ICE_002_011/\n\n\nDetails\n\n\n\n\nSEAICE_ARC_PHY_AUTO_L4_NRT_011_015\n\n\nDec 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/PHY/SEAICE_ARC_PHY_AUTO_L4_NRT_011_015/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_002\n\n\nJan 2010 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/SI/SEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_002/\n\n\nDetails\n\n\n\n\nSEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_003\n\n\nJun 2008 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/SI/SEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_003/\n\n\nN/A\n\n\n\n\nSEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_007\n\n\nApr 2010 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/SI/SEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_007/\n\n\nDetails\n\n\n\n\nSEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_008\n\n\nJan 1982 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/SI/SEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_008/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nARCTIC_ANALYSIS_FORECAST_WAV_002_006\n\n\nDec 2016 - Feb 2020\n\n\n/eodata/CMEMS/NRT/ARC/WAV/ARCTIC_ANALYSIS_FORECAST_WAV_002_006/\n\n\nN/A\n\n\n\n\nARCTIC_ANALYSIS_FORECAST_WAV_002_010\n\n\nDec 2016 - Feb 2020\n\n\n/eodata/CMEMS/NRT/ARC/WAV/ARCTIC_ANALYSIS_FORECAST_WAV_002_010/\n\n\nN/A\n\n\n\n\n\n\nATL - Atlantic North\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_ATL_CHL_L3_NRT_OBSERVATIONS_009_036\n\n\nFeb 2016 - Aug 2022\n\n\n/eodata/CMEMS/NRT/ATL/CHL/OCEANCOLOUR_ATL_CHL_L3_NRT_OBSERVATIONS_009_036/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_CHL_L4_NRT_OBSERVATIONS_009_037\n\n\nMay 2019 - Aug 2021\n\n\n/eodata/CMEMS/NRT/ATL/CHL/OCEANCOLOUR_ATL_CHL_L4_NRT_OBSERVATIONS_009_037/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_CHL_L4_NRT_OBSERVATIONS_009_090\n\n\nApr 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/ATL/CHL/OCEANCOLOUR_ATL_CHL_L4_NRT_OBSERVATIONS_009_090/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_ATL_OPTICS_L3_NRT_OBSERVATIONS_009_034\n\n\nApr 2016 - Aug 2022\n\n\n/eodata/CMEMS/NRT/ATL/OPT/OCEANCOLOUR_ATL_OPTICS_L3_NRT_OBSERVATIONS_009_034/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_OPTICS_L4_NRT_OBSERVATIONS_009_092\n\n\nApr 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/ATL/OPT/OCEANCOLOUR_ATL_OPTICS_L4_NRT_OBSERVATIONS_009_092/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_ATL_SST_L4_NRT_OBSERVATIONS_010_025\n\n\nJan 2018 - Nov 2022\n\n\n/eodata/CMEMS/NRT/ATL/SST/SST_ATL_SST_L4_NRT_OBSERVATIONS_010_025/\n\n\nDetails\n\n\n\n\n\n\nBAL - Baltic Sea\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nOCEANCOLOUR_BAL_BGC_HR_L3_NRT_009_202\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/BGC/OCEANCOLOUR_BAL_BGC_HR_L3_NRT_009_202/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_BAL_BGC_HR_L4_NRT_009_208\n\n\nFeb 2020 - Jan 2023\n\n\n/eodata/CMEMS/NRT/BAL/BGC/OCEANCOLOUR_BAL_BGC_HR_L4_NRT_009_208/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nBALTICSEA_ANALYSIS_FORECAST_BIO_003_007\n\n\nMar 2016 - Feb 2021\n\n\n/eodata/CMEMS/NRT/BAL/BIO/BALTICSEA_ANALYSIS_FORECAST_BIO_003_007/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_BAL_CHL_L3_NRT_OBSERVATIONS_009_049\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BAL/CHL/OCEANCOLOUR_BAL_CHL_L3_NRT_OBSERVATIONS_009_049/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_BAL_NRT_OBSERVATIONS_013_032\n\n\nJan 2015 - Jan 2023\n\n\n/eodata/CMEMS/NRT/BAL/OBS/INSITU_BAL_NRT_OBSERVATIONS_013_032/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_BAL_OPTICS_L3_NRT_OBSERVATIONS_009_048\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BAL/OPT/OCEANCOLOUR_BAL_OPTICS_L3_NRT_OBSERVATIONS_009_048/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nBALTICSEA_ANALYSIS_FORECAST_PHY_003_006\n\n\nMar 2016 - Feb 2021\n\n\n/eodata/CMEMS/NRT/BAL/PHY/BALTICSEA_ANALYSIS_FORECAST_PHY_003_006/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_BAL_SEAICE_L4_NRT_OBSERVATIONS_011_004\n\n\nJan 2010 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/SI/SEAICE_BAL_SEAICE_L4_NRT_OBSERVATIONS_011_004/\n\n\nDetails\n\n\n\n\nSEAICE_BAL_SEAICE_L4_NRT_OBSERVATIONS_011_011\n\n\nJan 2011 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/SI/SEAICE_BAL_SEAICE_L4_NRT_OBSERVATIONS_011_011/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_BAL_SST_L3S_NRT_OBSERVATIONS_010_032\n\n\nMar 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/SST/SST_BAL_SST_L3S_NRT_OBSERVATIONS_010_032/\n\n\nDetails\n\n\n\n\nSST_BAL_SST_L4_NRT_OBSERVATIONS_010_007_b\n\n\nJan 2016 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/SST/SST_BAL_SST_L4_NRT_OBSERVATIONS_010_007_b/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nBALTICSEA_ANALYSIS_FORECAST_WAV_003_010\n\n\nJul 2017 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/WAV/BALTICSEA_ANALYSIS_FORECAST_WAV_003_010/\n\n\nDetails\n\n\n\n\n\n\nBLA, BLK and BS (Black Sea)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nOCEANCOLOUR_BLK_BGC_HR_L3_NRT_009_206\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BLK/BGC/OCEANCOLOUR_BLK_BGC_HR_L3_NRT_009_206/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_BLK_BGC_HR_L4_NRT_009_212\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/BLK/BGC/OCEANCOLOUR_BLK_BGC_HR_L4_NRT_009_212/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nBLKSEA_ANALYSIS_FORECAST_BIO_007_009\n\n\nMay 2019 - Aug 2019\n\n\n/eodata/CMEMS/NRT/BLA/BIO/BLKSEA_ANALYSIS_FORECAST_BIO_007_009/\n\n\nN/A\n\n\n\n\nBLKSEA_ANALYSIS_FORECAST_BIO_007_010\n\n\nJan 2018 - Feb 2023\n\n\n/eodata/CMEMS/NRT/BLA/BIO/BLKSEA_ANALYSIS_FORECAST_BIO_007_010/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_BS_CHL_L3_NRT_OBSERVATIONS_009_044\n\n\nJun 2013 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BLA/CHL/OCEANCOLOUR_BS_CHL_L3_NRT_OBSERVATIONS_009_044/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_BS_CHL_L4_NRT_OBSERVATIONS_009_045\n\n\nJun 2013 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BLA/CHL/OCEANCOLOUR_BS_CHL_L4_NRT_OBSERVATIONS_009_045/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_BS_NRT_OBSERVATIONS_013_034\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/BLA/OBS/INSITU_BS_NRT_OBSERVATIONS_013_034/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_BS_OPTICS_L3_NRT_OBSERVATIONS_009_042\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BLA/OPT/OCEANCOLOUR_BS_OPTICS_L3_NRT_OBSERVATIONS_009_042/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_BS_OPTICS_L4_NRT_OBSERVATIONS_009_043\n\n\nJan 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/BLA/OPT/OCEANCOLOUR_BS_OPTICS_L4_NRT_OBSERVATIONS_009_043/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nBLKSEA_ANALYSISFORECAST_PHY_007_001\n\n\nJan 2019 - Feb 2023\n\n\n/eodata/CMEMS/NRT/BLA/PHY/BLKSEA_ANALYSISFORECAST_PHY_007_001/\n\n\nDetails\n\n\n\n\nSEALEVEL_BS_PHY_L3_NRT_OBSERVATIONS_008_039\n\n\nMar 2017 - Jun 2019\n\n\n/eodata/CMEMS/NRT/BLA/PHY/SEALEVEL_BS_PHY_L3_NRT_OBSERVATIONS_008_039/\n\n\nN/A\n\n\n\n\nSEALEVEL_BS_PHY_L4_NRT_OBSERVATIONS_008_041\n\n\nJan 2017 - Jun 2019\n\n\n/eodata/CMEMS/NRT/BLA/PHY/SEALEVEL_BS_PHY_L4_NRT_OBSERVATIONS_008_041/\n\n\n\n\n\n\nSEALEVEL_BLK_PHY_MDT_L4_STATIC_008_067\n\n\nJan 1970 - Jan 1970\n\n\n/eodata/CMEMS/NRT/BLK/PHY/SEALEVEL_BLK_PHY_MDT_L4_STATIC_008_067/\n\n\nDetails\n\n\n\n\nSST_BS_PHY_SUBSKIN_L4_NRT_010_035\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BS/PHY/SST_BS_PHY_SUBSKIN_L4_NRT_010_035/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_BS_SST_L3S_NRT_OBSERVATIONS_010_013\n\n\nJan 2008 -Apr 2023\n\n\n/eodata/CMEMS/NRT/BLA/SST/SST_BS_SST_L3S_NRT_OBSERVATIONS_010_013/\n\n\nDetails\n\n\n\n\nSST_BS_SST_L4_NRT_OBSERVATIONS_010_006\n\n\nJan 2008 -Apr 2023\n\n\n/eodata/CMEMS/NRT/BLA/SST/SST_BS_SST_L4_NRT_OBSERVATIONS_010_006/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nBLKSEA_ANALYSIS_FORECAST_WAV_007_003\n\n\nJul 2018 -Feb 2021\n\n\n/eodata/CMEMS/NRT/BLA/WAV/BLKSEA_ANALYSIS_FORECAST_WAV_007_003/\n\n\nDetails\n\n\n\n\n\n\nEUR - EUROPE\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_EUR_CHL_L3_NRT_OBSERVATIONS_009_050\n\n\nJan 2017 - Jun 2022\n\n\n/eodata/CMEMS/NRT/EUR/CHL/OCEANCOLOUR_EUR_CHL_L3_NRT_OBSERVATIONS_009_050/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nSEALEVEL_EUR_PHY_L3_NRT_OBSERVATIONS_008_059\n\n\nApr 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/EUR/PHY/SEALEVEL_EUR_PHY_L3_NRT_OBSERVATIONS_008_059/\n\n\nDetails\n\n\n\n\nSEALEVEL_EUR_PHY_L4_NRT_OBSERVATIONS_008_060\n\n\nApr 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/EUR/PHY/SEALEVEL_EUR_PHY_L4_NRT_OBSERVATIONS_008_060/\n\n\nDetails\n\n\n\n\nPHY_ASS (Physics_assimilation)\n\n\nSEALEVEL_EUR_PHY_ASSIM_L3_NRT_OBSERVATIONS_008_043\n\n\nMar 2017 - Jun 2019\n\n\n/eodata/CMEMS/NRT/EUR/PHY_ASS/SEALEVEL_EUR_PHY_ASSIM_L3_NRT_OBSERVATIONS_008_043/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_EUR_SST_L3C_NRT_OBSERVATIONS_010_009_b\n\n\nAug 2018 - Jan 2022\n\n\n/eodata/CMEMS/NRT/EUR/SST/SST_EUR_SST_L3C_NRT_OBSERVATIONS_010_009_b/\n\n\nN/A\n\n\n\n\nSST_EUR_SST_L3S_NRT_OBSERVATIONS_010_009_a\n\n\nJan 2016 - Jan 2022\n\n\n/eodata/CMEMS/NRT/EUR/SST/SST_EUR_SST_L3S_NRT_OBSERVATIONS_010_009_a/\n\n\nN/A\n\n\n\n\n\n\nIBI - Atlantic: Iberia-Biscay-Ireland\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nOCEANCOLOUR_IBI_BGC_HR_L3_NRT_009_204\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/IBI/BGC/OCEANCOLOUR_IBI_BGC_HR_L3_NRT_009_204/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_IBI_BGC_HR_L4_NRT_009_210\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/IBI/BGC/OCEANCOLOUR_IBI_BGC_HR_L4_NRT_009_210/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nIBI_ANALYSIS_FORECAST_BIO_005_004\n\n\nDec 2015 - Feb 2021\n\n\n/eodata/CMEMS/NRT/IBI/BIO/IBI_ANALYSIS_FORECAST_BIO_005_004/\n\n\nDetails\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_IBI_NRT_OBSERVATIONS_013_033\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/IBI/OBS/INSITU_IBI_NRT_OBSERVATIONS_013_033/\n\n\nDetails\n\n\n\n\nPHY (Physics)\n\n\nIBI_ANALYSIS_FORECAST_PHYS_005_001\n\n\nDec 2011 - Feb 2021\n\n\n/eodata/CMEMS/NRT/IBI/PHY/IBI_ANALYSIS_FORECAST_PHYS_005_001/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nIBI_ANALYSIS_FORECAST_WAV_005_005\n\n\nJan 2015 - Apr 2023\n\n\n/eodata/CMEMS/NRT/IBI/WAV/IBI_ANALYSIS_FORECAST_WAV_005_005/\n\n\nDetails\n\n\n\n\n\n\nMED - Mediterranean Sea\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nMEDSEA_ANALYSISFORECAST_BGC_006_014\n\n\nNov 2019 - Feb 2023\n\n\n/eodata/CMEMS/NRT/MED/BGC/MEDSEA_ANALYSISFORECAST_BGC_006_014/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_MED_BGC_HR_L3_NRT_009_205\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/MED/BGC/OCEANCOLOUR_MED_BGC_HR_L3_NRT_009_205/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_MED_BGC_HR_L4_NRT_009_211\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/MED/BGC/OCEANCOLOUR_MED_BGC_HR_L4_NRT_009_211/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nMEDSEA_ANALYSIS_FORECAST_BIO_006_014\n\n\nJul 2017 - Aug 2018\n\n\n/eodata/CMEMS/NRT/MED/BIO/MEDSEA_ANALYSIS_FORECAST_BIO_006_014/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_MED_CHL_L3_NRT_OBSERVATIONS_009_040\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/MED/CHL/OCEANCOLOUR_MED_CHL_L3_NRT_OBSERVATIONS_009_040/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_MED_CHL_L4_NRT_OBSERVATIONS_009_041\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/MED/CHL/OCEANCOLOUR_MED_CHL_L4_NRT_OBSERVATIONS_009_041/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_MED_NRT_OBSERVATIONS_013_035\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/MED/OBS/INSITU_MED_NRT_OBSERVATIONS_013_035/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_MED_OPTICS_L3_NRT_OBSERVATIONS_009_038\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/MED/OPT/OCEANCOLOUR_MED_OPTICS_L3_NRT_OBSERVATIONS_009_038/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_MED_OPTICS_L4_NRT_OBSERVATIONS_009_039\n\n\nApr 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/MED/OPT/OCEANCOLOUR_MED_OPTICS_L4_NRT_OBSERVATIONS_009_039/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nMEDSEA_ANALYSIS_FORECAST_PHY_006_013\n\n\nJul 2017 - Aug 2019\n\n\n/eodata/CMEMS/NRT/MED/PHY/MEDSEA_ANALYSIS_FORECAST_PHY_006_013/\n\n\nDetails\n\n\n\n\nMEDSEA_ANALYSISFORECAST_PHY_006_013\n\n\nMay 2019 - Feb 2023\n\n\n/eodata/CMEMS/NRT/MED/PHY/MEDSEA_ANALYSISFORECAST_PHY_006_013/\n\n\nDetails\n\n\n\n\nSEALEVEL_MED_PHY_L4_NRT_OBSERVATIONS_008_050\n\n\nJan 2017 -Jun 2019\n\n\n/eodata/CMEMS/NRT/MED/PHY/SEALEVEL_MED_PHY_L4_NRT_OBSERVATIONS_008_050/\n\n\nN/A\n\n\n\n\nSEALEVEL_MED_PHY_MDT_L4_STATIC_008_066\n\n\nJan 1970 - Jan 1970\n\n\n/eodata/CMEMS/NRT/MED/PHY/SEALEVEL_MED_PHY_MDT_L4_STATIC_008_066/\n\n\nDetails\n\n\n\n\nSST_MED_PHY_SUBSKIN_L4_NRT_010_036\n\n\nJan 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/MED/PHY/SST_MED_PHY_SUBSKIN_L4_NRT_010_036/\n\n\nDetails\n\n\n\n\nPHY_ASS (Physics_assimilation)\n\n\nSEALEVEL_MED_PHY_ASSIM_L3_NRT_OBSERVATIONS_008_048\n\n\nMar 2017 - Jun 2019\n\n\n/eodata/CMEMS/NRT/MED/PHY_ASS/SEALEVEL_MED_PHY_ASSIM_L3_NRT_OBSERVATIONS_008_048/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_MED_SST_L3S_NRT_OBSERVATIONS_010_012\n\n\nJan 2008 - Apr 2023\n\n\n/eodata/CMEMS/NRT/MED/SST/SST_MED_SST_L3S_NRT_OBSERVATIONS_010_012/\n\n\nDetails\n\n\n\n\nSST_MED_SST_L4_NRT_OBSERVATIONS_010_004\n\n\nJan 2008 - Apr 2023\n\n\n/eodata/CMEMS/NRT/MED/SST/SST_MED_SST_L4_NRT_OBSERVATIONS_010_004/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nMEDSEA_ANALYSIS_FORECAST_WAV_006_011\n\n\nJul 2017 - May 2018\n\n\n/eodata/CMEMS/NRT/MED/WAV/MEDSEA_ANALYSIS_FORECAST_WAV_006_011/\n\n\nN/A\n\n\n\n\nMEDSEA_ANALYSIS_FORECAST_WAV_006_017\n\n\nJul 2017 - Aug 2019\n\n\n/eodata/CMEMS/NRT/MED/WAV/MEDSEA_ANALYSIS_FORECAST_WAV_006_017/\n\n\nDetails\n\n\n\n\nMEDSEA_ANALYSISFORECAST_WAV_006_017\n\n\nNov 2019 - Nov 2022\n\n\n/eodata/CMEMS/NRT/MED/WAV/MEDSEA_ANALYSISFORECAST_WAV_006_017/\n\n\nDetails\n\n\n\n\n\n\nNWS (Atlantic: NW European Shelf)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nNWSHELF_ANALYSISFORECAST_BGC_004_002\n\n\nMay 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/BGC/NWSHELF_ANALYSISFORECAST_BGC_004_002/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_NWS_BGC_HR_L3_NRT_009_203\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/BGC/OCEANCOLOUR_NWS_BGC_HR_L3_NRT_009_203/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_NWS_BGC_HR_L4_NRT_009_209\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/NWS/BGC/OCEANCOLOUR_NWS_BGC_HR_L4_NRT_009_209/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nNORTHWESTSHELF_ANALYSIS_FORECAST_BIO_004_002_b\n\n\nJul 2018 - Aug 2021\n\n\n/eodata/CMEMS/NRT/NWS/BIO/NORTHWESTSHELF_ANALYSIS_FORECAST_BIO_004_002_b/\n\n\nDetails\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_NWS_NRT_OBSERVATIONS_013_036\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/NWS/OBS/INSITU_NWS_NRT_OBSERVATIONS_013_036/\n\n\nDetails\n\n\n\n\nPHY (Physics)\n\n\nNORTHWESTSHELF_ANALYSIS_FORECAST_PHY_004_013\n\n\nAug 2018 -Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/PHY/NORTHWESTSHELF_ANALYSIS_FORECAST_PHY_004_013/\n\n\nDetails\n\n\n\n\nNORTHWESTSHELF_ANALYSIS_FORECAST_PHYS_004_001_b\n\n\nJan 2018 - May 2020\n\n\n/eodata/CMEMS/NRT/NWS/PHY/NORTHWESTSHELF_ANALYSIS_FORECAST_PHYS_004_001_b/\n\n\nN/A\n\n\n\n\nNWSHELF_ANALYSISFORECAST_PHY_LR_004_001\n\n\nAug 2021 - Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/PHY/NWSHELF_ANALYSISFORECAST_PHY_LR_004_001/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nNORTHWESTSHELF_ANALYSIS_FORECAST_WAV_004_014\n\n\nAug 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/WAV/NORTHWESTSHELF_ANALYSIS_FORECAST_WAV_004_014/\n\n\nDetails\n\n\n\n\n\nN/A - data no longer provided by CMEMS"
  },
  {
    "objectID": "Data/CMEMS.html#copernicus-marine-environment-monitoring-service-cmems---reprocessed-rep",
    "href": "Data/CMEMS.html#copernicus-marine-environment-monitoring-service-cmems---reprocessed-rep",
    "title": "Copernicus Marine Environment Monitoring Service (CMEMS)",
    "section": "Copernicus Marine Environment Monitoring Service (CMEMS) - Reprocessed (REP)",
    "text": "Copernicus Marine Environment Monitoring Service (CMEMS) - Reprocessed (REP)\n\nOverview\n\nOffered Data\n\n\nGLO - Global\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nGLOBAL_MULTIYEAR_BGC_001_033\n\n\nJan 1998 - May 2020\n\n\n/eodata/CMEMS/REP/GLO/BGC/GLOBAL_MULTIYEAR_BGC_001_033/\n\n\nDetails\n\n\n\n\nINSITU_GLO_BGC_REP_OBSERVATIONS_013_046\n\n\nJan 1990 - Dec 2021\n\n\n/eodata/CMEMS/REP/GLO/BGC/INSITU_GLO_BGC_REP_OBSERVATIONS_013_046/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nGLOBAL_REANALYSIS_BIO_001_029\n\n\nJan 1992 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/BIO/GLOBAL_REANALYSIS_BIO_001_029/\n\n\nDetails\n\n\n\n\nGLOBAL_REANALYSIS_BIO_001_033\n\n\nJan 2001 - Jun 2019\n\n\n/eodata/CMEMS/REP/GLO/BIO/GLOBAL_REANALYSIS_BIO_001_033/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_BIO_REP_015_005\n\n\nJan 1985 - Dec 2019\n\n\n/eodata/CMEMS/REP/GLO/BIO/MULTIOBS_GLO_BIO_REP_015_005/\n\n\nDetails\n\n\n\n\nMULTIOBS_GLO_BIO_REP_015_006\n\n\nSep 2002 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/BIO/MULTIOBS_GLO_BIO_REP_015_006/\n\n\n\n\n\n\nCAR (Carbon)\n\n\nINSITU_GLO_CARBON_REP_OBSERVATIONS_013_050\n\n\n\n\n/eodata/CMEMS/REP/GLO/CAR/INSITU_GLO_CARBON_REP_OBSERVATIONS_013_050/\n\n\nDetails\n\n\n\n\nMULTIOBS_GLO_BIO_CARBON_SURFACE_REP_015_008\n\n\nJan 1985 - Dec 2021\n\n\n/eodata/CMEMS/REP/GLO/CAR/MULTIOBS_GLO_BIO_CARBON_SURFACE_REP_015_008/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_GLO_CHL_L3_REP_OBSERVATIONS_009_065\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/CHL/OCEANCOLOUR_GLO_CHL_L3_REP_OBSERVATIONS_009_065/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_CHL_L3_REP_OBSERVATIONS_009_085\n\n\nSep 1997 - Jun 2018\n\n\n/eodata/CMEMS/REP/GLO/CHL/OCEANCOLOUR_GLO_CHL_L3_REP_OBSERVATIONS_009_085/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_082\n\n\nSep 1997 - Jun 2018\n\n\n/eodata/CMEMS/REP/GLO/CHL/OCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_082/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_093\n\n\nSep 1997 - Jun 2018\n\n\n/eodata/CMEMS/REP/GLO/CHL/OCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_093/\n\n\nN/A\n\n\n\n\nOHC (Ocean Heat Content)\n\n\nGLOBAL_OMI_OHC_anomalies (anomalies in respect to various years)\n\n\nAnomalies in respect to various years\n\n\n/eodata/CMEMS/REP/GLO/OHC/GLOBAL_OMI_OHC_anomalies/\n\n\n\n\n\n\nGLOBAL_OMI_OHC_area_averaged_anomalies (anomalies in respect to various years)\n\n\nAnomalies in respect to various years\n\n\n/eodata/CMEMS/REP/GLO/OHC/GLOBAL_OMI_OHC_area_averaged_anomalies/\n\n\n\n\n\n\nGLOBAL_OMI_OHC_trend (trends in respect to various years)\n\n\nTrends in respect to various years\n\n\n/eodata/CMEMS/REP/GLO/OHC/GLOBAL_OMI_OHC_trend/\n\n\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_GLO_OPTICS_L3_REP_OBSERVATIONS_009_064\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L3_REP_OBSERVATIONS_009_064/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_OPTICS_L3_REP_OBSERVATIONS_009_086\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L3_REP_OBSERVATIONS_009_086/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_OPTICS_L4_REP_OBSERVATIONS_009_081\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L4_REP_OBSERVATIONS_009_081/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nGLOBAL_REANALYSIS_PHY_001_025\n\n\nJan 1993 - Dec 2015\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHY_001_025/\n\n\nN/A\n\n\n\n\nGLOBAL_REANALYSIS_PHY_001_026\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHY_001_026/\n\n\nDetails\n\n\n\n\nGLOBAL_REANALYSIS_PHY_001_030\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHY_001_030/\n\n\nDetails\n\n\n\n\nGLOBAL_REANALYSIS_PHY_001_031\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHY_001_031/\n\n\nDetails\n\n\n\n\nGLOBAL_REANALYSIS_PHY_001_017\n\n\nJan 1979 - Dec 2013\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHYS_001_017/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_REP_015_002\n\n\nJan 1993 - Dec 2018\n\n\n/eodata/CMEMS/REP/GLO/PHY/MULTIOBS_GLO_PHY_REP_015_002/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_REP_015_004\n\n\nJan 1993 - Dec 2021\n\n\n/eodata/CMEMS/REP/GLO/PHY/MULTIOBS_GLO_PHY_REP_015_004/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_W_3D_REP_015_007\n\n\nJan 1993 - Dec 2018\n\n\n/eodata/CMEMS/REP/GLO/PHY/MULTIOBS_GLO_PHY_W_3D_REP_015_007/\n\n\nDetails\n\n\n\n\nSEALEVEL_GLO_PHY_L3_REP_OBSERVATIONS_008_062\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/GLO/PHY/SEALEVEL_GLO_PHY_L3_REP_OBSERVATIONS_008_062/\n\n\nDetails\n\n\n\n\nSEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047\n\n\nJan 1993 - Feb 2022\n\n\n/eodata/CMEMS/REP/GLO/PHY/SEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047/\n\n\nDetails\n\n\n\n\nPHY_CLIM (Physics climate)\n\n\nSEALEVEL_GLO_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_057\n\n\nJan 1993 - Feb 2022\n\n\n/eodata/CMEMS/REP/GLO/PHY_CLIM/SEALEVEL_GLO_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_057/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_GLO_SEAICE_L4_REP_OBSERVATIONS_011_009\n\n\nOct 1978 - Dec 2019\n\n\n/eodata/CMEMS/REP/GLO/SI/SEAICE_GLO_SEAICE_L4_REP_OBSERVATIONS_011_009/\n\n\nDetails\n\n\n\n\nSL (Sea level)\n\n\nGLOBAL_OMI_SL_regional_trends (anomalies in respect to various years)\n\n\nJan 1993 - Jan 1993\n\n\n/eodata/CMEMS/REP/GLO/SL/GLOBAL_OMI_SL_regional_trends/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_GLO_SST_L4_REP_OBSERVATIONS_010_011\n\n\nOct 1981 - May 2022\n\n\n/eodata/CMEMS/REP/GLO/SST/SST_GLO_SST_L4_REP_OBSERVATIONS_010_011/\n\n\nDetails\n\n\n\n\nSST_GLO_SST_L4_REP_OBSERVATIONS_010_024\n\n\nNov 1991 - Dec 2010\n\n\n/eodata/CMEMS/REP/GLO/SST/SST_GLO_SST_L4_REP_OBSERVATIONS_010_024/\n\n\nDetails\n\n\n\n\nTS (Temperature and salinity)\n\n\nINSITU_GLO_TS_OA_REP_OBSERVATIONS_013_002_b\n\n\nJan 1990 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/TS/INSITU_GLO_TS_OA_REP_OBSERVATIONS_013_002_b/\n\n\nDetails\n\n\n\n\nINSITU_GLO_TS_REP_OBSERVATIONS_013_001_b\n\n\nJan 1950 - Dec 2018\n\n\n/eodata/CMEMS/REP/GLO/TS/INSITU_GLO_TS_REP_OBSERVATIONS_013_001_b/\n\n\nDetails\n\n\n\n\nUV (water velocity)\n\n\nINSITU_GLO_UV_L2_REP_OBSERVATIONS_013_044\n\n\nJan 2012 - Dec 2021\n\n\n/eodata/CMEMS/REP/GLO/UV/INSITU_GLO_UV_L2_REP_OBSERVATIONS_013_044/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nGLOBAL_REANALYSIS_WAV_001_032\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/WAV/GLOBAL_REANALYSIS_WAV_001_032/\n\n\nDetails\n\n\n\n\nINSITU_GLO_WAVE_REP_OBSERVATIONS_013_045\n\n\nJan 1990 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/WAV/INSITU_GLO_WAVE_REP_OBSERVATIONS_013_045/\n\n\nDetails\n\n\n\n\nWIN (Wind)\n\n\nSST_NWS_SST_L4_REP_OBSERVATIONS_010_023\n\n\nMar 1992 - Nov 2021\n\n\n/eodata/CMEMS/REP/GLO/WIN/SST_NWS_SST_L4_REP_OBSERVATIONS_010_023/\n\n\nN/A\n\n\n\n\nWIND_GLO_WIND_L3_REP_OBSERVATIONS_012_005\n\n\nMar 1992 - Dec 2017\n\n\n/eodata/CMEMS/REP/GLO/WIN/WIND_GLO_WIND_L3_REP_OBSERVATIONS_012_005/\n\n\nDetails\n\n\n\n\nWIND_GLO_WIND_L4_REP_OBSERVATIONS_012_003\n\n\nMay 2007 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/WIN/WIND_GLO_WIND_L4_REP_OBSERVATIONS_012_003/\n\n\nDetails\n\n\n\n\nWIND_GLO_WIND_L4_REP_OBSERVATIONS_012_006\n\n\nJan 1992 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/WIN/WIND_GLO_WIND_L4_REP_OBSERVATIONS_012_006/\n\n\nDetails\n\n\n\n\n\n\nANT - Antarctic Ocean\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSI (Sea Ice)\n\n\nANTARCTIC_OMI_SI_extent (anomalies in respect to various years)\n\n\nJan 1993 - Mar 2022\n\n\n/eodata/CMEMS/REP/ANT/SI/ANTARCTIC_OMI_SI_extent/\n\n\nN/A\n\n\n\n\n\n\nARC - Arctic Ocean\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nARCTIC_MULTIYEAR_BGC_002_005\n\n\nJan 2007 - Dec 2020\n\n\n/eodata/CMEMS/REP/ARC/BGC/ARCTIC_MULTIYEAR_BGC_002_005/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nARCTIC_REANALYSIS_BIO_002_005\n\n\nJan 2007 - Dec 2010\n\n\n/eodata/CMEMS/REP/ARC/BIO/ARCTIC_REANALYSIS_BIO_002_005/\n\n\nN/A\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_ARC_CHL_L3_REP_OBSERVATIONS_009_069\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/ARC/CHL/OCEANCOLOUR_ARC_CHL_L3_REP_OBSERVATIONS_009_069/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ARC_CHL_L4_REP_OBSERVATIONS_009_088\n\n\nAug 1997 - Dec 2018\n\n\n/eodata/CMEMS/REP/ARC/CHL/OCEANCOLOUR_ARC_CHL_L4_REP_OBSERVATIONS_009_088/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_ARC_OPTICS_L3_REP_OBSERVATIONS_009_068\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/ARC/OPT/OCEANCOLOUR_ARC_OPTICS_L3_REP_OBSERVATIONS_009_068/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nARCTIC_REANALYSIS_PHYS_002_003\n\n\nJan 1991 - Dec 2019\n\n\n/eodata/CMEMS/REP/ARC/PHY/ARCTIC_REANALYSIS_PHYS_002_003/\n\n\nDetails\n\n\n\n\nSEAICE_ARC_PHY_CLIMATE_L4_MY_011_016\n\n\nJan 1982 - May 2021\n\n\n/eodata/CMEMS/REP/ARC/PHY/SEAICE_ARC_PHY_CLIMATE_L4_MY_011_016/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nARCTIC_OMI_SI_extent (Anomalies in respect to various years)\n\n\nAnomalies in respect to various years\n\n\n/eodata/CMEMS/REP/ARC/SI/ARCTIC_OMI_SI_extent/\n\n\nN/A\n\n\n\n\nSEAICE_ARC_SEAICE_L3_REP_OBSERVATIONS_011_010\n\n\nSep 1999 - May 2022\n\n\n/eodata/CMEMS/REP/ARC/SI/SEAICE_ARC_SEAICE_L3_REP_OBSERVATIONS_011_010/\n\n\nDetails\n\n\n\n\n\n\nATL - Atlantic North\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_ATL_CHL_L3_REP_OBSERVATIONS_009_067\n\n\nSep 1997 - Jun 2017\n\n\n/eodata/CMEMS/REP/ATL/CHL/OCEANCOLOUR_ATL_CHL_L3_REP_OBSERVATIONS_009_067/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_CHL_L4_REP_OBSERVATIONS_009_091\n\n\nAug 1997 - Dec 2018\n\n\n/eodata/CMEMS/REP/ATL/CHL/OCEANCOLOUR_ATL_CHL_L4_REP_OBSERVATIONS_009_091/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_CHL_L4_REP_OBSERVATIONS_009_098\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/ATL/CHL/OCEANCOLOUR_ATL_CHL_L4_REP_OBSERVATIONS_009_098/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_ATL_OPTICS_L3_REP_OBSERVATIONS_009_066\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/ATL/OPT/OCEANCOLOUR_ATL_OPTICS_L3_REP_OBSERVATIONS_009_066/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_ATL_SST_L4_REP_OBSERVATIONS_010_026\n\n\nJan 1982 - Dec 2018\n\n\n/eodata/CMEMS/REP/ATL/SST/SST_ATL_SST_L4_REP_OBSERVATIONS_010_026/\n\n\nDetails\n\n\n\n\n\n\nBAL - Baltic Sea\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nBALTICSEA_REANALYSIS_BIO_003_012\n\n\nJan 1993 - Dec 2021\n\n\n/eodata/CMEMS/REP/BAL/BIO/BALTICSEA_REANALYSIS_BIO_003_012/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_BAL_CHL_L3_REP_OBSERVATIONS_009_080\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BAL/CHL/OCEANCOLOUR_BAL_CHL_L3_REP_OBSERVATIONS_009_080/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_BAL_OPTICS_L3_REP_OBSERVATIONS_009_097\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BAL/OPT/OCEANCOLOUR_BAL_OPTICS_L3_REP_OBSERVATIONS_009_097/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nBALTICSEA_REANALYSIS_PHY_003_011\n\n\nSep 1997 - Dec 2021\n\n\n/eodata/CMEMS/REP/BAL/PHY/BALTICSEA_REANALYSIS_PHY_003_011/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSEALEVEL_MED_PHY_L4_REP_OBSERVATIONS_008_051\n\n\nJul 1982 - Dec 2011\n\n\n/eodata/CMEMS/REP/BAL/SST/SEALEVEL_MED_PHY_L4_REP_OBSERVATIONS_008_051/\n\n\nN/A\n\n\n\n\nSST_BAL_SST_L4_REP_OBSERVATIONS_010_016\n\n\nJan 1982 - Dec 2011\n\n\n/eodata/CMEMS/REP/BAL/SST/SST_BAL_SST_L4_REP_OBSERVATIONS_010_016/\n\n\nDetails\n\n\n\n\n\n\nBLA (Black Sea)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nBLKSEA_REANALYSIS_BIO_007_005\n\n\nJan 1992 - Oct 2022\n\n\n/eodata/CMEMS/REP/BLA/BIO/BLKSEA_REANALYSIS_BIO_007_005/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_BS_CHL_L3_REP_OBSERVATIONS_009_071\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BLA/CHL/OCEANCOLOUR_BS_CHL_L3_REP_OBSERVATIONS_009_071/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_BS_CHL_L4_REP_OBSERVATIONS_009_079\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BLA/CHL/OCEANCOLOUR_BS_CHL_L4_REP_OBSERVATIONS_009_079/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_BS_OPTICS_L3_REP_OBSERVATIONS_009_096\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BLA/OPT/OCEANCOLOUR_BS_OPTICS_L3_REP_OBSERVATIONS_009_096/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nBLKSEA_REANALYSIS_PHYS_007_004\n\n\nJan 1992 - Jun 2019\n\n\n/eodata/CMEMS/REP/BLA/PHY/BLKSEA_REANALYSIS_PHYS_007_004/\n\n\nDetails\n\n\n\n\nSEALEVEL_BS_PHY_L4_REP_OBSERVATIONS_008_042\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/BLA/PHY/SEALEVEL_BS_PHY_L4_REP_OBSERVATIONS_008_042/\n\n\nN/A\n\n\n\n\nPHY_CLIM (Physics climate)\n\n\nSEALEVEL_BS_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_058\n\n\nJan 1992 - Jun 2020\n\n\n/eodata/CMEMS/REP/BLA/PHY_CLIM/SEALEVEL_BS_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_058/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_BS_SST_L4_REP_OBSERVATIONS_010_022\n\n\nAug 1981 - Jun 2022\n\n\n/eodata/CMEMS/REP/BLA/SST/SST_BS_SST_L4_REP_OBSERVATIONS_010_022/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nBLKSEA_REANALYSIS_WAV_007_006\n\n\nJan 2002 - Jun 2019\n\n\n/eodata/CMEMS/REP/BLA/WAV/BLKSEA_REANALYSIS_WAV_007_006/\n\n\nDetails\n\n\n\n\n\n\nEUR - EUROPE\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nPHY (Physics)\n\n\nSEALEVEL_EUR_PHY_L3_REP_OBSERVATIONS_008_061\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/EUR/PHY/SEALEVEL_EUR_PHY_L3_REP_OBSERVATIONS_008_061/\n\n\nDetails\n\n\n\n\n\n\nIBI - Atlantic: Iberia-Biscay-Ireland\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nIBI_REANALYSIS_BIO_005_003\n\n\nJan 1992 - Dec 2019\n\n\n/eodata/CMEMS/REP/IBI/BIO/IBI_REANALYSIS_BIO_005_003/\n\n\nDetails\n\n\n\n\nIBI_REANALYSIS_PHYS_005_002\n\n\nJan 2014 - Dec 2019\n\n\n/eodata/CMEMS/REP/IBI/BIO/IBI_REANALYSIS_PHYS_005_002/\n\n\nDetails\n\n\n\n\nPHY (Physics)\n\n\nIBI_REANALYSIS_PHYS_005_002\n\n\nJan 1992 - Dec 2019\n\n\n/eodata/CMEMS/REP/IBI/PHY/IBI_REANALYSIS_PHYS_005_002/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nIBI_REANALYSIS_WAV_005_006\n\n\nJan 1992 - Dec 2019\n\n\n/eodata/CMEMS/REP/IBI/WAV/IBI_REANALYSIS_WAV_005_006/\n\n\nDetails\n\n\n\n\n\n\nMED - Mediterranean Sea\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nMEDSEA_MULTIYEAR_BGC_006_008\n\n\nJan 1999 - Dec 2019\n\n\n/eodata/CMEMS/REP/MED/BGC/MEDSEA_MULTIYEAR_BGC_006_008/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nMEDSEA_REANALYSIS_BIO_006_008\n\n\nJan 1999 - Dec 2018\n\n\n/eodata/CMEMS/REP/MED/BIO/MEDSEA_REANALYSIS_BIO_006_008/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_MED_CHL_L3_REP_OBSERVATIONS_009_073\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/MED/CHL/OCEANCOLOUR_MED_CHL_L3_REP_OBSERVATIONS_009_073/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_MED_CHL_L4_REP_OBSERVATIONS_009_078\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/MED/CHL/OCEANCOLOUR_MED_CHL_L4_REP_OBSERVATIONS_009_078/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_MED_OPTICS_L3_REP_OBSERVATIONS_009_095\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/MED/OPT/OCEANCOLOUR_MED_OPTICS_L3_REP_OBSERVATIONS_009_095/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nMEDSEA_REANALYSIS_PHYS_006_004\n\n\nJan 1987 - Dec 2018\n\n\n/eodata/CMEMS/REP/MED/PHY/MEDSEA_REANALYSIS_PHYS_006_004/\n\n\nDetails\n\n\n\n\nSEALEVEL_MED_PHY_L4_REP_OBSERVATIONS_008_051\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/MED/PHY/SEALEVEL_MED_PHY_L4_REP_OBSERVATIONS_008_051/\n\n\nN/A\n\n\n\n\nPHY_CLIM (Physics climate)\n\n\nSEALEVEL_MED_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_056\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/MED/PHY_CLIM/SEALEVEL_MED_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_056/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_MED_SST_L4_REP_OBSERVATIONS_010_021\n\n\nAug 1981 - Jun 2022\n\n\n/eodata/CMEMS/REP/MED/SST/SST_MED_SST_L4_REP_OBSERVATIONS_010_021/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nMEDSEA_HINDCAST_WAV_006_012\n\n\nFeb 2006 - Jan 2020\n\n\n/eodata/CMEMS/REP/MED/WAV/MEDSEA_HINDCAST_WAV_006_012/\n\n\nDetails\n\n\n\n\nMEDSEA_MULTIYEAR_WAV_006_012\n\n\nJan 1993 - Dec 2019\n\n\n/eodata/CMEMS/REP/MED/WAV/MEDSEA_MULTIYEAR_WAV_006_012/\n\n\nDetails\n\n\n\n\n\n\nNWS (Atlantic: NW European Shelf)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nNORTHWESTSHELF_REANALYSIS_BIO_004_009\n\n\nJan 1993 - July 2022\n\n\n/eodata/CMEMS/REP/NWS/BIO/NORTHWESTSHELF_REANALYSIS_BIO_004_009/\n\n\nDetails\n\n\n\n\nNORTHWESTSHELF_REANALYSIS_BIO_004_011\n\n\nJan 1993 - Jun 2022\n\n\n/eodata/CMEMS/REP/NWS/BIO/NORTHWESTSHELF_REANALYSIS_BIO_004_011/\n\n\nDetails\n\n\n\n\nPHY (Physics)\n\n\nNORTHWESTSHELF_REANALYSIS_PHY_004_009\n\n\nJan 1992 - Dec 2017\n\n\n/eodata/CMEMS/REP/NWS/PHY/NORTHWESTSHELF_REANALYSIS_PHY_004_009/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_NWS_SST_L4_REP_OBSERVATIONS_010_023\n\n\nJan 1982 - Nov 2021\n\n\n/eodata/CMEMS/REP/NWS/SST/SST_NWS_SST_L4_REP_OBSERVATIONS_010_023/\n\n\nN/A\n\n\n\n\n\nN/A - data no longer provided by CMEMS\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://data.marine.copernicus.eu/products"
  },
  {
    "objectID": "Data/Landsat8.html",
    "href": "Data/Landsat8.html",
    "title": "Landsat-8",
    "section": "",
    "text": "The Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters.\nLandsat-8 carries the Operational Land Imager (OLI) and the Thermal Infrared Sensor (TIRS). OLI provides imagery in the VIS, NIR and SWIR spectral ranges. It acquires images with 15 m panchromatic and 30 m multi-spectral spatial resolutions, covering a wide 185 km swath. This allows it to capture extensive areas of the Earth’s landscape while maintaining enough resolution to identify features like urban centers, farms, forests, and other land uses. The entire Earth falls within view once every 16 days due to Landsat-8’s near-polar orbit. The TIRS instrument is a thermal imager operating in a pushbroom mode with two Infra-Red channels: 10.8 µm and 12 µm with 100 m spatial resolution."
  },
  {
    "objectID": "Data/Landsat8.html#landsat-8-olitirs_l1gt",
    "href": "Data/Landsat8.html#landsat-8-olitirs_l1gt",
    "title": "Landsat-8",
    "section": "Landsat-8 OLI/TIRS_L1GT",
    "text": "Landsat-8 OLI/TIRS_L1GT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nOLI/TIRS_L1GT\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nMar 2013 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LANDSAT-8_L1\n\n\nMore Information: https://earth.esa.int/eogateway/missions/landsat-8"
  },
  {
    "objectID": "Data/Landsat8.html#landsat-8-olitirs_l1t",
    "href": "Data/Landsat8.html#landsat-8-olitirs_l1t",
    "title": "Landsat-8",
    "section": "Landsat-8 OLI/TIRS_L1T",
    "text": "Landsat-8 OLI/TIRS_L1T\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nOLI/TIRS_L1T\n\n\n(*) Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nMar 2013 - Present\n\n\n\n\n\n(*) not accessible by landsat-diss.eo.esa.int\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LANDSAT-8_L1\n\n\nMore Information: https://earth.esa.int/eogateway/missions/landsat-8"
  },
  {
    "objectID": "Data/Landsat8.html#landsat-8-olitirs_l1tp",
    "href": "Data/Landsat8.html#landsat-8-olitirs_l1tp",
    "title": "Landsat-8",
    "section": "Landsat-8 OLI/TIRS_L1TP",
    "text": "Landsat-8 OLI/TIRS_L1TP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nOLI/TIRS_L1TP\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nMar 2013 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LANDSAT-8_L1\n\n\nMore Information: https://earth.esa.int/eogateway/missions/landsat-8"
  },
  {
    "objectID": "Data/Landsat8.html#landsat-8-olitirs_l2sp",
    "href": "Data/Landsat8.html#landsat-8-olitirs_l2sp",
    "title": "Landsat-8",
    "section": "Landsat-8 OLI/TIRS_L2SP",
    "text": "Landsat-8 OLI/TIRS_L2SP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nOLI/TIRS_L2SP\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nJan 2015 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LANDSAT-8_L1\n\n\nMore Information: https://earth.esa.int/eogateway/missions/landsat-8"
  },
  {
    "objectID": "Data/CAMS.html",
    "href": "Data/CAMS.html",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "",
    "text": "The Copernicus Atmosphere Monitoring Service (CAMS) is a service implemented by the European Centre for Medium-Range Weather Forecasts (ECMWF) which provides continuous, open, free, regular data and information on atmospheric composition. CAMS describes the current situation, forecasts, reanalysis and analyses consistently retrospective data records for recent years.\nCopernius Data Space Ecosystem provides data from Global Fire Assimilation System (GFAS), Global Atmospheric Composition Forecasts (GLOBAL) including analysis and forecast data on vertical level, Global Additional (GLOBAL_ADDITIOANL) and WMO Essential including data on cyclones."
  },
  {
    "objectID": "Data/CAMS.html#global-fire-assimilation-system-gfs",
    "href": "Data/CAMS.html#global-fire-assimilation-system-gfs",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "Global Fire Assimilation System (GFS)",
    "text": "Global Fire Assimilation System (GFS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nAN (Analysis)\n\n\nWorld\n\n\n(*) Nov 2022 - Apr 2023\n\n\n/eodata/CAMS/GFAS/\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition."
  },
  {
    "objectID": "Data/CAMS.html#global-atmospheric-composition-forecasts-global",
    "href": "Data/CAMS.html#global-atmospheric-composition-forecasts-global",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "Global Atmospheric Composition Forecasts (GLOBAL)",
    "text": "Global Atmospheric Composition Forecasts (GLOBAL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nAN (Analysis)\nFC (Forecasts)\n\n\nWorld\n\n\n(*) Nov 2022 - Apr 2023\n\n\n/eodata/CAMS/GLOBAL/\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition"
  },
  {
    "objectID": "Data/CAMS.html#global-additional",
    "href": "Data/CAMS.html#global-additional",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "GLOBAL ADDITIONAL",
    "text": "GLOBAL ADDITIONAL\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nAN (Analysis)\nFC (Forecasts)\n\n\nWorld\n\n\n(*) Nov 2022 - Apr 2023\n\n\n/eodata/CAMS/GLOBAL_ADDITIONAL/\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition"
  },
  {
    "objectID": "Data/CAMS.html#wmo-essentials",
    "href": "Data/CAMS.html#wmo-essentials",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "WMO ESSENTIALS",
    "text": "WMO ESSENTIALS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nGH (Geopotential Height),\nT (Temperature),\nMSL (Mean sea level pressure),\nU (U component of wind),\nV (V component of wind),\nTCT (Tropical Cyclone Trajectory)\n\n\nWorld\n\n\n(*) Mar 2018 - Oct 2022\n\n\n/eodata/CAMS/WMO_ESSENTIAL/\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition"
  },
  {
    "objectID": "Data/SMOS.html",
    "href": "Data/SMOS.html",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "",
    "text": "The Soil Moisture and Ocean Salinity (SMOS) mission was launched on 2 November 2009. It is one of the European Space Agency’s Earth Explorer missions, which form the science and research element of ESA’s Living Planet Programme.\nThe SMOS payload consists of the Microwave Imaging Radiometer using Aperture Synthesis (MIRAS) instrument, a passive microwave 2-D interferometric radiometer operating in the L-band (1.413 GHz, 21 cm) within a protected wavelength/frequency band. The SMOS mission operates on a sun-synchronous orbit (dusk-dawn 6am/6pm). SMOS measurements are made over a range of incidence angles (0 to 55°) across a swath of approximately 1000 km with a spatial resolution of 35 to 50 km. MIRAS can provide measurements in dual and full polarisation, the latter being its current mode of operation.\nSMOS Level 1 data products are designed for scientific and operational users who need to work with calibrated MIRAS instrument measurements, while SMOS Level 2 data products are designed for scientific and operational users who need to work with geo-located estimates of soil moisture and sea surface salinity as retrieved from the Level 1 dataset."
  },
  {
    "objectID": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l1b",
    "href": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l1b",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L1B",
    "text": "Soil Moisture and Ocean Salinity - L1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nMIR_SC_F1B\nMIR_SC_D1B\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l1cl",
    "href": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l1cl",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L1CL",
    "text": "Soil Moisture and Ocean Salinity - L1CL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nMIR_BWLF1C/MIR_BWLD1C\nMIR_BWSF1C/MIR_BWSD1C - SCLD1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l1cs",
    "href": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l1cs",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L1CS",
    "text": "Soil Moisture and Ocean Salinity - L1CS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nMIR_SCLF1C/MIR_SCLD1C\nMIR_SCSF1C/MIR_SCSD1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l1os",
    "href": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l1os",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L1OS",
    "text": "Soil Moisture and Ocean Salinity - L1OS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nMIR_OSUDP2\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l2sm",
    "href": "Data/SMOS.html#soil-moisture-and-ocean-salinity---l2sm",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L2SM",
    "text": "Soil Moisture and Ocean Salinity - L2SM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nMIR_SMUDP2\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/Additional.html",
    "href": "Data/Additional.html",
    "title": "Additional Data",
    "section": "",
    "text": "Copernicus Data Space Ecosystem provides data that are not associated with any of the Copernicus Services or are generated by third parties. These datasets include Sentinel-1 related products such as RTC (Radiometrically Terrain Corrected), CARD-BS (Terrain-Corrected Backscatter), Orbits; Sentinel-2 based global mosaics; land cover for Europe and Poland (S2GLC) and Digital Elevation Models (COP DEM and SRTM DEM)."
  },
  {
    "objectID": "Data/Additional.html#sentinel-1-rtc",
    "href": "Data/Additional.html#sentinel-1-rtc",
    "title": "Additional Data",
    "section": "Sentinel-1 RTC",
    "text": "Sentinel-1 RTC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nWorld\n\n\nJan 2018 - Present"
  },
  {
    "objectID": "Data/Additional.html#sentinel-1-card-bs",
    "href": "Data/Additional.html#sentinel-1-card-bs",
    "title": "Additional Data",
    "section": "Sentinel-1 CARD-BS",
    "text": "Sentinel-1 CARD-BS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nWorld\n\n\nOct 2014 - Present"
  },
  {
    "objectID": "Data/Additional.html#sentinel-1-orbits",
    "href": "Data/Additional.html#sentinel-1-orbits",
    "title": "Additional Data",
    "section": "Sentinel-1 Orbits",
    "text": "Sentinel-1 Orbits\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpatial Extext\n\n\n\n\n\n\nWorld"
  },
  {
    "objectID": "Data/Additional.html#sentinel-2-mosaics",
    "href": "Data/Additional.html#sentinel-2-mosaics",
    "title": "Additional Data",
    "section": "Sentinel-2 Mosaics",
    "text": "Sentinel-2 Mosaics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nWorld\n\n\n2019 - 2020"
  },
  {
    "objectID": "Data/Additional.html#sentinel-2-glc-s2glc",
    "href": "Data/Additional.html#sentinel-2-glc-s2glc",
    "title": "Additional Data",
    "section": "Sentinel-2 GLC (S2GLC)",
    "text": "Sentinel-2 GLC (S2GLC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nEurope\n\n\nEurope\n\n\n2017\n\n\nLink\n\n\n\n\nPoland\n\n\nPoland\n\n\n2019 - 2021\n\n\nLink"
  },
  {
    "objectID": "Data/Additional.html#copernicus-digital-elevation-model-cop-dem",
    "href": "Data/Additional.html#copernicus-digital-elevation-model-cop-dem",
    "title": "Additional Data",
    "section": "Copernicus Digital Elevation Model (COP DEM)",
    "text": "Copernicus Digital Elevation Model (COP DEM)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\n\n\n\n\nCOP_DEM, COP_DEM_COG\n\n\nWorld"
  },
  {
    "objectID": "Data/Additional.html#shuttle-radar-topography-mission-dem-srtm-dem",
    "href": "Data/Additional.html#shuttle-radar-topography-mission-dem-srtm-dem",
    "title": "Additional Data",
    "section": "Shuttle Radar Topography Mission DEM (SRTM DEM)",
    "text": "Shuttle Radar Topography Mission DEM (SRTM DEM)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\n\n\n\n\nSRTMGL1\n\n\nWorld"
  },
  {
    "objectID": "Data/Sentinel3.html",
    "href": "Data/Sentinel3.html",
    "title": "Sentinel-3",
    "section": "",
    "text": "The main objective of theCopernicus Sentinel-3 mission is to measure ocean and land surface colour, sea and land surface temperature, and sea surface topography with high accuracy and reliability to support ocean forecasting systems, environmental monitoring and climate monitoring. The mission definition is driven by the need for continuity in provision of ERS, ENVISAT and SPOT vegetation data, with improvements in instrument performance and coverage."
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-olci-level-1",
    "href": "Data/Sentinel3.html#sentinel-3-olci-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI Level 1",
    "text": "Sentinel-3 OLCI Level 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-olci-level-2",
    "href": "Data/Sentinel3.html#sentinel-3-olci-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI Level 2",
    "text": "Sentinel-3 OLCI Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level-2 product provides geophysical data that is derived from the Level-1 product. The level-2 land product provides land and atmospheric geophysical parameters computed for full and Reduced Resolution. The Level-2 product also includes data quality flags that provide information on the reliability of the geophysical parameters, as well as information on the atmospheric correction applied to the data. These flags can be used to filter out data that is not of sufficient quality for a particular application.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-olci-level-0",
    "href": "Data/Sentinel3.html#sentinel-3-olci-level-0",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI Level 0",
    "text": "Sentinel-3 OLCI Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level 0 is the reconstructed and time-sorted Instrument Source Packet (ISP) at full space-time resolution. The first part of the process involves unpacking the ISPs, performing a quality check and appending annotation data to them. Once the input raw data files are read, all necessary data are extracted and parsed. The ISPs are then sorted and checked, including missing and duplicated packet numbering. The final part of the processing is the Level-0 product generation. Several quality flags are computed and included in the associated metadata. Raw data, time sorted and annotated are included in the Level-0 package.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply.\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nOa01\n\n\nAerosol correction\n\n\n300\n\n\n0.4000\n\n\n\n\nOa02\n\n\nYellow substance and detrital pigments (turbidity)\n\n\n300\n\n\n0.4125\n\n\n\n\nOa03\n\n\nChlorophyll absorption maximum\n\n\n300\n\n\n0.4425\n\n\n\n\nOa04\n\n\nChlorophyll\n\n\n300\n\n\n0.4900\n\n\n\n\nOa05\n\n\nChlorophyll\n\n\n300\n\n\n0.5100\n\n\n\n\nOa06\n\n\nChlorophyll reference (minimum)\n\n\n300\n\n\n0.5600\n\n\n\n\nOa07\n\n\nSediment loading\n\n\n300\n\n\n0.6200\n\n\n\n\nOa08\n\n\n2nd Chlorophyll absorption maximum\n\n\n300\n\n\n0.6650\n\n\n\n\nOa09\n\n\nImproved fluorescence retrieval\n\n\n300\n\n\n0.6737\n\n\n\n\nOa010\n\n\nChlorophyll fluorescence peak\n\n\n300\n\n\n0.6813\n\n\n\n\nOa11\n\n\nChlorophyll fluorescence baseline\n\n\n300\n\n\n0.7087\n\n\n\n\nOa12\n\n\nO2 absorption / clouds\n\n\n300\n\n\n0.7538\n\n\n\n\nOa16\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.7788\n\n\n\n\nOa17\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.8650\n\n\n\n\nOa18\n\n\nWater vapour absorption\n\n\n300\n\n\n0.8850\n\n\n\n\nOa19\n\n\nWater vapour absorption\n\n\n300\n\n\n0.9000\n\n\n\n\nOa21\n\n\nWater vapour absorption\n\n\n300\n\n\n1.0200"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-slstr-level-1",
    "href": "Data/Sentinel3.html#sentinel-3-slstr-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SLSTR Level 1",
    "text": "Sentinel-3 SLSTR Level 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-slstr-level-2",
    "href": "Data/Sentinel3.html#sentinel-3-slstr-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SLSTR Level 2",
    "text": "Sentinel-3 SLSTR Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level-2 product provides higher-level geophysical parameters, but with a longer processing time and coarser spatial resolution compared to the Level-1 product. The product also includes additional data quality flags to provide more information on the reliability and accuracy of the data.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-slstr-level-0",
    "href": "Data/Sentinel3.html#sentinel-3-slstr-level-0",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SLSTR Level 0",
    "text": "Sentinel-3 SLSTR Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level 0 product is the raw unprocessed data acquired by the SLSTR instrument on board the Sentinel-3 satellite. It consists of the uncalibrated digital counts received by the SLSTR detectors for each pixel in the image. It provides a valuable source of unprocessed data for researchers and advanced users who require access to the raw data for their applications.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply.\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543\n\n\n\n\nS2\n\n\nVegetation monitoring\n\n\n500\n\n\n0.6595\n\n\n\n\nS3\n\n\nNDVI, cloud flagging\n\n\n500\n\n\n0.8680\n\n\n\n\nS4\n\n\nCirrus detection over land\n\n\n500\n\n\n1.3748\n\n\n\n\nS5\n\n\nCloud clearing\n\n\n500\n\n\n1.6134\n\n\n\n\nS6\n\n\nVegetation state and cloud clearing\n\n\n500\n\n\n2.2557\n\n\n\n\nS7\n\n\nSST, LST, Active fire\n\n\n500\n\n\n3.7420\n\n\n\n\nS8\n\n\nSST, LST, Active fire\n\n\n500\n\n\n10.8540\n\n\n\n\nS9\n\n\nSST, LST\n\n\n1000\n\n\n12.0225\n\n\n\n\nF1\n\n\nActive fire\n\n\n500\n\n\n3.7420\n\n\n\n\nF2\n\n\nActive fire\n\n\n1000\n\n\n3.9400"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-syn-level-2",
    "href": "Data/Sentinel3.html#sentinel-3-syn-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SYN Level 2",
    "text": "Sentinel-3 SYN Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SYN Level 2 product is a higher-level processed product that contains information about the Earth’s atmosphere and its constituents. It is derived from the Level-1 and Level-2 products of the OLCI and SLSTR instruments on board the Sentinel-3 satellite.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-sral-level-1",
    "href": "Data/Sentinel3.html#sentinel-3-sral-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SRAL Level 1",
    "text": "Sentinel-3 SRAL Level 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SRAL Level-1 product provides corrected and validated geophysical parameters derived from the raw SRAL Level-0 data, along with metadata and data quality flags that enable the user to assess the reliability and suitability of the data for specific applications.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-sral-level-2",
    "href": "Data/Sentinel3.html#sentinel-3-sral-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SRAL Level 2",
    "text": "Sentinel-3 SRAL Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SRAL Level-2 product is a higher-level processed product that contains more detailed and refined geophysical parameters suitable for scientific and research applications. It contains advanced geophysical parameters such as sea surface height, significant wave height, and wind speed, that are derived from the SRAL Level-1 products using advanced processing algorithms and quality control procedures.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-sral-level-0",
    "href": "Data/Sentinel3.html#sentinel-3-sral-level-0",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SRAL Level 0",
    "text": "Sentinel-3 SRAL Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 Synthetic Aperture Radar Altimeter (SRAL) Level-0 product contains raw data acquired by the SRAL instrument onboard the Sentinel-3 satellite. The data contains raw, time-tagged radar echoes and instrument housekeeping data, along with metadata describing the acquisition parameters and instrument characteristics.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]"
  },
  {
    "objectID": "Data/Sentinel5P.html",
    "href": "Data/Sentinel5P.html",
    "title": "Sentinel-5P",
    "section": "",
    "text": "The Copernicus Sentinel-5 Precursor mission is the first Copernicus mission dedicated to monitoring our atmosphere.\nThe main objective of the Copernicus Sentinel-5P mission is to perform atmospheric measurements with high spatio-temporal resolution, to be used for air quality, ozone & UV radiation, and climate monitoring & forecasting.\nThere are different data products associated with the three levels of TROPOMI processing: Level-0, Level-1B and Level-2."
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-aerosol-index",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-aerosol-index",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Aerosol Index",
    "text": "Sentinel-5P Level 2 Aerosol Index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-carbon-monoxide",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-carbon-monoxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Carbon Monoxide",
    "text": "Sentinel-5P Level 2 Carbon Monoxide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-cloud",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-cloud",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Cloud",
    "text": "Sentinel-5P Level 2 Cloud\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-formaldehyde",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-formaldehyde",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Formaldehyde",
    "text": "Sentinel-5P Level 2 Formaldehyde\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-methane",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-methane",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Methane",
    "text": "Sentinel-5P Level 2 Methane\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-nitrogen-dioxide",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-nitrogen-dioxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Nitrogen Dioxide",
    "text": "Sentinel-5P Level 2 Nitrogen Dioxide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-ozone",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-ozone",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Ozone",
    "text": "Sentinel-5P Level 2 Ozone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-sulfur-dioxide",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-sulfur-dioxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Sulfur Dioxide",
    "text": "Sentinel-5P Level 2 Sulfur Dioxide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-1b",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-1b",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 1B",
    "text": "Sentinel-5P Level 1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 1B data refers to a processed and calibrated dataset derived from the raw measurements acquired by the Sentinel-5P satellite. This level of data undergoes initial processing steps to correct for instrument effects, atmospheric disturbances, and other artifacts.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-0",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-0",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 0",
    "text": "Sentinel-5P Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 0 data refers to the raw data acquired by the Sentinel-5P satellite during its mission. These instruments include the Tropospheric Monitoring Instrument (TROPOMI), which is capable of measuring a wide range of atmospheric pollutants such as nitrogen dioxide, ozone, formaldehyde, and aerosols, among others.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "Data/CEMS.html",
    "href": "Data/CEMS.html",
    "title": "Documentation",
    "section": "",
    "text": "The Copernicus Emergency Management Service (CEMS) provides geospatial data and images for informed decision making in order to support all involved in the management of natural or manmade disasters. CEMS constantly monitors Europe and the globe for signals of an impending disaster or evidence of one happening in real time. Products of CEMS are generated using remote sensing, satellite, in-situ (non-space) and modelled data.\nOne of the products offered by CEMS is Rapid Mapping which provides geospatial information within hours or days of a service request in order to support emergency management activities in the immediate aftermath of a disaster.\nThe Rapid Mapping datasets are provided categorised by emergency type, be it floods, fires, earthquakes, epidemic, humanitarian crisis, industrial accidents, mass movements, storms, volcanic activity etc. For each emergency activation, Rapid Mapping data is available as shapefiles of the event itself (flood extent, fire scar, etc.), transportation systems, hydrography, land use, etc."
  },
  {
    "objectID": "Data/CEMS.html#copernicus-emergency-management-service---cems",
    "href": "Data/CEMS.html#copernicus-emergency-management-service---cems",
    "title": "Documentation",
    "section": "",
    "text": "The Copernicus Emergency Management Service (CEMS) provides geospatial data and images for informed decision making in order to support all involved in the management of natural or manmade disasters. CEMS constantly monitors Europe and the globe for signals of an impending disaster or evidence of one happening in real time. Products of CEMS are generated using remote sensing, satellite, in-situ (non-space) and modelled data.\nOne of the products offered by CEMS is Rapid Mapping which provides geospatial information within hours or days of a service request in order to support emergency management activities in the immediate aftermath of a disaster.\nThe Rapid Mapping datasets are provided categorised by emergency type, be it floods, fires, earthquakes, epidemic, humanitarian crisis, industrial accidents, mass movements, storms, volcanic activity etc. For each emergency activation, Rapid Mapping data is available as shapefiles of the event itself (flood extent, fire scar, etc.), transportation systems, hydrography, land use, etc."
  },
  {
    "objectID": "FAQ.html",
    "href": "FAQ.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "What is the phase-out timing for the current Copernicus Data Hub distribution services?\n\n\nThe legacy Copernicus Data Hub distribution service will remain in operations until end of June 2023 to allow a smooth migration to the new Copernicus Data Access service by all user communities. The Copernicus Data Hub distribution service will continue offering access to Sentinel data with a gradual ramp-down of the operations capacity and data offering until end of September 2023.\n\n\n\n\nComparing with existing legacy Copernicus Data Hub, what will be the other free services other than stac/cog?\n\n\nCompared to existing Copernicus Data Hub, there will indeed be additional APIs - OGC interfaces (WMS, WMTS, WCS), OpenEO, Sentinel Hub API, S3, and others. Please refer to the Roadmap for more info on the timing of these interfaces.\n\n\n\n\nIs there an end user document available online that describes the specific data products available and specific services?\n\n\nThe user level details for every service and dataset will be provided in this documentation. With every service and dataset embedded into the ecosystem, this documentation will be updated accordingly.\n\n\n\n\nHow long is the project timescale in total ?\n\n\nThe time scale of the project is 6 years (i.e., to the end of 2028) with an optional extension up to 10 years (i.e., 2032).\n\n\n\n\nCan anyone outside from Europe have free access to any data?\n\n\nYes, data and services will be available to users worldwide."
  },
  {
    "objectID": "FAQ.html#general",
    "href": "FAQ.html#general",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "What is the phase-out timing for the current Copernicus Data Hub distribution services?\n\n\nThe legacy Copernicus Data Hub distribution service will remain in operations until end of June 2023 to allow a smooth migration to the new Copernicus Data Access service by all user communities. The Copernicus Data Hub distribution service will continue offering access to Sentinel data with a gradual ramp-down of the operations capacity and data offering until end of September 2023.\n\n\n\n\nComparing with existing legacy Copernicus Data Hub, what will be the other free services other than stac/cog?\n\n\nCompared to existing Copernicus Data Hub, there will indeed be additional APIs - OGC interfaces (WMS, WMTS, WCS), OpenEO, Sentinel Hub API, S3, and others. Please refer to the Roadmap for more info on the timing of these interfaces.\n\n\n\n\nIs there an end user document available online that describes the specific data products available and specific services?\n\n\nThe user level details for every service and dataset will be provided in this documentation. With every service and dataset embedded into the ecosystem, this documentation will be updated accordingly.\n\n\n\n\nHow long is the project timescale in total ?\n\n\nThe time scale of the project is 6 years (i.e., to the end of 2028) with an optional extension up to 10 years (i.e., 2032).\n\n\n\n\nCan anyone outside from Europe have free access to any data?\n\n\nYes, data and services will be available to users worldwide."
  },
  {
    "objectID": "FAQ.html#data",
    "href": "FAQ.html#data",
    "title": "Frequently Asked Questions",
    "section": "Data",
    "text": "Data\n\n\nWhat data will be offered online and what is the timeline for the following months?\n\n\nFor the details on the data offer and timing, we would like to refer to the Roadmap\n\n\n\n\nIs there a page that indicates anomalies with the datasets?\n\n\nThe Copernicus Operations Dashboard provides details of events over the past three months that have impact on the completeness of the data production, such as planned calibration activities, manoeuvrers, or anomalies. The information of which data is affected is included.\n\n\n\n\nWith regard to cloud native formats/interfaces, will the data also be available in the original data formats (e.g. for data downloading)?\n\n\nYes, data will also be available in original data formats (i.e. .SAFE).\n\n\n\n\nAt the moment some of the data are delivered in Jpeg2000, is there any plan to abandon that format for the COG?\n\n\nThere is currently no plan to convert Sentinel-2 in COGs. However, there is a parallel activity happening within ESA to define format evolution for all Sentinels which will be followed, once decisions are taken. But this is not something that is happening on the short term.\n\n\n\n\nWill data, such as Sentinel-2, be processed to a consistent version?\n\n\nThe Sentinel-2 data will be available at the latest processing baseline. And with the reprocessing of Sentinel-2 happening in parallel (out of scope of this project), these will become available on this service as well.\n\n\n\n\nIs it possible to download a subset of data corresponding to an AOI, instead of the whole image?\n\n\nYes, you will be able to download a subset of data, either using S3 interface, or dedicated APIs, i.e. Sentinel Hub, OpenEO when they become available. See Roadmap section of the documentation.\n\n\n\n\nAre the data offered via Cloud Optimized Geotiffs (also Level 1)?\n\n\nSentinel-1 GRD data will be available in COG format. Sentinel-2 will stay in JP2 for the moment, as it is a similarly performant cloud optimised format.\n\n\n\n\nWhen “on-line data” is mentioned, does that mean the data are not on tape?\n\n\nThe “on-line data” or IAD we are referring to, are indeed not on the tapes. Tapes will still be there for redundancy reasons.\n\n\n\n\nCan we download the data acquired by all Sentinel missions (1, 2, 3, 5P, 6) and the other satellites (e.g. Meteosat) via the new interface? Some missions are not managed by ESA, but by EUMETSAT for example.\n\n\nInitialy Sentinel 1, Sentinel 2, Sentinel 3 and Sentinel 5P data up to L2 products will be available. Sentinel 6 data and data from Meteosat are currently not in the roadmap of the project. However access to Copernicus Contributing Missions CORE Datasets, Digital Elevation Models, data from Copernicus Services and additional data sets such as Landsat and ENVISAT and Belgian Collaborative Ground Segment hosted data are planned in the future. The Data Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data will become available.\n\n\n\n\nWill it still be the case that data is labelled as “on/offline” on the current legacy portal?\n\n\nThe vast majority of the data will be on-line : all Sentinel-2 L1C/L2A, Sentinel-1 SLC/GRD and just about all other relevant data collections.\n\n\n\n\nWill the new interface offer EO ready-to-use products or just L0 and L1 data?\n\n\nUp to L2 products will be available. The Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data become available.\n\n\n\n\nWhat is the highest resolution SAR data available in Copernicus Data Space Ecosystem?\n\n\nThe Sentinel-1 SAR achieves a spatial resolution of approximately 5 by 20 m. More info can be found here.\n\n\n\n\nIs it possible to acquire compressed data?\n\n\nCopernicus Data Space Ecosystem provides an access to EO data in zip format without compression (concatination). The availability of compressed data is in the platform development plan."
  },
  {
    "objectID": "FAQ.html#services",
    "href": "FAQ.html#services",
    "title": "Frequently Asked Questions",
    "section": "Services",
    "text": "Services\n\n\nWill there be an integrated free and commercial offering to support/encourage the transfer of the users from “try basics for free towards paid subscriptions”?\n\n\nYes, there will be a common user identity, which will allow registered users to seamlessly transfer between systems. This will also extend to other systems that will be added to the free tier to the commerical tier ecosystem in the future, assuming they will integrate it.\n\n\n\n\nWhen we develop an EO ready-to-use product, could we integrate it into the interface and ask the payment from clients?\n\n\nYes, commercial services can be built on top, similar to Copernicus open license.\n\n\n\n\nCan the user come with wish-list to services data products?\n\n\nUser can come with suggestions to improve or expand the service portfolio. A user forum will be set up and released by July to accommodate this.\n\n\n\n\nAre you going to develop new services on DAS after July 2023?\n\n\nYes, a marketplace will be available where new Third party services will be able to onboard from July onwards to expand the ecosystem.\n\n\n\n\nIs there any limitation on the max number of downloads at one time?\n\n\nYes, there will be quotas and constraints for different services.\n\n\n\n\nIs it possible to download Sentinel-2 data for a large area at a high resolution in Copernicus Data Space Browser?\n\n\nDepending on your use, we suggest to use the high-res print (via the high-res print tab) where you will get large areas in a high resolution (the data is though not georeferenced) or if you need georeferenced data, split your area in several smaller images that you download or choose a bit lower resolution to stay within the limits of 2500px.\n\n\n\n\nCan you provide detailed information regarding the quotas and limits for accessing data and using the services through your platform?\n\n\nWe understand the importance of knowing the limitations and restrictions imposed on the usage of our services. For detailed information about the quotas, we recommend referring to the Service Description and Evolution document available on our documentation portal. You can find the document at https://documentation.dataspace.copernicus.eu/Roadmap.html . The quotas information can be found in Annex B.\n\n\n\n\nHow can I request to change my Copernicus user type (e.g. ‘Copernicus general user’ -&gt; ‘Copernicus service user’)?\n\n\n\nTo change your Copernicus user type, submit a request with our support team via Submit a request. Please select ‘Other’ for the ’I have a question about*:’.\n\n\nFor detailed information about the eligibility and quotas allocated to Copernicus user types, we recommend referring to the Service Description and Evolution document available on our documentation portal. The quotas information can be found in Annex B. The document can be found at Roadmap .\n\n\nWe aim to process requests as efficiently as possible, but it is advisable to allow for a reasonable timeframe for the evaluation and approval process."
  },
  {
    "objectID": "FAQ.html#registration-and-authentication",
    "href": "FAQ.html#registration-and-authentication",
    "title": "Frequently Asked Questions",
    "section": "Registration and authentication",
    "text": "Registration and authentication\n\n\nWill there be an integrated free and commercial offering to support/encourage the transfer of the users from “try basics for free towards paid subscriptions”?\n\n\nYes, there will be a common user identity, which will allow registered users to seamlessly transfer between systems. This will also extend to other systems that will be added to the free tier to the commerical tier ecosystem in the future, assuming they will integrate it.\n\n\n\n\nIf I’m having troubles with registering, what can I do?\n\n\nPlease e-mail the help-login@dataspace.copernicus.eu address for direct support on this matter."
  },
  {
    "objectID": "FAQ.html#apis",
    "href": "FAQ.html#apis",
    "title": "Frequently Asked Questions",
    "section": "APIs",
    "text": "APIs\n\n\nSNAP/gpt processing codes can be used in these on-line and cloud processing services?\n\n\nSNAP is integrated in cloud environment, and there will even be some dedicated on-demand services based on SNAP (i.e. S1 processing to coherence, etc).\n\n\n\n\nIs a STAC catalog planned ? Will the data be accessible on cloud object storage (S3)?\n\n\nSTAC Catalog API is indeed planned. Note that the phase-in will take from end of January to July 2023. So services will be added during this timeline, not everything will be available at the beginning. All the data will be available over S3 as well.\n\n\n\n\nWill LTA process be discontinued when all archived data become online?\n\n\nThere will still be services available for so called “deferred data access” : data collections that are not commonly used. That said, all most relevant collections will be available on-line. The Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data become available.\n\n\n\n\nWill the platform use STAC standards?\n\n\nYes, there will be STAC compliant Catalog API, as well as STAC items for inpidual products.\n\n\n\n\nAny plan to offer the Pangeo platform for a “pythonist”?\n\n\nThis is currently not in the offer or roadmap.\n\n\n\n\nHow do I generate S3 access and secret keys?\n\n\nYou can request such credentials as the guided in  https://documentation.dataspace.copernicus.eu/APIs/S3.html\n\n\n\n\nWhich one amongst the 4 catalog APIs (OData, STAC, OpenSearch, Sentinel Hub catalogue ) is updated first when new products are published?\n\n\nOpenSearch, OData and STAC catalog APIs all use the same backend database. Sentinel Hub catalog API contains a subset of the collections, hence it works only for the ones that have been imported to Sentinel Hub, Therefore there is no first updated one.\n\n\n\n\nWhat is the limitation of the number of requests that I can do at the time?\n\n\nFor detailed information about the limits, we recommend referring to the Service Description and Evolution document available on our documentation portal. You can find the document in https://documentation.dataspace.copernicus.eu/Roadmap.html. The quotas information can be found in Annex B.\n\n\n\n\nCan I connect directly to the S3 bucket using AWS S3 commands with the S3 keys provided or do I have to use “s3cmd” to download images?\n\n\nYes, you can connect to S3 bucket using AWS S3 connection. However some functionality may not be supported. It is recommended to use the ‘s3cmd’ command to download products.\n\n\n\n\nDo you have to authenticate for requesting through OpenSearch API?\n\n\nThere’s no need to use any user or authentication when you want to search. User authentication is required for downloading products.\n\n\n\n\nCan we use the Sentinel Hub bucket and fetch the products based on the id we fetched from OpenSearch API?\n\n\nYou can use Sentinel Hub bucket in addition to some programming tools by providing product ID obtained using OpenSearch API or OData of the Copernicus Dataspace Ecosystem.\n\n\n\n\nWhat is the benefit of fetching imagery from Copernicus Dataspace S3 bucket?\n\n\nDownloading products via S3 is faster as it delivers products as an .zip archive, skipping the need of zipper.\n\n\n\n\nOn which region resides the Copernicus Dataspace S3 bucket?\n\n\nRepo is located in Warsaw/Poland.\n\n\n\n\nHow can we search for the product in S3 bucket?\n\n\nSearching via ID or product name in the OpenSearch or OData will give the S3 path to the product in response."
  },
  {
    "objectID": "FAQ.html#documentation",
    "href": "FAQ.html#documentation",
    "title": "Frequently Asked Questions",
    "section": "Documentation",
    "text": "Documentation\n\n\nIs there any difference between EU users and non-EU users?\n\n\nThere is no difference between EU users and non-EU users. That said, there will be a continuity of the accounts with higher throughput, managed by ESA (i.e. Copernicus Services, International Hub, etc.).\n\n\n\n\n\nWhich distribution channels will be available for high-throughput data access? Does the public side have user tiers, or is high-throughput data transfer (such as EOdata ) only a paid service?\n\n\n\nAll distribution options (i.e. OData, S3, Sentinel Hub,..) will be constrained with user quotas, which includes both bandwidth limitation, as well as monthly limits.\n\n\n\n\nCan you give indictions about the cost of the “extra” services?\n\n\nPricing will be published soon.\n\n\n\n\n This December advertisement of DAS says that “For those interested in processing, there will be scalable cloud resources available, optimized for EO tasks”. Does this refer to the current CreoDIAS resources, or something completely new that hasn’t been addressed yet? \n\n\nScalable cloud resources will be part of the commercial offering and can be obtained at CREODIAS in first instance. ICT-wise, there will be two options, including Open Telekom Cloud.\n\n\n\n\nAre there tutorials (online & physical meetings) to use the new interface?\n\n\nTutorials will be added to the documentation in due time explaining the usage of the different interfaces. We will also be present on different conferences explaining the service & ecosystem."
  },
  {
    "objectID": "APIs.html",
    "href": "APIs.html",
    "title": "APIs",
    "section": "",
    "text": "This section gives an overview on the APIs provided by Copernicus Data Space Ecosystem.\n\n\nThere are various interfaces providing capability to search the catalog, to serve various users’ needs and to ensure continuity over the existing Copernicus Hubs. All interfaces are connected to the same database to guarantee consistency.\n\n\nSTAC data have become a de-facto standard in the EO community, also being onboarded to OGC at the moment. STAC items are provided for all online products, as well as for products generated by users within the Copernicus Data Space Ecosystem.\n\n\n\nOData is an SO/IEC approved, OASIS standard , which is based on http RESTful Application Programming Interfaces. It enables resources, which are identified by URLs and defined in a data model, to be created and edited using simple HTTP messages.\n\n\n\nThe OpenSearch catalogue allows you to search through Copernicus data using a standardized web service. Search can be performed based on multiple attributes such as collection, spatial extent, time range, metadata. Orders can be based on the data collection, area, time range or any other selection criteria available in the search APIs\n\n\n\n\n\n\nSentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service, capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use its APIs to retrieve satellite data over their AOI and specific time range from full archives in a matter of seconds.\n\n\n\nWith openEO’s collaborative nature, users can seamlessly share code, workflows, and data processing methods across platforms and tools, fostering collaboration and advancing the accessibility, scalability, and reproducibility of Earth observation data. Additionally, openEO provides intuitive programming libraries that enable easy analysis of diverse Earth observation datasets.\n\n\n\n\n\n\nS3 API is one of the main access methods for EO data. It is suitable for Third Party applications that require high-performance parallel access and scalability. Moreover, any user who wants to connect from an external infrastructure to the Copernicus Data Space Ecosystem collection can do so through the S3 protocol.\n\n\n\nTraceability service allows user to verify and register traces for user level data available in the Copernicus Data Space. The general design of the Traceability Service centers around a REST API service. Users may interact with Traceability API either directly using e.g. curl, or through the open source Traceability command line utility.\n\n\n\nOn-demand processing capability for CARD-BS, CARD-COH6/12 is available on the Copernicus Data Space Ecosystem. This service is offered free to the use via a limited pool of resources, shared across all users, which can be used for processing the data free of charge. This is suitable for users who need to process smaller batches of products."
  },
  {
    "objectID": "APIs.html#catalog-apis",
    "href": "APIs.html#catalog-apis",
    "title": "APIs",
    "section": "",
    "text": "There are various interfaces providing capability to search the catalog, to serve various users’ needs and to ensure continuity over the existing Copernicus Hubs. All interfaces are connected to the same database to guarantee consistency.\n\n\nSTAC data have become a de-facto standard in the EO community, also being onboarded to OGC at the moment. STAC items are provided for all online products, as well as for products generated by users within the Copernicus Data Space Ecosystem.\n\n\n\nOData is an SO/IEC approved, OASIS standard , which is based on http RESTful Application Programming Interfaces. It enables resources, which are identified by URLs and defined in a data model, to be created and edited using simple HTTP messages.\n\n\n\nThe OpenSearch catalogue allows you to search through Copernicus data using a standardized web service. Search can be performed based on multiple attributes such as collection, spatial extent, time range, metadata. Orders can be based on the data collection, area, time range or any other selection criteria available in the search APIs"
  },
  {
    "objectID": "APIs.html#streamlined-data-access",
    "href": "APIs.html#streamlined-data-access",
    "title": "APIs",
    "section": "",
    "text": "Sentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service, capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use its APIs to retrieve satellite data over their AOI and specific time range from full archives in a matter of seconds.\n\n\n\nWith openEO’s collaborative nature, users can seamlessly share code, workflows, and data processing methods across platforms and tools, fostering collaboration and advancing the accessibility, scalability, and reproducibility of Earth observation data. Additionally, openEO provides intuitive programming libraries that enable easy analysis of diverse Earth observation datasets."
  },
  {
    "objectID": "APIs.html#additionally",
    "href": "APIs.html#additionally",
    "title": "APIs",
    "section": "",
    "text": "S3 API is one of the main access methods for EO data. It is suitable for Third Party applications that require high-performance parallel access and scalability. Moreover, any user who wants to connect from an external infrastructure to the Copernicus Data Space Ecosystem collection can do so through the S3 protocol.\n\n\n\nTraceability service allows user to verify and register traces for user level data available in the Copernicus Data Space. The general design of the Traceability Service centers around a REST API service. Users may interact with Traceability API either directly using e.g. curl, or through the open source Traceability command line utility.\n\n\n\nOn-demand processing capability for CARD-BS, CARD-COH6/12 is available on the Copernicus Data Space Ecosystem. This service is offered free to the use via a limited pool of resources, shared across all users, which can be used for processing the data free of charge. This is suitable for users who need to process smaller batches of products."
  },
  {
    "objectID": "Registration.html",
    "href": "Registration.html",
    "title": "User registration and authentication",
    "section": "",
    "text": "This section provides information on how to register and authenticate on the Copernicus Data Space Ecosystem.\n\n\nGo to website and click “login” in the top right corner.\n\n\nYou will now get the Copernicus Data Space Ecosystems login form. Click “here” in the bottom.\n\n\nYou will now get the Copernicus Data Space Ecosystems registration form. Fill in all required fields (all except Thematic activity and Purpose of use), you can fill in optional fields, next you have to accept terms and conditions and you can accept other consents (they are optional) and then click “Register”.\n\n\n\n\n\nWhen you register, you will be asked to verify your email address. You should receive a verification email.\n\n\nWhen you open an email you need to click “Verify email address”.\n\n\n\nEmail\n\n\nNow you can log in with your credentials (providing Email and Password).\nIf you have an issue with registering or you want to deregister, please contact us directly."
  },
  {
    "objectID": "Registration.html#step-1-registration",
    "href": "Registration.html#step-1-registration",
    "title": "User registration and authentication",
    "section": "",
    "text": "Go to website and click “login” in the top right corner.\n\n\nYou will now get the Copernicus Data Space Ecosystems login form. Click “here” in the bottom.\n\n\nYou will now get the Copernicus Data Space Ecosystems registration form. Fill in all required fields (all except Thematic activity and Purpose of use), you can fill in optional fields, next you have to accept terms and conditions and you can accept other consents (they are optional) and then click “Register”."
  },
  {
    "objectID": "Registration.html#step-2-e-mail-verification",
    "href": "Registration.html#step-2-e-mail-verification",
    "title": "User registration and authentication",
    "section": "",
    "text": "When you register, you will be asked to verify your email address. You should receive a verification email.\n\n\nWhen you open an email you need to click “Verify email address”.\n\n\n\nEmail\n\n\nNow you can log in with your credentials (providing Email and Password).\nIf you have an issue with registering or you want to deregister, please contact us directly."
  },
  {
    "objectID": "logos.html",
    "href": "logos.html",
    "title": "Documentation",
    "section": "",
    "text": "```{=html}\n&lt;div class=\"logos\"&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/EU.svg\"&gt;\n    &lt;/a&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/copernicus-white-BL.svg\"&gt;\n    &lt;/a&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/ESA_White.svg\"&gt;\n    &lt;/a&gt;\n    \n    ```"
  },
  {
    "objectID": "notebook-samples/openeo/basics.html",
    "href": "notebook-samples/openeo/basics.html",
    "title": "How to get started with openEO Platform: Basics",
    "section": "",
    "text": "Connect to openEO Platform and print list of available collections\n\nimport openeo\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n\n\nprint(connection.list_collection_ids())\n\n['EEA_VEGETATION_INDICES', 'SEASONAL_TRAJECTORIES', 'VEGETATION_PHENOLOGY_AND_PRODUCTIVITY_PARAMETERS_SEASON_1', 'ESA_WORLDCOVER_10M_2020_V1', 'ESA_WORLDCOVER_10M_2021_V2', 'SENTINEL3_OLCI_L1B', 'SENTINEL3_SLSTR', 'SENTINEL2_L1C', 'SENTINEL2_L2A', 'SENTINEL1_GRD', 'COPERNICUS_30']\n\n\nGet detailed information about a collection\n\nconnection.describe_collection(\"SENTINEL2_L2A\")\n\n\n    \n    \n        \n    \n    \n\n\nList processes that can be applied on the (EO) data\n\nprocesses_list = (connection.list_processes())\nprint(processes_list[:3])\n\n[{'categories': ['arrays'], 'description': 'Applies a process to each individual value in the array. This is basically what other languages call either a `for each` loop or a `map` function.', 'id': 'array_apply', 'links': [{'href': 'https://processes.openeo.org/1.2.0/examples/array_find_nodata.json', 'rel': 'example', 'title': 'Find no-data values in arrays', 'type': 'application/json'}, {'href': 'https://processes.openeo.org/1.2.0/examples/array_contains_nodata.json', 'rel': 'example', 'title': 'Check for no-data values in arrays', 'type': 'application/json'}], 'parameters': [{'description': 'An array.', 'name': 'data', 'schema': {'items': {'description': 'Any data type is allowed.'}, 'type': 'array'}}, {'description': 'A process that accepts and returns a single value and is applied on each individual value in the array. The process may consist of multiple sub-processes and could, for example, consist of processes such as ``abs()`` or ``linear_scale_range()``.', 'name': 'process', 'schema': {'parameters': [{'description': 'The value of the current element being processed.', 'name': 'x', 'schema': {'description': 'Any data type.'}}, {'description': 'The zero-based index of the current element being processed.', 'name': 'index', 'schema': {'minimum': 0, 'type': 'integer'}}, {'default': None, 'description': 'The label of the current element being processed. Only populated for labeled arrays.', 'name': 'label', 'optional': True, 'schema': [{'type': 'number'}, {'type': 'string'}, {'type': 'null'}]}, {'default': None, 'description': 'Additional data passed by the user.', 'name': 'context', 'optional': True, 'schema': {'description': 'Any data type.'}}], 'returns': {'description': 'The value to be set in the new array.', 'schema': {'description': 'Any data type.'}}, 'subtype': 'process-graph', 'type': 'object'}}, {'default': None, 'description': 'Additional data to be passed to the process.', 'name': 'context', 'optional': True, 'schema': {'description': 'Any data type.'}}], 'returns': {'description': 'An array with the newly computed values. The number of elements are the same as for the original array.', 'schema': {'items': {'description': 'Any data type is allowed.'}, 'type': 'array'}}, 'summary': 'Apply a process to each array element'}, {'categories': ['math &gt; trigonometric'], 'description': 'Computes the arc cosine of `x`. The arc cosine is the inverse function of the cosine so that *`arccos(cos(x)) = x`*.\\n\\nWorks on radians only.\\nThe no-data value `null` is passed through and therefore gets propagated.', 'examples': [{'arguments': {'x': 1}, 'returns': 0}], 'id': 'arccos', 'links': [{'href': 'http://mathworld.wolfram.com/InverseCosine.html', 'rel': 'about', 'title': 'Inverse cosine explained by Wolfram MathWorld'}], 'parameters': [{'description': 'A number.', 'name': 'x', 'schema': {'type': ['number', 'null']}}], 'returns': {'description': 'The computed angle in radians.', 'schema': {'type': ['number', 'null']}}, 'summary': 'Inverse cosine'}, {'categories': ['math &gt; trigonometric'], 'description': 'Computes the inverse hyperbolic cosine of `x`. It is the inverse function of the hyperbolic cosine so that *`arcosh(cosh(x)) = x`*.\\n\\nWorks on radians only.\\nThe no-data value `null` is passed through and therefore gets propagated.', 'examples': [{'arguments': {'x': 1}, 'returns': 0}], 'id': 'arcosh', 'links': [{'href': 'http://mathworld.wolfram.com/InverseHyperbolicCosine.html', 'rel': 'about', 'title': 'Inverse hyperbolic cosine explained by Wolfram MathWorld'}], 'parameters': [{'description': 'A number.', 'name': 'x', 'schema': {'type': ['number', 'null']}}], 'returns': {'description': 'The computed angle in radians.', 'schema': {'type': ['number', 'null']}}, 'summary': 'Inverse hyperbolic cosine'}]\n\n\nInspect one process closer\n\nconnection.describe_process(\"add\")"
  },
  {
    "objectID": "notebook-samples/openeo/Load_Collection.html",
    "href": "notebook-samples/openeo/Load_Collection.html",
    "title": "How to load a data collection?",
    "section": "",
    "text": "This notebook provides a detailed guide on how to load a data collection, including all the necessary steps involved. Additionally, it will explain how to authenticate your account to ensure secure access to the data.\n\n# import necessary packages\n\nimport openeo\n\n# connect to the backend\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n\nTo verify whether the users is authenticated, they can check if connection to the backend is authenticated.\n\n# check your connection details\nconnection\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with NullAuth&gt;\n\n\nIf the user’s connection to the backend returns a NullAuth status, it means that they are not authenticated. In this case, they can authenticate themselves by using the authenticate_oidc() method.\n\n# authenticate and recheck for your connection\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;\n\n\nAfter authentication to load the data collection, the next step is to filter it based on the specific requirements or criteria of the user. This involves narrowing down the dataset to a particular period or geographic location.\n\n# load collection\n\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\",\n                bands=[\"B04\", \"B03\", \"B02\", \"SCL\"],\n                temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n                spatial_extent={\n                    \"west\": 3.202609,\n                    \"south\": 51.189474,\n                    \"east\": 3.254708,\n                    \"north\": 51.204641,\n                    \"crs\": \"EPSG:4326\",\n                },\n                max_cloud_cover=50,\n)\n\nIn this step we will apply cloud masking to filter out cloud pixels to make the result more usable. It is very common for earth observation data to have separate masking layers that for instance indicate whether a pixel is covered by a (type of) cloud or not. For Sentinel-2, one such layer is the “scene classification” layer generated by the Sen2Cor algorithm. In the following cells, we will use this layer to mask out unwanted data.\n\n# Select the \"SCL\" band from the data cube\nscl_cube = cube.band(\"SCL\")\n\n# Build mask to mask out everything but cloud\nmask = (scl_cube == 7) | (scl_cube == 8)\n\nBefore we can apply this mask to the cube we have to resample it, as the “SCL” layer has a “ground sample distance” of 20 meter, while it is 10 meter for the “B02”, “B03” and “B04” bands. We can easily do the resampling by referring directly to the cube.\n\nmask_resampled = mask.resample_cube_spatial(cube)\n\n# Apply the mask to the `evi_cube`\ncube_masked = cube.mask(mask_resampled)\n\n\n# Because GeoTIFF does not support a temporal dimension, we first eliminate it by taking the temporal maximum value for each pixel\n\nfinal_image = cube_masked.max_time()\nimage = cube.max_time()\n\nTo complete the data analysis process, the final step involves downloading the filtered data. This can be done in two ways: synchronously or through the batch job-based method. Synchronous downloading allows the user to download the data immediately, whereas batch job-based downloading enables the user to download the data in batches or at a scheduled time. The choice of method depends on the user’s preference and the size of the dataset. In this example we follow the first method, i.e., Synchronous download.\n\n# # download the RGB image\n# final_image.download(\"output/RGB_masked.tiff\")\n# image.download(\"output/RGB_withoutmask.tiff\")\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"output/RGB_withoutmask.tiff\").read()\nmasked_img = rasterio.open(\"output/RGB_masked.tiff\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\n# Assuming you have two images img1 and img2\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2), dpi=150)\n\n# Plotting the first image on the left subplot\nax1.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\nax1.set_title(\"RGB Image\")\n\n# Plotting the second image on the right subplot\nax2.imshow(normalizeimg(np.moveaxis(masked_img, 0, -1)))\nax2.set_title(\"Masked RGB Image\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "notebook-samples/openeo/NDVI_Timeseries.html",
    "href": "notebook-samples/openeo/NDVI_Timeseries.html",
    "title": "NDVI Timeseries",
    "section": "",
    "text": "This notebook presents an application case, that demonstrates how to display the NDVI (Normalized Difference Vegetation Index) timeseries for specific fields. The case study showcases the process of selecting the fields and generating average NDVI timeseries data for analysis and visualization.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shapely.geometry\nimport json\nimport scipy.signal\nimport numpy as np\n\nimport openeo\nfrom openeo.rest.conversions import timeseries_json_to_pandas\n\n\n# defining the plotting function\n\nDEFAULT_FIGSIZE = (5, 4)\n\n\ndef plot_timeseries(filename):\n    \"\"\"Helper to plot the timeseries directly from JSON file\"\"\"\n    with open(filename) as f:\n        ts = timeseries_json_to_pandas(json.load(f)).dropna()\n    ts.index = pd.to_datetime(ts.index)\n    fig, ax = plt.subplots(figsize=DEFAULT_FIGSIZE)\n    ts.plot(marker=\"o\", ax=ax)\n    ax.set_title(\"Average NDVI\")\n    ax.set_ylabel(\"NDVI\")\n    ax.set_ylim(0, 1)\n    ax.legend(title=\"parcel id\", loc=\"lower left\", ncol=2)\n\n\n# connect to the backend and authenticate\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nlet’s calculate a time series of the average NDVI in a couple of fields in this area.\nFirst, load the fields as shapely geometries:\n\nfields_geojson = '{\"type\": \"GeometryCollection\", \"geometries\": [{\"type\": \"Polygon\", \"coordinates\": [[[5.055945487931457, 51.222709834076504], [5.064972484168688, 51.221122565090525], [5.064972484168688, 51.221122565090525], [5.067474954083448, 51.218249806779134], [5.064827929485983, 51.21689628072789], [5.05917785594747, 51.217191909908095], [5.053553857094518, 51.21807492332223], [5.055945487931457, 51.222709834076504]]]}, {\"type\": \"Polygon\", \"coordinates\": [[[5.063345886679116, 51.23087606640057], [5.06604742694687, 51.22886710731809], [5.070627820472246, 51.22874440121892], [5.068403609708207, 51.22657208381529], [5.064823257492447, 51.22676051738515], [5.064892324615199, 51.2283032878514], [5.063641745941974, 51.2285757299238], [5.062340811262595, 51.227722351687945], [5.06076005158084, 51.228042312276536], [5.063345886679116, 51.23087606640057]]]}, {\"type\": \"Polygon\", \"coordinates\": [[[5.07163184674986, 51.23481147556147], [5.076706025697324, 51.23317590781036], [5.077828303041866, 51.233226237184724], [5.078024733866917, 51.23263978271262], [5.080771081607657, 51.23259097170763], [5.083734842574312, 51.23530464074437], [5.080957826735458, 51.23646091560258], [5.079752631651647, 51.23519531038643], [5.077238400183506, 51.23490534677628], [5.072856439300575, 51.23593546777778], [5.07163184674986, 51.23481147556147]]]}, {\"type\": \"Polygon\", \"coordinates\": [[[5.083897244679042, 51.23510639883143], [5.081302408741335, 51.232922477780846], [5.082963802194108, 51.233146058575876], [5.084497702305552, 51.232672717580655], [5.085732850338428, 51.2340852086282], [5.083897244679042, 51.23510639883143]]]}]}'\nfields = shapely.geometry.shape(json.loads(fields_geojson))\nfields\n\n\n\n\nWe want to calculate the NDVI for a larger time window covering of a couple of months.\nAlso note that we don’t have to specify a bounding box explicitly when loading the cube, because we will pass the desired fields in a next step, and the backend will limit the data loading to those areas appropriately.\n\ndates = (\"2020-06-01\", \"2020-10-01\")\n\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\", temporal_extent=dates, bands=[\"B04\", \"B08\", \"SCL\"]\n)\n\nred = cube.band(\"B04\")\nnir = cube.band(\"B08\")\nndvi = (nir - red) / (nir + red)\n\nWith the DataCube.aggregate_spatial() method , we can calculate the mean NDVI for each of the fields.\n\ntimeseries = ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\")\n\nWe trigger execution by downloading the result. Because DataCube.aggregate_spatial() returns a timeseries (instead of raster data), we download it in JSON format.\n\ntimeseries.download(\"output/timeseries.json\")\n\n\nplot_timeseries( \"output/timeseries.json\")\n\n\n\n\nThe result above is a good start, but needs some work: there are quite some outliers and zero’s that don’t look right.\nTo filter out the cloudy pixels: we create a cloud mask based on the scene classification band on which gaussian filter is applied.\nBy convolving the mask with the kernel, the values of neighboring pixels are taken into account when determining whether a pixel should be classified as cloud or non-cloud. This improves the accuracy of the cloud mask by considering the spatial context of each pixel in relation to its surroundings.\nTherefore, we need a simple gaussian kernel:\n\ng = scipy.signal.windows.gaussian(11, std=1.6)\nkernel = np.outer(g, g)\nkernel = kernel / kernel.sum()\nim = plt.imshow(kernel)\nplt.colorbar(im)\n\n&lt;matplotlib.colorbar.Colorbar at 0x7f413782b190&gt;\n\n\n\n\n\n\nclassification = cube.band(\"SCL\")\nmask = ~((classification == 4) | (classification == 5))\nmask = mask.apply_kernel(kernel)\nmask = mask &gt; 0.1\n\nmasked_ndvi = ndvi.mask(mask)\n\n\nmasked_timeseries = masked_ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\")\nmasked_timeseries.download(\"output/timeseries-masked.json\")\n\n\nplot_timeseries( \"output/timeseries-masked.json\")\n\n\n\n\n\nTimeseries Smoothing\nFurthermore with an aim to improve the plot’s smoothness by using a kernel, in this notebook we define a kernel as an smoothening UDF. The kernel will help to reduce noise and fluctuations in the data, resulting in a smoother and more accurate representation of the NDVI timeseries.\nHere We define an UDF (user-defined function) to interpolate the missing values and to apply a Savitzky-Golay filter for smoothing of the timeseries, using scipy.signal.savgol_filter.\n\nudf = openeo.UDF(\n    \"\"\"\nfrom scipy.signal import savgol_filter\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    filled = array.interpolate_na(dim='t')\n    smoothed_array = savgol_filter(filled.values, 5, 2, axis=0)\n    return DataCube(xarray.DataArray(smoothed_array, dims=array. dims,coords=array.coords))\n\"\"\"\n)\n\nsmoothed_ndvi = masked_ndvi.apply_dimension(code=udf, dimension=\"t\")\n\nNow, aggregate this again per field and get the time series.\n\nsmoothed_timeseries = smoothed_ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\")\n\n\nsmoothed_timeseries.download(\"output/timeseries-smoothed.json\")\n\n\nplot_timeseries(\"output/timeseries-smoothed.json\")"
  },
  {
    "objectID": "notebook-samples/openeo/UDP.html",
    "href": "notebook-samples/openeo/UDP.html",
    "title": "User-Defined Processes (UDP)",
    "section": "",
    "text": "openEO API allows processes to be chained together in a process graph to build a particular algorithm. Often, users have specific (sub)chains that reoccur in the same process graph or even in different process graphs or algorithms. Here user can store such (sub)chains on the back-end as a so-called user-defined process. This allows you to build your library of reusable building blocks. Ultimately, the openEO API allows you to publicly expose your user-defined process, so that other users can invoke it as a service.\nThis notebook provides a step-by-step guide on how to create your User-Defined Process (UDP) for Normalized Difference Water Index (NDWI) analysis. The guide covers the fundamental steps that need to be followed to create the UDP.\n\n# import necessary packages\n\nfrom openeo.processes import array_create\nfrom openeo.api.process import Parameter\nimport openeo\nimport json\n\n\n# establish a connection to the backend and authenticate\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nThe openEO Python client lets you define parameters as Parameter instances. In general you have to specify at least the parameter name, a description and a schema.\n\n# define input parameters\ntime_param = Parameter(\n    name=\"date\",\n    description=\"A date within wich you wish to load the Terrasope NDVI product.\",\n    schema={\"type\": \"string\"},\n)\nspatial_param = Parameter(\n    name=\"aoi\",\n    description=\"Spatial extent for area of interst to calculate ndvi\",\n    schema={\"type\": \"object\", \"subtype\": \"geojson\"},\n)\n\n\n# specify the collection with input as parameter variables that will be used in the process\n\nband = [\"B03\", \"B08\"]\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\",\n                temporal_extent=time_param,\n                spatial_extent=spatial_param,\n                bands=band,\n)\n\ncube = cube.max_time()\n\nThe NDWI is a vegetation index sensitive to the water content of vegetation and is complementary to the NDVI. High NDWI values show a high water content of the vegetation. \\[ \\mathrm{NDWI} = \\frac{\\mathrm{Green} - \\mathrm{NIR}}{\\mathrm{Green} + \\mathrm{NIR}} \\]\n\ngreen = cube.band(\"B03\")\nnir = cube.band(\"B08\")\n\nndwi = (green - nir) / (green + nir)\nndwi\n\n\n    \n    \n        \n    \n    \n\n\nWe can now store this as a user-defined process called NDWI on the back-end and pass Parameter objects\n\n# publishing the service\nprocess_name = \"NDWI\"\nconnection.save_user_defined_process(\n    user_defined_process_id=process_name,\n    process_graph=ndwi,\n    parameters=[time_param, spatial_param],\n    public=True,\n)\n\n\n    \n    \n        \n    \n    \n\n\nNow, let’s evaluate the user-defined processes we defined.\nTo use our custom NDWI process, we only have to specify a temporal and spatial extent, and let the predefined and default values do their work. We will use datacube_from_process() to construct a DataCube object which we can process further and download.\n\nbbox = {\"west\": 5.09, \"south\": 51.18, \"east\": 5.15, \"north\": 51.21, \"crs\": 4326}\ncreated_process = connection.datacube_from_process(\n    process_id=\"NDWI\", date=[\"2022-06-01\", \"2022-10-01\"], aoi=bbox\n)\n\n\ncreated_process.download(\"output/ndwi.tiff\")\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"output/ndwi.tiff\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\nfig, ax = plt.subplots(figsize=(6, 2), dpi=150)\nax.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\n\nax.set_title(\"NDWI\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html",
    "href": "notebook-samples/openeo/Batch_job.html",
    "title": "How to execute large jobs?: Using Batch Job",
    "section": "",
    "text": "Most of the simple, basic openEO usage examples show synchronous downloading of results: you submit a process graph with a (HTTP POST) request and receive the result as direct response of that same request. This only works properly if the processing doesn’t take too long (order of seconds, or a couple of minutes at most).\nFor the heavier work (larger regions of interest, larger time series, more intensive processing, …) you have to use batch jobs.\nThis notebook shows how to programmatically create and interact with batch job using the openEO Python client library.\n\nimport openeo\n\n# connect to the backend and authenticate\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;\n\n\n\n# load your data collection\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\",\n                bands=[\"B04\", \"B03\", \"B02\"],\n                temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n                spatial_extent={\n                    \"west\": 3.202609,\n                    \"south\": 51.189474,\n                    \"east\": 3.254708,\n                    \"north\": 51.204641,\n                    \"crs\": \"EPSG:4326\",\n    },\n    max_cloud_cover=50,\n)\n\ncube = cube.max_time()\n\n\n# Store raster data as GeoTIFF files\ncube = cube.save_result(format=\"GTiff\")\n\nWhile not necessary, it is also recommended to give your batch job a descriptive title so it’s easier to identify in your job listing.\n\njob = cube.execute_batch()\n\n0:00:00 Job 'j-e6e8567c637443298bca57e2cfda0e3f': send 'start'\n0:00:11 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:16 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:23 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:31 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:41 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:53 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:01:08 Job 'j-e6e8567c637443298bca57e2cfda0e3f': finished (progress N/A)\n\n\nAn additional but longer way of executing the job is following a couple of steps starting with creating it using create_job() then starting it with either start_job() or using start_and_wait().\nA batch job on a back-end is fully identified by its job_id.\n\njob.job_id\n\n'j-e6e8567c637443298bca57e2cfda0e3f'\n\n\nDepending on your situation or use case: make sure to properly take note of the batch job id. It allows you to “reconnect” to your job on the back-end, even if it was created at another time, by another script/notebook or even with another openEO client. Then you can later use use Connection.job(\"your job id\") to create a BatchJob object for an existing batch job.\nA batch job typically takes some time to finish, and you can check its status with the status() method.\n\njob.status()\n\n'finished'\n\n\nBatch job logs can be fetched with job.logs(). If you prefer a graphical, web-based interactive environment to manage and monitor your batch jobs, feel free to switch to an openEO web editor like openeo.dataspace.copernicus.eu at any time.\n\njob.logs()\n\n\n    \n    \n        \n    \n    \n\n\nOnce a batch job is finished you can get a handle to the results (which can be a single file or multiple files) with get_results().\n\nresults = job.get_results()\n\n\nresults\n\n\n    \n    \n        \n    \n    \n\n\nIn the general case, when you have one or more result files (also called “assets”), the easiest option to download them is using download_files() (plural) where you just specify a download folder (otherwise the current working directory will be used by default).\n\nresults.download_files(\"output/out\")\n\n[WindowsPath('output/out/openEO.tif'),\n WindowsPath('output/out/job-results.json')]\n\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"output/out/openEO.tif\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\nfig, ax = plt.subplots(figsize=(6, 2), dpi=150)\nax.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\n\nax.set_title(\"RGB Image\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "notebook-samples/openeo/UDF.html",
    "href": "notebook-samples/openeo/UDF.html",
    "title": "User-Defined Functions (UDF)",
    "section": "",
    "text": "While openEO supports a wide range of pre-defined processes and allows to build more complex user-defined processes from them, you sometimes need operations or algorithms that are not (yet) available or standardized as openEO process. User-Defined Functions (UDF) is an openEO feature (through the run_udf process) that aims to fill that gap by allowing a user to express (a part of) an algorithm as a Python/R/… script to be run back-end side.\nThough several types of algorithms can be used as UDF applications, in this notebook, we showcase a simple example of how to work with UDF using the openEO Python Client library.\n\n# estabish connection to the backend and authenticate it\nimport openeo\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n\n# load collection\n\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\",\n                bands=[\"B04\", \"B03\", \"B02\"],\n                temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n                spatial_extent={\n                    \"west\": 5.05,\n                    \"south\": 51.21,\n                    \"east\": 5.1,\n                    \"north\": 51.23,\n                    \"crs\": \"EPSG:4326\",\n                },\n                max_cloud_cover=50,\n)\n\ncube = cube.reduce_dimension(dimension=\"t\", reducer=\"max\")\ncube\n\n\n    \n    \n        \n    \n    \n\n\nHere the UDF code shown in the following cell does the actual value rescaling.\n\n# Build a UDF object from an inline string with Python source code.\nudf = openeo.UDF(\n    \"\"\"\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    array.values = 0.0001 * array.values\n    return cube\n\"\"\"\n)\n\nUser can also load their UDF from a seperate file using openeo.UDF.from_file('my_udf.py') and apply it.\n\n# Apply the UDF to a cube.\nrescaled_cube = cube.apply(process=udf)\n\n\nrescaled_cube.download(\"output/rescale_s2.tiff\")\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"output/rescale_s2.tiff\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\nfig, ax = plt.subplots(figsize=(6, 2), dpi=150)\nax.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\n\nax.set_title(\"Rescaled Image\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html",
    "href": "notebook-samples/sentinelhub/process_request.html",
    "title": "Sentinel Hub Process API",
    "section": "",
    "text": "In this example notebook we show how to use Sentinel Hub Process API to download satellite imagery. We describe how to use various parameters and configurations to obtain either processed products or raw band data. For more information about the service please check the official service documentation."
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#prerequisites",
    "href": "notebook-samples/sentinelhub/process_request.html#prerequisites",
    "title": "Sentinel Hub Process API",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nCredentials\nProcess API requires Sentinel Hub account. Please check configuration instructions about how to set up your Sentinel Hub credentials.\n\nfrom sentinelhub import SHConfig\n\nconfig = SHConfig(sh_base_url='https://sh.dataspace.copernicus.eu')\n\nif not config.sh_client_id or not config.sh_client_secret:\n    print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")\n\n\n\nImports\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n\nimport datetime\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sentinelhub import (\n    CRS,\n    BBox,\n    DataCollection,\n    DownloadRequest,\n    MimeType,\n    MosaickingOrder,\n    SentinelHubDownloadClient,\n    SentinelHubRequest,\n    bbox_to_dimensions,\n)\n\n# The following is not a package. It is a file utils.py which should be in the same folder as this notebook.\nfrom utils import plot_image\n\n\n\nSetting area of interest\nWe will download Sentinel-2 imagery of Betsiboka Estuary such as the one shown below (taken by Sentinel-2 on 2017-12-15):\n\n\n\ntitle\n\n\nThe bounding box in WGS84 coordinate system is [46.16, -16.15, 46.51, -15.58] (longitude and latitude coordinates of lower left and upper right corners). You can get the bbox for a different area at the bboxfinder website.\nAll requests require bounding box to be given as an instance of sentinelhub.geometry.BBox with corresponding Coordinate Reference System (sentinelhub.constants.CRS). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from sentinelhub.constants.CRS.\n\nbetsiboka_coords_wgs84 = (46.16, -16.15, 46.51, -15.58)\n\nWhen the bounding box bounds have been defined, you can initialize the BBox of the area of interest. Using the bbox_to_dimensions utility function, you can provide the desired resolution parameter of the image in meters and obtain the output image shape.\n\nresolution = 60\nbetsiboka_bbox = BBox(bbox=betsiboka_coords_wgs84, crs=CRS.WGS84)\nbetsiboka_size = bbox_to_dimensions(betsiboka_bbox, resolution=resolution)\n\nprint(f\"Image shape at {resolution} m resolution: {betsiboka_size} pixels\")"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-1-true-color-png-on-a-specific-date",
    "href": "notebook-samples/sentinelhub/process_request.html#example-1-true-color-png-on-a-specific-date",
    "title": "Sentinel Hub Process API",
    "section": "Example 1: True color (PNG) on a specific date",
    "text": "Example 1: True color (PNG) on a specific date\nWe build the request according to the API Reference, using the SentinelHubRequest class. Each Process API request also needs an evalscript.\nThe information that we specify in the SentinelHubRequest object is:\n\nan evalscript,\na list of input data collections with time interval,\na format of the response,\na bounding box and it’s size (size or resolution).\n\nThe evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L1C bands.\nThe image from Jun 12th 2020 is downloaded. Without any additional parameters in the evalscript, the downloaded data will correspond to reflectance values in UINT8 format (values in 0-255 range).\n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\ntrue_color_imgs = request_true_color.get_data()\n\nThe method get_data() will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays.\n\nprint(f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\")\nprint(f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\")\n\n\nimage = true_color_imgs[0]\nprint(f\"Image type: {image.dtype}\")\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\nplot_image(image, factor=3.5 / 255, clip_range=(0, 1))\n\n\nExample 1.1 Adding cloud mask data\nIt is also possible to obtain cloud masks when requesting Sentinel-2 data by using the cloud mask band (CLM) or the cloud probabilities band (CLP). More info here.\nThe factor for increasing the image brightness can already be provided in the evalscript.\n\nevalscript_clm = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"CLM\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.CLM == 1) {\n    return [0.75 + sample.B04, sample.B03, sample.B02]\n  }\n  return [3.5*sample.B04, 3.5*sample.B03, 3.5*sample.B02];\n}\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_clm,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\ndata_with_cloud_mask = request_true_color.get_data()\n\n\nplot_image(data_with_cloud_mask[0], factor=1 / 255)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-2-true-color-mosaic-of-least-cloudy-acquisitions",
    "href": "notebook-samples/sentinelhub/process_request.html#example-2-true-color-mosaic-of-least-cloudy-acquisitions",
    "title": "Sentinel Hub Process API",
    "section": "Example 2: True color mosaic of least cloudy acquisitions",
    "text": "Example 2: True color mosaic of least cloudy acquisitions\nThe SentinelHubRequest automatically creates a mosaic from all available images in the given time interval. By default, the mostRecent mosaicking order is used. More information available here.\nIn this example we will provide a month long interval, order the images w.r.t. the cloud coverage on the tile level (leastCC parameter), and mosaic them in the specified order.\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\nplot_image(request_true_color.get_data()[0], factor=3.5 / 255, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-3-all-sentinel-2s-raw-band-values",
    "href": "notebook-samples/sentinelhub/process_request.html#example-3-all-sentinel-2s-raw-band-values",
    "title": "Sentinel Hub Process API",
    "section": "Example 3: All Sentinel-2’s raw band values",
    "text": "Example 3: All Sentinel-2’s raw band values\nNow let’s define an evalscript which will return all Sentinel-2 spectral bands with raw values.\nIn this example we are downloading already quite a big chunk of data, so optimization of the request is not out of the question. Downloading raw digital numbers in the INT16 format instead of reflectances in the FLOAT32 format means that much less data is downloaded, which results in a faster download and a smaller usage of SH processing units.\nIn order to achieve this, we have to set the input units in the evalscript to DN (digital numbers) and the output sampleType argument to INT16. Additionally, we can’t pack all Sentinel-2’s 13 bands into a PNG image, so we have to set the output image type to the TIFF format via MimeType.TIFF in the request.\nThe digital numbers are in the range from 0-10000, so we have to scale the downloaded data appropriately.\n\nevalscript_all_bands = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"],\n                units: \"DN\"\n            }],\n            output: {\n                bands: 13,\n                sampleType: \"INT16\"\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B01,\n                sample.B02,\n                sample.B03,\n                sample.B04,\n                sample.B05,\n                sample.B06,\n                sample.B07,\n                sample.B08,\n                sample.B8A,\n                sample.B09,\n                sample.B10,\n                sample.B11,\n                sample.B12];\n    }\n\"\"\"\n\nrequest_all_bands = SentinelHubRequest(\n    evalscript=evalscript_all_bands,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\nall_bands_response = request_all_bands.get_data()\n\n\n# Image showing the SWIR band B12\n# Factor 1/1e4 due to the DN band values in the range 0-10000\n# Factor 3.5 to increase the brightness\nplot_image(all_bands_response[0][:, :, 12], factor=3.5 / 1e4, vmax=1)\n\n\n# From raw bands we can also construct a False-Color image\n# False color image is (B03, B04, B08)\nplot_image(all_bands_response[0][:, :, [2, 3, 7]], factor=3.5 / 1e4, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-4-save-downloaded-data-to-disk-and-read-it-from-disk",
    "href": "notebook-samples/sentinelhub/process_request.html#example-4-save-downloaded-data-to-disk-and-read-it-from-disk",
    "title": "Sentinel Hub Process API",
    "section": "Example 4: Save downloaded data to disk and read it from disk",
    "text": "Example 4: Save downloaded data to disk and read it from disk\nAll downloaded data can be saved to disk and later read from it. Simply specify the location on disk where data should be saved (or loaded from) via the data_folder argument of the request’s constructor. When executing the request’s get_data method, set the argument save_data to True.\nThis also means that in all the future requests for data, the request will first check the provided location if the data is already there, unless you explicitly demand to redownload the data.\n\nrequest_all_bands = SentinelHubRequest(\n    data_folder=\"test_dir\",\n    evalscript=evalscript_all_bands,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\n%%time\nall_bands_img = request_all_bands.get_data(save_data=True)\n\n\nprint(\n    \"The output directory has been created and a tiff file with all 13 bands was saved into the following structure:\\n\"\n)\n\nfor folder, _, filenames in os.walk(request_all_bands.data_folder):\n    for filename in filenames:\n        print(os.path.join(folder, filename))\n\n\n%%time\n# try to re-download the data\nall_bands_img_from_disk = request_all_bands.get_data()\n\n\n%%time\n# force the redownload\nall_bands_img_redownload = request_all_bands.get_data(redownload=True)\n\n\nExample 4.1: Save downloaded data directly to disk\nThe get_data method returns a list of numpy arrays and can save the downloaded data to disk, as we have seen in the previous example. Sometimes it is convenient to just save the data directly to disk. You can do that by using save_data method instead.\n\n%%time\nrequest_all_bands.save_data()\n\n\nprint(\n    \"The output directory has been created and a tiff file with all 13 bands was saved into the following structure:\\n\"\n)\n\nfor folder, _, filenames in os.walk(request_all_bands.data_folder):\n    for filename in filenames:\n        print(os.path.join(folder, filename))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-5-other-data-collections",
    "href": "notebook-samples/sentinelhub/process_request.html#example-5-other-data-collections",
    "title": "Sentinel Hub Process API",
    "section": "Example 5: Other Data Collections",
    "text": "Example 5: Other Data Collections\nThe sentinelhub-py package supports various data collections. The example below is shown for one of them, but the process is the same for all of them.\n\nNote:\nFor more examples and information check the tutorial about data collections and Sentinel Hub documentation about data collections.\n\n\nprint(\"Supported DataCollections:\\n\")\nfor collection in DataCollection.get_available_collections():\n    print(collection)\n\nFor this example let’s download the digital elevation model data (DEM). The process is similar as before, we just provide the evalscript and create the request. More data on the DEM data collection is available here. DEM values are in meters and can be negative for areas which lie below sea level, so it is recommended to set the output format in your evalscript to FLOAT32.\n\nevalscript_dem = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output:{\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32\n    }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM]\n}\n\"\"\"\n\n\ndem_request = SentinelHubRequest(\n    evalscript=evalscript_dem,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.DEM,\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\ndem_data = dem_request.get_data()\n\n\n# Plot DEM map\n# vmin = 0; cutoff at sea level (0 m)\n# vmax = 120; cutoff at high values (120 m)\nplot_image(dem_data[0], factor=1.0, cmap=plt.cm.Greys_r, vmin=0, vmax=120)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-6-multi-response-request-type",
    "href": "notebook-samples/sentinelhub/process_request.html#example-6-multi-response-request-type",
    "title": "Sentinel Hub Process API",
    "section": "Example 6 : Multi-response request type",
    "text": "Example 6 : Multi-response request type\nProcess API enables downloading multiple files in one response, packed together in a TAR archive.\nWe will get the same image as before, download in the form of digital numbers (DN) as a UINT16 TIFF file. Along with the image we will download the inputMetadata which contains the normalization factor value in a JSON format.\nAfter the download we will be able to convert the INT16 digital numbers to get the FLOAT32 reflectances.\n\nevalscript = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"],\n                units: \"DN\"\n            }],\n            output: {\n                bands: 3,\n                sampleType: \"INT16\"\n            }\n        };\n    }\n\n    function updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n        outputMetadata.userData = { \"norm_factor\":  inputMetadata.normalizationFactor }\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_multitype = SentinelHubRequest(\n    evalscript=evalscript,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response(\"default\", MimeType.TIFF),\n        SentinelHubRequest.output_response(\"userdata\", MimeType.JSON),\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\n# print out information\nmulti_data = request_multitype.get_data()[0]\nmulti_data.keys()\n\n\n# normalize image\nimg = multi_data[\"default.tif\"]\nnorm_factor = multi_data[\"userdata.json\"][\"norm_factor\"]\n\nimg_float32 = img * norm_factor\n\n\nplot_image(img_float32, factor=3.5, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-7-raw-dictionary-request",
    "href": "notebook-samples/sentinelhub/process_request.html#example-7-raw-dictionary-request",
    "title": "Sentinel Hub Process API",
    "section": "Example 7 : Raw dictionary request",
    "text": "Example 7 : Raw dictionary request\nAll requests so far were built with some helper functions. We can also construct a raw dictionary as defined in the API Reference, without these helper functions, so we have full control over building the request body.\n\nrequest_raw_dict = {\n    \"input\": {\n        \"bounds\": {\"properties\": {\"crs\": betsiboka_bbox.crs.opengis_string}, \"bbox\": list(betsiboka_bbox)},\n        \"data\": [\n            {\n                \"type\": \"S2L1C\",\n                \"dataFilter\": {\n                    \"timeRange\": {\"from\": \"2020-06-01T00:00:00Z\", \"to\": \"2020-06-30T00:00:00Z\"},\n                    \"mosaickingOrder\": \"leastCC\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": betsiboka_size[0],\n        \"height\": betsiboka_size[1],\n        \"responses\": [{\"identifier\": \"default\", \"format\": {\"type\": MimeType.TIFF.get_string()}}],\n    },\n    \"evalscript\": evalscript_true_color,\n}\n\n\n# create request\ndownload_request = DownloadRequest(\n    request_type=\"POST\",\n    url=\"https://services.sentinel-hub.com/api/v1/process\",\n    post_values=request_raw_dict,\n    data_type=MimeType.TIFF,\n    headers={\"content-type\": \"application/json\"},\n    use_session=True,\n)\n\n# execute request\nclient = SentinelHubDownloadClient(config=config)\nimg = client.download(download_request)\n\n\nplot_image(img, factor=3.5 / 255, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-8-multiple-timestamps-data",
    "href": "notebook-samples/sentinelhub/process_request.html#example-8-multiple-timestamps-data",
    "title": "Sentinel Hub Process API",
    "section": "Example 8 : Multiple timestamps data",
    "text": "Example 8 : Multiple timestamps data\nIt is possible to construct some logic in order to return data for multiple timestamps. By defining the time_interval parameter and some logic of splitting it, it is possible to create an SH reques per each “time slot” and then download the data from all the requests with the SentinelHubDownloadClient in sentinelhub-py. In this example we will create least cloudy monthly images for the year 2019.\nHowever, this is already a functionality built on top of this SH API package. We have extended the support for such usage in our package eo-learn. We recommend to use eo-learn for more complex cases where you need multiple timestamps or high-resolution data for larger areas.\n\nstart = datetime.datetime(2019, 1, 1)\nend = datetime.datetime(2019, 12, 31)\nn_chunks = 13\ntdelta = (end - start) / n_chunks\nedges = [(start + i * tdelta).date().isoformat() for i in range(n_chunks)]\nslots = [(edges[i], edges[i + 1]) for i in range(len(edges) - 1)]\n\nprint(\"Monthly time windows:\\n\")\nfor slot in slots:\n    print(slot)\n\n\ndef get_true_color_request(time_interval):\n    return SentinelHubRequest(\n        evalscript=evalscript_true_color,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.SENTINEL2_L1C,\n                time_interval=time_interval,\n                mosaicking_order=MosaickingOrder.LEAST_CC,\n            )\n        ],\n        responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n        bbox=betsiboka_bbox,\n        size=betsiboka_size,\n        config=config,\n    )\n\n\n# create a list of requests\nlist_of_requests = [get_true_color_request(slot) for slot in slots]\nlist_of_requests = [request.download_list[0] for request in list_of_requests]\n\n# download data with multiple threads\ndata = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=5)\n\n\n# some stuff for pretty plots\nncols = 4\nnrows = 3\naspect_ratio = betsiboka_size[0] / betsiboka_size[1]\nsubplot_kw = {\"xticks\": [], \"yticks\": [], \"frame_on\": False}\n\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows), subplot_kw=subplot_kw)\n\nfor idx, image in enumerate(data):\n    ax = axs[idx // ncols][idx % ncols]\n    ax.imshow(np.clip(image * 2.5 / 255, 0, 1))\n    ax.set_title(f\"{slots[idx][0]}  -  {slots[idx][1]}\", fontsize=10)\n\nplt.tight_layout()"
  },
  {
    "objectID": "Support.html",
    "href": "Support.html",
    "title": "Support",
    "section": "",
    "text": "If you don’t find answer to your questions in the documentation portal, this page describes how to ask for support.\n\n\nImportant to know is that only users with a Copernicus Data Space Ecosystem account can ask for support. If you don’t have one yet, you can register here. If you have an issue with registering or you want to deregister, please contact us directly.\n\n\n\nNavigate to the following website.\nIn case you’re not logged in, click on LOGIN.\n\nYou will now get the Copernicus Data Space Ecosystems login form.\n\nEnter your credentials and click LOG IN.\n\n\n\nOnce you have logged in you should see this window, click SUBMIT A REQUEST.\n\nThe form used to create tickets should now appear.\n\nFrom the dropdown select what the question is about.\nEnter the subject.\nDescribe your problem in detail in the field Description.\nYou can also upload attachments such as screenshots in the Attachments section.\nOnce you’ve finished, click SUBMIT.\nYour ticket should now be submitted.\n\nYou can see its status here. You can also post additional comments and attachments.\n\n\n\nAfter logging in (as described in Step 1), you can see the status of your requests under your account. Select Requests from the drop-down.\n\nYou will now see all your requests.\n\nIf you can’t see your request here, make sure that Status “Any” is selected from the drop-down.\nYou should now see your request."
  },
  {
    "objectID": "Support.html#prerequisites",
    "href": "Support.html#prerequisites",
    "title": "Support",
    "section": "",
    "text": "Important to know is that only users with a Copernicus Data Space Ecosystem account can ask for support. If you don’t have one yet, you can register here. If you have an issue with registering or you want to deregister, please contact us directly."
  },
  {
    "objectID": "Support.html#step-1-navigate-to-the-help-center",
    "href": "Support.html#step-1-navigate-to-the-help-center",
    "title": "Support",
    "section": "",
    "text": "Navigate to the following website.\nIn case you’re not logged in, click on LOGIN.\n\nYou will now get the Copernicus Data Space Ecosystems login form.\n\nEnter your credentials and click LOG IN."
  },
  {
    "objectID": "Support.html#step-2-submit-a-request",
    "href": "Support.html#step-2-submit-a-request",
    "title": "Support",
    "section": "",
    "text": "Once you have logged in you should see this window, click SUBMIT A REQUEST.\n\nThe form used to create tickets should now appear.\n\nFrom the dropdown select what the question is about.\nEnter the subject.\nDescribe your problem in detail in the field Description.\nYou can also upload attachments such as screenshots in the Attachments section.\nOnce you’ve finished, click SUBMIT.\nYour ticket should now be submitted.\n\nYou can see its status here. You can also post additional comments and attachments."
  },
  {
    "objectID": "Support.html#accessing-your-submitted-requests",
    "href": "Support.html#accessing-your-submitted-requests",
    "title": "Support",
    "section": "",
    "text": "After logging in (as described in Step 1), you can see the status of your requests under your account. Select Requests from the drop-down.\n\nYou will now see all your requests.\n\nIf you can’t see your request here, make sure that Status “Any” is selected from the drop-down.\nYou should now see your request."
  },
  {
    "objectID": "Applications.html",
    "href": "Applications.html",
    "title": "Applications",
    "section": "",
    "text": "This section provides an overview of the EO Applications available from Copernicus Data Space Ecosystem.\n\n\nThe Copernicus Data Space Ecosystem Browser serves as a central hub for accessing, exploring and utilizing the wealth of Earth observation and environmental data provided by the Copernicus Sentinel constellations, contributing missions, Auxiliary engineering data, on-demand data and more (Check out the documentation on Data for more details) . Based on Sentinel Hub’s EO Browser, users can visualise, compare and analyse and download all this data for a variety of applications, from environmental monitoring and disaster management to urban planning and agriculture. Check out the user guide to know more about the features of the Browser and how to use it.\n\n\n\nJupyter Hub is an open-source, online, interactive web application. It gives access to computational environments and resources without burdening the users with installation and maintenance tasks. JupyterHub provides a multi-user environment for hosting JupyterLab or Jupyter Notebook instances. Therefore, registered Copernicus Data Space Users have access to JupyterLab and Jupyter Notebooks free of charge at a limited capacity of resources beneath. You can access them with the same Copernicus Data Space Ecosystem credentials.\n\n\n\nThe openEO algorithm plaza host many algorithms that are built on top of the openEO API. These algorithms also termed as Earth Observation services can be addressed via openEO Web Editor or via API to embed into new services or platforms. Users are granted with credits to explore the available algorithms and check if they are fit for purpose for their needs. The plaza not only allows to explore the services but also enables third party services provider to onboard their algorithms semi-automatically for further exposure.\n\n\n\nThe openEO Web Editor is a web app that allows users to interact with an openEO back-end and perform various tasks related to Earth observation data processing. This application can be of great use for users who are not familiar with a programming language. The openEO Web Editor can act as a simple interface for:\n\nData Discovery: User can explore and discover available Earth observation datasets.\nWorkflow Creation: User can create an openEO processing workflow from basic building blocks in a drag-and-drop interface.\nWorkflow Execution: Once User have defined their processing workflow and configured the parameters, User can execute the workflow using the Web Editor.\nResult Visualization: User can explore the output data on interactive maps, generate charts and graphs\nJob Management: The Web Editor allows you to monitor your processing jobs, view job histories, and access the generated results."
  },
  {
    "objectID": "Applications.html#browser",
    "href": "Applications.html#browser",
    "title": "Applications",
    "section": "",
    "text": "The Copernicus Data Space Ecosystem Browser serves as a central hub for accessing, exploring and utilizing the wealth of Earth observation and environmental data provided by the Copernicus Sentinel constellations, contributing missions, Auxiliary engineering data, on-demand data and more (Check out the documentation on Data for more details) . Based on Sentinel Hub’s EO Browser, users can visualise, compare and analyse and download all this data for a variety of applications, from environmental monitoring and disaster management to urban planning and agriculture. Check out the user guide to know more about the features of the Browser and how to use it."
  },
  {
    "objectID": "Applications.html#jupyter-hub",
    "href": "Applications.html#jupyter-hub",
    "title": "Applications",
    "section": "",
    "text": "Jupyter Hub is an open-source, online, interactive web application. It gives access to computational environments and resources without burdening the users with installation and maintenance tasks. JupyterHub provides a multi-user environment for hosting JupyterLab or Jupyter Notebook instances. Therefore, registered Copernicus Data Space Users have access to JupyterLab and Jupyter Notebooks free of charge at a limited capacity of resources beneath. You can access them with the same Copernicus Data Space Ecosystem credentials."
  },
  {
    "objectID": "Applications.html#openeo-algorithm-plaza",
    "href": "Applications.html#openeo-algorithm-plaza",
    "title": "Applications",
    "section": "",
    "text": "The openEO algorithm plaza host many algorithms that are built on top of the openEO API. These algorithms also termed as Earth Observation services can be addressed via openEO Web Editor or via API to embed into new services or platforms. Users are granted with credits to explore the available algorithms and check if they are fit for purpose for their needs. The plaza not only allows to explore the services but also enables third party services provider to onboard their algorithms semi-automatically for further exposure."
  },
  {
    "objectID": "Applications.html#openeo-web-editor",
    "href": "Applications.html#openeo-web-editor",
    "title": "Applications",
    "section": "",
    "text": "The openEO Web Editor is a web app that allows users to interact with an openEO back-end and perform various tasks related to Earth observation data processing. This application can be of great use for users who are not familiar with a programming language. The openEO Web Editor can act as a simple interface for:\n\nData Discovery: User can explore and discover available Earth observation datasets.\nWorkflow Creation: User can create an openEO processing workflow from basic building blocks in a drag-and-drop interface.\nWorkflow Execution: Once User have defined their processing workflow and configured the parameters, User can execute the workflow using the Web Editor.\nResult Visualization: User can explore the output data on interactive maps, generate charts and graphs\nJob Management: The Web Editor allows you to monitor your processing jobs, view job histories, and access the generated results."
  },
  {
    "objectID": "Data.html",
    "href": "Data.html",
    "title": "Data",
    "section": "",
    "text": "This section provides an overview of the EO data available from Copernicus Data Space Ecosystem.\nThe data offer will gradually extend starting from January 2023\nFor the latest information about available satellite data, users and stakeholders can follow them in Copernicus Sentinel Operations Dashboard."
  },
  {
    "objectID": "Data.html#copernicus-sentinel-mission",
    "href": "Data.html#copernicus-sentinel-mission",
    "title": "Data",
    "section": "Copernicus Sentinel Mission",
    "text": "Copernicus Sentinel Mission\n\nSentinel 1\nThe Sentinel-1 radar imaging mission is composed of a constellation of two polar-orbiting satellites providing continous all-weather, day and night imagery for Land and Maritime Monitoring. C-band synthentic aperture radar imaging has the advantage of operating at wavelenghts that are not obstructed by clouds or …..load more\n\n\nSentinel 2\nThe Copernicus Sentinel-2 mission comprises a land monitoring constellation of two polar-orbiting satellites placed in the same sun-synchronous orbit, phased at 180° to each other. It aims at monitoring variability in land surface conditions, and its wide swath width (290 km) and …..load more\n\n\nSentinel 3\nThe main objective of theCopernicus Sentinel-3 mission is to measure ocean and land surface colour, sea and land surface temperature, and sea surface topography with high accuracy and reliability to…..load more\n\n\nSentinel 5P\nThe Copernicus Sentinel-5 Precursor mission is the first Copernicus mission dedicated to monitoring our atmosphere. The main objective of the Copernicus Sentinel-5P mission is to…..load more"
  },
  {
    "objectID": "Data.html#complementary-data",
    "href": "Data.html#complementary-data",
    "title": "Data",
    "section": "Complementary data",
    "text": "Complementary data\n\nSoil Moisture and Ocean Salinity (SMOS)\nThe Soil Moisture and Ocean Salinity (SMOS) mission was launched on 2 November 2009. It is one of the European Space Agency’s Earth Explorer missions, which form the science and research element of ESA’s Living Planet Programme. The SMOS payload consists of…..load more\n\n\nENVISAT- Medium Resolution Imaging Spectrometer (MERIS)\nThe Medium Resolution Imaging Spectrometer (MERIS) was a programmable spectrometer on board the Envisat mission, operating in the solar reflective spectral range. Although primarily dedicated to ocean colour observations, MERIS broadened its scope of objectives to atmospheric and land surface related studies. MERIS had a high spectral and radiometric resolution and a dual spatial resolution, within a global mission covering open ocean and coastal zone waters and a regional mission covering land surfaces.Load more\n\n\nLandsat-5\nThe Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters……load more\n\n\nLandsat-7\nThe Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters. Landsat-7 has continued……load more\n\n\nLandsat-8\nThe Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters. Landsat-8 carries……load more\n\n\nCopernicus Atmosphere Monitoring Service (CAMS)\nThe Copernicus Atmosphere Monitoring Service (CAMS) is a service implemented by the European Centre for Medium-Range Weather Forecasts (ECMWF) which provides continuous, open, free, regular data and information on atmospheric composition. CAMS describes……load more\n\n\nCopernicus Emergency Management Service (CEMS)\nThe Copernicus Emergency Management Service (CEMS) provides geospatial data and images for informed decision making in order to support all involved in the management of natural or manmade disasters. CEMS constantly monitors Europe and the globe for signals of an impending disaster or evidence of one happening in real time. Products of CEMS are generated using remote sensing, satellite, in-situ (non-space) and modelled data.Load more\n\n\nCopernicus Land Monitoring Service (CLMS)\nCopernicus program priorities are to gain from Earth Observation techniques and make research, administration, agriculture, economy, environmental protection of our lands easier, cheaper and more effective. Copernicus Land Monitoring Service (CLMS) constitute rich data hub with archival and near real……load more\n\n\nCopernicus Marine Service (CMEMS)\nThe Copernicus Marine Environment Monitoring Service (CMEMS) provides open, free, regular and systematic reference data on the blue (physical), white (sea ice), and green (biogeochemical) state of the marine environment, as well as data on variability and dynamics across the global ocean and European seas…….load more\n\n\nAdditional Complementary Data\nCopernicus Data Space Ecosystem provides data that are not associated with any of the Copernicus Services or are generated by third parties. These datasets include Sentinel-1 related products such as RTC (Radiometrically Terrain Corrected), CARD-BS (Terrain-Corrected Backscatter), Orbits; Sentinel-2 based global mosaics; land cover…….load more\n\n\nVHR Commercial Data\nCommercial data give users access to a wide range of very high-resolution satellite data. Diversified sources of archival or new products ordered according to customer’s tasks, provide the possibility to choose an appropriate product for every project where VHR imaging is crucial. Depending on the source, VHR imagery varies by product type - it can be optical or radar data.Load more"
  },
  {
    "objectID": "Data/Dashboard.html",
    "href": "Data/Dashboard.html",
    "title": "Copernicus Operations Dashboard",
    "section": "",
    "text": "This dashboard keeps users and stakeholders up to date with the latest information about available satellite data.\nAccess Link : https://operations.dashboard.copernicus.eu/index\nIt aims at providing details on the status of the Copernicus operations, covering Sentinel-1, 2, 3 (Land) and Sentinel-5P.\nThe Homepage includes a high-level overview of the Copernicus Sentinel missions over the past 24 h, including the number of missions, time spent gathering data, data volumes, and the number of products delivered.\nThe Events tab provides details of events over the past three months that have impact on the completeness of the data production, such as planned calibration activities, manoeuvrers, or anomalies. The information of which data is affected is included.\n\n\n\n\n\n\n\n\n\n\nThe Data Takes tab hosts a real-time list of available collections delivered by the missions, enabling users to scan through these products to find data that meet their research and development requirements, and to assess their availability.\n\n\n\n\n\nThe Publication Statistics tab provides detailed information on Copernicus Sentinel data – such as number of products delivered – covering anywhere between the past 24h and the past three months. These insights are represented visually, with one graphical representation per mission that is subdivided by sensor.\n\n\n\n\n\nIn the coming year the Dashboard is planned to improve the emerging requirements.\nFor any inquiries on the Copernicus Sentinel Operations Dashboard contact us."
  },
  {
    "objectID": "Data/Sentinel1.html",
    "href": "Data/Sentinel1.html",
    "title": "Sentinel-1",
    "section": "",
    "text": "The Sentinel-1 radar imaging mission is composed of a constellation of two polar-orbiting satellites providing continous all-weather, day and night imagery for Land and Maritime Monitoring. C-band synthentic aperture radar imaging has the advantage of operating at wavelenghts that are not obstructed by clouds or lack of illumination and therefore can acquire data during day or night under all weather conditions.\nThe end of mission of the Sentinel-1B satellite has been declared in July 2022 On 23 December 2021, Copernicus Sentinel-1B experienced an anomaly related to the instrument electronics power supply provided by the satellite platform, leaving it unable to deliver radar data. Despite all investigations and recovery attempts, ESA and the European Commission had to announce that it is the end of the mission for Sentinel-1B. Copernicus Sentinel-1A remains fully operational. More information about the end of the mission for the Sentinel-1B satellite can be found on the webpage Mission ends for Copernicus Sentinel-1B satellite. In response to the loss of Sentinel-1B, the mission observation scenario of Sentinel-1A was adjusted, affecting the nominal global coverage frequency. An up-to-date overview of the observation scenario in place can be consulted on the webpage Sentinel-1 Observation Scenario. Some regions are currently not observed by Sentinel-1. Nevertheless, the regions that are still observed, now have a repeat cycle of 12 days under a one-satellite constellation scenario, which affects possible interferometric analyses.\nSentinel data products are made available systematically and free of charge to all data users including the general public, scientific and commercial users. These data products are available in single polarisation for Wave mode and dual polarisation or single polarisation for SM, IW and EW modes."
  },
  {
    "objectID": "Data/Sentinel1.html#sentinel-1-level-1-ground-range-detected-grd",
    "href": "Data/Sentinel1.html#sentinel-1-level-1-ground-range-detected-grd",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 1 Ground Range Detected (GRD)",
    "text": "Sentinel-1 Level 1 Ground Range Detected (GRD)"
  },
  {
    "objectID": "Data/Sentinel1.html#sentinel-1-level-1-single-look-complex-slc",
    "href": "Data/Sentinel1.html#sentinel-1-level-1-single-look-complex-slc",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 1 Single Look Complex (SLC)",
    "text": "Sentinel-1 Level 1 Single Look Complex (SLC)"
  },
  {
    "objectID": "Data/Sentinel1.html#sentinel-1-level-2-ocean-ocn",
    "href": "Data/Sentinel1.html#sentinel-1-level-2-ocean-ocn",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 2 Ocean (OCN)",
    "text": "Sentinel-1 Level 2 Ocean (OCN)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-1 Level 2 OCN (Ocean) products are specifically processed radar data products for oceanographic applications. These products are derived from Sentinel-1 SAR data. They are tailored to meet the needs of oceanographic studies, such as monitoring sea surface conditions, detecting oil spills, tracking marine vessels, and studying ocean currents. The OCN products typically involve specialized processing techniques to extract relevant oceanographic information from the radar data. This can include surface wave analysis, wind speed and direction estimation, ocean surface current mapping, and identifying features such as oil slicks or marine traffic.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nDec 2014 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nDec 2014 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023.\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2014-10-03T00:00:00Z’, None]"
  },
  {
    "objectID": "Data/Sentinel1.html#sentinel-1-level-0",
    "href": "Data/Sentinel1.html#sentinel-1-level-0",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 0",
    "text": "Sentinel-1 Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-1 Level 0 products are unprocessed radar measurements obtained by the satellite’s SAR system, containing amplitude and phase information. They serve as the initial input for generating higher-level radar products with calibrated and corrected data.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nOct 2014 - Present (1 year)\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nExcept Europe (RoW)\n\n\nLast one year\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023."
  },
  {
    "objectID": "Data/Landsat5.html",
    "href": "Data/Landsat5.html",
    "title": "Landsat-5",
    "section": "",
    "text": "The Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters.\nLandsat-5 was launched on 1 March 1984 and ended its mission on 5 June 2013. It carried the Thematic Mapper (TM), a multispectral scanning radiometer operating in the visible and infrared regions of the electromagnetic spectrum. It was characterized by 185 km swath width and 30 m resolution for visible (VIS), near infrared (NIR) and shortwave infrared (SWIR), and 120 m for thermal infrared (TIR). The acquired Landsat TM scene covers an area of approximately 183 km x 172.8 km. A standard full scene is nominally centred on the intersection of a path and a row (the actual image centre can vary by up to 100 m). A full image consists of 6920 pixels x 5760 lines and each uncompressed band in the VIS, NIR, SWIR and TIR spectral regions requires 40 MB of storage space.\nThe objective of Landsat-5 and every Landsat mission has been to repeatedly image Earth’s land and coastal areas in order to monitor changes to these areas over time."
  },
  {
    "objectID": "Data/Landsat5.html#landsat-5-tm-l1g",
    "href": "Data/Landsat5.html#landsat-5-tm-l1g",
    "title": "Landsat-5",
    "section": "Landsat-5 TM-L1G",
    "text": "Landsat-5 TM-L1G\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nTM__GEO_1P\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nApr 1984 - Nov 2011\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatTM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-tm-esa-archive"
  },
  {
    "objectID": "Data/Landsat5.html#landsat-5-tm-l1t",
    "href": "Data/Landsat5.html#landsat-5-tm-l1t",
    "title": "Landsat-5",
    "section": "Landsat-5 TM-L1T",
    "text": "Landsat-5 TM-L1T\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nTM__GTC_1P\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nApr 1984 - Nov 2011\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatTM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-tm-esa-archive"
  },
  {
    "objectID": "Data/MERIS.html",
    "href": "Data/MERIS.html",
    "title": "Documentation",
    "section": "",
    "text": "The Medium Resolution Imaging Spectrometer (MERIS) was a programmable spectrometer on board the Envisat mission, operating in the solar reflective spectral range. Although primarily dedicated to ocean colour observations, MERIS extended its objectives to atmospheric- and land-surface-related studies. MERIS had high spectral and radiometric resolution and a dual spatial resolution of 260m x 290m over land and coastal regions and reduced resolution of 1040m x 1160m over ocean.\nMERIS was operational throughout the Envisat mission lifetime, from 2002 to 2012, and the first data from the instrument were available from May 2002.\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nMER_FRS_1P\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMay 2002 - Apr 2012\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: https://meris-ds.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/instruments/meris"
  },
  {
    "objectID": "Data/MERIS.html#medium-resolution-imaging-spectrometer-meris---envisat",
    "href": "Data/MERIS.html#medium-resolution-imaging-spectrometer-meris---envisat",
    "title": "Documentation",
    "section": "",
    "text": "The Medium Resolution Imaging Spectrometer (MERIS) was a programmable spectrometer on board the Envisat mission, operating in the solar reflective spectral range. Although primarily dedicated to ocean colour observations, MERIS extended its objectives to atmospheric- and land-surface-related studies. MERIS had high spectral and radiometric resolution and a dual spatial resolution of 260m x 290m over land and coastal regions and reduced resolution of 1040m x 1160m over ocean.\nMERIS was operational throughout the Envisat mission lifetime, from 2002 to 2012, and the first data from the instrument were available from May 2002.\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nMER_FRS_1P\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMay 2002 - Apr 2012\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource: https://meris-ds.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/instruments/meris"
  },
  {
    "objectID": "Data/Sentinel2.html",
    "href": "Data/Sentinel2.html",
    "title": "Sentinel-2",
    "section": "",
    "text": "The Copernicus Sentinel-2 mission comprises a land monitoring constellation of two polar-orbiting satellites placed in the same sun-synchronous orbit, phased at 180° to each other. It aims at monitoring variability in land surface conditions, and its wide swath width (290 km) and high revisit time (10 days at the equator with one satellite, and 5 days with 2 satellites which results in 2-3 days at mid-latitudes) will support monitoring of Earth’s surface changes.\nEach Sentinel-2 products is composed of approximately 110x110 km tiles in cartographic geometry (UTM/WGS84 projection). Earth is subdivided on a predefined set of tiles, defined in UTM/WGS84 projection and using a 100 km step. However, each tile has a surface of 110x110 km² in order to provide large overlap with the neighbouring."
  },
  {
    "objectID": "Data/Sentinel2.html#sentinel-2-level-2a-top-of-canopy-toc",
    "href": "Data/Sentinel2.html#sentinel-2-level-2a-top-of-canopy-toc",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 2A Top of Canopy (TOC)",
    "text": "Sentinel-2 Level 2A Top of Canopy (TOC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel2.html#sentinel-2-level-1c-top-of-atmosphere-toa",
    "href": "Data/Sentinel2.html#sentinel-2-level-1c-top-of-atmosphere-toa",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 1C Top of Atmosphere (TOA)",
    "text": "Sentinel-2 Level 1C Top of Atmosphere (TOA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser"
  },
  {
    "objectID": "Data/Sentinel2.html#sentinel-2-level-1b",
    "href": "Data/Sentinel2.html#sentinel-2-level-1b",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 1B",
    "text": "Sentinel-2 Level 1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-2 Level 1B product provides radiometrically corrected imagery in Top-Of-Atmosphere (TOA) radiance values and in sensor geometry. Additionally, this product includes the refined geometric model which is used to generate the Level 1C product.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) EUP (Packed)\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFull Archive\n\n\nOct 2023\n\n\n\n\nEUP\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast two weeks\n\n\nOct 2023\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "Data/Sentinel2.html#sentinel-2-level-0",
    "href": "Data/Sentinel2.html#sentinel-2-level-0",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 0",
    "text": "Sentinel-2 Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nSentinel-2 Level-0 data is the raw data acquired by the Sentinel-2 satellite before any processing or calibration is applied. The purpose of Sentinel-2 Level-0 data is to provide a baseline for further processing and analysis of the images. Before the data can be used for scientific or operational applications, it must be preprocessed to correct for geometric distortions, radiometric calibration, atmospheric corrections, and other factors that can affect the accuracy and quality of the data.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "Data/CLMS.html",
    "href": "Data/CLMS.html",
    "title": "Copernicus Land Monitoring Service (CLMS)",
    "section": "",
    "text": "Copernicus program priorities are to gain from Earth Observation techniques and make research, administration, agriculture, economy, environmental protection of our lands easier, cheaper and more effective. Copernicus Land Monitoring Service (CLMS) constitute rich data hub with archival and near real time environmental resources. Copernicus Data Space Ecosystem platform makes CLMS products accessible over S3 or NFS protocol . Each User can make his own contribution to expanding data land applications using Copernius Data Space Ecosystem resources.\nCLMS provides three kinds of data related to its coverage: Global, Pan-European and Local. It also provides imagery and reference data (IAR)."
  },
  {
    "objectID": "Data/CLMS.html#copernicus-land-monitoring-service-clms---global",
    "href": "Data/CLMS.html#copernicus-land-monitoring-service-clms---global",
    "title": "Copernicus Land Monitoring Service (CLMS)",
    "section": "Copernicus Land Monitoring Service (CLMS) - Global",
    "text": "Copernicus Land Monitoring Service (CLMS) - Global\n\nOverview\nThe Copernicus Global Land Service continuously provides a series of well-qualified bio-geophysical products on the state and evolution of the land surface on a global scale. The data are provided at medium to low spatial resolution and, for most products, cover the period from 1998 or 1999 till today. It is ready-to-use data that allows comprehensive and immediate analysis for the entire Earth.\n\nOffered Data\n\n\nEnergy\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nLAND SURFACE TEMPERATURE\n\n\nHOURLY_LST_V1,\nHOURLY_LST_V2,\n10DAY_LST_V1,\n10DAY_LST_V2,\n10DAY_TCI_V1,\n10DAY_TCI-V2\n\n\nWorld\n\n\n(*) Jun 2010 - Present\n\n\n/eodata/CLMS/Global/Energy/Land_Surface_Temperature/\n\n\nDetails\n\n\n\n\nSURFACE ALBEDO\n\n\nDIRECTIONAL_1.4_ALDH,\nDIRECTIONAL_1.5_ALDH,\nHEMPISPHERICAL_1.4_ALBH,\nHEMPISPHERICAL_1.5_ALBH\n\n\nWorld\n\n\n(**) Jan 1999 - Jun 2020\n\n\n/eodata/CLMS/Global/Energy/Surface_Albedo/\n\n\nDetails\n\n\n\n\nTOC (TOP OF THE CANOPY) REFLECTANCE\n\n\nTOC_REFLECTANCE\n\n\nWorld\n\n\nJan 1990 - Sep 2018\n\n\n/eodata/CLMS/Global/Energy/Top_Of_Canopy_Reflectances/\n\n\nDetails\n\n\n\n\n\n\nVegetation\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBURNT AREA\n\n\nBURNT_AREA_V3\n\n\nWorld\n\n\nJul 2020 - Jul 2021\n\n\n/eodata/CLMS/Global/Vegetation/Burnt_Area/\n\n\nDetails\n\n\n\n\nDRY MATTER PRODUCTIVITY\n\n\nDMP_300,\nGDMP_300,\nDMP_1000_V2,\nGDMP_1000_V2\n\n\nWorld\n\n\n(*) Jan 1999 - Jun 2020\n\n\n/eodata/CLMS/Global/Vegetation/Dry_Matter_Productivity/\n\n\nDetails\n\n\n\n\nFAPAR\n\n\nFAPAR_300,\nFAPAR_1000_V1.5,\nFAPAR_1000_V2\n\n\nWorld\n\n\n(**) Jan 1999 - Present\n\n\n/eodata/CLMS/Global/Vegetation/FAPAR/\n\n\nDetails\n\n\n\n\nFCOVER\n\n\nFCOVER_300,\nFCOVER_1000_V1.5,\nFCOVER_1000_V2\n\n\nWorld\n\n\n(**) Jan 1999 - Present\n\n\n/eodata/CLMS/Global/Vegetation/FCOVER/\n\n\nDetails\n\n\n\n\nLEAF AREA INDEX\n\n\nLAI_300,\nLAI_1000_V2\n\n\nWorld\n\n\n(*) Jan 1999 - Present\n\n\n/eodata/CLMS/Global/Vegetation/Leaf_Area_Index/\n\n\nDetails\n\n\n\n\nLAND COVER\n\n\nGLOBAL_LAND_COVER,\nGLOBAL_LAND_COVER_COG\n\n\nWorld\n\n\nAnnual 2015-2019\n\n\n/eodata/CLMS/Global/Vegetation/Global_Land_Cover_COG/\n\n\nDetails\n\n\n\n\nNDVI\n\n\nNDVI_300_V1,\nNDVI_300_V2,\nNDVI_1000_V2.2,\nNDVI_1000_V2.2_LTS,\nNDVI_1000_V3\n\n\nWorld\n\n\n(**) Apr 1998 - Present\n\n\n/eodata/CLMS/Global/Vegetation/NDVI/\n\n\nDetails\n\n\n\n\nSOIL WATER INDEX\n\n\nSWI_1000_EUROPE,\nSWI_GLOBAL,\nSWI10_GLOBAL,\nSTATIC_LAYERS\n\n\nWorld\n\n\n(**) Jan 2007 - Present\n\n\n/eodata/CLMS/Global/Vegetation/Soil_Water_Index/\n\n\nDetails\n\n\n\n\nSURFACE SOIL MOISTURE\n\n\nSSM\n\n\nWorld\n\n\n(**) Oct 2014 - Present\n\n\n/eodata/CLMS/Global/Vegetation/Surface_Soil_Moisture/\n\n\nDetails\n\n\n\n\n\n\nWater\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nLAKE WATER QUALITY\n\n\nLWQ_100,\nLWQ_300_SENTINEL3\n\n\nWorld\n\n\n(**) Apr 2016 - Present\n\n\n/eodata/CLMS/Global/Water/Lake_Water_Quality/\n\n\nDetails\n\n\n\n\nWATER BODIES\n\n\nWB_300_V1,\nWB_1000_PROBA_V1,\nWB_1000_PROBA_V2,\nWB_1000_SPOT_V1\n\n\nWorld (WB_1000_PROBA_V1 - AFRICA)\n\n\n(*) Apr 1998 - Sep 2021\n\n\n/eodata/CLMS/Global/Water/Water_Bodies/\n\n\nDetails\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition.\n(**) Depending on specific product.\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nMore Information: https://land.copernicus.eu/global/"
  },
  {
    "objectID": "Data/CLMS.html#copernicus-land-monitoring-service-clms--pan-european",
    "href": "Data/CLMS.html#copernicus-land-monitoring-service-clms--pan-european",
    "title": "Copernicus Land Monitoring Service (CLMS)",
    "section": "Copernicus Land Monitoring Service (CLMS)- Pan-European",
    "text": "Copernicus Land Monitoring Service (CLMS)- Pan-European\n\nOverview\nThe production of pan-European data is coordinated by the European Environment Agency (EEA). Copernius Data Space Ecosystem provides access to pan-European datasets such as: CORINE Land Cover datasets, High Resolution Layers and related pan-European products.\nThe CORINE Land Cover (CLC) inventory was initiated in 1985 (reference year 1990). It was updated in 2000, 2006, 2012, and 2018. The CLC database contains an inventory of land cover in 44 classes. The Minimum Mapping Unit (MMU) for the status layer is defined as 25 hectares (ha) for areal phenomena and 100 meters in width for linear phenomena. The time series are complemented by change layers which highlight changes in land cover between the most recent and the previous status layers with an MMU of 5 ha.\nHigh Resolution Layers (HRL) provide information on specific land cover characteristics, including status and changes. The HRLs are complementary to the CLC datasets. The HRLs are produced from satellite imagery through a combination of automatic processing and interactive rule-based classification.\nThe European Settlement Map (ESM) is a raster dataset mapping human settlements in Europe, produced from SPOT-5 and SPOT-6 satellite imagery. It has been produced with Global Human Settlement Layer (GHSL) technology by the European Commission, Joint Research Centre, Institute for the Protection and Security of the Citizen, Global Security and Crisis Management Unit.\n\nOffered Data\n\n\nCORINE LAND COVER (CLC)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSTATUS\n\n\nCLC_1990,\nCLC_2000,\nCLC_2006,\nCLC_2012,\nCLC_2018\n\n\nEurope\n\n\n(*) Apr 1998 - Sep 2021\n\n\n/eodata/CLMS/Pan-European/CORINE_Land_Cover/\n\n\nDetails\n\n\n\n\nCHANGES\n\n\nCHA_1990_2000,\nCHA_2000_2006,\nCHA_2006_2012, CHA_2012_2018\n\n\nEurope\n\n\n(*) Apr 1998 - Sep 2021\n\n\n/eodata/CLMS/Pan-European/CORINE_Land_Cover/\n\n\nDetails\n\n\n\n\n\n\nHIGH RESOLUTION LAYERS (HRL)\n\n\n\n\n\n\nProduct Type\n\n\nProducts\n\n\nSub-Product\n\n\nSpecific Products\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nIMPERVIOUSNESS\n\n\nSTATUS\n\n\n\n\nIMP_STATUS_2006,\nIMP_STATUS_2009,\nIMP_STATUS_2012,\nIMP_STATUS_2015,\nIMP_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Imperviousness/Status_Maps/\n\n\nDetails\n\n\n\n\nSTATUS (BUILD-UP AREAS)\n\n\n\n\nIMP_BU_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Imperviousness/Status_Maps/Impervious_Built-up_2018/\n\n\nDetails\n\n\n\n\nCHANGES\n\n\n\n\nCHA_2006_2009,\nCHA_2006_2012,\nCHA_2009_2012,\nCHA_2012_2015\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Imperviousness/Change_Maps/\n\n\nDetails\n\n\n\n\nFORESTS\n\n\nSTATUS\n\n\nTREE COVER DENSITY (TCD)\n\n\nTCD_STATUS_2012,\nTCD_STATUS_2015,\nTCD_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Tree_Cover_Density/Status_Maps/\n\n\nDetails\n\n\n\n\nSTATUS\n\n\nDOMINANT LEAF TYPE (DMT)\n\n\nDLT_STATUS_2012,\nDLT_STATUS_2015,\nDLT_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Dominant_Leaf_Type/Status_Maps/\n\n\nDetails\n\n\n\n\nSTATUS\n\n\nFOREST TYPE (FT)\n\n\nFT_STATUS_2012,\nFT_STATUS_2015,\nFT_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Forest_Type/Status_Maps/\n\n\nDetails\n\n\n\n\nCHANGES\n\n\nTREE COVER DENSITY (TCD)\n\n\nTCD_CHA_2012_2015\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Tree_Cover_Density/Change_Maps/\n\n\nDetails\n\n\n\n\nEXPERT PRODUCTS\n\n\n\n\nForest_Additional_Support_Layer_2012,\nForest_Additional_Support_Layer_2015\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Forest_Type/Expert_Products/Forest_Additional_Support_Layer/\n\n\nDetails\n\n\n\n\nGRASSLANDS\n\n\nSTATUS\n\n\n\n\nGRS_STATUS_2015,\nGRS_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Grassland/Status_Maps/\n\n\nDetails\n\n\n\n\nEXPERT PRODUCTS\n\n\n\n\nPloughing_Indicator,\nGrassland_Vegetation_Probability_Index\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Grassland/Expert_Products/\n\n\nDetails\n\n\n\n\nWATER AND WETNESS\n\n\nSTATUS\n\n\n\n\nWAT_STATUS_2015\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Water_Wetness/Status_Maps/\n\n\nDetails\n\n\n\n\nEXPERT PRODUCTS\n\n\n\n\nWater_Wetness_Probability_Index\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Water_Wetness/Expert_Products\n\n\nDetails\n\n\n\n\n\n\nRELATED PAN-EUROPEAN\n\n\n\n\n\n\nProduct Type\n\n\nProducts\n\n\nSpecific Products\n\n\nSpatial\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSTATUS\n\n\nEuropean Settlement Map\n\n\nESM_2012_V2016,\nESM_2012_V2017\n\n\nEurope\n\n\n/eodata/CLMS/Pan-European/Related_Pan-European_Products/European_Settlement_Map/\n\n\nDetails\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nMore Information: https://land.copernicus.eu/pan-european"
  },
  {
    "objectID": "Data/CLMS.html#copernicus-land-monitoring-service-clms--local",
    "href": "Data/CLMS.html#copernicus-land-monitoring-service-clms--local",
    "title": "Copernicus Land Monitoring Service (CLMS)",
    "section": "Copernicus Land Monitoring Service (CLMS)- Local",
    "text": "Copernicus Land Monitoring Service (CLMS)- Local\n\nOverview\nThe production of local component’s datasets is coordinated by the European Environment Agency (EEA). The goal of local components products is to provide more detailed information that is complementary to the information obtained through the Pan-European component. The local component focuses on areas which are prone to specific environmental challenges and problems.\nCopernius Data Space Ecosystem provides three components of CLMS - Local: Urban Atlas, Riparian Zones and Natura 2000.\n\nOffered Data\n\n\nLocal\n\n\n\n\n\n\nProduct Type\n\n\nProducts\n\n\nSpecific Products\n\n\nSpatial\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSTATUS\n\n\nURBAN ATLAS\n\n\nUA_2006,\nUA_2012\n\n\nEurope\n\n\n/eodata/CLMS/Local/Urban_Atlas/Urban_Atlas_2006/,\n/eodata/CLMS/Local/Urban_Atlas/Urban_Atlas_2012/\n\n\nDetails\n\n\n\n\nRIPARIAN ZONES\n\n\nRZ_2012\n\n\nEurope\n\n\n/eodata/CLMS/Local/Riparian_Zones/Land_Cover_Land_Use/\n\n\nDetails\n\n\n\n\nNATURA 2000\n\n\nN2K_2006,\nN2K_2012\n\n\nEurope\n\n\n/eodata/CLMS/Local/Natura_2000/\n\n\nDetails\n\n\n\n\nCHANGES\n\n\nURBAN ATLAS\n\n\nUA_CHA_2006_2012\n\n\nEurope\n\n\n/eodata/CLMS/Local/Urban_Atlas/Change_2006-2012/\n\n\nDetails\n\n\n\n\nOTHER\n\n\nURBAN ATLAS\n\n\nBUILDING HEIGHT 2012 (BH_2012)\n\n\nEuropean’s capital cities\n\n\n/eodata/CLMS/Local/Urban_Atlas/Building_Height_2012/\n\n\nDetails\n\n\n\n\nRIPARIAN ZONES\n\n\nDELINEATION_RZ,\nGREEN_LINEAR_ELEMENTS\n\n\nEurope\n\n\n/eodata/CLMS/Local/Riparian_Zones/Green_Linear_Elements/,\n/eodata/CLMS/Local/Riparian_Zones/Delineation_of_Riparian_Zones/\n\n\nDetails\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nMore Information: https://land.copernicus.eu/local"
  },
  {
    "objectID": "Data/Sentinel1_COG.html",
    "href": "Data/Sentinel1_COG.html",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "",
    "text": "The Sentinel-1 GRD COG_SAFE products can be filtered by the Odata API query using three methods:\n\nFiltering ‘COG.SAFE’ substring in the product name:\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T00:00:00.000Z\n\n\n\n\nUsing proper data type with “-COG” suffix. One of: S1_GRDF_1S-COG,S2_GRDF_1S-COG,S3_GRDF_1S-COG,S4_GRDF_1S-COG,S5_GRDF_1S-COG,S6_GRDF_1S-COG,S1_GRDH_1S-COG,S2_GRDH_1S-COG,S3_GRDH_1S-COG,S4_GRDH_1S-COG,S5_GRDH_1S-COG,S6_GRDH_1S-COG,S1_GRDM_1S-COG,S2_GRDM_1S-COG,S3_GRDM_1S-COG,S4_GRDM_1S-COG,S5_GRDM_1S-COG,S6_GRDM_1S-COG,IW_GRDH_1S-COG,IW_GRDM_1S-COG,EW_GRDH_1S-COG,EW_GRDM_1S-COG,WV_GRDM_1S-COG\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27productType%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27IW_GRDH_1S-COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T04:00:00.000Z&$top=10\n\n\n\n\nFiltering ‘GRD’ substring in product name and ’’origin” attribute equal “CLOUDFERRO”.\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27GRD%27)%20and%20Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27origin%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27CLOUDFERRO%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T04:00:00.000Z&$top=10"
  },
  {
    "objectID": "Data/Sentinel1_COG.html#how-to-search-for-cog_safe-products-with-odata-api",
    "href": "Data/Sentinel1_COG.html#how-to-search-for-cog_safe-products-with-odata-api",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "",
    "text": "The Sentinel-1 GRD COG_SAFE products can be filtered by the Odata API query using three methods:\n\nFiltering ‘COG.SAFE’ substring in the product name:\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T00:00:00.000Z\n\n\n\n\nUsing proper data type with “-COG” suffix. One of: S1_GRDF_1S-COG,S2_GRDF_1S-COG,S3_GRDF_1S-COG,S4_GRDF_1S-COG,S5_GRDF_1S-COG,S6_GRDF_1S-COG,S1_GRDH_1S-COG,S2_GRDH_1S-COG,S3_GRDH_1S-COG,S4_GRDH_1S-COG,S5_GRDH_1S-COG,S6_GRDH_1S-COG,S1_GRDM_1S-COG,S2_GRDM_1S-COG,S3_GRDM_1S-COG,S4_GRDM_1S-COG,S5_GRDM_1S-COG,S6_GRDM_1S-COG,IW_GRDH_1S-COG,IW_GRDM_1S-COG,EW_GRDH_1S-COG,EW_GRDM_1S-COG,WV_GRDM_1S-COG\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27productType%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27IW_GRDH_1S-COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T04:00:00.000Z&$top=10\n\n\n\n\nFiltering ‘GRD’ substring in product name and ’’origin” attribute equal “CLOUDFERRO”.\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27GRD%27)%20and%20Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27origin%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27CLOUDFERRO%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T04:00:00.000Z&$top=10"
  },
  {
    "objectID": "Data/Sentinel1_COG.html#how-to-search-for-cog_safe-products-in-the-browser",
    "href": "Data/Sentinel1_COG.html#how-to-search-for-cog_safe-products-in-the-browser",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "How to search for COG_SAFE products in the Browser?",
    "text": "How to search for COG_SAFE products in the Browser?\nThere are two separate options available for Sentinel-1 GRD products. Selecting the “Level-1 GRD COG” option under Sentinel-1 will return COG_SAFE products while option “Level-1 GRD” will return original GRD products. If you would like to search for both type of products, select both options."
  },
  {
    "objectID": "Data/Sentinel1_COG.html#how-were-original-sentinel-1-grd-products-converted-to-cog_safe-products",
    "href": "Data/Sentinel1_COG.html#how-were-original-sentinel-1-grd-products-converted-to-cog_safe-products",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "How were original Sentinel-1 GRD products converted to COG_SAFE products?",
    "text": "How were original Sentinel-1 GRD products converted to COG_SAFE products?\nThe following changes were made during the conversion of original Sentinel-1 GRD products to COG_SAFE products:\n\nAll GeoTiff files available in the measurements folder were converted to cloud optimized GeoTIFF format with the gdal command:\n\n\nCLI\n\n\ngdal_translate -of COG -a_nodata 0 -co OVERVIEW_COUNT=6 -co BLOCKSIZE=1024 -co BIGTIFF=NO -co OVERVIEW_RESAMPLING=RMS -co COMPRESS=ZSTD -co NUM_THREADS=ALL_CPUS -mo GRD_ORIGINAL_HEADER_SIZE=&lt;original_header_size&gt; -mo GRD_ORIGINAL_FOOTER_SIZE=&lt;original_footer_size&gt; &lt;input_tiff&gt;.tiff &lt;input_tiff&gt;-cog.tiff \n\n\n\nMore information about what these options mean can be found in the [GDAL official documentation](https://gdal.org/programs/gdal_translate.html){target='_blank'}. Note that the output filename has a suffix “-cog”, which indicates that the files were converted to COGs.\n\nA suffix “_COG” was added to the name of the product and a new CRC code was calculated. For example, the original product\nS1A_IW_GRDH_1SDV_20230206T165050_20230206T165115_047118_05A716_53C5.safe became\nS1A_IW_GRDH_1SDV_20230206T165050_20230206T165115_047118_05A716_74F9_COG.safe.\nManifest file was adjusted so that it reflects these changes:\n\nsafe:processing element with a name=“COG Conversion” was added. It contains metadata about the conversion and includes the name of the original product under safe:resource child element.\ndataObject elements, which describe the measurements files, have updated values for “size”, “href”, “checksum”."
  },
  {
    "objectID": "Data/Landsat7.html",
    "href": "Data/Landsat7.html",
    "title": "Landsat-7",
    "section": "",
    "text": "The Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters.\nLandsat-7 has continued the goal of the Landsat programme to repeatedly image Earth’s land and coastal areas in order to monitor changes to these areas over time. The satellite has continued to provide data continuity for the Thematic Mapper aboard Landsat-4 and 5, utilising an enhanced version of the instrument.\nThe Enhanced Thematic Mapper Plus (ETM+) is the main instrument on board Landsat-7 and has been operational since 1999. It provides 30 m resolution for visible (VIS), near-infrared (NIR) and shortwave infrared (SWIR) as well as 60 m resolution for thermal infrared. Moreover, it adds a 15 m resolution panchromatic band (PAN)."
  },
  {
    "objectID": "Data/Landsat7.html#landsat-7-etm-gtc-1p",
    "href": "Data/Landsat7.html#landsat-7-etm-gtc-1p",
    "title": "Landsat-7",
    "section": "Landsat-7 ETM-GTC-1P",
    "text": "Landsat-7 ETM-GTC-1P\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\n(*)ETM-GTC-1P\n\n\n(*) Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nSep 1999 - Dec 2003\n\n\n\n\n\n(*) Landsat ETM+ ESA archive\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatETM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-etm-esa-archive"
  },
  {
    "objectID": "Data/Landsat7.html#landsat-7-etm-l1g",
    "href": "Data/Landsat7.html#landsat-7-etm-l1g",
    "title": "Landsat-7",
    "section": "Landsat-7 ETM-L1G",
    "text": "Landsat-7 ETM-L1G\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nETM-L1G\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nSep 1999 - Nov 2015\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatETM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-etm-esa-archive"
  },
  {
    "objectID": "Data/Landsat7.html#landsat-7-etm-l1gt",
    "href": "Data/Landsat7.html#landsat-7-etm-l1gt",
    "title": "Landsat-7",
    "section": "Landsat-7 ETM-L1GT",
    "text": "Landsat-7 ETM-L1GT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nETM-L1GT\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nSep 1999 - Jan 2017\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatETM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-etm-esa-archive"
  },
  {
    "objectID": "Data/Landsat7.html#landsat-7-etm-l1t",
    "href": "Data/Landsat7.html#landsat-7-etm-l1t",
    "title": "Landsat-7",
    "section": "Landsat-7 ETM-L1T",
    "text": "Landsat-7 ETM-L1T\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nETM-L1T\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nSep 1999 - Jan 2017\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatETM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-etm-esa-archive"
  },
  {
    "objectID": "Data/VHR.html",
    "href": "Data/VHR.html",
    "title": "Documentation",
    "section": "",
    "text": "Dataset provider\n\n\nSatellite constellation\n\n\nProduct Type\n\n\nSpatial Resolution\n\n\nType of Access\n\n\n\n\n\n\nAirbus\n\n\nSPOT 6/7\n\n\nOptical\n\n\n1.5\n\n\nBrowser (WMS)\n\n\n\n\nPleiades\n\n\nOptical\n\n\n0.5\n\n\nBrowser (WMS)\n\n\n\n\nPleiades Neo\n\n\nOptical\n\n\n0.3\n\n\nBrowser (WMS)\n\n\n\n\nPlanet\n\n\nPlanetScope\n\n\nOptical\n\n\n\n\nBrowser (WMS)\n\n\n\n\nSkysat\n\n\n\n\n\n\n\n\n\n\nMaxar\n\n\nWorldView\n\n\n\n\n\n\nBrowser (WMS)\n\n\n\n\nGeoEye\n\n\n\n\n\n\nBrowser (WMS)\n\n\n\n\nAxelSpace\n\n\nGRUS\n\n\nOptical\n\n\n2.5\n\n\n\n\n\n\nSIIS\n\n\nKOMPSAT\n\n\nOptical\n\n\n0.5"
  },
  {
    "objectID": "Data/VHR.html#very-high-resolution-vhr-commercial-data",
    "href": "Data/VHR.html#very-high-resolution-vhr-commercial-data",
    "title": "Documentation",
    "section": "",
    "text": "Dataset provider\n\n\nSatellite constellation\n\n\nProduct Type\n\n\nSpatial Resolution\n\n\nType of Access\n\n\n\n\n\n\nAirbus\n\n\nSPOT 6/7\n\n\nOptical\n\n\n1.5\n\n\nBrowser (WMS)\n\n\n\n\nPleiades\n\n\nOptical\n\n\n0.5\n\n\nBrowser (WMS)\n\n\n\n\nPleiades Neo\n\n\nOptical\n\n\n0.3\n\n\nBrowser (WMS)\n\n\n\n\nPlanet\n\n\nPlanetScope\n\n\nOptical\n\n\n\n\nBrowser (WMS)\n\n\n\n\nSkysat\n\n\n\n\n\n\n\n\n\n\nMaxar\n\n\nWorldView\n\n\n\n\n\n\nBrowser (WMS)\n\n\n\n\nGeoEye\n\n\n\n\n\n\nBrowser (WMS)\n\n\n\n\nAxelSpace\n\n\nGRUS\n\n\nOptical\n\n\n2.5\n\n\n\n\n\n\nSIIS\n\n\nKOMPSAT\n\n\nOptical\n\n\n0.5"
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html",
    "href": "APIs/openEO/R_Client/R.html",
    "title": "Getting started with R client",
    "section": "",
    "text": "This Getting Started guide will give you just a simple overview of the capabilities of the openEO R client library."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#installation",
    "href": "APIs/openEO/R_Client/R.html#installation",
    "title": "Getting started with R client",
    "section": "Installation",
    "text": "Installation\nBefore you install the R client module into your R environment, please make sure that you have at least R version 3.6. Older versions might also work, but were not tested.\nStable releases can be installed from CRAN:\ninstall.packages(\"openeo\")\n\n\n\n\n\n\nInstalling the development version\n\n\n\n\n\nIf you want to install the development version, you can install from GitHub. It may contain more features, but may also be unstable.\nYou need to have the package ‘devtools’ installed. If it is not installed use install.packages(\"devtools\").\nNow you can use install_github from the devtools package to install the development version:\n\ndevtools::install_github(repo=\"Open-EO/openeo-r-client\", dependencies=TRUE, ref=\"develop\")\nIf this gives you an error, something went wrong with the installation so please check the requirements again.\n\n\n\nIf you have troubles installing the package, feel free to to create a ticket or leave an issue at the GitHub project.\nNow that the installation was successfully finished, we can load the package and connect to openEO compliant back-ends. In the following chapters we quickly walk through the main features of the R client."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#exploring-a-back-end",
    "href": "APIs/openEO/R_Client/R.html#exploring-a-back-end",
    "title": "Getting started with R client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO instance of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu.\nFirst we need to establish a connection to the back-end.\n\nlibrary(openeo)\nconnection = connect(host = \"https://openeo.dataspace.copernicus.eu\")\nThe capabilities of the back-end and the collections are generally publicly available, unless the data collections are proprietary and licensing issues prevent the back-end provider from publishing the collection. For the publicly available information you do not need to have an account on the back-end for reading them.\n\nCollections\nCollections represent the basic data the back-end provides (e.g. Sentinel 1 collection) and are therefore often used as input data for job executions (more info on collections). With the following code snippet you can get all available collection names and their description. The collection list and its entries have their own implementations of the print function. The collection list object is coerced into a data.frame only for printing purposes and the collection for the collection some key information are printed.\nTo get the collection list can be indexed by the collections ID to get the more details about the overview information. With the describe_collection function you can get an even more detailed information about the collection.\n\n# Dictionary of the full metadata of the \"COPERNICUS/S2\" collection (dict)\ns2 = describe_collection(\"SENTINEL2_L2A\") # or use the collection entry from the list, e.g. collections$`COPERNICUS/S2`\nprint(s2)\nIn general all metadata objects are based on lists, so you can use str() to get the structure of the list and address fields by the $ operator.\n\n\n\n\n\n\nTip\n\n\n\n\n\nIf the package is used with RStudio the metadata can also be nicely rendered as a web page in the viewer panel by running collection_viewer(x=\"SENTINEL2_L2A\").\n\n\n\n\n\nProcesses\nProcesses in openEO are tasks that can be applied to (EO) data. The input of a process might be the output of another process, so that several connected processes form a new (user-defined) process itself. Therefore, a process resembles the smallest unit of task descriptions in openEO (more details on processes). The following code snippet shows how to get the available processes.\n# List of available openEO processes with full metadata\nprocesses = list_processes()\n\n# List of available openEO processes by identifiers (string)\nprint(names(processes))\n\n# print metadata of the process with ID \"load_collection\"\nprint(processes$load_collection)\nThe list_processes() method returns a list of process metadata objects that the back-end provides. Each process list entry is a more complex list object (called ‘ProcessInfo’) and contains the process identifier and additional metadata about the process, such as expected arguments and return types.\n\n\n\n\n\n\nTip\n\n\n\n\n\nAs for the collection, processes can also be rendered as a web page in the viewer panel, if RStudio is used. In order to open the viewer use process_viewer() with either a particular process (process_viewer(\"load_collection\")) or you can pass on all processes (process_viewer(processes)). When all processes are chosen, there is also a search bar and a category tree.\n\n\n\nFor other graphical overviews of the openEO processes, there is an online documentation for general process descriptions and the openEO Hub for back-end specific process descriptions."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#authentication",
    "href": "APIs/openEO/R_Client/R.html#authentication",
    "title": "Getting started with R client",
    "section": "Authentication",
    "text": "Authentication\nIn the code snippets above we did not need to log in since we just queried publicly available back-end information. However, to run non-trivial processing queries one has to authenticate so that permissions, resource usage, etc. can be managed properly.\nTo authenticate your account on the backend of the Copernicus Data Space Ecosystem, it is necessary for you to complete the registration process. Once registered, the OIDC (OpenID Connect)authentication method will be employed to verify your identity using an external service.\nThe following code snippet shows how to log in via OIDC authentication if the back-end supports the simplified authentication method:\n\nlogin()\nThe following code snippet shows how to log in via OIDC authentication if the simplified authentication method doesn’t work and you need to provide a client ID and secret:\n\n# get supported OIDC providers which the back-end supports\noidc_providers = list_oidc_providers()\n\nlogin(provider = oidc_providers$some_provider,\n      config = list(\n        client_id= \"...\",\n        secret = \"...\"))\nCalling this method opens your system web browser, with which you can authenticate yourself on the back-end authentication system. After that the website will give you the instructions to go back to the R client, where your connection has logged your account in. This means, that every call that comes after that via the connection variable is executed by your user account."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#creating-a-user-defined-process",
    "href": "APIs/openEO/R_Client/R.html#creating-a-user-defined-process",
    "title": "Getting started with R client",
    "section": "Creating a (user-defined) process",
    "text": "Creating a (user-defined) process\nNow that we know how to discover the back-end and how to authenticate, lets continue by creating a new batch job to process some data.\nFirst we need to create a process builder object that carries all the available predefined openEO processes of the connected back-end as attached R functions with the parameters stated in the process metadata.\n\np = processes()\nThe functions of the builder return process nodes, which represent a particular result in the workflow. As one of the first steps we need to select the source data collection.\ndatacube = p$load_collection(\n  id = \"SENTINEL1_GRD\",\n  spatial_extent=list(west = 16.06, south = 48.06, east = 16.65, north = 48.35),\n  temporal_extent=c(\"2017-03-01\", \"2017-04-01\"),\n  bands=c(\"VV\", \"VH\")\n)\nThis results in a process node that represents a datacube and contains the “SENTINEL1_GRD” data restricted to the given spatial extent, the given temporal extent and the given bands .\n\n\n\n\n\n\nSample Data Retrieval\n\n\n\n\n\nIn order to get a better understanding about the processing mechanisms and the data structures used in openEO Platform, it helps to check the actual data from time to time. The function get_sample aids the user in downloading data for a very small spatial extent. It is automatically loaded into R so that you can directly inspect it with stars. Read the vignette on “Sample Data Retrieval” for more details.\n\n\n\nHaving the input data ready, we want to apply a process on the datacube. Therefore, we can call the process directly on the datacube object, which then returns a datacube with the process applied.\n\nmin_reducer = function(data,context) { \n  return(p$min(data = data))\n}\n\nreduced = p$reduce_dimension(data = datacube, reducer = min_reducer, dimension=\"t\")\nThe datacube is now reduced by the time dimension named t, by taking the minimum value of the timeseries values. Now the datacube has no time dimension left. Other so called “reducer” processes exist, e.g. for computing maximum and mean values.\n\n\n\n\n\n\nNote\n\n\n\nEverything applied to the datacube at this point is neither executed locally on your machine nor executed on the back-end. It just defines the input data and process chain the back-end needs to apply when it sends the datacube to the back-end and executes it there.\n\n\nAfter applying all processes you want to execute, we need to tell the back-end to export the datacube, for example as GeoTiff:\n\nformats = list_file_formats()\n\nresult = p$save_result(data = reduced, format = formats$output$`GTIFF-ZIP`)\nThe first line retrieves the back-ends offered input and output formats. The second line creates the result node, which stores the data as a zipped GeoTiff."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#batch-job-management",
    "href": "APIs/openEO/R_Client/R.html#batch-job-management",
    "title": "Getting started with R client",
    "section": "Batch Job Management",
    "text": "Batch Job Management\nAfter you have finished working on your (user-defined) process, we can now send it to the back-end and start the execution. In openEO, an execution of a (user-defined) process is called a (batch job). Therefore, we need to create a job at the back-end using our datacube, giving it the title Example Title.\n\njob = create_job(graph=result,title = \"Example Title\")\nThe create_job method sends all necessary information to the back-end and creates a new job, which gets returned. After this, the job is just created, but has not started the execution at the back-end yet. It needs to be queued for processing explicitly:\n\nstart_job(job = job)\nAfter the job was executed, status updates can be fetched by using the list_jobs() function. This function returns a list of job descriptions, which can be indexed with the jobs ID to limit the search results. But remember that only list_jobs() refreshes this list. So, to monitor a job you have to iteratively call the job (describe_job()) or the job list list_jobs().\n\njobs = list_jobs()\njobs # printed as a tibble or data.frame, but the object is a list\n\n# or use the job id (in this example 'cZ2ND0Z5nhBFNQFq') as index to get a particular job overview\njobs$cZ2ND0Z5nhBFNQFq\n\n# alternatively request detailed information about the job\ndescribe_job(job = job)\nWhen the job is finished, calling download_results() will download the results of a job. Using list_results() will return an overview about the created files and their download link or it states the error message, in case of an error.\n\n# list the processed results\nlist_results(job = job)\n\n# download all the files into a folder on the file system\ndownload_results(job = job, folder = \"/some/folder/on/filesystem\")\n\n\n\n\n\n\nNote\n\n\n\nThe printing behavior and the actual data structure might differ!\n\n\nNow you know the general workflow of job executions."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#full-example",
    "href": "APIs/openEO/R_Client/R.html#full-example",
    "title": "Getting started with R client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the R client. Instead of batch job processing, we compute the image synchronously. Synchronous processing means the result is directly returned in the response, which usually works only for smaller amounts of data.\nHere, we want to produce a monthly RGB composite of Sentinel 1 backscatter data over the area of Vienna, Austria for three months in 2017. This can be used for classification and crop monitoring.\nIn the following code example, we use inline code comments to describe what we are doing.\nlibrary(openeo)\nlibrary(tibble)\n\n\n# connect  to the back-end and login either via explicit call of login, or use your credentials in the connect function\nconnection = login(connect(host = \"https://openeo.dataspace.copernicus.eu\"))\n\n# get the process collection to use the predefined processes of the back-end\np = processes()\n\n# get the collection list to get easier access to the collection ids, via auto completion\ncollections = list_collections()\n\n# get the formats\nformats = list_file_formats()\n\n# load the initial data collection and limit the amount of data loaded\n# note: for the collection id and later the format you can also use the its character value\ndata = p$load_collection(id = collections$`SENTINEL1_GRD`,\n                         spatial_extent = list(west=16.06, \n                                               south=48.06,\n                                               east=16.65,\n                                               north=48.35),\n                         temporal_extent = c(\"2017-03-01\", \"2017-06-01\"),\n                         bands = c(\"VV\"))\n\n# create three monthly sub data sets, which will be merged back into a single data cube later\nmarch = p$filter_temporal(data = data,\n                          extent = c(\"2017-03-01\", \"2017-04-01\"))\n\napril = p$filter_temporal(data = data,\n                          extent = c(\"2017-04-01\", \"2017-05-01\"))\n\nmay = p$filter_temporal(data = data,\n                        extent = c(\"2017-05-01\", \"2017-06-01\"))\n\n# The aggregation function for the following temporal reducer\nagg_fun_mean = function(data, context) {\n  mean(data)\n}\n\nmarch_reduced = p$reduce_dimension(data = march,\n                                   reducer = agg_fun_mean,\n                                   dimension = \"t\")\n\napril_reduced = p$reduce_dimension(data = april,\n                                   reducer = agg_fun_mean,\n                                   dimension = \"t\")\n\nmay_reduced = p$reduce_dimension(data = may,\n                                 reducer = agg_fun_mean,\n                                 dimension = \"t\")\n\n# Each band is currently called VV. We need to rename at least the label of one dimension, \n# because otherwise identity of the data cubes is assumed. The bands dimension consists \n# only of one label, so we can rename this to be able to merge those data cubes.\nmarch_renamed = p$rename_labels(data = march_reduced,\n                                dimension = \"bands\",\n                                target = c(\"R\"),\n                                source = c(\"VV\"))\n\napril_renamed = p$rename_labels(data = april_reduced,\n                                dimension = \"bands\",\n                                target = c(\"G\"),\n                                source = c(\"VV\"))\n\nmay_renamed = p$rename_labels(data = may_reduced,\n                              dimension = \"bands\",\n                              target = c(\"B\"),\n                              source = c(\"VV\"))\n\n# combine the individual data cubes into one\n# this is done one by one, since the dimensionalities have to match between each of the data cubes\nmerge_1 = p$merge_cubes(cube1 = march_renamed,cube2 = april_renamed)\nmerge_2 = p$merge_cubes(cube1 = merge_1, cube2 = may_renamed)\n\n# rescale the the back scatter measurements into 8Bit integer to view the results as PNG\nrescaled = p$apply(data = merge_2,\n        process = function(data,context) {\n          p$linear_scale_range(x=data, inputMin = -20,inputMax = -5, outputMin = 0, outputMax = 255)\n        })\n\n# export shall be format PNG\n# look at the format description\nformats$output$PNG\n\n# store the results using the format and set the create options\nresult = p$save_result(data = rescaled,format = formats$output$PNG, options = list(red=\"R\",green=\"G\",blue=\"B\"))\n\n# create a job\njob = create_job(graph = result, title = \"S1 Example R\", description = \"Getting Started example on openeo.org for R-client\")\n\n# then start the processing of the job and turn on logging (messages that are captured on the back-end during the process execution)\nstart_job(job = job, log = TRUE)\nNow the resulting PNG file of the RGB backscatter composite is stored as a PNG file in the current working directory. It looks like this:"
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#user-defined-functions",
    "href": "APIs/openEO/R_Client/R.html#user-defined-functions",
    "title": "Getting started with R client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function.\nIn general the processing workflow works by uploading the Python or R script into the users file directory on the back-end and reference the script via its URL or by its relational name (e.g. /scripts/script1.R) in the function run_udf. The latter function is a predefined openEO process that the back-end might provide, if UDFs are supported.\nFind out more about UDFs in the respective Python UDF and R UDF repositories with their documentation and examples."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#useful-links",
    "href": "APIs/openEO/R_Client/R.html#useful-links",
    "title": "Getting started with R client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO R Client Library:\n\nDocumentation\nVignettes\nCode Repository\nfor function documentation, use R’s ? function or see the online documentation"
  },
  {
    "objectID": "APIs/openEO/Glossary.html",
    "href": "APIs/openEO/Glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "The following glossary provides an introduction to the key technical terms commonly used when working with the openEO API."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#general-terms",
    "href": "APIs/openEO/Glossary.html#general-terms",
    "title": "Glossary",
    "section": "General terms",
    "text": "General terms\n\nEO: Earth Observation\nAPI: Application Programming Interface (wikipedia), a (standardized) communication protocol, for example between a client application and back-end service\nclient: Software tool, framework or environment that an end-user directly interacts with. For example: a Jupyter notebook, a Python script/application, an RStudio session, a JavaScript based web app, etc.\nback-end: computer (cloud) infrastructure that takes care of the actual EO (big) data storage and processing. The end-user only interacts with the back-end through a standardized API, while the operational complexity is hidden."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#processes",
    "href": "APIs/openEO/Glossary.html#processes",
    "title": "Glossary",
    "section": "Processes",
    "text": "Processes\nA process is an operation that performs a specific task on a set of parameters and returns a result. An example is computing a statistical operation, such as mean or median, on selected EO data. A process is similar to a function or method in programming languages.\nA pre-defined process is a process provided by the back-end, typically one of the processes centrally defined by openeo.org.\nA user-defined process is a process defined by the user. It can directly be part of another process graph or be stored as custom process on a back-end. Internally it is a process graph with optional additional metadata.\nA process graph chains specific process calls from the set of pre-defined and user-defined processes together. A process graph itself is a (user-defined) process again."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#eo-data-collections",
    "href": "APIs/openEO/Glossary.html#eo-data-collections",
    "title": "Glossary",
    "section": "EO data (Collections)",
    "text": "EO data (Collections)\nIn openEO, all collections can be requested using a client. These collection follows the STAC (SpatioTemporal Asset Catalog) metadata specification. Within openEO, a product (sometimes also called item or asset in the specification) typically refers to a limited area and a single overpass leading to a very short observation period (seconds) or a temporal aggregation of such data. A user can load (a subset of) a collection using a special process, which returns a (spatial) datacube. All further processing is then applied to the datacube on the back-end."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#spatial-datacubes",
    "href": "APIs/openEO/Glossary.html#spatial-datacubes",
    "title": "Glossary",
    "section": "Spatial datacubes",
    "text": "Spatial datacubes\nA spatiotemporal datacube is a multidimensional array with one or more spatial or temporal dimensions. In the EO domain, it is common to be implicit about the temporal dimension and just refer to them as spatial datacubes in short. Special cases are raster and vector datacubes. Learn more about datacubes in the datacube documentation."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#user-defined-function-udf",
    "href": "APIs/openEO/Glossary.html#user-defined-function-udf",
    "title": "Glossary",
    "section": "User-defined function (UDF)",
    "text": "User-defined function (UDF)\nThe abbreviation UDF stands for user-defined function. With this concept, users are able to upload custom code and have it executed e.g. for every pixel of a scene, or applied to a particular dimension or set of dimensions, allowing custom server-side calculations."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#data-processing-modes",
    "href": "APIs/openEO/Glossary.html#data-processing-modes",
    "title": "Glossary",
    "section": "Data Processing modes",
    "text": "Data Processing modes\nProcesses can run in three different ways:\n\nResults can be pre-computed by creating a batch job. They are submitted to the back-end’s processing system, but will remain inactive until explicitly put into the processing queue. They will run only once and store results after execution. Results can be downloaded. Batch jobs are typically time consuming and user interaction is not possible although log files are generated for them. This is the only mode that allows to get an estimate about time, volume and costs beforehand.\nProcesses can also be executed on-demand (i.e. synchronously). Results are delivered with the request itself and no job is created. Only lightweight computations, for example previews, should be executed using this approach as timeouts are to be expected for long-polling HTTP requests.\nThe third way of data processing in openEO is client-side processing. The client-side processing functionality allows to test and use openEO with its processes locally, i.e. without any connection to an openEO back-end. It relies on the projects openeo-pg-parser-networkx, which provides an openEO process graph parsing tool, and openeo-processes-dask, which provides an Xarray and Dask implementation of most openEO processes."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/BurntMapping/burntmapping_chunks.html",
    "href": "APIs/openEO/openeo-community-examples/python/BurntMapping/burntmapping_chunks.html",
    "title": "Burnt area mapping using chunk_polygon on UDF",
    "section": "",
    "text": "In this notebook classical Normalized Burnt Ratio(NBR) difference is performedon a chunk of polygons. You can find ways to develop your process and use chunk_polygon on a usecase. The method followed in this notebook to compute DNBR is inspired from UN SPIDER’s recommended preactices.\n(To be noted: chunk_polygon are experimental at the moment)\n\n# import necessary packages\nimport openeo\nfrom openeo.api.process import Parameter\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport rasterio\nimport numpy as np\n\n# connect with the backend\neoconn = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nUser can choose among different backend available here to connect to their choice of backend. Regarding the authentication process OpenID connect (oidc) is recommended, but not always straightforward to use. In cases where you are unable to connect with the backend use basic authentication method explained here.\n\n# function to load geojson file\ndef read_json(path: Path) -&gt; dict:\n    with open(path) as input:\n        field = json.load(input)\n        input.close()\n    return field\n\nTo use the data collection, a user must use the correct backend with the data collection. Then using load_collection, they can specify bands, temporal extent (i.e. interested time interval) and even spatial extent. In this example, we have loaded the entire collection so that process (including UDF) can later be applied to spatial chunks.\n\n# load datacube for beforeand after fire \nbefore_date = [\"2021-01-12\",\"2021-03-12\"]\nafter_date = [\"2021-05-18\", \"2021-07-18\"]\n\nbefore_cube = eoconn.load_collection(\n                            \"SENTINEL2_L1C_SENTINELHUB\",\n                            temporal_extent = before_date,\n                            bands = ['B08','B12']\n                            )\nafter_cube = eoconn.load_collection(\n                            \"SENTINEL2_L1C_SENTINELHUB\",\n                            temporal_extent = after_date,\n                            bands = ['B08','B12'],\n                            )\n\nHere we tried in presenting a method to create and use UDF as an openEO feature. In a similar manner user can create their own UDF as needed to apply to their data cube. More information on UDF. The reason to create UDF openEO, is similar to creating a function in general python i.e to avoid recursive script.\nOur UDF computes Normalised Burnt Ratio (NBR) from the selected band by performing simple band computation and returns a NBR datacube.\n\n# Create a UDF object from inline source code for computing nbr\nmy_code = \"\"\"\nfrom openeo.udf import XarrayDataCube\n\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    # access the underlying xarray\n    inarr = cube.get_array()\n\n    # nbr\n    nir = inarr.loc[:,'B08']\n    swir = inarr.loc[:,'B12']\n    nbr = (nir-swir)/(nir+swir)\n    \n    # extend bands dim\n    nbr=nbr.expand_dims(dim='bands', axis=-3).assign_coords(bands=['nbr'])\n    \n    # wrap back to datacube and return\n    return XarrayDataCube(nbr)\n\"\"\"\nudf_process = lambda data: data.run_udf(udf=my_code,runtime='python')\n\nWe used the chunk_polygon method to apply our UDF over a spatial chunk of the datacube. In the case of a simple process that does not require UDF, you can directly load your spatial extent in the dataset.\n\n#specify aoi chunks\nspatial_param = read_json(\"cal_aoi_v2.geojson\") \n\n# compute nbr for pre and post datacube\npre_nbr = before_cube.chunk_polygon(chunks=spatial_param,process=udf_process)\npost_nbr = after_cube.chunk_polygon(chunks=spatial_param,process=udf_process)\n\nFurthermore, since we loaded our collection for specific time intervals, it can include multiple time dimensions. Thus reduce_dimension applies a reducer to a data cube dimension by collapsing all the pixel values along the time dimension into an output value computed by the reducer.\n\n# perform time dimension reduction\npre_n = pre_nbr.reduce_dimension(dimension=\"t\", reducer=\"mean\")\npost_n = post_nbr.reduce_dimension(dimension=\"t\", reducer=\"mean\")\n\n# find the difference between pre and post image\nsub = post_n-pre_n\n\nOnce the process is completed, you can also save it as your process using save_user_defined_process that can later be used for a similar task. Otherwise, you can download the result either by direct download (in case of the small spatial extent with few processing) or perform create a batch job in case it is a heavy task over a large extent.\n\n#download your output\nsub.download(\"sub_nbr_udf.tiff\")\n\n\n#set colors for plotting and classes based on UN SPIDER recommended practices\nimport matplotlib\nimg = rasterio.open(\"sub_nbr_udf.tiff\").read()\ncmap = matplotlib.colors.ListedColormap(['green','yellow','orange','red','purple'])\nbounds = [-0.5, 0.1, 0.27, 0.440, 0.660, 1.3] \nnorm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\ncmap.set_over('purple')\ncmap.set_under('white')\nfig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'xticks': [], 'yticks': []})\ncax = ax.imshow(img[0], cmap=cmap,norm=norm)\nplt.title('Burn Severity Map')\ncbar = fig.colorbar(cax, ax=ax, fraction=0.035, pad=0.04, ticks=bounds)\ncbar.ax.set_yticklabels(['Unburned', 'Low Severity', 'Moderate-low Severity', 'Moderate-high Severity', 'High Severity'])\nplt.show()\n\n\n\n\nThe bound set for the legend are based on the description provided in the UN SPIDER guideline."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/FloodNDWI/flood_ndwi.html",
    "href": "APIs/openEO/openeo-community-examples/python/FloodNDWI/flood_ndwi.html",
    "title": "Comparitive study of before and after flash flood in Cologne using NDWI service available in EOplaza",
    "section": "",
    "text": "In this notebook, we tried in performing comparative study between pre and post image for Cologne during 2021 flood. A simple technique to subtract pre and post image is done to know the change in water content due to flood in that region. Refernce: https://labo.obs-mip.fr/multitemp/the-ndwi-applied-to-the-recent-flooding-in-the-central-us/\n\n# import necessary packages\nimport openeo\nfrom openeo.api.process import Parameter\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport rasterio\nimport numpy as np\n\n# connect with the backend\neoconn = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nUser can choose among different backend available here to connect to the backend. Rrgarding the authentication process OpenID connect (oidc) is recommended, but not always straightforward to use. In cases where you are unable to connect with the backend use basic authentication method explained here.\n\n# function to load geojson file\ndef read_json(path: Path) -&gt; dict:\n    with open(path) as input:\n        field = json.load(input)\n        input.close()\n    return field\n\nSince this is an already published service available service, they need not be concerned with selecting the backend. They can directly execute the process by providing time and area of interest.\n\nbefore_date = [\"2021-05-12\",\"2021-05-12\"]\nafter_date = [\"2021-06-18\", \"2021-06-18\"]\naoi = read_json(\"cologne_all.geojson\")\n\n# Create a processing graph from the NDWI process using an active openEO connection\nbefore_ndwi = eoconn.datacube_from_process(\"NDWI\", namespace=\"vito\", date=before_date\n                                        ,polygon=aoi)\n# Create a processing graph from the NDWI process using an active openEO connection\nafter_ndwi = eoconn.datacube_from_process(\"NDWI\", namespace=\"vito\", date=after_date\n                                        ,polygon=aoi)\n\n/home/pratixa/.local/lib/python3.6/site-packages/openeo/metadata.py:252: UserWarning: No cube:dimensions metadata\n  complain(\"No cube:dimensions metadata\")\n\n\nAs you can see a userwarning for missing data pops up which might not be an issue in normal case but here we wish to further evaluate our result in our process thus defining metadata is needed.\nNot all the available service requires updating metadata. If a service lack metadata then performing further computation on output of the service could be an issue. In such case user can update the metadata based on it’s status.\n\n# check available information is available in metadata or not\nbefore_ndwi.metadata\n\n\n    \n    \n        \n    \n    \n\n\n\n# updating our metadata\nfrom openeo.metadata import CollectionMetadata\n\nbefore_ndwi.metadata = CollectionMetadata({\"cube:dimensions\":{\"t\":{\"type\":\"temporal\"}}})\nafter_ndwi.metadata = CollectionMetadata({\"cube:dimensions\":{\"t\":{\"type\":\"temporal\"}}})\n\nOnce the metadata is updated you can perform further operations like subtraction or sum etc as done for this use case.\nSince now we have details on temporal dimension we can perform dimension reduction. As we loaded our collection for specific time intervals, it can include multiple time dimensions. Thus reduce_dimension applies a reducer to a data cube dimension by collapsing all the pixel values along the time dimension into an output value computed by the reducer.\nIt is then followed by subtracting our before datacube from the later.\n\n# compute the change between pre and post image\nmerging_cubes = after_ndwi.merge_cubes(-before_ndwi)\ndifferenced_cube = merging_cubes.reduce_dimension(dimension=\"t\",reducer='sum')\n\nOnce the process is completed, you can also save it as your process using save_user_defined_process that can later be used for a similar task. Otherwise, you can download the result either by direct download (in case of the small spatial extent with few processing) or perform create a batch job in case it is a heavy task over a large extent.\n\n# download your result either using synchronous method or batch\n# synchronous download\ndifferenced_cube.download(\"changed_ndwi.tiff\")\n# \n# # Or perform batch processing if area is comparatively large\n# batch_job = Rrescaled_chunks.create_job(out_format = \"GTiff\", title=\"changed_ndwi\")\n# batch_job.start_and_wait()\n# results = batch_job.get_results()\n# results.download_files()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/FloodSAR/flood_sar_udf.html",
    "href": "APIs/openEO/openeo-community-examples/python/FloodSAR/flood_sar_udf.html",
    "title": "Flood extent using Sentinel 1",
    "section": "",
    "text": "Flood extent can be determined using a change detection approach on Sentinel-1 data. In this process, we have tried adopting UN SPIDER’s recommended practice for computing flood extents by implementing an openEO UDF.\n\n# import necessary packages\nimport openeo\nfrom openeo.api.process import Parameter\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport rasterio\nimport numpy as np\n\n# connect with the backend\neoconn = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nUser can choose among different backend available here to connect to the backend. Rrgarding the authentication process OpenID connect (oidc) is recommended, but not always straightforward to use. In cases where you are unable to connect with the backend use basic authentication method explained here.\n\n# function to load geojson file\ndef read_json(path: Path) -&gt; dict:\n    with open(path) as input:\n        field = json.load(input)\n        input.close()\n    return field\n\nTo use the data collection, a user must use the correct backend with the data collection. Then using load_collection, they can specify bands, temporal extent (i.e. interested time interval) and even spatial extent.\n\n# load before flash flood params\nbefore_date = [\"2021-05-12\",\"2021-05-12\"]\nafter_date = [\"2021-06-18\", \"2021-06-18\"]\nspatial_param = read_json(\"aoi/cologne_all.geojson\")\n\n\n# using S1 data from Sentinelhub (https://hub.openeo.org/) directly instead of downloading\n\nbefore_cube = eoconn.load_collection(\n                            \"SENTINEL1_GAMMA0_SENTINELHUB\",\n                            temporal_extent = before_date,\n                            spatial_extent = spatial_param,\n                            bands = ['VV'],\n                            properties={\"sat:orbit_state\": lambda v: v==\"ascending\"}\n                            )\nafter_cube = eoconn.load_collection(\n                            \"SENTINEL1_GAMMA0_SENTINELHUB\",\n                            temporal_extent = after_date,\n                            spatial_extent = spatial_param,\n                            bands = ['VV'],\n                            properties={\"sat:orbit_state\": lambda v: v==\"ascending\"}\n                            )\n\nSince now we have details on temporal dimension we can perform dimension reduction. As we loaded our collection for specific time intervals, it can include multiple time dimensions. Thus reduce_dimension applies a reducer to a data cube dimension by collapsing all the pixel values along the time dimension into an output value computed by the reducer.\n\n#'reduce_dimension' to reduce temporal dimension\nrbefore_cube = before_cube.reduce_dimension(dimension=\"t\", reducer=\"mean\")\nrafter_cube = after_cube.reduce_dimension(dimension=\"t\", reducer=\"mean\")\n\n\n# calculating the ratio of post and pre datacube as mentioned in the UNSPIDER documentation for flood extent using Sentinel 1\ndifference = rafter_cube.divide(rbefore_cube)\n\nHere we tried in presenting a method to create and use UDF as an openEO feature. In a similar manner user can create their own UDF as needed to apply to their data cube. More information on UDF.\nOur UDF is designed to perform thresholding to the final result obtained by comparing pre and post datacubes and returns a cube that assigns 1 to region with higher value than threshold otherwise 0.\n\n# define a udf that will perform thresholding of the dataset\nudf = openeo.UDF(\"\"\"\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    \n    # UN defined difference threshold\n    array.values = np.where(array &gt; 1.5, 1, 0)\n    return cube\n\"\"\")\n\n# Apply the UDF to a cube.\nthreshold_cube = difference.apply(process=udf)\n\nOnce the process is completed, you can also save it as your process using save_user_defined_process that can later be used for a similar task. Otherwise, you can download the result either by direct download (in case of the small spatial extent with few processing) or perform create a batch job in case it is a heavy task over a large extent.\n\n# download your result either syncronous or proceed as batch job\nthreshold_cube.download(\"s1_diff.tiff\")"
  },
  {
    "objectID": "APIs/openEO/openEO.html",
    "href": "APIs/openEO/openEO.html",
    "title": "openEO",
    "section": "",
    "text": "openEO represents an innovative community standard that revolutionizes geospatial data processing and analysis. This groundbreaking framework provides a novel approach to accessing, processing, and analyzing diverse Earth observation data. By adopting openEO, developers, researchers, and data scientists gain access to a unified and interoperable platform, empowering them to harness distributed computing environments and leverage cloud-based resources for addressing complex geospatial challenges.\n\n\n\nWith openEO’s collaborative nature, users can seamlessly share code, workflows, and data processing methods across platforms and tools, fostering collaboration and advancing the accessibility, scalability, and reproducibility of Earth observation data. Additionally, openEO provides intuitive programming libraries that enable easy analysis of diverse Earth observation datasets. These libraries facilitate efficient access and processing of large-scale data across multiple infrastructures, supporting various applications, including exploratory research, detailed mapping, and information extraction from Earth observation. Moreover, this streamlined approach enhances the development process, enabling the utilization of Earth observation data for a wide range of applications and services."
  },
  {
    "objectID": "APIs/openEO/openEO.html#overview",
    "href": "APIs/openEO/openEO.html#overview",
    "title": "openEO",
    "section": "",
    "text": "openEO represents an innovative community standard that revolutionizes geospatial data processing and analysis. This groundbreaking framework provides a novel approach to accessing, processing, and analyzing diverse Earth observation data. By adopting openEO, developers, researchers, and data scientists gain access to a unified and interoperable platform, empowering them to harness distributed computing environments and leverage cloud-based resources for addressing complex geospatial challenges.\n\n\n\nWith openEO’s collaborative nature, users can seamlessly share code, workflows, and data processing methods across platforms and tools, fostering collaboration and advancing the accessibility, scalability, and reproducibility of Earth observation data. Additionally, openEO provides intuitive programming libraries that enable easy analysis of diverse Earth observation datasets. These libraries facilitate efficient access and processing of large-scale data across multiple infrastructures, supporting various applications, including exploratory research, detailed mapping, and information extraction from Earth observation. Moreover, this streamlined approach enhances the development process, enabling the utilization of Earth observation data for a wide range of applications and services."
  },
  {
    "objectID": "APIs/openEO/openEO.html#added-value-of-openeo-api",
    "href": "APIs/openEO/openEO.html#added-value-of-openeo-api",
    "title": "openEO",
    "section": "Added-value of openEO API",
    "text": "Added-value of openEO API\nThe key benefits of using openEO API can be summarized as follows:\n\nUnified and straightforward access to multiple Earth observation datasets.\nScalable and efficient processing capabilities.\nA standardized system that works across different platforms.\nIndependence from underlying technologies and software libraries.\nReproducibility through transparent workflows, supporting principles of FAIR (Findable, Accessible, Interoperable, and Reusable) and Open Science.\n\nWhen using the openEO API, users can choose JavaScript, Python, or R as their client library. This allows them to work with any back-end and compare them based on capacity, cost, and result quality.\nNevertheless, if you are not familiar with programming, you could start using the web-based editor for openEO. It supports visual modelling of your algorithms and simplified JavaScript-based access to the openEO workflows and providers. An overview of the openEO web-editor is available in the Application section of this documentation."
  },
  {
    "objectID": "APIs/openEO/openEO.html#datacubes",
    "href": "APIs/openEO/openEO.html#datacubes",
    "title": "openEO",
    "section": "Datacubes",
    "text": "Datacubes\nIn openEO, a datacube is a fundamental concept and a key component of the platform. Data is represented as datacubes in openEO, which are multi-dimensional arrays with additional information about their dimensionality. Datacubes can provide a nice and tidy interface for spatiotemporal data as well as for the operations you may want to execute on them. An in-depth introduction to datacubes and processing them with openEO can be found here"
  },
  {
    "objectID": "APIs/openEO/openEO.html#support",
    "href": "APIs/openEO/openEO.html#support",
    "title": "openEO",
    "section": "Support",
    "text": "Support\nUnable to locate your preferred programming language? Or you don’t find functionalities that you want to use. Then you have the option to report issues or feedbacks via the to be CDSE forum or also please feel free to create a ticket or actively propose API changes through Pull Requests."
  },
  {
    "objectID": "APIs/openEO/openEO.html#free-tier-limitations",
    "href": "APIs/openEO/openEO.html#free-tier-limitations",
    "title": "openEO",
    "section": "Free tier limitations",
    "text": "Free tier limitations\nThe following limitations need to be taken into account:\n\nSynchronous requests are limited to 2 concurrent requests\nBatch jobs are limited to 2 concurrent jobs\n\nThese limits are in place to avoid that individual users can overload the service, please contact support if they are problematic for your use case."
  },
  {
    "objectID": "APIs/openEO/openEO.html#collections",
    "href": "APIs/openEO/openEO.html#collections",
    "title": "openEO",
    "section": "Collections",
    "text": "Collections"
  },
  {
    "objectID": "APIs/openEO/openEO.html#file-formats",
    "href": "APIs/openEO/openEO.html#file-formats",
    "title": "openEO",
    "section": "File formats",
    "text": "File formats"
  },
  {
    "objectID": "APIs/openEO/openEO.html#processes",
    "href": "APIs/openEO/openEO.html#processes",
    "title": "openEO",
    "section": "Processes",
    "text": "Processes"
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html",
    "title": "Getting started with JavaScript client",
    "section": "",
    "text": "This Getting Started guide will give you just a simple overview of the capabilities of the openEO JavaScript client library."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#installation",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#installation",
    "title": "Getting started with JavaScript client",
    "section": "Installation",
    "text": "Installation\nThe openEO JavaScript Client can be used in all modern browsers (excludes Internet Explorer) and all maintained Node.js versions (&gt;= 10.x). It can also been used for mobile app development with the Ionic Framework, for example.\nThe easiest way to try out the client is using one of the examples. Alternatively, you can create an HTML file and include the client with the following HTML script tags:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/axios@0.21/dist/axios.min.js\"&gt;&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/@openeo/js-client@2/openeo.min.js\"&gt;&lt;/script&gt;\nThis gives you a minified version for production environments. If you’d like a better development experience, use the following code:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/axios@0.21/dist/axios.js\"&gt;&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/@openeo/js-client@2/openeo.js\"&gt;&lt;/script&gt;\nIf you are working on a Node.js application or you are using a Node.js-based build tool for web development (e.g. Webpack), you can install the client via npm by using the following command:\n\nnpm install @openeo/js-client\nAfterwards you can load the library. Depending on whether you are directly working in Node.js or are just using a Node.js build tool, the import can be different. Please inform yourself which import is suited for your project.\nThis is usually used directly in Node.js:\nconst { OpenEO } = require('@openeo/js-client');\nThis may be used in build tools such as Webpack:\nimport { OpenEO } from '@openeo/js-client';\nNow that the installation was successfully finished, we can now connect to openEO compliant back-ends. In the following chapters we quickly walk through the main features of the JavaScript client.\nIf you have trouble installing the client, feel free to create a ticket or leave an issue at the GitHub project."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#exploring-a-back-end",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#exploring-a-back-end",
    "title": "Getting started with JavaScript client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO instance of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu.\nFirst we need to establish a connection to the back-end.\nvar con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n\n\n\n\n\n\nNote\n\n\n\nThe JavaScript client uses Promises (async/await). So there are two ways to express the code above:\nPromises:\nOpenEO.connect(\"https://openeo.dataspace.copernicus.eu\").then(function(con) {\n  // Success\n}).catch(function(error) {\n  // Error\n});\nasync/await:\ntry {\n  var con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n  // Success\n} catch (error) {\n  // Error\n}\n\n\nTo simplify the code here, we use async/await in all examples and don’t catch errors. So we assume you run the code in an async function and also in a try/catch block.\nAfter establishing the connection to the back-end, it can be explored using the Connection object returned. The basic service’s metadata (capabilities) can be accessed via\nvar info = con.capabilities();\nThis allows to request a couple of different information, like API version, description, related links or the billing plans. You can print some of these information to the console as follows:\nconsole.log(\"API Version: \", info.apiVersion());\nconsole.log(\"Description: \", info.description());\n\nconsole.log(\"Billing plans:\");\ninfo.listPlans().forEach(plan =&gt; {\n  console.log(`${plan.name}: ${plan.url}`);\n});\n\nconsole.log(\"Related links:\");\ninfo.links().forEach(link =&gt; {\n  console.log(`${link.title}: ${link.href}`);\n});\n\nCollections\nCollections represent the basic data the back-end provides (e.g. Sentinel 2 collection). Collections are used as input data for job executions (more info on collections). With the following code snippet you can print all 400+ available collection names and their summary.\nconsole.log(\"Available Collections:\");\nvar response = await con.listCollections();\nresponse.collections.forEach(collection =&gt; {\n  console.log(`${collection.id}: ${collection.summary}`);\n});\nTo get detailed information about a single collection, you can pass any of the collection IDs requested earlier to describeCollection and get a full object of STAC compliant Collection metadata back. In this example we request information about the Sentinel-2 Level 1C data from Google:\nconsole.log(await con.describeCollection(\"COPERNICUS/S2\"));\nTo get the full set of metadata you should always use describeCollection.\n\n\nProcesses\nProcesses in openEO are small tasks that can be applied on (EO) data. The input of a process might be the output of another process, so that several connected processes form a new (user-defined) process itself. Therefore, a process resembles the smallest unit of task descriptions in openEO (more details on processes). With the following code snippet you can print all available process IDs and their summaries.\nconsole.log(\"Available Collections:\");\nvar response = await con.listProcesses();\nresponse.processes.forEach(process =&gt; {\n  console.log(`${process.id}: ${process.summary}`);\n});\nIn contrast to the collections, the process descriptions returned by listProcesses are complete. There’s no need to call describeProcess to get the full set of metadata. describeProcess is just a convenience function to get a single process from listProcesses. In this example we request the process specification for the apply process:\nconsole.log(await con.describeProcess(\"apply\"));\nFor a graphical overview of the openEO processes, there is an online documentation for general process descriptions and the openEO Hub for back-end specific process descriptions."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#authentication",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#authentication",
    "title": "Getting started with JavaScript client",
    "section": "Authentication",
    "text": "Authentication\nIn the code snippets above we did not need to log in since we just queried publicly available back-end information. However, to run non-trivial processing queries one has to authenticate so that permissions, resource usage, etc. can be managed properly.\nTo authenticate your account on the backend of the Copernicus Data Space Ecosystem, it is necessary for you to complete the registration process. Once registered, the OIDC (OpenID Connect)authentication method will be employed to verify your identity using an external service.\n\n\n\n\n\n\nWarning\n\n\n\nIf you have included the library using HTML script tags, then you need to include the following OIDC client before the openEO client:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/oidc-client@1/lib/oidc-client.min.js\"&gt;&lt;/script&gt;\nNo further action is required, if you have installed the client via npm.\n\n\nAs OpenID Connect authentication is a bit more complex and depends on the environment your are using it in, please refer to the JavaScript client documentation for more information.\nCalling this method opens your system web browser, with which you can authenticate yourself on the back-end authentication system. After that the website will give you the instructions to go back to the JavaScript client, where your connection has logged your account in. This means that every call that comes after that via the con variable is executed by your user account."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#creating-a-user-defined-process",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#creating-a-user-defined-process",
    "title": "Getting started with JavaScript client",
    "section": "Creating a (user-defined) process",
    "text": "Creating a (user-defined) process\nNow that we know how to discover the back-end and how to authenticate, lets continue by creating a new batch job to process some data. First we need to create a user-defined process and for that a process builder is the easiest method.\n\nvar builder = await con.buildProcess();\nWith the builder, a datacube can be initialized by selecting a collection from the back-end with the process load_collection:\nvar datacube = builder.load_collection(\n        \"SENTINEL2_L2A\",\n        {west: 3.20, south: 51.19, east: 3.26, north: 51.21},\n        [\"2022-05-01\", \"2022-05-30\"],\n        [\"B04\", \"B03\", \"B02\"]\n);\nThis results in a datacube containing the “SENTINEL2_L2A” data restricted to the given spatial extent, the given temporal extend and the given bands .\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can also filter the datacube at a later stage by using the following filter methods:\ndatacube = builder.filter_bbox(datacube, {west: 3.20, south: 51.19, east: 3.26, north: 51.21});\ndatacube = builder.filter_temporal(datacube, [\"2022-05-01\", \"2022-05-30\"]);\ndatacube = builder.filter_bands(datacube, [\"B04\", \"B03\", \"B02\"]);\nStill, it is recommended to always use the filters in load_collection to avoid loading too much data upfront.\n\n\n\nHaving the input data ready, we want to apply a process on the datacube, which returns a datacube with the process applied:\n\nvar min = function(data) { return this.min(data); };\ndatacube = builder.reduce_dimension(datacube, min, \"t\");\nThe datacube is now reduced by the time dimension named t, by taking the minimum value of the timeseries values. Now the datacube has no time dimension left.\nOther so called “reducer” processes exist, e.g. for computing maximum and mean values.\n\n\n\n\n\n\nNote\n\n\n\nEverything applied to the datacube at this point is neither executed locally on your machine nor executed on the back-end. It just defines the input data and process chain the back-end needs to apply when it sends the datacube to the back-end and executes it there. How this can be done is the topic of the next chapter.\n\n\nAfter applying all processes you want to execute, we need to tell the back-end to export the datacube, for example as GeoTiff:\n\nvar result = builder.save_result(datacube, \"GTiff\");"
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#batch-job-management",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#batch-job-management",
    "title": "Getting started with JavaScript client",
    "section": "Batch Job Management",
    "text": "Batch Job Management\nAfter you finished working on your (user-defined) process, we can now send it to the back-end and start the execution. In openEO, an execution of a (user-defined) process (here defined using the process builder) is called a (batch) job. Therefore, we need to create a job at the back-end using our datacube, giving it the title Example Title.\n\nvar job = await con.createJob(result, \"Example Title\");\nThe createJob method sends all necessary information to the back-end and creates a new job, which gets returned. After this, the job is just created, but has not started the execution at the back-end yet. It needs to be queued for processing explicitly:\n\nawait job.startJob();\nNow the execution of the job can be monitored by requesting the job status and the log files every once in a while (30 seconds in this example):\n\nlet stopFn = job.monitorJob((job, logs) =&gt; {\n  console.log(job.status);\n  logs.forEach(log =&gt; console.log(`${log.level}: ${log.message}`));\n}, 30);\nThe monitoring stops automatically once the job has finished, was canceled or errored out. But with the return value of the monitorJob function, you can also stop monitoring the job manually:\n\nstopFn();\nWhen the job is finished, calling listResults gets you the URLs to the results.\n\nvar urls = await job.listResults();\n\n\n\n\n\n\nTip\n\n\n\n\n\nThis only works if the job execution has finished. We recommend to use listResults in combination with monitorJob, for example as follows:\n\nlet stopFn = job.monitorJob(async (job, logs) =&gt; {\n  if (job.status === \"finished\") {\n    var urls = await job.listResults();\n    urls.forEach(url =&gt; console.log(`Download result from: ${url.href}`));\n  }\n});\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere’s also the method downloadResults to download the results directly. Unfortunately, you can only download files from a Node.js environment where file access to your local drive is possible. In a Browser environment, it is also an option to download the STAC Item or Collection for the results using the getResultsAsStac method and point a STAC client to it for downloading.\n\n\nNow you know the general workflow of job executions."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#full-example",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#full-example",
    "title": "Getting started with JavaScript client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the JavaScript client in a Node.js environment. Instead of batch job processing, we compute the image synchronously. Synchronous processing means the result is directly returned in the response, which usually works only for smaller amounts of data.\nHere, we want to produce a monthly RGB composite of Sentinel 1 backscatter data over the area of Vienna, Austria for three months in 2017. This can be used for classification and crop monitoring.\nIn the following code example, we use inline code comments to describe what we are doing.\n// Make the client available to the Node.js script\n// Also include the Formula library for simple math expressions\nconst { OpenEO, Formula } = require('@openeo/js-client');\n\nasync function example() {\n  // Connect to the back-end\n  var con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n  // Authenticate \n  await con.authenticateOIDC();\n  // Create a process builder\n  var builder = await con.buildProcess();\n  // We are now loading the Sentinel-1 data over the Area of Interest\n  var datacube = builder.load_collection(\n    \"SENTINEL1_GRD\",\n    {west: 16.06, south: 48.06, east: 16.65, north: 48.35},\n    [\"2017-03-01\", \"2017-06-01\"],\n    [\"VV\"]\n  );\n\n  // Since we are creating a monthly RGB composite, we need three separated time ranges (March aas R, April as G and May as G).\n  // Therefore, we split the datacube into three datacubes using a temporal filter.\n  var march = builder.filter_temporal(datacube, [\"2017-03-01\", \"2017-04-01\"]);\n  var april = builder.filter_temporal(datacube, [\"2017-04-01\", \"2017-05-01\"]);\n  var may = builder.filter_temporal(datacube, [\"2017-05-01\", \"2017-06-01\"]);\n\n  // We aggregate the timeseries values into a single image by reducing the time dimension using a mean reducer.\n  var mean = function(data) {\n    return this.mean(data);\n  };\n  march = builder.reduce_dimension(march, mean, \"t\");\n  april = builder.reduce_dimension(april, mean, \"t\");\n  may = builder.reduce_dimension(may, mean, \"t\");\n\n  // Now the three images will be combined into the temporal composite.\n  // We rename the bands to R, G and B as otherwise the bands are overlapping and the merge process would fail.\n  march = builder.rename_labels(march, \"bands\", [\"R\"], [\"VV\"]);\n  april = builder.rename_labels(april, \"bands\", [\"G\"], [\"VV\"]);\n  may = builder.rename_labels(may, \"bands\", [\"B\"], [\"VV\"]);\n\n  datacube = builder.merge_cubes(march, april);\n  datacube = builder.merge_cubes(datacube, may);\n\n  // To make the values match the RGB values from 0 to 255 in a PNG file, we need to scale them.\n  // We can simplify expressing math formulas using the openEO Formula parser.\n  datacube = builder.apply(datacube, new Formula(\"linear_scale_range(x, -20, -5, 0, 255)\"));\n\n  // Finally, save the result as PNG file.\n  // In the options we specify which band should be used for \"red\", \"green\" and \"blue\" color.\n  datacube = builder.save_result(datacube, \"PNG\", {\n    red: \"R\",\n    green: \"G\",\n    blue: \"B\"\n  });\n\n  // Now send the processing instructions to the back-end for (synchronous) execution and save the file as result.png\n  await con.downloadResult(datacube, \"../_images/result.png\");\n}\n\n// Run the example, write errors to the console.\nexample().catch(error =&gt; console.error(error));\nNow the resulting PNG file of the RGB backscatter composite is stored as result.png in the node.JS working directory and should look as follows:"
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#user-defined-functions",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#user-defined-functions",
    "title": "Getting started with JavaScript client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function. Unfortunately, you can only create Python and R functions at the moment. Therefore, this guide doesn’t get into detail. For more information check out the Python or R tutorials on UDFs."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#useful-links",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#useful-links",
    "title": "Getting started with JavaScript client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO JavaScript Client Library:\n\nExamples\nDocumentation\nRepository"
  },
  {
    "objectID": "APIs/SentinelHub.html",
    "href": "APIs/SentinelHub.html",
    "title": "Sentinel Hub",
    "section": "",
    "text": "Sentinel Hub\nSentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service, capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use APIs to retrieve satellite data over their AOI and specific time range from full archives in a matter of seconds."
  },
  {
    "objectID": "APIs/STAC.html",
    "href": "APIs/STAC.html",
    "title": "STAC product catalog",
    "section": "",
    "text": "STAC product catalog\nSTAC API endpoint: https://catalogue.dataspace.copernicus.eu/stac/\nSTAC (Spatio-Temporal Asset Catalog) is a relatively new web service specification for catalogs that is increasingly used and supported.\nThe version exposed in the Copernicus Dataspace is still subject to change as the quality of STAC metadata is still improving. Nevertheless, it already supports basic product search.\nWe are aware of issues with using the current version with generic STAC libraries. The data model in the Copernicus Dataspace Ecosystem is still evolving to comply fully with all standardized properties. Our dedicated teams are actively working on its development to ensure a seamless experience for all our customers. However, as the version exposed in the Copernicus Dataspace is still subject to change as the quality of STAC metadata is still improving, we kindly ask for your patience and understanding."
  },
  {
    "objectID": "APIs/On-Demand Production API.html",
    "href": "APIs/On-Demand Production API.html",
    "title": "Documentation",
    "section": "",
    "text": "On-demand processing capability for CARD-BS, CARD-COH6/12 is available on the Copernicus Data Space Ecosystem. This service is offered free to the use via a limited pool of resources, shared across all users, which can be used for processing the data free of charge. This is suitable for users who need to process smaller batches of products. There is no guarantee that processing will be completed in certain time.  For commercial use the price list is available from the Creodias portal https://creodias.eu/billing-models.The service is available via an On Demand Processing API allows the users to interact with the service to issue and control the orders. It provides functionalities like creation, update, cancellation, pausing and monitoring of orders. This allows the users to have a better control over the workflow execution process."
  },
  {
    "objectID": "APIs/On-Demand Production API.html#introduction",
    "href": "APIs/On-Demand Production API.html#introduction",
    "title": "Documentation",
    "section": "",
    "text": "On-demand processing capability for CARD-BS, CARD-COH6/12 is available on the Copernicus Data Space Ecosystem. This service is offered free to the use via a limited pool of resources, shared across all users, which can be used for processing the data free of charge. This is suitable for users who need to process smaller batches of products. There is no guarantee that processing will be completed in certain time.  For commercial use the price list is available from the Creodias portal https://creodias.eu/billing-models.The service is available via an On Demand Processing API allows the users to interact with the service to issue and control the orders. It provides functionalities like creation, update, cancellation, pausing and monitoring of orders. This allows the users to have a better control over the workflow execution process."
  },
  {
    "objectID": "APIs/On-Demand Production API.html#ondemand-processing-api-with-odata-interface",
    "href": "APIs/On-Demand Production API.html#ondemand-processing-api-with-odata-interface",
    "title": "Documentation",
    "section": "OnDemand Processing API with OData interface",
    "text": "OnDemand Processing API with OData interface\nThe OnDemand Processing API allows the users to interact with the service to issue and control the orders. It provides functionalities like creation, update, cancellation, pausing and monitoring of orders. This allows the users to have a better control over the workflow execution process."
  },
  {
    "objectID": "APIs/On-Demand Production API.html#general-information",
    "href": "APIs/On-Demand Production API.html#general-information",
    "title": "Documentation",
    "section": "General information",
    "text": "General information\nThis documentation provides an overview of the OnDemand Processing (ODP) API, which is based on the Open Data Protocol (OData) standard. The ODP API provides a RESTful interface for accessing data and metadata from the Copernicus data catalogue. Access to the API is limited by the Authentication service. Quotas are assigned according to the user typology and include limits on number of concurrent orders and available processing workflows. The API allows discovery of all available workflows which can be run in the CDSE platform, indicating which data types can be processed, what are the available parameters and output modes.\n\nAPI Endpoint\nThe ODP API endpoint is https://odp.dataspace.copernicus.eu/odata/v1. The endpoint supports both HTTP and HTTPS protocols.\nOpenAPI documentation is located at https://odp.dataspace.copernicus.eu/odata/docs\n\n\nAPI Operations\nThe ODP API supports the following operations: - GET: This operation is used to retrieve data and metadata from the ODP. The GET operation supports various query options to filter, order, and limit the data retrieved. - POST: This operation is used to create new entities in the ODP. The POST operation requires a payload in JSON format that specifies the properties of the new entity. - PATCH: This operation is used to update existing entities in the ODP. The PATCH operation requires a payload in JSON format that specifies the properties of the entity to update. - DELETE: This operation is used to delete existing entities from the ODP. The DELETE operation requires the URL of the entity to delete. - ### API Resources\nThe ODP API provides access to the following resources: - Workflow: predefined processor which creates a single output product or series of products based on the input parameters provided by the user. Typical inputs are name of the source product and parameters specific to the processing chain. - Production Order: request for production using a Workflow chosen by the user. - Batch Order: request for production of multiple products using a chosen Workflow. - Order Item: single processing job within and Production Order or Batch Order.\n\n\nAuthentication\nTo access the ODP API you need an authorization token as only authorized users are allowed to interact with the processing service. To get the token you can use the following script:\nexport KEYCLOAK_TOKEN=$(curl -d 'client_id=cdse-public' \\\n-d 'username=&lt;LOGIN&gt;' \\\n-d 'password=&lt;PASSWORD&gt;' \\\n-d 'grant_type=password' \\\n'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | \\\npython -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}')\nOnce you have your token, you can execute request to the API including the token in the request header. For example to list available Workflows you can use the following command:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ 'https://odp.dataspace.copernicus.eu/odata/v1/Workflows'\nMore information on the tokens and authentication can be found here: https://documentation.dataspace.copernicus.eu/APIs/OData.html#product-download"
  },
  {
    "objectID": "APIs/On-Demand Production API.html#querying-the-api",
    "href": "APIs/On-Demand Production API.html#querying-the-api",
    "title": "Documentation",
    "section": "Querying the API",
    "text": "Querying the API\n\nWorkflows\n\nListing available Workflows\nTo list all processing Workflows available to the user:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/Workflows\nTo search for specific Workflows you can use filters on the attributes. To find workflow named “coh”:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/Workflows?$filter=Name eq 'coh'\nIn a similar way to find all Workflows suitable for processing Sentinel-1 SLC products:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/Workflows?\n$filter=contains(InputProductType,'SL````C')\nDetails of the Workflow in the response list the parameters which are needed to create new Production Order:\n        {\n            \"Id\": \"47\",\n            \"Name\": \"card_coh12_public\",\n            \"DisplayName\": \"Sentinel-1: Coherence (12 days)\",\n            \"Documentation\": null,\n            \"Description\": \"The Sentinel-1 CARD COH12 (Copernicus Analysis Ready\n             Data Coherence) processor generates a Sentinel-1 Level 2 product describing \n             the coherence of a pair of images - 12 days apart. \n             Concurrently, a terrain-correction (using DEM) is performed. This processor \n             provided by the Joint Research Centre is based on a GPT graph that can be run \n             with ESA SNAP.\",\n            \"InputProductType\": \"SLC\",\n            \"InputProductTypes\": [\n                \"SLC\",\n                \"S1_SLC__1S\",\n                \"S2_SLC__1S\",\n                \"S3_SLC__1S\",\n                \"S4_SLC__1S\",\n                \"S5_SLC__1S\",\n                \"S6_SLC__1S\",\n                \"IW_SLC__1S\",\n                \"EW_SLC__1S\",\n                \"WV_SLC__1S\"\n            ],\n            \"OutputProductType\": \"CARD-COH12\",\n            \"WorkflowVersion\": \"3.1.0\"\n        }\n\n\n\nProduction Orders\n\nCreate a new Production Order\nTo submit a new processing job you need to use the POST method and send the parameters as a JSON message according to the requirements of a specific Workflows:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder/OData.CSC.Order \\\n-d '&lt;json_message&gt;'\nProduction orders accept the following general parameters: - WorkflowName: the identifier of the workflow – “Name” attribute in the /Workflows response - InputProductReference: information about the input data to be used by the processor - Reference: identifier of a single input product or multiple products (example – mosaicking processors) - ContentDate: time period which should be used by the Workflows (example - time-series based processors) - WorkflowOptions: parameters specific to the Workflows (example – DEM version, cloud coverage) - Priority: priority of the order in the users job queue. Orders with higher priority will be processed first - NotificationEndpoint: (not used) URL of the endpoint which should receive the information once the order is completed (done or failed) - Name: non-unique name for the order to help identify the orders The structure of the JSON message:\n{\n  \"WorkflowName\": \"string\",\n  \"InputProductReference\": {\n    \"Reference\": \"string\",\n    \"ContentDate\": {\n      \"Start\": \"YYYY-MM-DDTHH:mm:ss.SSSZ\",\n      \"End\": \"YYYY-MM-DDTHH:mm:ss.SSSZ\"\n    }\n  },\n  \"WorkflowOptions\": [\n    {\n      \"Name\": \"string\",\n      \"Value\": \"string\"\n    }\n  ],\n  \"Priority\": 0,\n  \"NotificationEndpoint\": \"string\",\n  \"Name\": \"string\"\n}\nExample: to submit an order for the Sentinel-1 CARD Backscatter product:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder/OData.CSC.Order \\\n-d '{ \\\n  \"WorkflowName\": \"card_bs\",\n  \"InputProductReference\": {\n    \"Reference\": \"S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\"\n  },\n  \"Priority\": 1,\n  \"Name\": \"card_bs_order_1\"\n}'\nSample response after successful submission of the order:\n{\n  \"@odata.context\": \"$metadata#OData.CSC.Order\",\n  \"value\": {\n    \"Id\": \"9999999\",\n    \"Status\": \"queued\",\n    \"StatusMessage\": \"queued\",\n    \"SubmissionDate\": \"2023-04-05T10:03:25.474Z\",\n    \"Name\": \"S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\",\n    \"EstimatedDate\": \"2023-04-05T10:33:16.161Z\",\n    \"InputProductReference\": {\n      \"Reference\": S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\",\n      \"ContentDate\": null\n    },\n    \"WorkflowOptions\": [],\n    \"WorkflowName\": \"card_bs\",\n    \"WorkflowId\": null,\n    \"Priority\": 1\n  }\n}\n\n\nCheck list of Production Orders\nTo list all Production Orders requested by the user:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\nhttps://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders\nWhen looking for completed orders for a specific processor:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https:// odp.dataspace.copernicus.eu/odata/v1/ProductionOrders?\n$filter=WorkflowName eq 'coh' and Status eq 'completed'\"\n\n\nCheck the status of a single Production Order\nTo check details of the single order using the order Id:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders(&lt;order_id&gt;)'\n\n\nCancel a Production Order\nTo cancel an existing order:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/\nOData.CSC.Cancel'\nThe orders which are in the queue and not yet processed will be removed instantly. For the orders in processing, the Order Items (single item within a Production Order) being processed will complete but the remaining part of the Order will be canceled. #### Display details of the result The order generates a new product which can be downloaded from the public repository or private storage. To check the details of the result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/Product\"\n\n\nDownload the result\nOnce the order is successfully processed the status changes to completed and the result is ready for download. The user may choose to instruct the service to put the results in a specified location (mandatory if custom parameters have been passed to the Workflow), and standard results (for Workflows like CARD-BS or CARD-COH12) are stored in the CDSE public repository and can be retrieved through the API. To download the result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/Product/$value' \\\n-o result.zip\n\n\n\nBatch Orders\n\nCreate a new Batch Order\nIn a way similar to single Production Order you can request processing of multiple input products as a Batch Order. The Batch Order will run a selected Workflow with the same parameters for all inputs and output the results to the same location. Using Batch Orders makes it easier to process time series or large AOIs. Batch Order endpoint uses the same mechanism as described for the Production Order:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/BatchOrder/OData.CSC.Order \\\n-d '&lt;json_message&gt;'\nBatch Orders accept the following general parameters: - WorkflowName: the identifier of the workflow – “Name” attribute in the /Workflows response - IdentifierList: information about the input data to be used by the processor - identifiers of products - WorkflowOptions: parameters specific to the Workflows (example – DEM version, cloud coverage) - Priority: priority of the order in the users job queue. Orders with higher priority will be processed first - Callback: (not used) URL of the endpoint which should receive the information once the order is completed (done or failed) - Name: non-unique name for the order to help identify the orders - BatchSize: maximum number of items in the batch - BatchVolume: maximum size of output data The structure of the JSON message:\n{\n  \"Name\": \"string\",\n  \"Priority\": 0,\n  \"WorkflowName\": \"string\",\n  \"Callback\": \"string\",\n  \"WorkflowOptions\": [\n    {\n      \"Name\": \"string\",\n      \"Value\": \"string\"\n    }\n  ],\n  \"IdentifierList\": [\n    \"string\"\n  ],\n  \"BatchSize\": 0,\n  \"BatchVolume\": 0\n}\n\n\nCheck list of Batch Orders\nTo list all Production Orders requested by the user:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/BatchOrder\nWhen looking for batch orders for a specific processor:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https:// odp.dataspace.copernicus.eu/odata/v1/BatchOrder?$filter=WorkflowName eq 'coh'\n\n\nCheck the status of a single Batch Order\nTo check details of the single order using the order Id:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)'\n\n\nList products generated in a Batch Order\nWhen the batch order is processed, for each input product an output is generated. To list the output of a batch:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)/Products'\n\n\nDisplay details of the results\nEach item in the batch is an individual Production Order. To check the details of the single result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)/Product(&lt;order_id&gt;)\""
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html",
    "href": "APIs/SentinelHub/Process/Crs.html",
    "title": "CRS support",
    "section": "",
    "text": "The list of coordinate reference systems supported by Sentinel Hub API is provided below. The coordinate reference system must be set with an URL starting with http://www.opengis.net/def/crs/ and it must be set under the field input.bounds.properties.crs, e.g. request in WGS 84 reference system, defined with the URL http://www.opengis.net/def/crs/EPSG/0/4326:"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#wgs-84",
    "href": "APIs/SentinelHub/Process/Crs.html#wgs-84",
    "title": "CRS support",
    "section": "WGS 84:",
    "text": "WGS 84:\n\nhttp://www.opengis.net/def/crs/OGC/1.3/CRS84\nhttp://www.opengis.net/def/crs/EPSG/0/4326"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#wgs-84--pseudo-mercator",
    "href": "APIs/SentinelHub/Process/Crs.html#wgs-84--pseudo-mercator",
    "title": "CRS support",
    "section": "WGS 84 / Pseudo-Mercator:",
    "text": "WGS 84 / Pseudo-Mercator:\n\nhttp://www.opengis.net/def/crs/EPSG/0/3857"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#utm-northern-hemisphere",
    "href": "APIs/SentinelHub/Process/Crs.html#utm-northern-hemisphere",
    "title": "CRS support",
    "section": "UTM northern hemisphere:",
    "text": "UTM northern hemisphere:\n\nhttp://www.opengis.net/def/crs/EPSG/0/32601\nhttp://www.opengis.net/def/crs/EPSG/0/32602\n...\nhttp://www.opengis.net/def/crs/EPSG/0/32660\n\nThe last two digits of EPSG codes above represent the number of corresponding UTM zone in northern hemisphere, e.g. use http://www.opengis.net/def/crs/EPSG/0/32612 for UTM zone 12N."
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#utm-southern-hemisphere",
    "href": "APIs/SentinelHub/Process/Crs.html#utm-southern-hemisphere",
    "title": "CRS support",
    "section": "UTM southern hemisphere:",
    "text": "UTM southern hemisphere:\n\nhttp://www.opengis.net/def/crs/EPSG/0/32701\nhttp://www.opengis.net/def/crs/EPSG/0/32702\n...\nhttp://www.opengis.net/def/crs/EPSG/0/32760\n\nThe last two digits of EPSG codes above represent the number of corresponding UTM zone in southern hemisphere, e.g. use http://www.opengis.net/def/crs/EPSG/0/32712 for UTM zone 12S."
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#others",
    "href": "APIs/SentinelHub/Process/Crs.html#others",
    "title": "CRS support",
    "section": "Others:",
    "text": "Others:\n\nhttp://www.opengis.net/def/crs/EPSG/0/2154\nhttp://www.opengis.net/def/crs/EPSG/0/2180\nhttp://www.opengis.net/def/crs/EPSG/0/2193\nhttp://www.opengis.net/def/crs/EPSG/0/3003\nhttp://www.opengis.net/def/crs/EPSG/0/3004\nhttp://www.opengis.net/def/crs/EPSG/0/3031\nhttp://www.opengis.net/def/crs/EPSG/0/3035\nhttp://www.opengis.net/def/crs/EPSG/0/3346\nhttp://www.opengis.net/def/crs/EPSG/0/3413\nhttp://www.opengis.net/def/crs/EPSG/0/3416\nhttp://www.opengis.net/def/crs/EPSG/0/3765\nhttp://www.opengis.net/def/crs/EPSG/0/3794\nhttp://www.opengis.net/def/crs/EPSG/0/3844\nhttp://www.opengis.net/def/crs/EPSG/0/3912\nhttp://www.opengis.net/def/crs/EPSG/0/3995\nhttp://www.opengis.net/def/crs/EPSG/0/4026\nhttp://www.opengis.net/def/crs/EPSG/0/5514\nhttp://www.opengis.net/def/crs/EPSG/0/28992"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S2L2A.html",
    "href": "APIs/SentinelHub/Process/Examples/S2L2A.html",
    "title": "Examples for S2L2A",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 100,\n        \"resy\": 100,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTIff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue Color, cloudy pixels masked out\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"SCL\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if ([8, 9, 10].includes(sample.SCL)) {\n    return [1, 0, 0]\n  } else {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-11T00:00:00Z\",\n                        \"to\": \"2018-11-18T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    mosaicking: Mosaicking.ORBIT,\n    output: { id: \"default\", bands: 3 },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.orbits }\n}\n\nfunction evaluatePixel(samples) {\n  return [2.5 * samples[0].B04, 2.5 * samples[0].B03, 2.5 * samples[0].B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ]\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-27T00:00:00Z\",\n                        \"to\": \"2018-12-27T23:59:59Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 200,\n        \"height\": 100,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nTrue color multi-part-reponse (different formats and SampleType)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B03\", \"B02\"],\n        units: \"REFLECTANCE\", // default units\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 3,\n        sampleType: \"AUTO\", // default  - scales the output values from input values [0,1] to [0,255].\n      },\n      {\n        id: \"true_color_8bit\",\n        bands: 3,\n        sampleType: \"UINT8\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_16bit\",\n        bands: 3,\n        sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_32float\",\n        bands: 3,\n        sampleType: \"FLOAT32\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return {\n    // output band values are scaled from [0,1] to [0,255]. Multiply by 2.5 to increase brightness\n    default: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n\n    // Multiply input reflectance values by 2.5 to increase brighness and by 255 to return the band values clamped to [0, 255] unsigned 8 bit range.\n    true_color_8bit: [\n      2.5 * sample.B04 * 255,\n      2.5 * sample.B03 * 255,\n      2.5 * sample.B02 * 255,\n    ],\n\n    // Multiply input reflectance values by 2.5 to increase brightness and by 65535 to return the band values clamped to [0, 65535] unsigned 16 bit range.\n    true_color_16bit: [\n      2.5 * sample.B04 * 65535,\n      2.5 * sample.B03 * 65535,\n      2.5 * sample.B02 * 65535,\n    ],\n\n    // Returns band reflectance.\n    true_color_32float: [sample.B04, sample.B03, sample.B02],\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                12.206251,\n                41.627351,\n                12.594042,\n                41.856879,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-06-01T00:00:00Z\",\n                        \"to\": \"2018-08-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/jpeg\"},\n            },\n            {\n                \"identifier\": \"true_color_8bit\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"true_color_16bit\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"true_color_32float\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) return [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) return [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) return [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) return [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) return [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) return [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) return [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) return [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) return [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) return [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) return [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) return [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) return [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) return [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) return [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) return [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) return [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) return [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) return [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) return [0.06, 0.33, 0.04]\n  else return [0, 0.27, 0]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 80,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nExact NDVI values using a floating point GeoTIFF\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  return [ndvi]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI values as INT16 raster\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.INT16, //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  // Return NDVI multiplied by 10000 as integers to save processing units. To obtain NDVI values, simply divide the resulting pixel values by 10000.\n  return [ndvi * 10000]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: SampleType.FLOAT32,\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: SampleType.AUTO,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) image = [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) image = [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) image = [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) image = [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) image = [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) image = [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) image = [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) image = [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) image = [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) image = [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) image = [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) image = [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) image = [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) image = [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) image = [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) image = [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) image = [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) image = [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) image = [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) image = [0.06, 0.33, 0.04]\n  else image = [0, 0.27, 0]\n\n  return {\n    default: [ndvi],\n    ndvi_image: image,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S2L2A raw bands, original data (no harmonization)\nLearn about harmonization here.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B8A\",\n          \"B09\",\n          \"B11\",\n          \"B12\",\n        ],\n        units: \"DN\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 12,\n      sampleType: SampleType.UINT16,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [\n    sample.B01,\n    sample.B02,\n    sample.B03,\n    sample.B04,\n    sample.B05,\n    sample.B06,\n    sample.B07,\n    sample.B08,\n    sample.B8A,\n    sample.B09,\n    sample.B11,\n    sample.B12,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"false\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nOther S2L2A specific data (Aerosol Optical Thickness, Scene Classification, Snow and Cloud probabilities, Sun and View angles)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"AOT\",\n          \"SCL\",\n          \"SNW\",\n          \"CLD\",\n          \"sunAzimuthAngles\",\n          \"sunZenithAngles\",\n          \"viewAzimuthMean\",\n          \"viewZenithMean\",\n        ],\n      },\n    ],\n    output: [\n      { id: \"TrueColor\", bands: 3, sampleType: SampleType.FLOAT32 },\n      { id: \"AOT\", bands: 1, sampleType: SampleType.UINT16 },\n      { id: \"SCL\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"SNW\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"CLD\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"SAA\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"SZA\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"VAM\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"VZM\", bands: 1, sampleType: SampleType.FLOAT32 },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  var truecolor = [sample.B04, sample.B03, sample.B02]\n  var aot = [sample.AOT]\n  var scl = [sample.SCL]\n  var snw = [sample.SNW]\n  var cld = [sample.CLD]\n  var saa = [sample.sunAzimuthAngles]\n  var sza = [sample.sunZenithAngles]\n  var vam = [sample.viewAzimuthMean]\n  var vzm = [sample.viewZenithMean]\n\n  return {\n    TrueColor: truecolor,\n    AOT: aot,\n    SCL: scl,\n    SNW: snw,\n    CLD: cld,\n    SAA: saa,\n    SZA: sza,\n    VAM: vam,\n    VZM: vzm,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-01T00:00:00Z\",\n                        \"to\": \"2019-03-22T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"TrueColor\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"AOT\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SCL\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SNW\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"CLD\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SAA\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SZA\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"VAM\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"VZM\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S5PL2.html",
    "href": "APIs/SentinelHub/Process/Examples/S5PL2.html",
    "title": "Examples for S5PL2",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCarbon Monoxide, CO (RGB visualization and transparency with dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CO\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 0.1\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CO)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNitrogen Dioxide, NO2 (NRTI timeliness, RGB visualization and transparency with dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"NO2\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 0.0001\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.NO2)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    },\n                    \"timeliness\": \"NRTI\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFormaldehyde, HCHO (float32 format, specific value for no data, GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"HCHO\", \"dataMask\"],\n    output: { bands: 1, sampleType: \"FLOAT32\" },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1) {\n    return [sample.HCHO]\n  } else {\n    return [-9999]\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nOzone, O3 (RPRO timeliness, streched values and dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"O3\", \"dataMask\"],\n    output: { bands: 2 },\n  }\n}\n\nfunction evaluatePixel(sample, scene) {\n  var maxVal = 0.36\n  return [sample.O3 / maxVal, sample.dataMask]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-22T00:00:00Z\",\n                        \"to\": \"2019-04-23T00:00:00Z\",\n                    },\n                    \"timeliness\": \"RPRO\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nSulfur Dioxide, SO2 (minQa=20 applied, streched values)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"SO2\", \"dataMask\"],\n    output: { bands: 2 },\n  }\n}\n\nfunction evaluatePixel(sample, scene) {\n  var maxVal = 0.01\n  return [sample.SO2 / maxVal, sample.dataMask]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"minQa\": 20},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nMethane, CH4\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CH4\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 1600.0\nconst maxVal = 2000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CH4)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                10,\n                20,\n                15,\n                25,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nAER AI 340 and 380\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"AER_AI_340_380\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = -1.0\nconst maxVal = 5.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.AER_AI_340_380)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nAER AI 354 and 388\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"AER_AI_354_388\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = -1.0\nconst maxVal = 5.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.AER_AI_354_388)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud base height\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_BASE_HEIGHT\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0\nconst maxVal = 20000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_BASE_HEIGHT)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud base pressure\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_BASE_PRESSURE\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 10000.0\nconst maxVal = 110000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_BASE_PRESSURE)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nEffective radiometric cloud fraction\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_FRACTION\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 1.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_FRACTION)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud optical thickness\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_OPTICAL_THICKNESS\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 250.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_OPTICAL_THICKNESS)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud top height\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_TOP_HEIGHT\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 20000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_TOP_HEIGHT)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud top pressure\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_TOP_PRESSURE\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 10000.0\nconst maxVal = 110000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_TOP_PRESSURE)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S3OLCI.html",
    "href": "APIs/SentinelHub/Process/Examples/S3OLCI.html",
    "title": "Examples for S3OLCI",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the data from 0-255.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    },\n                    \"processing\": {\"upsampling\": \"BILINEAR\"},\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 150,\n        \"resy\": 150,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTiff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B06\", \"B08\"],\n        units: \"REFLECTANCE\", // default value\n      },\n    ],\n    output: {\n      bands: 3,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [10000 * sample.B08, 10000 * sample.B06, 10000 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B06\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    mosaicking: Mosaicking.SIMPLE,\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.tiles }\n}\n\nfunction evaluatePixel(samples) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [10000 * samples.B08, 10000 * samples.B06, 10000 * samples.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nOTCI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B10\", \"B11\", \"B12\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\n// Create a new visualiser to represent data\nvar cm = new ColorMapVisualizer([\n  [0, [0, 0, 0.5]],\n  [1, [0, 0.3, 0.8]],\n  [1.8, [1, 0.2, 0.2]],\n  [2.5, [1, 0.9, 0]],\n  [4, [0, 0.8, 0.1]],\n  [4.5, [0, 0.6, 0.2]],\n  [5, [1, 1, 1]],\n])\n\nfunction evaluatePixel(sample) {\n  let OTCI = (sample.B12 - sample.B11) / (sample.B11 - sample.B10)\n  return cm.process(OTCI)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                        [\n                            8.6956787109375,\n                            42.370720143531976,\n                        ],\n                        [\n                            8.7890625,\n                            42.238685347536496,\n                        ],\n                        [\n                            8.60504150390625,\n                            42.20614200929954,\n                        ],\n                        [\n                            8.70391845703125,\n                            42.15322331239858,\n                        ],\n                        [\n                            8.83575439453125,\n                            41.97991089691236,\n                        ],\n                        [\n                            8.81378173828125,\n                            41.797935707842974,\n                        ],\n                        [\n                            8.9208984375,\n                            41.777456667491066,\n                        ],\n                        [\n                            8.94012451171875,\n                            41.68316883525891,\n                        ],\n                        [\n                            9.0472412109375,\n                            41.52297326747377,\n                        ],\n                        [\n                            9.35760498046875,\n                            41.70777900286713,\n                        ],\n                        [\n                            9.33013916015625,\n                            42.06764572379527,\n                        ],\n                        [\n                            9.48394775390625,\n                            42.261049162113856,\n                        ],\n                        [\n                            9.47021484375,\n                            42.51462626746592,\n                        ],\n                        [\n                            9.33837890625,\n                            42.62385465855651,\n                        ],\n                        [\n                            9.1900634765625,\n                            42.6844544397102,\n                        ],\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 90,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nOTCI image and value (multi-part response png and GeoTIFF containing floats)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B10\", \"B11\", \"B12\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: \"FLOAT32\",\n      },\n      {\n        id: \"otci_image\",\n        bands: 3,\n        sampleType: \"AUTO\",\n      },\n    ],\n  }\n}\n\n// Create a new visualiser to represent data\nvar cm = new ColorMapVisualizer([\n  [0, [0, 0, 0.5]],\n  [1, [0, 0.3, 0.8]],\n  [1.8, [1, 0.2, 0.2]],\n  [2.5, [1, 0.9, 0]],\n  [4, [0, 0.8, 0.1]],\n  [4.5, [0, 0.6, 0.2]],\n  [5, [1, 1, 1]],\n])\n\nfunction evaluatePixel(sample) {\n  let OTCI = (sample.B12 - sample.B11) / (sample.B11 - sample.B10)\n  return {\n    default: [OTCI],\n    otci_image: cm.process(OTCI),\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                        [\n                            8.6956787109375,\n                            42.370720143531976,\n                        ],\n                        [\n                            8.7890625,\n                            42.238685347536496,\n                        ],\n                        [\n                            8.60504150390625,\n                            42.20614200929954,\n                        ],\n                        [\n                            8.70391845703125,\n                            42.15322331239858,\n                        ],\n                        [\n                            8.83575439453125,\n                            41.97991089691236,\n                        ],\n                        [\n                            8.81378173828125,\n                            41.797935707842974,\n                        ],\n                        [\n                            8.9208984375,\n                            41.777456667491066,\n                        ],\n                        [\n                            8.94012451171875,\n                            41.68316883525891,\n                        ],\n                        [\n                            9.0472412109375,\n                            41.52297326747377,\n                        ],\n                        [\n                            9.35760498046875,\n                            41.70777900286713,\n                        ],\n                        [\n                            9.33013916015625,\n                            42.06764572379527,\n                        ],\n                        [\n                            9.48394775390625,\n                            42.261049162113856,\n                        ],\n                        [\n                            9.47021484375,\n                            42.51462626746592,\n                        ],\n                        [\n                            9.33837890625,\n                            42.62385465855651,\n                        ],\n                        [\n                            9.1900634765625,\n                            42.6844544397102,\n                        ],\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"otci_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S3OLCI reflectance bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B09\",\n          \"B10\",\n          \"B11\",\n          \"B12\",\n          \"B13\",\n          \"B14\",\n          \"B15\",\n          \"B16\",\n          \"B17\",\n          \"B18\",\n          \"B19\",\n          \"B20\",\n          \"B21\",\n        ],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      bands: 21,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [\n    10000 * sample.B01,\n    10000 * sample.B02,\n    10000 * sample.B03,\n    10000 * sample.B04,\n    10000 * sample.B05,\n    10000 * sample.B06,\n    10000 * sample.B07,\n    10000 * sample.B08,\n    10000 * sample.B09,\n    10000 * sample.B10,\n    10000 * sample.B11,\n    10000 * sample.B12,\n    10000 * sample.B13,\n    10000 * sample.B14,\n    10000 * sample.B15,\n    10000 * sample.B16,\n    10000 * sample.B17,\n    10000 * sample.B18,\n    10000 * sample.B19,\n    10000 * sample.B20,\n    10000 * sample.B21,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 300,\n        \"resy\": 300,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})"
  },
  {
    "objectID": "APIs/SentinelHub/Process/DataFusion.html",
    "href": "APIs/SentinelHub/Process/DataFusion.html",
    "title": "Data Fusion",
    "section": "",
    "text": "Sentinel Hub (SH) allows you to combine the data from various data sources in the same request. To use this functionality you need to prepare a request with several data sources as explained below. Data fusion can be used for any data available in Sentinel Hub including PlanetScope, Pleiades, SPOT (TPDI) and your own data (BYOC) and with all SH data-processing APIs (Process, Statistical, Batch, etc).\nAll SH endpoint locations support data fusion of collections hosted at that endpoint. However, only the Processing API endpoint sh.dataspace.copernicus.eu/api/v1/process also allows combining collections hosted at different SH endpoints, such as this example.\nWe invite you to read our Data Fusion blog post, where you will find 6 interesting use cases and a short guide on how to use data fusion in Sentinel Hub."
  },
  {
    "objectID": "APIs/SentinelHub/Process/DataFusion.html#preparing-a-data-fusion-request",
    "href": "APIs/SentinelHub/Process/DataFusion.html#preparing-a-data-fusion-request",
    "title": "Data Fusion",
    "section": "Preparing a Data Fusion Request",
    "text": "Preparing a Data Fusion Request\nPreparing a data fusion request is very similar to preparing any process API request that uses a single data source. Thus, only the parts which differ when performing data fusion requests are described below.\n\nRequest Body\nIn the body of the request, more specifically in the input.data array, you need to add more than one data object. For each of these objects you can optionally specify the property:\n\nid (optional) - a string of your choosing. It is used as an identifier for this input so that it can be referred to in the evalscript. It is not mandatory to define it but we recommend to do so, see examples below. Note that the type (e.g., \"sentinel-2-l1c\") is insufficient as an identifier because you may use multiple inputs from the same data collection.\n\nAn example of the input.data array with two elements:\n{\n  \"input\": {\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l1c\",\n        \"id\": \"l1c\",\n        \"dataFilter\": {\n          \"timeRange\": {\n            \"from\": \"2018-10-01T00:00:00Z\",\n            \"to\": \"2018-11-01T00:00:00Z\"\n          },\n          \"mosaickingOrder\": \"leastRecent\"\n        }\n      },\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"id\": \"l2a\",\n        \"dataFilter\": {\n          \"timeRange\": {\n            \"from\": \"2018-10-01T00:00:00Z\",\n            \"to\": \"2018-11-01T00:00:00Z\"\n          },\n          \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  }\n}\nAs you can see in the example above all data collection specific options are still available.\n\n\nEvalscript\n\nSetup\nIn the evalscript, under the input array in the setup function, specify all input collections. Optionally, match the id from the input.data object of the request body to the datasource parameter of each input collection. This ensures that the correct collection will be used for input bands. For example:\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n        {datasource: \"l2a\", bands: [\"SCL\"], units: \"DN\"},\n        {datasource: \"l1c\", bands: [\"B02\", \"B03\", \"B04\"], units: \"REFLECTANCE\"}\n    ],\n    output: [\n      {bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\nSince the datasource parameter is optional, in case you choose to omit it, the order of the input objects becomes relevant and must be the same as in the request body.\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {bands: [\"B02\", \"B03\", \"B04\"], units: \"REFLECTANCE\"}, // sentinel-2-l1c\n      {bands: [\"SCL\"], units: \"DN\"} // sentinel-2-l2a\n    ],\n    output: [\n      {bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\nSpecifying mosaicking for each input is also possible. Simply add the mosaicking parameter to each input object. This overrides the global mosaicking parameter which you typically use outside the input object. Combinations of both are therefore possible, and when present, the value within the input object is used. The default remains SIMPLE. In the example below, the global default SIMPLE mosaicking value is never used as ORBIT is specified for all inputs.\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {bands: [\"B02\", \"B03\", \"B04\"], units: \"REFLECTANCE\", mosaicking: \"ORBIT\"}, // sentinel-2-l1c\n      {bands: [\"SCL\"], units: \"DN\", mosaicking: \"ORBIT\"} // sentinel-2-l2a\n    ],\n    output: [\n      {bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\n\n\nData Access\nData from each collection can be accessed inside the evaluatePixel function, however as now multiple inputs are accessible the syntax is slightly different to the single data collection case. Assuming the evaluatePixel parameter is called samples, this object is always a key-value pair (dictionary). Obtain data for each collection in one of two ways.\nIf you are using the datasource object in your setup function, simply use its values as keys to the samples object. This gets an array of mosaicked values. Each array behaves exactly the same way as a non-datafusion non-SIMPLE mosaicking samples object. Note that this is an array even for datafusion with SIMPLE mosaicking, unlike non-datafusion requests; of course in this case the array either contains exactly one object or is empty.\nIf datasource was specified in setup:\nfunction evaluatePixel(samples) {\n  // \"l1c\" and \"l2a\" match the datasource values specified in the setup function\n  var l1cMosaics = samples.l1c;  // gets the array of sentinel-2-l1c mosaics\n  var l1cSample = l1cMosaics[0]; // gets the first mosaic. access bands from this object\n  var scl = samples.l2a[0].SCL;  // gets the SCL band of the first sentinel-2-l2a mosaic\n  if (2 &lt;= scl && scl &lt;= 7) {\n    return [l1cSample.B04, l1cSample.B03, l1cSample.B02];\n  }\n  return [0,0,0];\n}\nIf datasource wasn't specified in setup, you can access the data with keys being ordinal numbers starting with 0. Again, the order is as specified in the request body.\nfunction evaluatePixel(samples) {\n  // '0' is the identifier of the first input in the input.data array (sentinel-2-l1c)\n  // '1' is the identifier of the second input in the input.data array (sentinel-2-l2a)\n  var l1cMosaics = samples['0']; // gets the array of mosaics of the first input (sentinel-2-l1c)\n  var l1cSample = l1cMosaics[0]; // gets the first mosaic. access bands from this object\n  var scl = samples['1'][0].SCL; // gets the SCL band of the first mosaic of the second input (sentinel-2-l2a)\n  if (2 &lt;= scl && scl &lt;= 7) {\n    return [l1cSample.B04, l1cSample.B03, l1cSample.B02];\n  }\n  return [0,0,0];\n}\n\n\n\n\n\n\nNote\n\n\n\nWhile the above example works for all mosaicking types, it makes most sense for SIMPLE mosaicking. This is because only one mosaic is accessed for each input in the script, any additional mosaics, which would get generated if ORBIT or TILE mosaicking was used, are ignored."
  },
  {
    "objectID": "APIs/SentinelHub/Process/DataFusion.html#examples",
    "href": "APIs/SentinelHub/Process/DataFusion.html#examples",
    "title": "Data Fusion",
    "section": "Examples",
    "text": "Examples\n\nData Fusion Examples"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/TimeSeries.html",
    "href": "APIs/SentinelHub/UserGuides/TimeSeries.html",
    "title": "Time series",
    "section": "",
    "text": "Processing API uses a timeRange parameter, where a user can select from-to dates. When such a request is ran, only one image is returned. timeRange is used to specify the scenes that are going to be considered for mosaicking (for example all the scenes from April 1 to June 1). Which one will be chosen for the output depends on the mosaicking type and order specified. If the user specified SIMPLE mosaicking order to be mostRecent, the first image considered for mosaicking would be the most recent image available from April 1 to June 1. If a user selected a mosaicking type TILE, and requested second samples (sample[1]), the samples of the second available scene in the specified time range would be returned. Learn more about mosaicking here and mosaicking orders here.\nIf you would like to return all the scenes in a given time range, the recommended approach is to first search for all the available scenes using our Catalog service API, which you can use to view detailed geospatial information, such as the acquisition date and time, for each of the available scenes of your specified BBOX, collection and time range. You can control your Catalog search by specifying fields, limits and other properties. See the Catalog API examples to learn how to do so. It's also possible to search the available scenes using the OGC WFS request, which might be a bit easier to use, but gives you much less search control. See a WFS request example here.\nWhen you have a list of the available scenes, you can then request each by using a separate Processing API call. To do so, limit time-range to only allow for the desired time frame, which matches the acquisition time of your scene."
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/TimeSeries.html#working-with-time-series",
    "href": "APIs/SentinelHub/UserGuides/TimeSeries.html#working-with-time-series",
    "title": "Time series",
    "section": "",
    "text": "Processing API uses a timeRange parameter, where a user can select from-to dates. When such a request is ran, only one image is returned. timeRange is used to specify the scenes that are going to be considered for mosaicking (for example all the scenes from April 1 to June 1). Which one will be chosen for the output depends on the mosaicking type and order specified. If the user specified SIMPLE mosaicking order to be mostRecent, the first image considered for mosaicking would be the most recent image available from April 1 to June 1. If a user selected a mosaicking type TILE, and requested second samples (sample[1]), the samples of the second available scene in the specified time range would be returned. Learn more about mosaicking here and mosaicking orders here.\nIf you would like to return all the scenes in a given time range, the recommended approach is to first search for all the available scenes using our Catalog service API, which you can use to view detailed geospatial information, such as the acquisition date and time, for each of the available scenes of your specified BBOX, collection and time range. You can control your Catalog search by specifying fields, limits and other properties. See the Catalog API examples to learn how to do so. It's also possible to search the available scenes using the OGC WFS request, which might be a bit easier to use, but gives you much less search control. See a WFS request example here.\nWhen you have a list of the available scenes, you can then request each by using a separate Processing API call. To do so, limit time-range to only allow for the desired time frame, which matches the acquisition time of your scene."
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Transparency.html",
    "href": "APIs/SentinelHub/UserGuides/Transparency.html",
    "title": "Transparency",
    "section": "",
    "text": "Parts of the image can be made fully or partially transparent by including the fourth output channel, also known as the alpha channel. The value 0 in the alpha channel makes a pixel fully transparent, while the maximum value in the alpha channel makes it fully opaque (not transparent). Values in between will make the pixel proportionally transparent. Maximum value in alpha channel depends on an image bit depth which is in SH specified by sampleType:\n\nfor sampleType AUTO or FLOAT32: values in alpha channel should be from the interval [0, 1]\nfor sampleType UINT8: values in alpha channel should be from the interval [0, 255]\nfor sampleType UINT16: values in alpha channel should be from the interval [0, 65535]\n\nOutput file formats which support transparency are PNG and TIFF. Note that the JPEG format does not support alpha channel.\n\n\nNo-data pixels are marked by the value 0 in the dataMask band. In the evalscript below, we return value 0 in the forth band for such pixels, which made them transparent. This evalscript can be used as part of any request for Sentinel-2 data and it will display a true color image with transparent background.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    if (samples.dataMask == 1){\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 1]\n    } else if (samples.dataMask == 0) {\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 0]\n    }\n}\nIn the example above we see that the value of dataMask band is exactly the value we want to use for the alpha channel (i.e. fourth channel) of the output. We can thus simplify the evalscript and return dataMask as the fourth band for all pixels.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, samples.dataMask]\n}\nExamine in EO Browser\nElegant! This will work whenever you request sampleType AUTO or FLOAT32. However, for other sampleTypes, you will have to scale the output values to achieve the same transparency. Let us check how to do this in the examples below.\n\n\nWhen using sampleType UINT16 the range of output values in an image becomes [0, 65535] and we must return value 65535 in the alpha channel for pixels which should not be transparent. The above example, if using sampleType UINT16, would be:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT16\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 65535, samples.B03 * 3.5 * 65535, samples.B02 * 3.5 * 65535, samples.dataMask * 65535]\n}\n\n\n\nThe same logic applies also for sampleType UINT8 except that the range of output values in this case is [0, 255]. The same evalscript as above but for sampleType UINT8 is:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT8\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 255, samples.B03 * 3.5 * 255, samples.B02 * 3.5 * 255, samples.dataMask * 255]\n}\n\n\n\n\nTo use some other condition for turning pixels transparent, simply return the condition in the fourth channel, while also outputting four bands in the function setup(). In the example below, we are returning the Sentinel-2 L1C NDVI index larger than 0.6 as transparent. We also leave the no-data pixels non-transparent and thus do not need to use the the dataMask input band.\n//VERSION=3\nfunction setup () {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"B08\"],\n    output: {bands: 4}\n  }\n}\nfunction evaluatePixel(samples, scenes) {\n  var NDVI = (samples.B08 - samples.B04) / (samples.B08 + samples.B04)\n  return [samples.B04 * 2.5, samples.B03 * 2.5, samples.B02 * 2.5, NDVI &lt; 0.6]\n}\nExamine in EO Browser\n\n\n\n  \n      \n         Cloud Masks\n                \n  \n  \n      \n        Time Series"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Transparency.html#transparency-and-background-color",
    "href": "APIs/SentinelHub/UserGuides/Transparency.html#transparency-and-background-color",
    "title": "Transparency",
    "section": "",
    "text": "Parts of the image can be made fully or partially transparent by including the fourth output channel, also known as the alpha channel. The value 0 in the alpha channel makes a pixel fully transparent, while the maximum value in the alpha channel makes it fully opaque (not transparent). Values in between will make the pixel proportionally transparent. Maximum value in alpha channel depends on an image bit depth which is in SH specified by sampleType:\n\nfor sampleType AUTO or FLOAT32: values in alpha channel should be from the interval [0, 1]\nfor sampleType UINT8: values in alpha channel should be from the interval [0, 255]\nfor sampleType UINT16: values in alpha channel should be from the interval [0, 65535]\n\nOutput file formats which support transparency are PNG and TIFF. Note that the JPEG format does not support alpha channel.\n\n\nNo-data pixels are marked by the value 0 in the dataMask band. In the evalscript below, we return value 0 in the forth band for such pixels, which made them transparent. This evalscript can be used as part of any request for Sentinel-2 data and it will display a true color image with transparent background.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    if (samples.dataMask == 1){\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 1]\n    } else if (samples.dataMask == 0) {\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 0]\n    }\n}\nIn the example above we see that the value of dataMask band is exactly the value we want to use for the alpha channel (i.e. fourth channel) of the output. We can thus simplify the evalscript and return dataMask as the fourth band for all pixels.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, samples.dataMask]\n}\nExamine in EO Browser\nElegant! This will work whenever you request sampleType AUTO or FLOAT32. However, for other sampleTypes, you will have to scale the output values to achieve the same transparency. Let us check how to do this in the examples below.\n\n\nWhen using sampleType UINT16 the range of output values in an image becomes [0, 65535] and we must return value 65535 in the alpha channel for pixels which should not be transparent. The above example, if using sampleType UINT16, would be:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT16\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 65535, samples.B03 * 3.5 * 65535, samples.B02 * 3.5 * 65535, samples.dataMask * 65535]\n}\n\n\n\nThe same logic applies also for sampleType UINT8 except that the range of output values in this case is [0, 255]. The same evalscript as above but for sampleType UINT8 is:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT8\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 255, samples.B03 * 3.5 * 255, samples.B02 * 3.5 * 255, samples.dataMask * 255]\n}\n\n\n\n\nTo use some other condition for turning pixels transparent, simply return the condition in the fourth channel, while also outputting four bands in the function setup(). In the example below, we are returning the Sentinel-2 L1C NDVI index larger than 0.6 as transparent. We also leave the no-data pixels non-transparent and thus do not need to use the the dataMask input band.\n//VERSION=3\nfunction setup () {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"B08\"],\n    output: {bands: 4}\n  }\n}\nfunction evaluatePixel(samples, scenes) {\n  var NDVI = (samples.B08 - samples.B04) / (samples.B08 + samples.B04)\n  return [samples.B04 * 2.5, samples.B03 * 2.5, samples.B02 * 2.5, NDVI &lt; 0.6]\n}\nExamine in EO Browser\n\n\n\n  \n      \n         Cloud Masks\n                \n  \n  \n      \n        Time Series"
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html",
    "href": "APIs/SentinelHub/Catalog.html",
    "title": "Catalog API",
    "section": "",
    "text": "Sentinel Hub Catalog API (or shortly \"Catalog\") is an API implementing the STAC Specification, describing geospatial information about different data used with Sentinel Hub."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#api-reference",
    "href": "APIs/SentinelHub/Catalog.html#api-reference",
    "title": "Catalog API",
    "section": "API Reference",
    "text": "API Reference\nAPI Reference for Sentinel Hub Catalog is available as an OpenAPI description.\nSimple search request for Sentinel-1 GRD with a bounding box (the coordinate reference system of the values is WGS84 longitude/latitude), available on 10th December 2019.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = requests.post(url, json=data)"
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#authentication",
    "href": "APIs/SentinelHub/Catalog.html#authentication",
    "title": "Catalog API",
    "section": "Authentication",
    "text": "Authentication\nAuthentication for the Catalog API works completely the same as authentication for other Sentinel Hub services, see Authentication chapter."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#pagination",
    "href": "APIs/SentinelHub/Catalog.html#pagination",
    "title": "Catalog API",
    "section": "Pagination",
    "text": "Pagination\nExecuting the request specified above returns search context fields at the end of the response, looking like this:\n{\n  \"context\": {\n    \"next\": 5,\n    \"limit\": 5,\n    \"returned\": 5\n  }\n}\nThe presence of the next attribute indicates there is more data available for this query, but the server chose to only return 5 results, because the limit specified was 5 (if limit is not specified, default value is 10). To query the next page of items, our request needs to include the next attribute with its value in the query, like so:\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"next\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = requests.post(url, json=data)\nThe response now includes the next page of items; in this case there is no next token in context, meaning no more items exist for this query."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#extensions",
    "href": "APIs/SentinelHub/Catalog.html#extensions",
    "title": "Catalog API",
    "section": "Extensions",
    "text": "Extensions\n\nFilter\nThe search endpoint by default only accepts the parameters described in OpenAPI. The Filter extension enables users to specify an additional parameter to filter on, while searching through data.\nThe syntax for filter is CQL2:\n{\n  \"filter\": {\n    \"op\": \"&lt;operator&gt;\",\n    \"args\": [\n      {\n        \"property\": \"&lt;property_name&gt;\"\n      },\n      \"&lt;value&gt;\"\n    ]\n  },\n  \"filter-lang\": \"cql2-json\"\n}\nIt is also possible to use simple cql2-text:\n{\n  \"filter\": \"eo:cloud_cover &gt; 90\"\n}\nThe available operators are eq, neq, lt, lte, gt, gte, between and not. Only and is currently supported as a logical operator. Be careful - different collections have different properties for the query filter available. The information describing this is available inside the documentation for each specific collection (ex. Sentinel-1 GRD).\n\n\nFields\nBy default, the search endpoint returns all the available attributes of each item. The fields extension provides a way for the client to specify which attributes should not be part of the output, making it easy for the client to not have to deal with unnecessary data.\nSyntax for the fields is:\n{\n  \"fields\": {\n    \"include\": [\n      \"&lt;property_name_1&gt;\",\n      \"&lt;property_name_2&gt;\"\n    ],\n    \"exclude\": [\n      \"&lt;property_name_3&gt;\",\n      \"&lt;property_name_4&gt;\",\n      \"&lt;property_name_5&gt;\"\n    ]\n  }\n}\n\nInclude/Exclude behaviour\n\nWhen no fields attribute is specified in the request, all the available attributes will be included in the response.\nIf the fields attribute is specified with an empty object, or both include and exclude are set to null or an empty array is returned, the attributes for each item will be as if include was set to a default set of [\"id\", \"type\", \"geometry\", \"bbox\", \"links\", \"assets\", \"properties.datetime\"].\nIf only include is specified, the attributes in include will be merged with the default set above.\nIf only exclude is specified, the attributes in exclude will be removed from the default set above.\nIf both include and exclude are specified, the rule is that an attribute must be included in and not excluded from the response.\n\n\n\n\nDistinct\nSometimes we don't want to search for product metadata, but want some general information about the product, such as for example, which acquisition dates are available for Sentinel-1 inside the specified bbox and time interval. distinct attribute inside a search request makes this possible.\nSyntax for distinct attribute is:\n{\n  \"distinct\": \"&lt;property_name&gt;\"\n}\nAs with the filter attribute, distinct is also a collection limited to some specific properties. Information describing these properties can be found inside each collection's documentation (ex. Sentinel-1 GRD)."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html",
    "href": "APIs/SentinelHub/Batch.html",
    "title": "Batch Processing API",
    "section": "",
    "text": "The Batch Processing API is available only for users with Copernicus Service accounts. Contact our Copernicus Data Space Ecosystem support to request your Copernicus Service account.\nBatch Processing API (or shortly \"Batch API\") enables you to request data for large areas and/or longer time periods for any Sentinel Hub supported collection, including BYOC (bring your own data).\nIt is an asynchronous REST service. This means that data will not be returned immediately in a request response but will be delivered to your object storage, which needs to be specified in the request (e.g. a bucket, see Bucket settings below). The processing results will be divided in tiles as described below."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#workflow",
    "href": "APIs/SentinelHub/Batch.html#workflow",
    "title": "Batch Processing API",
    "section": "Workflow",
    "text": "Workflow\nThe batch processing API comes with the set of REST APIs which support the execution of various workflows. The diagram below shows all possible statuses of a batch processing request (CREATED, ANALYSING, ANALYSIS_DONE, PROCESSING, DONE, FAILED, CANCELED, PARTIAL) and user's actions (ANALYSE, START, RESTART, CANCEL) which trigger transitions among them.\n\n\n\n\nstateDiagram\n    [*]--&gt;CREATED\n    state fork_state_created &lt;&lt;fork&gt;&gt;\n    CREATED--&gt;fork_state_created\n    fork_state_created--&gt;PROCESSING: #128100; START\n    fork_state_created--&gt;ANALYSING: #128100; ANALYSE\n    ANALYSING --&gt; ANALYSIS_DONE\n    state fork_state_analysis_done &lt;&lt;fork&gt;&gt;\n    ANALYSIS_DONE--&gt;fork_state_analysis_done\n    fork_state_analysis_done--&gt;PROCESSING: #128100; START\n    PROCESSING--&gt;CANCELED: #128100; CANCEL\n    fork_state_analysis_done--&gt;CANCELED: #128100; CANCEL\n    fork_state_created--&gt;CANCELED: #128100; CANCEL\n    PROCESSING--&gt;DONE\n    PROCESSING--&gt;PARTIAL\n    PROCESSING--&gt;FAILED\n    PARTIAL--&gt;PROCESSING: #128100; RESTART\n    DONE--&gt;[*]\n    PARTIAL--&gt;[*]\n    FAILED--&gt;[*]\n    CANCELED--&gt;[*]\n\n\n\n\n\nThe workflow starts when a user posts a new batch processing request. In this step the system:\n\ncreates new batch processing request with status CREATED,\nvalidates the user's inputs, and\nreturns an estimated number of output tiles that will be processed.\n\nUser can then decide to either request an additional analysis of the request, start the processing or cancel the request. When additional analysis is requested:\n\nthe status of the request changes to ANALYSING,\nthe evalscript is validated,\na list of required tiles is created, and\nthe request's cost is estimated, i.e. the estimated number of processing units (PU) needed for the requested processing. Note that in case of ORBIT or TILE mosaicking the cost estimate can be significantly inaccurate, as described below.\nAfter the analysis is finished the status of the request changes to ANALYSIS_DONE.\n\nIf the user chooses to directly start processing, the system still executes the analysis but when the analysis is done it automatically starts with processing. This is not explicitly shown in the diagram in order to keep it simple.\nThe user can now request a list of tiles for their request, start the processing, or cancel the request. When the user starts the processing:\n\nthe estimated number of PU is reserved,\nthe status of the request changes to PROCESSING (this may take a while),\nthe processing starts.\n\nWhen the processing finishes, the status of the request changes to:\n\nFAILED when all tiles failed processing,\nPARTIAL when some tiles were processed and some failed,\nDONE when all tiles were processed.\n\nAlthough the process has built-in fault tolerance, occasionally, tile processing may fail. In this case, the batch request ends up in status PARTIAL and user can request restart its processing as shown in this example. This will restart processing of all FAILED tiles.\n\nCanceling the request\nUser may cancel the request at any time. However:\n\nif the status is ANALYSING, the analysis will complete,\nif the status is PROCESSING, all tiles that have been processed or are being processed at that moment are charged for. The remaining PUs are returned to the user.\n\n\n\nAutomatic deletion of stale data\nStale requests will be deleted after some time. Specifically, the following requests will be deleted:\n\nfailed requests (request status FAILED),\nrequests that were created but never started (request statuses CREATED, ANALYSIS_DONE),\nsuccessful requests (request statuses DONE and PARTIAL) for which it was not requested to add the results to your collections. Note that only such requests themselves will be deleted, while the requests' result (created imagery) will remain under your control in your S3 bucket.\n\n\n\nCost estimate\nThe cost estimate, provided in the analysis stage, is based on the rules for calculating processing units. It takes the number of output pixels, the number of input bands, and the output format into account. However, for mosaicking ORBIT or TILE the number of data samples (i.e. the no. of observations available in the requested time range) can not be calculated accurately during the analysis. Our cost estimate is thus based on the assumption that one data sample is available every three days within the requested time range. For example, we assume 10 available data samples between 1.1.2021 and 31.1.2021. If you request batch processing of more/fewer data samples, the actual cost will be proportionally higher/lower.\nThe actual costs can be significantly different from the estimate if:\n\nthe number of data samples is reduced in your evalscript by preProcessScenes function or by filters such as maxCloudCoverage. The actual cost will be lower than the estimate.\nyour AOI (area of interest) includes large areas with no data, e.g. when requesting Sentinel-2 data over oceans. The actual cost will be lower than the estimate.\nyou request processing of data collections with revisit period shorter/longer than three days (e.g. your BYOC collection). The actual cost will be proportionally higher/lower than the estimate. Revisit period depends also on selected AOI, e.g. the actual costs of processing Sentinel-2 data close to the equator/at high latitudes will be lower/higher than the estimate.\n\nIf you know how many data samples per pixel will be processed, you can adjust the estimate yourself. For example, if you request processing for data that is available daily, the cost will be 3 times higher than our estimate.\nNote that the cost estimate does not take the multiplication factor of 1/3 for batch processing into account. The actual costs will be 3 times lower than the estimate.\n\n\nTile status\nUsers can follow the progress of tile processing by checking for their current status. This can be done directly in Dashboard, or via the API. The statuses are as follows:\n\nIn the analysis phase, tiles are created with status PENDING.\nWhen tiles move into scheduling queue, their status changes to SCHEDULED.\nWhen a tile is pulled from the queue and processing starts, it becomes PROCESSING.\nWhen tile processing succeeds/fails, it's DONE/FAILED.\nIf a tile gets stuck, it goes back into PENDING up to twice. If it gets stuck the third time, it becomes a FAILED tile.\nWhen a batch request with status PARTIAL is restarted, all its FAILed tiles go back into PENDING.\n\n\n\n\n\nstateDiagram\n    [*]--&gt;PENDING: Analyzer creates tiles\n    PENDING--&gt;SCHEDULED: Move to scheduling queue\n    SCHEDULED --&gt; PROCESSING: Start processing\n    PROCESSING--&gt;DONE: Finished\n    PROCESSING--&gt;FAILED: Error\n    PROCESSING--&gt;PENDING: Stuck (up to 2x)"
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#tiling-grids",
    "href": "APIs/SentinelHub/Batch.html#tiling-grids",
    "title": "Batch Processing API",
    "section": "Tiling grids",
    "text": "Tiling grids\nFor more effective processing we divide the area of interest into tiles and process each tile separately. While process API uses grids which come together with each datasource for processing of the data, the batch API uses one of the predefined tiling grids. The predefined tiling grids 0-2 are based on the Sentinel-2 tiling in WGS84/UTM projection with some adjustments:\n\nThe width and height of tiles in the original Sentinel 2 grid is 100 km while the width and height of tiles in our grids are given in the table below.\nAll redundant tiles (i.e. fully overlapped tiles) are removed.\n\nAll available tiling grids can be requested with (NOTE: To run this example you need to first create an OAuth client as is explained here):\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/batch/tilinggrids/\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()\nThis will return the list of available grids and information about tile size and available resolutions for each grid. Currently, available grids are:\n\n\n\nname\nid\ntile size\nresolutions\ncoverage\noutput CRS\ndownload the grid [zip with shp file] **\n\n\n\n\nUTM 20km grid\n0\n20040 m\n10 m, 20 m, 30m*, 60 m\nWorld, latitudes from -80.7° to 80.7°\nUTM\nUTM 20km grid\n\n\nUTM 10km grid\n1\n10000 m\n10 m, 20 m\nWorld, latitudes from -80.6° to 80.6°\nUTM\nUTM 10km grid\n\n\nUTM 100km grid\n2\n100080 m\n30m*, 60 m, 120 m, 240 m, 360 m\nWorld, latitudes from -81° to 81°\nUTM\nUTM 100km grid\n\n\nWGS84 1 degree grid\n3\n1 °\n0.0001°, 0.0002°\nWorld, all latitudes\nWGS84\nWGS84 1 degree grid\n\n\nLAEA 100km grid\n6\n100000 m\n40 m, 50 m, 100 m\nEurope, including Turkey, Iceland, Svalbald, Azores, and Canary Islands\nEPSG:3035\nLAEA 100km grid\n\n\nLAEA 20km grid\n7\n20000 m\n10 m, 20 m\nEurope, including Turkey, Iceland, Svalbald, Azores, and Canary Islands\nEPSG:3035\nLAEA 20km grid\n\n\n\n** The geometries of the tiles are reprojected to WGS84 for download. Because of this and other reasons the geometries of the output rasters may differ from the tile geometries provided here.\nTo use 20km grid with 60 m resolution, for example, specify id and resolution parameters of the tilingGrid object when creating a new batch request (see an example of full request) as:\n{\n  ...\n  \"tilingGrid\": {\n    \"id\": 0,\n    \"resolution\": 60.0\n  },\n  ...\n}\nContact us if you would like to use any other grid for processing."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#batch-collection",
    "href": "APIs/SentinelHub/Batch.html#batch-collection",
    "title": "Batch Processing API",
    "section": "Batch collection",
    "text": "Batch collection\nBatch processing results can also be uploaded into a BYOC-like collection, which makes it possible to:\n\nAccess data with Processing API, by using the collection ID\nCreate a configuration with custom layers\nMake OGC requests to a configuration\nView data in EO Browser\n\nThe users can either upload data to an existing batch collection by specyfing the collectionId, or create a new one by using the createCollection parameter. Read about both options in BATCH API reference.\nWhen creating a new batch collection, one has to be careful to:\n\nMake sure that \"cogOutput\"=true\nMake sure the evalscript returns only single-band outputs\nKeep sampleType in mind, as the values the evalscript returns when creating a collection will be the values available when making a request to access it\n\nRegardless of whether the user specifies an existing collection or requests a new one, processed data will still upload to the users S3 bucket, where they will be available for download and analysis."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#processing-results",
    "href": "APIs/SentinelHub/Batch.html#processing-results",
    "title": "Batch Processing API",
    "section": "Processing results",
    "text": "Processing results\nThe outputs of a batch processing will be stored to your object storage in either GeoTIFF (and JSON for metadata) or in Zarr format.\n\nGeoTIFF output format\nGeoTIFF format will be used if your request contains the output field. An example of a batch request with GeoTIFF output is available here.\nBy default, the results will be organized in sub-folders where one sub-folder will be created for each tile. Each sub-folder might contain one or more images depending on how many outputs were defined in the evalscript of the request.\nYou can also customize the sub-folder structure and file naming as described in the defaultTilePath parameter under output in BATCH API reference .\nYou can choose to return your GeoTIFF files as Cloud Optimized GeoTIFF (COG), by setting the cogOutput parameter under output in your request as true. Several advanced COG options can be selected as well - read about the parameter in BATCH API reference.\nThe results of batch processing will be in the projection of the selected tiling grid. For UTM-based grids, each part of the AOI (area of interest) is delivered in the UTM zone with which it intersects. In other words, in case your AOI intersects with more UTM zones, the results will be delivered as tiles in different UTM zones (and thus different CRSs).\n\n\nZarr output format\nZarr format will be used if your request contains the zarrOutput field. An example of a batch request with Zarr output is available here.\nThe outputs of a batch processing will be stored as a single Zarr group containing one data array for each evalscript output and multiple coordinate arrays. By default, the Zarr will be stored in the folder you pass to the batch processing api in the path parameter under zarrOutput (see BATCH API reference). The folder must not contain any existing Zarr files. We recommend using a placeholder &lt;requestId&gt; as explained in the API reference to keep the results of your processing better organized.\nThe results of batch processing will be in the projection of the selected tiling grid. The tiling grids where output CRS is UTM zone are not supported for Zarr format output."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#bucket-settings",
    "href": "APIs/SentinelHub/Batch.html#bucket-settings",
    "title": "Batch Processing API",
    "section": "Bucket settings",
    "text": "Bucket settings\nThe results will be delivered in your own bucket hosted at Copernicus Data Space Ecosystem.\nIf you do not yet have a bucket at Copernicus Data Space Ecosystem, please follow these steps to get one.\nYou will have to configure your bucket to allow full access to Sentinel Hub. To do this, update your bucket policy to include the following statement (don’t forget to replace &lt;bucket_name&gt; with your actual bucket name):\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::ddf4c98b5e6647f0a246f0624c8341d9:root\"\n            },\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;\",\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#tutorials-and-other-related-materials",
    "href": "APIs/SentinelHub/Batch.html#tutorials-and-other-related-materials",
    "title": "Batch Processing API",
    "section": "Tutorials and Other Related Materials",
    "text": "Tutorials and Other Related Materials\nWatch our webinar on batch processing, where you will learn how to process large amounts of satellite data step by step. The webinar will show you how to process and download data, create a collection and access it using processing API. June 23, 2021\nTo learn more about how batch processing can be used to create huge mosaics or to enhance your algorithms, read the following blog posts:\n\nHow to create your own Cloudless Mosaic in less than an hour, November 3, 2020\nScale-up your eo-learn workflow using Batch Processing API, September 17, 2020\nLarge-scale data preparation — introducing Batch Processing, January 7, 2020"
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#examples",
    "href": "APIs/SentinelHub/Batch.html#examples",
    "title": "Batch Processing API",
    "section": "Examples",
    "text": "Examples\nExample of Batch Processing Workflow"
  },
  {
    "objectID": "APIs/SentinelHub/Overview/Authentication.html",
    "href": "APIs/SentinelHub/Overview/Authentication.html",
    "title": "Authentication",
    "section": "",
    "text": "The Sentinel Hub API uses OAuth2 Authentication and requires that you have an access token. In essence, this is a piece of information you add to your requests so the server knows it's you. These tokens do not last forever for a multitude of reasons, but you can get new ones and when they expire from the Sentinel-Hub OAuth2 server at the token endpoint listed below. But first, if you do not have one already, you need to register an OAuth Client in your account settings. This is so the server can expect you to make such token requests.\n\nHow to use tokens\nOnce you have a token, do use it for authenticating all your requests within its validity period. While tokens do not last forever, they do last a reasonable amount of time, and sufficiently long that they can be reused. The information of how long each token lasts is embedded in the token itself in the exp claim, and can be read from there.\nDo not fetch a new token for each API request you make. Token requests are rate limited, so if you are getting an HTTP 429 error, that means you are requesting too many tokens.\nTokens are JSON Web Tokens (JWT), more information about them here or here.\n\n\nRegistering OAuth client\nTo register an OAuth client, open the \"User Settings\" tab in your dashboard, then click the Create new button (1) in the \"OAuth client\" section. Give your OAuth client a name (2), set the Client grant type to Client Credentials, and click the Create client button (3). Your client secret will be displayed. Copy the secret value (4) and paste it locally, as it will not be visible after the pop-up window closes! When you are finished, click Close (5). You should now see the newly created OAuth client name and ID (6) in the list of your OAuth clients. With client ID and client secret, you are now ready to request tokens.\n\nTo request tokens the easiest way is to have some software which understands OAuth2 and can make the proper request. For example, REST clients like Postman and Insomnia have support for OAuth2 Client credentials already included. See the Token Request Examples section below.\n\n\nOAuth2 Endpoints\nToken Endpoint - for requesting tokens\nhttps://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\n\n\nToken Request Examples\n\ncURL\nThe following cURL request will return an access token, just make sure to replace &lt;your client id&gt; with your client ID and &lt;your client secret&gt; with your client secret:\ncurl --request POST --url https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token --header 'content-type: application/x-www-form-urlencoded' --data 'grant_type=client_credentials&client_id=&lt;your client id&gt;' --data-urlencode 'client_secret=&lt;your client secret&gt;'\n\n\nPostman\nIn the Postman request Authorization tab set the Type to OAuth 2.0 and Add the authorization data to Request Headers. Then click the Get New Access Token button. Set the Grant Type to Client Credentials, the access token URL to the token endpoint, then set the Client ID and Client Secret to the values of your OAuth Client. Scope can be blank. Keep Client Authentication as Send As Basic Auth Header. Click Request Token. You should get a new one immediately. To use this token to authorize your request, click Use Token. For more information see the Postman authorization documentation\n\n\nPython\nIn python the requests-oauthlib library can handle the retrieval of access tokens using your OAuth Client configuration.\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Your client credentials\nclient_id = '&lt;client_id&gt;'\nclient_secret = '&lt;secret&gt;'\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token',\n                          client_secret=client_secret)\n\n# All requests using this session will have an access token automatically added\nresp = oauth.get(\"...\")\nprint(resp.content)\nrequests-oauthlib doesn't check for status before checking if the response is ok. In case there's a server error, the user can receive an incorrect error, which falsely makes it seem as if the issue is on client side. Library's compliance hooks will prevent the invalid status response from being ignored, returning the correct error. To use them, add the following code:\ndef sentinelhub_compliance_hook(response):\n    response.raise_for_status()\n    return response\n\noauth.register_compliance_hook(\"access_token_response\", sentinelhub_compliance_hook)\n\n\nJavascript\nExample using axios.\nimport axios from \"axios\"\nimport qs from \"qs\"\n\nconst client_id = \"&lt;client_id&gt;\"\nconst client_secret = \"&lt;secret&gt;\"\n\nconst instance = axios.create({\n  baseURL: \"https://sh.dataspace.copernicus.eu\"\n})\n\nconst config = {\n  headers: {\n    'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8'\n  }\n}\n\nconst body = qs.stringify({\n  client_id,\n  client_secret,\n  grant_type: \"client_credentials\"\n})\n\n\n// All requests using this instance will have an access token automatically added\ninstance.post(\"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\", body, config).then(resp =&gt; {\n  Object.assign(instance.defaults, {headers: {authorization: `Bearer ${resp.data.access_token}`}})\n})"
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ErrorHandling.html",
    "href": "APIs/SentinelHub/Overview/ErrorHandling.html",
    "title": "Error handling",
    "section": "",
    "text": "Whenever an error occurs, whether it be the fault of the user or an internal system, an error object will be returned. HTTP response codes of 4xx suggest a bad request. If you receive a 4xx response, we recommend reviewing the API docs for more context to help you troubleshoot. 5xx errors suggest a problem on Sentinel Hub's end, so if you receive a 5xx error, please contact support."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc/img/resources/python/cdse_set_bucket_policy.html",
    "href": "APIs/SentinelHub/Byoc/img/resources/python/cdse_set_bucket_policy.html",
    "title": "Documentation",
    "section": "",
    "text": "# Change the access key, secret_key and bucket_name\n\nfrom pprint import pprint\nimport boto3\nimport json\n\naccess_key = &lt;your-access-key&gt;  # OpenStack access key\nsecret_key = &lt;your-secret-key&gt;  # OpenStack secret key\nbucket_name = &lt;your-bucket-name&gt;  # bucket name\nhost = \"https://s3.waw3-1.cloudferro.com/\"\n\n\ns3 = boto3.client(\n    \"s3\",\n    aws_access_key_id=access_key,\n    aws_secret_access_key=secret_key,\n    endpoint_url=host,\n)\n\n# share a bucket\nshare_to = \"ddf4c98b5e6647f0a246f0624c8341d9\" # SH principal\n\nbucket_policy = {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\"AWS\": f\"arn:aws:iam::{share_to}:root\"},\n            \"Action\": [\n                \"s3:*\",\n            ],\n            \"Resource\": [\n                f\"arn:aws:s3:::{bucket_name}\",\n                f\"arn:aws:s3:::{bucket_name}/*\",\n            ],\n        }\n    ],\n}\n\n# Convert the policy from JSON dict to string\nbucket_policy = json.dumps(bucket_policy)\n\n# Set the new policy\ns3.put_bucket_policy(\n    Bucket=bucket_name,\n    Policy=bucket_policy,\n)\n\nresult = s3.get_bucket_policy(Bucket=bucket_name)\neval(result[\"Policy\"])"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html",
    "href": "APIs/SentinelHub/Evalscript/Functions.html",
    "title": "Utility Functions",
    "section": "",
    "text": "Visualizers are JavaScript classes with a method process which evaluates the representation value for a pixel from pixel’s band values.\n\n\nSets the color from a discrete color map.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\n\n\n\n\nconst map = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorMapVisualizer(map);\nvisualizer.process(199); // returns [ 1, 0, 0 ]\nvisualizer.process(200); // returns [ 1, 0, 0 ]\nvisualizer.process(250); // returns [ 1, 0, 0 ]\nvisualizer.process(299); // returns [ 1, 0, 0 ]\nvisualizer.process(300); // returns [ 0, 0, 1 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorMapVisualizer with following valColPairs\n[\n  [-1.0, 0x000000],\n  [-0.2, 0xff0000],\n  [-0.1, 0x9a0000],\n  [0.0, 0x660000],\n  [0.1, 0xffff33],\n  [0.2, 0xcccc33],\n  [0.3, 0x666600],\n  [0.4, 0x33ffff],\n  [0.5, 0x33cccc],\n  [0.6, 0x006666],\n  [0.7, 0x33ff33],\n  [0.8, 0x33cc33],\n  [0.9, 0x006600]\n]\n\n\n\n\nInterpolates a color based on interval.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\nminVal number (optional, default 0.0)\nmaxVal number (optional, default 1.0)\n\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs redTemperature\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createRedTemperature(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0.43137254901960786, 0, 0 ]\nvisualizer.process(0.5); // returns [ 0.7176470588235294, 0.047058823529411764, 0 ]\nvisualizer.process(0.8); // returns [ 1, 0.6196078431372549, 0.2 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs greenWhite\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createWhiteGreen(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0, 0.2980392156862745, 0 ]\nvisualizer.process(0.5); // returns [ 0.16862745098039217, 0.5019607843137255, 0 ]\nvisualizer.process(0.8); // returns [ 0.6666666666666666, 0.8, 0.3333333333333333 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs blueRed\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createBlueRed(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0.5019607843137255 ]\nvisualizer.process(0.3); // returns [ 0, 0.7019607843137254, 1 ]\nvisualizer.process(0.5); // returns [ 0.5019607843137255, 1, 0.5019607843137255 ]\nvisualizer.process(0.8); // returns [ 1, 0.2980392156862745, 0 ]\nvisualizer.process(1.0); // returns [ 0.5019607843137255, 0, 0 ]\nReturns ColorGradientVisualizer\n\n\n\n\n\nInterpolates a color based on the given color ramps.\n\n\n\nramps Array&lt;[number, number]&gt; Array of color ramps, which are defined as a pair of numbers - the ramp start and the ramp starting color.\n\n\n\n\nconst ramps = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorRampVisualizer(ramps);\nvisualizer.process(199); // [ 1, 0, 0 ]\nvisualizer.process(200); // [ 1, 0, 0 ]\nvisualizer.process(250); // [ 0.5019607843137255, 0, 0.5019607843137255 ]\nvisualizer.process(299); // [ 0.011764705882352941, 0, 0.9882352941176471 ]\nvisualizer.process(300); // [ 0, 1, 0 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nvalue number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\n\nThis is a piecewise linear function which compresses highlights. The minValue and maxValue will be mapped inside the interval [ 0, 1 ]. However, if maxValue lies in (0, 1) a second function which increases much more slowly will be used to further map the values which are mapped to 0.92 and above (see the figure below). This increases the visualized dynamic range while keeping most of the interval of interest linear. Useful, for example, for true color, with a maxValue of 0.4 to still keep some detail in clouds.\n\n\n\nPiecewise linear function which compresses highlights\n\n\n\n\n\nminValue number the value which will be mapped to 0. All values smaller than minValue will also be mapped to 0. (optional, default 0.0)\nmaxValue number the value which controls the position of the boundary point between both linear functions. It will be mapped to approx. 0.9259, while values greater than or equal to (2*maxValue - minValue) will be mapped to 1 (see the figure above). (optional, default 1.0)\ngain (optional, default 1.0)\noffset (optional, default 0.0)\ngamma (optional, default 1.0)\n\n\n\n\nconst visualizer = new HighlightCompressVisualizer(0.1, 0.4)\n\nvisualizer.process(0); // will return 0\nvisualizer.process(0.1); // will return 0\nvisualizer.process(0.25); // will return 0.5\nvisualizer.process(0.376); // will return 0.92. Note: 0.376 = minValue + 0.92*(maxValue - minValue)\nvisualizer.process(0.4); // will return 0.9259\nvisualizer.process(0.7); // will return 1 Note: 0.7 is the smallest value mapped to 1.\nvisualizer.process(1.1); // will return 1\n\n\n\nReturns mapped value.\n\n\n\nval number the input value to be mapped.\ni number the index of val. This is EO Browser specific.\n\nReturns [number] mapped value."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#visualizers",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#visualizers",
    "title": "Utility Functions",
    "section": "",
    "text": "Visualizers are JavaScript classes with a method process which evaluates the representation value for a pixel from pixel’s band values.\n\n\nSets the color from a discrete color map.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\n\n\n\n\nconst map = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorMapVisualizer(map);\nvisualizer.process(199); // returns [ 1, 0, 0 ]\nvisualizer.process(200); // returns [ 1, 0, 0 ]\nvisualizer.process(250); // returns [ 1, 0, 0 ]\nvisualizer.process(299); // returns [ 1, 0, 0 ]\nvisualizer.process(300); // returns [ 0, 0, 1 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorMapVisualizer with following valColPairs\n[\n  [-1.0, 0x000000],\n  [-0.2, 0xff0000],\n  [-0.1, 0x9a0000],\n  [0.0, 0x660000],\n  [0.1, 0xffff33],\n  [0.2, 0xcccc33],\n  [0.3, 0x666600],\n  [0.4, 0x33ffff],\n  [0.5, 0x33cccc],\n  [0.6, 0x006666],\n  [0.7, 0x33ff33],\n  [0.8, 0x33cc33],\n  [0.9, 0x006600]\n]\n\n\n\n\nInterpolates a color based on interval.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\nminVal number (optional, default 0.0)\nmaxVal number (optional, default 1.0)\n\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs redTemperature\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createRedTemperature(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0.43137254901960786, 0, 0 ]\nvisualizer.process(0.5); // returns [ 0.7176470588235294, 0.047058823529411764, 0 ]\nvisualizer.process(0.8); // returns [ 1, 0.6196078431372549, 0.2 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs greenWhite\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createWhiteGreen(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0, 0.2980392156862745, 0 ]\nvisualizer.process(0.5); // returns [ 0.16862745098039217, 0.5019607843137255, 0 ]\nvisualizer.process(0.8); // returns [ 0.6666666666666666, 0.8, 0.3333333333333333 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs blueRed\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createBlueRed(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0.5019607843137255 ]\nvisualizer.process(0.3); // returns [ 0, 0.7019607843137254, 1 ]\nvisualizer.process(0.5); // returns [ 0.5019607843137255, 1, 0.5019607843137255 ]\nvisualizer.process(0.8); // returns [ 1, 0.2980392156862745, 0 ]\nvisualizer.process(1.0); // returns [ 0.5019607843137255, 0, 0 ]\nReturns ColorGradientVisualizer\n\n\n\n\n\nInterpolates a color based on the given color ramps.\n\n\n\nramps Array&lt;[number, number]&gt; Array of color ramps, which are defined as a pair of numbers - the ramp start and the ramp starting color.\n\n\n\n\nconst ramps = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorRampVisualizer(ramps);\nvisualizer.process(199); // [ 1, 0, 0 ]\nvisualizer.process(200); // [ 1, 0, 0 ]\nvisualizer.process(250); // [ 0.5019607843137255, 0, 0.5019607843137255 ]\nvisualizer.process(299); // [ 0.011764705882352941, 0, 0.9882352941176471 ]\nvisualizer.process(300); // [ 0, 1, 0 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nvalue number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\n\nThis is a piecewise linear function which compresses highlights. The minValue and maxValue will be mapped inside the interval [ 0, 1 ]. However, if maxValue lies in (0, 1) a second function which increases much more slowly will be used to further map the values which are mapped to 0.92 and above (see the figure below). This increases the visualized dynamic range while keeping most of the interval of interest linear. Useful, for example, for true color, with a maxValue of 0.4 to still keep some detail in clouds.\n\n\n\nPiecewise linear function which compresses highlights\n\n\n\n\n\nminValue number the value which will be mapped to 0. All values smaller than minValue will also be mapped to 0. (optional, default 0.0)\nmaxValue number the value which controls the position of the boundary point between both linear functions. It will be mapped to approx. 0.9259, while values greater than or equal to (2*maxValue - minValue) will be mapped to 1 (see the figure above). (optional, default 1.0)\ngain (optional, default 1.0)\noffset (optional, default 0.0)\ngamma (optional, default 1.0)\n\n\n\n\nconst visualizer = new HighlightCompressVisualizer(0.1, 0.4)\n\nvisualizer.process(0); // will return 0\nvisualizer.process(0.1); // will return 0\nvisualizer.process(0.25); // will return 0.5\nvisualizer.process(0.376); // will return 0.92. Note: 0.376 = minValue + 0.92*(maxValue - minValue)\nvisualizer.process(0.4); // will return 0.9259\nvisualizer.process(0.7); // will return 1 Note: 0.7 is the smallest value mapped to 1.\nvisualizer.process(1.1); // will return 1\n\n\n\nReturns mapped value.\n\n\n\nval number the input value to be mapped.\ni number the index of val. This is EO Browser specific.\n\nReturns [number] mapped value."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#helper-functions",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#helper-functions",
    "title": "Utility Functions",
    "section": "Helper functions",
    "text": "Helper functions\nHelper functions that can be used in custom scripts.\n\nint2rgb\nTransforms a color as integer into RGB triplet.\n\nParameters\n\ncolor number as integer\n\n\n\nExamples\nint2rgb(255);    // returns [ 0, 0, 255 ]\nint2rgb(256);    // returns [ 0, 1, 0 ]\nint2rgb(65537);  // returns [ 1, 0, 1 ]\nReturns [number, number, number]\n\n\n\nrgb2int\nInverse of the int2rgb function. Transforms a RGB triplet into integer.\n\nParameters\n\ncolor [number, number, number] as RGB triplet\n\n\n\nExamples\nrgb2int([0, 0, 255]);  // returns 255\nrgb2int([0, 1, 0]);    // returns 256\nrgb2int([1, 0, 1]);    // returns 65537\nReturns number\n\n\n\ncombine\nCombines two colors.\n\nParameters\n\ncolor1 number The first color defined as an array of values.\ncolor2 number The second color defined as an array of values.\nalpha number A share of the first color defined as a floating point between 0 and\n\n\n\n\n\n\nExamples\ncombine([100, 0, 0], [0, 100, 0], 1);   // returns [ 100, 0, 0 ]\ncombine([100, 0, 0], [0, 100, 0], 0);   // returns [ 0, 100, 0 ]\ncombine([100, 0, 0], [0, 100, 0], 0.5); // returns [ 50, 50, 0 ]\nReturns number The combined color defined as an array of values.\n\n\n\nindex\nCalculate difference divided by sum\n\nParameters\n\nx number first value\ny number second value\n\n\n\nExamples\nindex(0.6, 0.4); // returns 0.2\nindex(0.5, -0.5); //returns 0.0\nReturns number (x - y) / (x + y), if sum is 0 returns 0\n\n\n\ninverse\nCalculate inverse value\n\nParameters\n\nx number value\n\n\n\nExamples\ninverse(2.0); // returns 0.5\ninverse(5.0); // returns 0.2\ninverse(0); // returns 1.7976931348623157E308\nReturns number inverse of value of x (1 / x), if x is 0 returns JAVA_DOUBLE_MAX_VAL\n\n\n\nvalueMap\nMaps a value to another value bound by an interval (from,to].\nintervals = [-10, -5, 0, 5, 10], values = [-100,-50, 0, 50, 100]\ndefines the following mapping:\n(-inf, -10]  =&gt; -100\n(-10, -5] =&gt; -50\n(-5,0] =&gt; 0\n(0, 5] =&gt; 50\n(5, +inf) =&gt; 100\n\nParameters\n\nvalue number input value\nintervals [number] array of numbers in ascending order defining intervals\nvalues [number] output value for the given interval\n\n\n\nExamples\nvalueMap(5, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 500\nvalueMap(1, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 100\nvalueMap(2, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 300\nvalueMap(12, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 900\nvalueMap(50); // returns 50\nReturns number\n\n\n\nvalueInterpolate\nInterpolates a value to another value bound by an interval (from,to]. Values at far ends of defined intervals are clamped to min/max value. This function is a replacement for the deprecated colorBlend function.\nintervals = [-10, -5, 0, 5, 10], values = [-1000,-50, 0, 50, 1000]\ndefines the following mapping:\n(-inf, -10]  =&gt; -1000\n(-10, -5] =&gt; (-1000, -50]\n(-5,0] =&gt; (-50,0]\n(0, 5] =&gt; (0,50]\n(5, 10] =&gt; (50,1000]\n(10, +inf) =&gt; 1000\n\nParameters\n\nvalue number input value\nintervals Array&lt;number&gt; array of numbers in ascending order defining intervals\nvalues (Array&lt;number&gt; | Array&lt;Array&lt;number&gt;&gt;) output interval for the given value/interval of the intervals array\n\n\n\nExamples\nvalueInterpolate(0, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns 0\nvalueInterpolate(-10, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns -1000\nvalueInterpolate(9, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns 810\nvalueInterpolate(50); // returns 50\nvalueInterpolate(0.1, [0, 0.2, 0.4, 0.6, 0.8, 1], [\n  [0, 0, 0],\n  [0.1, 0.2, 0.5],\n  [0.25, 0.4, 0.5],\n  [0.4, 0.6, 0.5],\n  [0.75, 0.8, 0.5],\n  [1, 1, 0.5]\n]); // return [0.05, 0.1, 0.25]\nReturns (number | Array&lt;number&gt;)"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#constants",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#constants",
    "title": "Utility Functions",
    "section": "Constants",
    "text": "Constants\n\nJAVA_DOUBLE_MAX_VAL\n const JAVA_DOUBLE_MAX_VAL = 1.7976931348623157E308;\nType: number\n\n\nblueRed\nconst blueRed = [\n  [1.000, 0x000080],\n  [0.875, 0x0000FF],\n  [0.625, 0x00FFFF],\n  [0.375, 0xFFFF00],\n  [0.125, 0xFF0000],\n  [0.000, 0x800000]\n]\nType: Array&lt;[number, number]&gt;\n\n\nredTemperature\nconst redTemperature = [\n  [1.000, 0x000000],\n  [0.525, 0xAE0000],\n  [0.300, 0xFF6E00],\n  [0.250, 0xFF8600],\n  [0.000, 0xFFFFFF]\n]\nType: Array&lt;[number, number]&gt;\n\n\ngreenWhite\nconst greenWhite = [\n  [1.000, 0x000000],\n  [0.600, 0x006600],\n  [0.300, 0x80B300],\n  [0.000, 0xFFFFFF]\n]\nType: Array&lt;[number, number]&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#colorblend",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#colorblend",
    "title": "Utility Functions",
    "section": "colorBlend",
    "text": "colorBlend\n\nParameters\n\nvalue number input value\nlimits Array&lt;number&gt; array of numbers in ascending order defining intervals\ncolors (Array&lt;number&gt; | Array&lt;Array&lt;number&gt;&gt;) output interval for the given value/interval of the intervals array\n\nReturns (number | Array&lt;number&gt;)\nMeta\n\ndeprecated: See valueInterpolate"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#landsat8c2qabandconditions",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#landsat8c2qabandconditions",
    "title": "Utility Functions",
    "section": "Landsat8C2QaBandConditions",
    "text": "Landsat8C2QaBandConditions\nCloud confidence, cloud shadow confidence, snow ice confidence and cirrus confidence represent levels of confidence that a condition exists:\n\n0 = “Not Determined”\n1 = “Low” = Low confidence.\n2 = “Medium / Reserved” = Medium only for cloud confidence.\n3 = “High” = High confidence.\n\nType: Object\n\nProperties\n\nfill number 0 for image data, 1 for fill data\ndilatedCloud number 0 for cloud is not dilated or no cloud, 1 for cloud dilation\ncirrus number 0 for no confidence level or low confidence, 1 for high confidence cirrus\ncloud number 0 for cloud confidence is not high, 1 for high confidence cloud\ncloudShadow number 0 for cloud shadow confidence is not high, 1 for high confidence cloud shadow\nsnow number 0 for snow/ice confidence is not high, 1 for high confidence snow cover\nclear number 0 if cloud or dilated cloud, or else 1\nwater number 0 for land or cloud, 1 for water\ncloudConfidence number\ncloudShadowConfidence number\nsnowIceConfidence number\ncirrusConfidence number"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#decodel8c2qa",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#decodel8c2qa",
    "title": "Utility Functions",
    "section": "decodeL8C2Qa",
    "text": "decodeL8C2Qa\nDecodes Landsat 8 Collection 2 Quality Assessment band conditions.\n\nParameters\n\nvalue integer band pixel (16-bit value)\n\n\n\nExamples\ndecodeL8C2Qa(55052);\n// returns {\n//   cirrus: 1, cirrusConfidence: 3,\n//   clear: 0,\n//   cloud: 1,\n//   cloudConfidence: 3,\n//   cloudShadow: 0,\n//   cloudShadowConfidence: 1,\n//   dilatedCloud: 0,\n//   fill: 0,\n//   snow: 0,\n//   snowIceConfidence: 1,\n//   water: 0\n// }\nReturns Landsat8C2QaBandConditions"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#decodes3olciqualityflags",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#decodes3olciqualityflags",
    "title": "Utility Functions",
    "section": "decodeS3OLCIQualityFlags",
    "text": "decodeS3OLCIQualityFlags\nUnpacks bit-packed Sentinel 3 OLCI Quality Flags values.\n\nParameters\n\nvalue integer QUALITY_FLAGS band DN value (32-bit value)\n\nReturns object An object containing the following keys with either 0 or 1 values: land, coastline, fresh_inland_water, tidal_region, bright, straylight_risk, invalid, cosmetic, duplicated, sun_glint_risk, dubious, saturatedBxy (where xy is the band number, e.g. saturatedB01)."
  },
  {
    "objectID": "APIs/SentinelHub/Process.html",
    "href": "APIs/SentinelHub/Process.html",
    "title": "Processing API",
    "section": "",
    "text": "The Processing API (or shortly \"Process API\") is the most commonly used API in Sentinel Hub as it provides images based on satellite data. Users can request raw satellite data, simple band combinations such as false colour composites, calculations of simple remote sensing indices like NDVI, or more advanced processing such as calculation of Leaf area index (LAI).\nEven though satellite imagery data are often distributed in \"tiles\", we do not want users to be limited to these. Tiles are an artificially introduced entity to make data distribution easier to handle. However, users should not have to care about whether their AOI is on one tile or another, or perhaps on the border of two tiles. This is why Sentinel Hub API hides this complexity and simply makes the data available over chosen area of interest and temporal period of interest. Tiles are therefore automatically stitched together based on defined parameters (AOI, time period, cloud coverage, priority, etc., depending on the data type)."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html",
    "href": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html",
    "title": "Additional Request Parameters",
    "section": "",
    "text": "WMS/WMTS/WFS/WCS services support many custom parameters which affect the generation of the service responses. In the following table, all the available custom parameters, such as preview modes, are listed. All these parameters are optional.\nFor the examples on how to use them, see this documentation.\nNote that atmospheric correction is not a parameter anymore, as we now only support L2A atmospheric correction. Read more about it here.\n\n\n\nCustom parameter\nInfo\nDefault value\nValid value range\nAvailable for\n\n\n\n\nMAXCC\nThe maximum allowable cloud coverage in percent. Cloud coverage is a product average and not viewport accurate hence images may have more cloud cover than specified here.\n100.0\n0.0 - 100.0\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nPRIORITY\nThe priority by which to select and sort the overlapping valid tiles from which the output result is made. For example, using mostRecent will place newer tiles over older ones therefore showing the latest image possible. Using leastCC will place the least cloudy tiles available on top.\nmostRecent\nmostRecent, leastRecent, leastCC, leastTimeDifference, maximumViewingElevation\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nEVALSCRIPT\nThis parameter allows for a custom evaluation script or formula specifying how the output image will be generated from the input bands. See Custom evaluation script usage for details.   EVALSCRIPT parameter has to be BASE64 encoded before it is passed to the service.\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nEVALSCRIPTURL\nThis parameter allows for a custom evaluation script or formula to be passed as an URL parameter, where the script itself is located (it should be on HTTPS).\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nPREVIEW\nSee Preview modes for details.\n0\n0, 1, 2\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nGEOMETRY\nOutputs imagery only within the given geometry and cropped to the geometry's minimum bounding box.\n\none WKT string, one WKB hex string, or a list of coordinate pairs representing a polygon (pairs separated by semicolons, components by comma, i.e. 1 1, 2 2;...) Coordinates should be specified using the CRS of the request (i.e. same CRS as BBOX).\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nQUALITY\nUsed only when requesting JPEGs.\n90\n0 - 100; where 0 is the lowest and 100 the highest quality\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nUPSAMPLING\nSets the image upsampling method. Used when the requested resolution is higher than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nDOWNSAMPLING\nSets the image downsampling method. Used when the requested resolution is lower than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC, BOX\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nWARNINGS\nEnables or disables the display of in-image warnings, like \"No data available for the specified area\".\nYES\nYES, NO\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\n\n\n\nPreview modes make it possible to receive data from across all zoom levels. Sentinel Hub is optimised for full resolution data access as this is what most users need. There are, however, some cases when lower resolution previews of the data make sense as well. This is done by adding the URL parameter PREVIEW. Optional, default=\"0\". Supported values:\n\n\n\nValues\nInfo\n\n\n\n\nPREVIEW=0\nOnly high resolution data from Sentinel-2 is used. This corresponds to real world distances up to 200m/pixel. This is the default.\n\n\nPREVIEW=1\nAllows zooming further out, up to a point. Up to 200m/pixel it displays the same data as PREVIEW=0. In addition to this it uses lower resolution data for real world distances up to 1500m/pixel.   With resolutions between 200m/pixel and 1500m/pixel cloud filtering is no longer applied.\n\n\nPREVIEW=2\nAllows any zoom level but is limited to a maximum of one month of data when most zoomed out. Up to 1500m/pixel it displays the same data as PREVIEW=1. With resolutions lower than 1500m/pixel (more zoomed out) it limits the data to one month prior to the \"TO\" date.   With resolutions less than 200m/pixel (more zoomed out) cloud filtering is no longer applied.\n\n\n\n\n\n\nSatellite images sometimes seem washed out or foggy, as atmosphere absorbs and scatters light on its way to the ground. We can correct for this to get clearer images using atmospheric correction. ESA provides a Sen2Cor processor, that applies atmospheric correction to the input Sentinel-2 L1C data with global coverage. The resulting product is called S2L2A data. To use Atmospheric correction, use the Sentinel-2 L2A (S2L2A) data collection.\nBelow, you can see the difference atmospheric correction makes. The first image of Marseille was made in EO Browser using S2L1C data, and the lower image was made using S2L2A atmospheric correction."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html#additional-request-parameters",
    "href": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html#additional-request-parameters",
    "title": "Additional Request Parameters",
    "section": "",
    "text": "WMS/WMTS/WFS/WCS services support many custom parameters which affect the generation of the service responses. In the following table, all the available custom parameters, such as preview modes, are listed. All these parameters are optional.\nFor the examples on how to use them, see this documentation.\nNote that atmospheric correction is not a parameter anymore, as we now only support L2A atmospheric correction. Read more about it here.\n\n\n\nCustom parameter\nInfo\nDefault value\nValid value range\nAvailable for\n\n\n\n\nMAXCC\nThe maximum allowable cloud coverage in percent. Cloud coverage is a product average and not viewport accurate hence images may have more cloud cover than specified here.\n100.0\n0.0 - 100.0\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nPRIORITY\nThe priority by which to select and sort the overlapping valid tiles from which the output result is made. For example, using mostRecent will place newer tiles over older ones therefore showing the latest image possible. Using leastCC will place the least cloudy tiles available on top.\nmostRecent\nmostRecent, leastRecent, leastCC, leastTimeDifference, maximumViewingElevation\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nEVALSCRIPT\nThis parameter allows for a custom evaluation script or formula specifying how the output image will be generated from the input bands. See Custom evaluation script usage for details.   EVALSCRIPT parameter has to be BASE64 encoded before it is passed to the service.\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nEVALSCRIPTURL\nThis parameter allows for a custom evaluation script or formula to be passed as an URL parameter, where the script itself is located (it should be on HTTPS).\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nPREVIEW\nSee Preview modes for details.\n0\n0, 1, 2\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nGEOMETRY\nOutputs imagery only within the given geometry and cropped to the geometry's minimum bounding box.\n\none WKT string, one WKB hex string, or a list of coordinate pairs representing a polygon (pairs separated by semicolons, components by comma, i.e. 1 1, 2 2;...) Coordinates should be specified using the CRS of the request (i.e. same CRS as BBOX).\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nQUALITY\nUsed only when requesting JPEGs.\n90\n0 - 100; where 0 is the lowest and 100 the highest quality\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nUPSAMPLING\nSets the image upsampling method. Used when the requested resolution is higher than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nDOWNSAMPLING\nSets the image downsampling method. Used when the requested resolution is lower than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC, BOX\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nWARNINGS\nEnables or disables the display of in-image warnings, like \"No data available for the specified area\".\nYES\nYES, NO\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\n\n\n\nPreview modes make it possible to receive data from across all zoom levels. Sentinel Hub is optimised for full resolution data access as this is what most users need. There are, however, some cases when lower resolution previews of the data make sense as well. This is done by adding the URL parameter PREVIEW. Optional, default=\"0\". Supported values:\n\n\n\nValues\nInfo\n\n\n\n\nPREVIEW=0\nOnly high resolution data from Sentinel-2 is used. This corresponds to real world distances up to 200m/pixel. This is the default.\n\n\nPREVIEW=1\nAllows zooming further out, up to a point. Up to 200m/pixel it displays the same data as PREVIEW=0. In addition to this it uses lower resolution data for real world distances up to 1500m/pixel.   With resolutions between 200m/pixel and 1500m/pixel cloud filtering is no longer applied.\n\n\nPREVIEW=2\nAllows any zoom level but is limited to a maximum of one month of data when most zoomed out. Up to 1500m/pixel it displays the same data as PREVIEW=1. With resolutions lower than 1500m/pixel (more zoomed out) it limits the data to one month prior to the \"TO\" date.   With resolutions less than 200m/pixel (more zoomed out) cloud filtering is no longer applied.\n\n\n\n\n\n\nSatellite images sometimes seem washed out or foggy, as atmosphere absorbs and scatters light on its way to the ground. We can correct for this to get clearer images using atmospheric correction. ESA provides a Sen2Cor processor, that applies atmospheric correction to the input Sentinel-2 L1C data with global coverage. The resulting product is called S2L2A data. To use Atmospheric correction, use the Sentinel-2 L2A (S2L2A) data collection.\nBelow, you can see the difference atmospheric correction makes. The first image of Marseille was made in EO Browser using S2L1C data, and the lower image was made using S2L2A atmospheric correction."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html",
    "title": "Output Formats",
    "section": "",
    "text": "For the requests that provide image output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\nimage/png - lossless image format for 1 (grayscale) or 3 (RGB) components\nimage/jpeg - lossy image format for 1 (grayscale) or 3 (RGB) components, without alpha channel. The quality can be controlled via the \"QUALITY\" URL parameter.\nimage/tiff - lossless image format for any number of the components.\n\nFind out more on how the values are reflected in the output.\n\n\nTo generate the output as jpeg, use the following example. Please replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=image/jpeg"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html#output-image-formats",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html#output-image-formats",
    "title": "Output Formats",
    "section": "",
    "text": "For the requests that provide image output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\nimage/png - lossless image format for 1 (grayscale) or 3 (RGB) components\nimage/jpeg - lossy image format for 1 (grayscale) or 3 (RGB) components, without alpha channel. The quality can be controlled via the \"QUALITY\" URL parameter.\nimage/tiff - lossless image format for any number of the components.\n\nFind out more on how the values are reflected in the output.\n\n\nTo generate the output as jpeg, use the following example. Please replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=image/jpeg"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html#output-vector-formats",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html#output-vector-formats",
    "title": "Output Formats",
    "section": "Output Vector Formats",
    "text": "Output Vector Formats\nFor the requests that provide vector output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\napplication/x-esri-shape - zip containing shape files\napplication/json - GeoJSON file\n\nBoth formats are returning polygons in vector format only in case when the image does not consists of more than 10 different values. Therefore, this formats only work with custom script layers.\n\nExample requests for vector formats:\nTo generate the output as GeoJSON file, follow the example below. Replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=application/json\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"properties\": {\n        \"COLOR_HEX\": \"FFFFFF\",\n        \"ID\": 0\n      },\n      \"geometry\": {\n        \"type\": \"MultiPolygon\",\n        \"crs\": {\n            \"type\": \"name\",\n            \"properties\": {\n                \"name\": \"urn:ogc:def:crs:OGC::CRS84\"\n            }\n        },\n        \"coordinates\": [[[\n            [16.225567302, 46.698948044],\n            [16.225567302, 46.6989451],\n            [16.225561399, 46.6989451],\n            [16.225561399, 46.698942156],\n            ...\n        ]]]\n      }\n    },\n    ...\n  ]\n}\nTo generate the output as x-esri-shape, replace the FORMAT with application/x-esri-shape, which will enable you to get the zip containing shape files."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html",
    "href": "APIs/SentinelHub/OGC/WMTS.html",
    "title": "Web Mapping Tile Service",
    "section": "",
    "text": "The Sentinel Hub WMTS (Web Map Tile Service) service conforms to the WMTS standard. It provides access to Sentinel-2's 13 unprocessed bands (B01 through B12, with B8A following B08) as well as processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration. Provides access to the same bands product and additional informational layers as the WMS request except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. As with the WMS service, WMTS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMTS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WMTS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request and supports the standard WMTS requests GetTile, GetCapabilities. It supports WMTS version 1.0.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nCheck GetCapabilities for a list of supported coordinate reference systems and tile matrix sets which can be used for the TILEMATRIX and TILEMATRIXSET parameters."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html#wmts-request",
    "href": "APIs/SentinelHub/OGC/WMTS.html#wmts-request",
    "title": "Web Mapping Tile Service",
    "section": "",
    "text": "The Sentinel Hub WMTS (Web Map Tile Service) service conforms to the WMTS standard. It provides access to Sentinel-2's 13 unprocessed bands (B01 through B12, with B8A following B08) as well as processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration. Provides access to the same bands product and additional informational layers as the WMS request except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. As with the WMS service, WMTS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMTS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WMTS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request and supports the standard WMTS requests GetTile, GetCapabilities. It supports WMTS version 1.0.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nCheck GetCapabilities for a list of supported coordinate reference systems and tile matrix sets which can be used for the TILEMATRIX and TILEMATRIXSET parameters."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html#wmts-parameters",
    "href": "APIs/SentinelHub/OGC/WMTS.html#wmts-parameters",
    "title": "Web Mapping Tile Service",
    "section": "WMTS Parameters",
    "text": "WMTS Parameters\nStandard common WMTS URL parameters (names are case insensitive):\n\n\n\nWMTS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WMTS\".\n\n\nVERSION\nWMTS version standard. Optional, default: \"1.0.0\". Supported values: \"1.0.0\".\n\n\nREQUEST\nWhat is requested, valid values: GetTile or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WMS URL parameters, the WMS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetTile request URL parameters:\n\n\n\nWMTS parameter\nInfo\n\n\n\n\nTILEMATRIXSET\nThe matrix set to be used for the output tile. Check GetCapabilities for a list of supported matrix sets.\n\n\nTILEMATRIX\nThe matrix to be used for the output tile. Check GetCapabilities for a list of supported matrices.\n\n\nTILECOL\nThe column index of the output tile. Check GetCapabilities for a list of supported matrix widths.\n\n\nTILEROW\nThe row index of the output tile. Check GetCapabilities for a list of supported matrix heights.\n\n\nLAYER\nThe preconfigured (in the instance) layer for which to generate the output tile.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/Examples.html",
    "href": "APIs/SentinelHub/OGC/Examples.html",
    "title": "Examples of OGC API",
    "section": "",
    "text": "Below are examples for all our OGC APIs. To run the examples yourself, replace &lt;INSTANCE_ID&gt; in the URLs with your own configuration instance id and paste the url in any web browser. Your configuration must be based on the \"Simple WMS template\", which can be found when you create new configuration in the Dashboard in \"Configuration Utility\" tab.\nIf you want to check interactive example use this link.\n\nWMS #1\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetMap&BBOX=3238005,5039853,3244050,5045897&LAYERS=NATURAL-COLOR&MAXCC=20&WIDTH=320&HEIGHT=320&FORMAT=image/jpeg&TIME=2018-03-29/2018-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2018-03-29/2018-05-29\n\n\n\n\n\nResult\n\n\n\n\nWMS #2\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetMap&BBOX=3238005,5039853,3244050,5045897&FORMAT=image/jpeg&LAYERS=NATURAL-COLOR&MAXCC=20&WIDTH=320&HEIGHT=320&TIME=2017-01-29/2017-02-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2017-01-29/2017-02-29\n\n\n\n\n\nResult\n\n\n\n\nWCS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;?SERVICE=WCS&REQUEST=GetCoverage&COVERAGE=NATURAL-COLOR&BBOX=3238005,5039853,3244050,5045897&MAXCC=20&WIDTH=320&HEIGHT=320&FORMAT=image/jpeg&TIME=2019-03-29/2019-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2019-03-29/2019-05-29\n\n\n\n\n\nResult\n\n\n\n\nWMTS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;?REQUEST=GetTile&BBOX=3238005,5039853,3244050,5045897&RESOLUTION=10&TILEMATRIXSET=PopularWebMercator512&LAYER=FALSE-COLOR&MAXCC=20&TILEMATRIX=14&TILEROW=3065&TILECOL=4758&TIME=2018-03-29/2018-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nFALSE-COLOR\n\n\nMAXCC\n20\n\n\nRESOLUTION\n10\n\n\nTILEMATRIXSET\nPopularWebMercator512\n\n\nTILEMATRIX\n14\n\n\nTILEROW\n3065\n\n\nTILECOL\n4758\n\n\nTIME\n2018-03-29/2018-05-29\n\n\n\n\n\nResult\n\n\n\n\nWFS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;?REQUEST=GetFeature&srsName=EPSG:3857&TYPENAMES=DSS2&BBOX=3238005,5039853,3244050,5045897&TIME=2019-02-11/2019-02-12\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nREQUEST\nGetFeature\n\n\nsrsName\nEPSG:3857\n\n\nTYPENAMES\nDSS2\n\n\nBBOX\n3238005,5039853,3244050,5045897\n\n\nTIME\n2019-02-11/2019-02-12\n\n\n\n\n\nResult\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\n&lt;wfs:FeatureCollection xsi:schemaLocation=\"http://www.opengis.net/wfs/2.0 http://schemas.opengis.net/wfs/2.0/wfs.xsd http://www.opengis.net/gml/3.2 http://schemas.opengis.net/gml/3.2.1/gml.xsd\"\n    xmlns:sh=\"https://www.sentinel-hub.com/\" xmlns:gml=\"http://www.opengis.net/gml/3.2\" xmlns:wfs=\"http://www.opengis.net/wfs/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n  &lt;wfs:boundedBy&gt;\n    &lt;gml:Box srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n      &lt;gml:coordinates&gt;\n        3137112.369571343,4944408.712920986 3285542.013115577,5093151.414429454\n      &lt;/gml:coordinates&gt;\n    &lt;/gml:Box&gt;\n  &lt;/wfs:boundedBy&gt;\n  &lt;wfs:member&gt;\n    &lt;DSS2&gt;\n      &lt;gml:boundedBy&gt;\n        &lt;gml:Box srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n          &lt;gml:coordinates&gt;\n            3137112.369571343,4944408.712920986 3285542.013115577,5093151.414429454\n          &lt;/gml:coordinates&gt;\n        &lt;/gml:Box&gt;\n      &lt;/gml:boundedBy&gt;\n      &lt;id&gt;S2A_OPER_MSI_L2A_TL_SGS__20190212T133228_A019023_T35TPF_N02.11&lt;/id&gt;\n      &lt;date&gt;2019-02-12&lt;/date&gt;\n      &lt;time&gt;09:08:52&lt;/time&gt;\n      &lt;path&gt;s3://sentinel-s2-l2a/tiles/35/T/PF/2019/2/12/0&lt;/path&gt;\n      &lt;crs&gt;EPSG:32635&lt;/crs&gt;\n      &lt;mbr&gt;600000,4490220 709800,4600020&lt;/mbr&gt;\n      &lt;cloudCoverPercentage&gt;97.48&lt;/cloudCoverPercentage&gt;\n      &lt;geometryProperty&gt;\n        &lt;gml:MultiPolygon srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n          &lt;gml:polygonMember&gt;\n            &lt;gml:Polygon&gt;\n              &lt;gml:outerBoundaryIs&gt;\n                &lt;gml:LinearRing&gt;\n                  &lt;gml:coordinates&gt;\n                    3139096.254297407,5093151.414429454 3137112.369571343,4947176.295365512 3272770.2640233915,4944408.712920986 3273149.797764646,4946283.966865066 3273655.8785869186,4947972.618733139 3274080.280822489,4949071.057870209 3275105.522264074,4952896.767191993 3275390.8923655148,4953708.980760984 3275718.486013052,4955098.598468996 3282365.302587746,4979008.234912587\n                    3285542.013115577,5089991.454384799 3139096.254297407,5093151.414429454\n                  &lt;/gml:coordinates&gt;\n                &lt;/gml:LinearRing&gt;\n              &lt;/gml:outerBoundaryIs&gt;\n            &lt;/gml:Polygon&gt;\n          &lt;/gml:polygonMember&gt;\n        &lt;/gml:MultiPolygon&gt;\n      &lt;/geometryProperty&gt;\n    &lt;/DSS2&gt;\n  &lt;/wfs:member&gt;\n&lt;/wfs:FeatureCollection&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/Batch/Examples.html",
    "href": "APIs/SentinelHub/Batch/Examples.html",
    "title": "Examples of Batch Processing Workflow",
    "section": "",
    "text": "The requests below are written in Python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCreate a batch processing request\n\nOption 1: GeoTiff format output\nThis request defines which data is requested and how it will be processed. In this particular example we will calculate maximum NDVI over two months period for an area in Corsica and visualize the results using a built-in visualizer. The resulting image will in a Geotiff format. To create a batch processing request replace &lt;MyBucket&gt; with the name of your S3 bucket and run:\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/batch/process\"\n\nevalscript = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B04\", \"B08\"]\n            }],\n            output: [{\n                id: \"default\",\n                bands: 3\n            }],\n            mosaicking: Mosaicking.ORBIT\n        }\n    }\n\n    function calcNDVI(sample) {\n        var denom = sample.B04 + sample.B08\n        return ((denom != 0) ? (sample.B08 - sample.B04) / denom : 0.0)\n    }\n\n    const maxNDVIcolors = [\n        [-0.2, 0xbfbfbf],\n        [0, 0xebebeb],\n        [0.1, 0xc8c682],\n        [0.2, 0x91bf52],\n        [0.4, 0x4f8a2e],\n        [0.6, 0x0f540c]\n    ]\n\n    const visualizer = new ColorRampVisualizer(maxNDVIcolors);\n\n    function evaluatePixel(samples) {\n        var max = 0\n        for (var i = 0; i &lt; samples.length; i++) {\n            var ndvi = calcNDVI(samples[i])\n            max = ndvi &gt; max ? ndvi : max\n        }\n        ndvi = max\n        return visualizer.process(ndvi)\n    }\n\"\"\"\n\npayload = {\n    \"processRequest\": {\n        \"input\": {\n            \"bounds\": {\n                \"bbox\": [\n                    8.44,\n                    41.31,\n                    9.66,\n                    43.1\n                ],\n                \"properties\": {\n                    \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n                }\n            },\n            \"data\": [{\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-01T00:00:00Z\",\n                        \"to\": \"2019-06-30T00:00:00Z\"\n                    },\n                \"maxCloudCoverage\": 70.0\n                },\n                \"type\": \"sentinel-2-l2a\"\n            }]\n        },\n        \"output\": {\n            \"responses\": [{\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/tiff\"\n                }\n            }]\n        },\n        \"evalscript\": evalscript\n    },\n    \"tilingGrid\": {\n        \"id\": 0,\n        \"resolution\": 60.0\n    },\n    \"bucketName\": \"&lt;MyBucket&gt;\",\n\n    \"description\": \"Max NDVI over Corsica\"\n}\n\nheaders = {\n  'Content-Type': 'application/json'\n}\n\nresponse = oauth.request(\"POST\", url, headers=headers, json = payload)\n\nresponse.json()\nExtracting the batch request id from the response:\nbatch_request_id = response.json()['id']\n\n\nOption 2: Zarr format output\nIn this example we will calculate maximum NDVI over two months period for an area in Corsica. Besides maximum NDVI, we will also return values of bands B04 and B08, which were used to calculate maximum NDVI. All three results will be stored as arrays of an output Zarr file. To create a batch processing request replace &lt;MyBucket&gt; with the name of your S3 bucket and run:\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/batch/process\"\n\nevalscript = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B04\", \"B08\"]\n            }],\n            output: [{\n                id: \"maxNDVI\",\n                sampleType: \"FLOAT32\",\n                bands: 1\n            },\n            {\n                id: \"band04\",\n                sampleType: \"UINT16\",\n                bands: 1\n            },\n            {\n                id: \"band08\",\n                sampleType: \"UINT16\",\n                bands: 1\n            }],\n            mosaicking: Mosaicking.ORBIT\n        }\n    }\n\n    function calcNDVI(sample) {\n        var denom = sample.B04 + sample.B08\n        return ((denom != 0) ? (sample.B08 - sample.B04) / denom : 0.0)\n    }\n\n    function evaluatePixel(samples) {\n        var maxNDVI = 0\n        var band04 = 0\n        var band08 = 0\n        for (var i = 0; i &lt; samples.length; i++) {\n            var ndvi = calcNDVI(samples[i])\n            if (ndvi &gt; maxNDVI){\n                maxNDVI = ndvi\n                band04 = samples[i].B04\n                band08 = samples[i].B08\n            }\n        }\n\n        return {\n            maxNDVI: [maxNDVI],\n            band04: [band04],\n            band08: [band08]\n        }\n    }\n\"\"\"\n\npayload = {\n    \"processRequest\": {\n        \"input\": {\n            \"bounds\": {\n                \"bbox\": [\n                    8.44,\n                    41.31,\n                    9.66,\n                    43.1\n                ],\n                \"properties\": {\n                    \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n                }\n            },\n            \"data\": [{\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-01T00:00:00Z\",\n                        \"to\": \"2019-06-30T00:00:00Z\"\n                    },\n                \"maxCloudCoverage\": 70.0\n                },\n                \"type\": \"sentinel-2-l2a\"\n            }]\n        },\n        \"output\": {\n            \"responses\": [{\n                \"identifier\": \"band08\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            },\n                {\n                \"identifier\": \"band04\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            },\n                {\n                \"identifier\": \"maxNDVI\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            }]\n        },\n        \"evalscript\": evalscript\n    },\n    \"tilingGrid\": {\n        \"id\": 6,\n        \"resolution\": 100.0\n    },\n    \"zarrOutput\": {\n        \"path\": \"&lt;MyBucket&gt;/&lt;requestId&gt;\",\n        \"group\": {\n            \"zarr_format\": 2\n        },\n        \"arrayParameters\": {\n            \"dtype\": \"&lt;u2\",\n            \"order\": \"C\",\n            \"chunks\": [1, 1000, 1000],\n            \"fill_value\": 0\n        },\n        \"arrayOverrides\": {\n            \"maxNDVI\": {\n                \"dtype\": \"&lt;f4\",\n                \"fill_value\": \"NaN\"\n            },\n        }\n    },\n    \"description\": \"Max NDVI over Corsica with Zarr format output\"\n}\n\nheaders = {\n  'Content-Type': 'application/json'\n}\n\nresponse = oauth.request(\"POST\", url, headers=headers, json = payload)\n\nresponse.json()\nExtracting the batch request id from the response:\nbatch_request_id = response.json()['id']\n\n\n\nGet information about all your batch processing requests\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()\n\n\nGet information about a batch processing request\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()\n\n\nGet current status of a batch processing request\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()['status']\n\n\nRequest detailed analysis (ANALYSE)\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/analyse\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\n\nGet tiles for a batch processing request (optional)\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/tiles\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()\n\n\nRequest the start of processing (START)\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/start\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\n\nGet the latest user's action for a batch processing request\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()['userAction']\n\n\nCancel a batch processing request (CANCEL)\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/cancel\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\n\nRestart a partially processed batch processing request (RESTART)\nIf case your batch processing fails only for some tiles while some are processed successfully (i.e. your batch processing request has status PARTIAL), you can restart the processing for all FAILED tiles by running the following code.\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/restartpartial\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\n\nCreate a new batch collection\nAdd the parameters cogOutput and createCollection as true to your request output. Add also description\": \"&lt;Name&gt;\" to the request, to name your collection.\n\"description\": \"&lt;Name&gt;\",\n\"output\": {\n  \"defaultTilePath\": \"s3://&lt;MyBucket&gt;/&lt;MyFolder&gt;\",\n  \"cogOutput\": true,\n  \"createCollection\": true\n}\nNote that custom collections can only contain single-band TIFFs. To create a multi-band collection, return separate bands as multiple outputs in the evalscript and connect them to multiple identifiers in the request.\nThe output format of batch requests determines the data format of the collection. By default, the output format of batch requests will be in sampleType.AUTO, which means that batch results 0..1 will be scaled to 0..255 and stored as UINT8. Processing API request on the resulting collection will thus get values 0..255 as input. We recommend you instead use FLOAT32 as the sampleType for the batch request, so the batch request output is exactly the same as what you get with a process requests on the resulting collection."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html",
    "href": "APIs/SentinelHub/BatchStatistical.html",
    "title": "Batch Statistical API",
    "section": "",
    "text": "The Batch Statistical API is available only for users with Copernicus Service accounts. Contact our Copernicus Data Space Ecosystem support to request your Copernicus Service account.\nThe Batch Statistical API (or shortly \"Batch Stats API\") enables you to request statistics similarly as with the Statistical API but for multiple polygons at once and/or for longer aggregations. A typical use case would be calculating statistics for all parcels in a country.\nSimilarly to the Batch Processing API, this is an asynchronous REST service. This means that data will not be immediately returned in the response of the request but delivered to your object storage, which needs to be specified in the request (e.g. a bucket, see bucket settings below).\nYou can find more details about the API in the API Reference or in the examples of the workflow."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#workflow",
    "href": "APIs/SentinelHub/BatchStatistical.html#workflow",
    "title": "Batch Statistical API",
    "section": "Workflow",
    "text": "Workflow\nThe Batch statistical API workflow in many ways resembles the Batch Processing API workflow. Available actions and statuses are:\n\nuser's actions ANALYSE, START and STOP.\nrequest's statuses CREATED, ANALYSING, ANALYSIS_DONE, STOPPED, PROCESSING, DONE, and FAILED.\n\nThe Batch statistical API comes with a set of REST actions that support the execution of various steps in the workflow. The diagram below shows all possible statuses of the batch statistical request and users' actions which trigger transitions among them.\n\n\n\n\nstateDiagram\n    [*]--&gt;CREATED\n    CREATED--&gt;ANALYSING: #128100; START/ANALYSE\n    state fork_state_analysis &lt;&lt;fork&gt;&gt;\n    ANALYSING --&gt; fork_state_analysis\n    fork_state_analysis --&gt; FAILED\n    fork_state_analysis --&gt; ANALYSIS_DONE\n    state fork_state_analysis_done &lt;&lt;fork&gt;&gt;\n    ANALYSIS_DONE--&gt;fork_state_analysis_done\n    fork_state_analysis_done--&gt;PROCESSING: #128100; START\n    PROCESSING--&gt; STOPPED: #128100; STOP\n    fork_state_analysis_done--&gt; STOPPED: #128100; STOP\n    PROCESSING--&gt; DONE\n    STOPPED --&gt; ANALYSIS_DONE: #128100; START\n    DONE--&gt;[*]\n    FAILED--&gt;[*]\n\n\n\n\n\nThe workflow starts when a user posts a new batch statistical request. In this step the system:\n\ncreates a new batch statistical request with status CREATED,\nvalidates the user's input (not the evalscript),\nreturns the overview of the created request.\n\nThe user can then decide to either request an additional analysis of the request or start the processing. When an additional analysis is requested:\n\nthe status of the request changes to ANALYSING,\nthe evalscript is validated,\nAfter the analysis is finished the status of the request changes to ANALYSIS_DONE.\n\nIf the user chooses to directly start processing, the system still executes the analysis but when the analysis is done it automatically starts with processing. This is not explicitly shown in the diagram in order to keep it simple.\nWhen the user starts the processing:\n\nthe status of the request changes to PROCESSING (this may take a while),\nthe processing starts,\nspent processing units are billed periodically.\n\nWhen the processing finishes, the status of the request changes to DONE.\n\nStopping the request\nA user may stop the request in following states: ANALYSING, ANALYSIS_DONE and PROCESSING. However:\n\nif the status is ANALYSING, the analysis will complete,\nif the status is PROCESSING, all features (polygons) that have been processed or are being processed at that moment are charged for,\nuser is not allowed to restart the request in the next 30 minutes.\n\n\n\nProcessing unit costs\nTo be able to create, analyse or start a request the user has to have at least 1000 processing units available in their account. If available processing units of a user drop below 1000 while request is being processed the request is automatically stopped and cannot be restarted in the next 60 minutes. Therefore it is highly recommended to start a request with a sufficient reserve.\nMore information about batch statistical costs is available here.\n\n\nAutomatic deletion of stale data\nStale (inactive) requests will be deleted after a certain period of inactivity, depending on their status:\n\nrequests with status CREATED are deleted after 7 days of inactivity\nrequests with status FAILED are deleted after 15 days of inactivity\nall other requests are deleted after 30 days of inactivity.\n\nNote that only such requests themselves will be deleted, while the requests' result (created statistics) will remain under your control in your S3 bucket."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#input-polygons-as-geopackage-file",
    "href": "APIs/SentinelHub/BatchStatistical.html#input-polygons-as-geopackage-file",
    "title": "Batch Statistical API",
    "section": "Input polygons as GeoPackage file",
    "text": "Input polygons as GeoPackage file\nThe Batch Statistical API accepts a GeoPackage file containing features (polygons) as an input. The GeoPackage must be stored in your object storage (e.g. AWS S3 bucket) and Sentinel Hub must be able to read from the storage (find more details about this in the bucket access section below). In a batch statistical request, the input GeoPackage is specified by setting the path to the .gpkg file in the input.features.s3 parameter.\nAll features (polygons) in an input GeoPackage must be in the same CRS supported by Sentinel Hub. An example of a GeoPackage file can be downloaded here."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#evalscript-and-batch-statistical-api",
    "href": "APIs/SentinelHub/BatchStatistical.html#evalscript-and-batch-statistical-api",
    "title": "Batch Statistical API",
    "section": "Evalscript and Batch statistical API",
    "text": "Evalscript and Batch statistical API\nThe same specifics as described for evalscript and Statistical API apply also for Batch statistical API.\nEvalscripts smaller than 32KB in size can be provided directly in a batch statistical request under evalscript parameter. If your evalsript exceeds this limit, you can store it to your S3 bucket and provide a reference to it in a batch statistical request under evalscriptReference parameter."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#processing-results",
    "href": "APIs/SentinelHub/BatchStatistical.html#processing-results",
    "title": "Batch Statistical API",
    "section": "Processing results",
    "text": "Processing results\nOutputs of a Batch Statistical API request are json files stored in your object storage. Each .json file will contain requested statistics for one feature (polygon) in the provided GeoPackage. You can connect statistics in a json file with corresponding feature (polygon) in the GeoPackge based on:\n\nid of a feature from GeoPackage is used as name of json file (e.g. 1.json, 2.json) and available in the json file as id property OR\na custom column identifier of type string can be added to GeoPackage and its value will be available in json file as identifier property.\n\nThe outputs will be stored in the bucket and the folder specified by output.s3.path parameter of the batch statistical request. The outputs will be available in a sub-folder named after the ID of your request (e.g. s3://&lt;my-bucket&gt;/&lt;my-folder&gt;/db7de265-dfd4-4dc0-bc82-74866078a5ce)."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#bucket-settings",
    "href": "APIs/SentinelHub/BatchStatistical.html#bucket-settings",
    "title": "Batch Statistical API",
    "section": "Bucket settings",
    "text": "Bucket settings\nAs noted above, the Batch Statistical API uses buckets to: - read GeoPackage file with input features (polygons) from a bucket, - read evalscript from a bucket (this is optional because an evalscript can also be provided directly in a request), - write results of processing to a bucket.\nOne bucket or different buckets can be used for all three purposes.\nIf you do not yet have a bucket at Copernicus Data Space Ecosystem, please follow these steps to get one.\nYou will have to configure your bucket to allow full access to Sentinel Hub. To do this, update your bucket policy to include the following statement (don’t forget to replace &lt;bucket_name&gt; with your actual bucket name):\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::ddf4c98b5e6647f0a246f0624c8341d9:root\"\n            },\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;\",\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}"
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#examples",
    "href": "APIs/SentinelHub/BatchStatistical.html#examples",
    "title": "Batch Statistical API",
    "section": "Examples",
    "text": "Examples\nExample of a Batch Statistical Workflow"
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html",
    "href": "APIs/SentinelHub/Byoc.html",
    "title": "Bring Your Own COG API",
    "section": "",
    "text": "Bring Your Own COG API is available only for users with Copernicus Service accounts. Contact our Copernicus Data Space Ecosystem support to request your Copernicus Service account."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#overview",
    "href": "APIs/SentinelHub/Byoc.html#overview",
    "title": "Bring Your Own COG API",
    "section": "Overview",
    "text": "Overview\nBring Your Own COG API (or shortly \"BYOC\") enables you to import your own data in Sentinel Hub and access it just like any other data you are used to. To be able to do so, the following conditions should be met:\n\nStore your raster data in the cloud optimized geotiff (COG) format on your own S3 bucket in the supported region.\nConfigure the bucket's permissions so that Sentinel Hub can read them.\nImport tiles using the Dashboard or API.\n\nYour data needs to be organized into collections of tiles. Each tile needs to contain a set of bands and (optionally) an acquisition date and time. Tiles with the same bands can be grouped into collections. Think of the Sentinel-2 data as a collection of Sentinel-2 tiles.\n\nA note about COG overviews used for processing\nWhen processing data, we select the nearest overview level which has higher resolution than your request, or the full resolution image.\n\n\nSentinel Hub BYOC Tool\nThe Sentinel Hub BYOC Tool is software which can be used to prepare your data for use in Sentinel Hub. It can be run either in Docker or as a Java JAR. It takes care of the entire process; it is simple to use for simple cases but is also highly configurable allowing for more complex requirements. The same steps can be done manually and are detailed below, should you prefer or require more control over the process. Get the tool here."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#converting-to-cog",
    "href": "APIs/SentinelHub/Byoc.html#converting-to-cog",
    "title": "Bring Your Own COG API",
    "section": "Converting to COG",
    "text": "Converting to COG\n\nConstraints and settings\nCOGs can contain either a single band or multiple bands. For multi-band COGs we support both planar configurations formats - chunky and planar format.\nThere are a few additional constraints in addition to having COG files. These are:\n\nThe COG header size must not exceed one megabyte.\nThe internal tile size must be between 256 x 256 and 2048 x 2048.\nThe projection needs to be one of: WGS84 (EPSG:4326), WebMercator (EPGS:3857), any UTM zone (EPSG:32601-32660, 32701-32760), or Europe LAEA (EPSG:3035).\nThe COG must not cross any of the two poles.\nThe band name should be a valid JavaScript identifier so it can be safely used in evalscripts; valid identifiers are case-sensitive, can contain Unicode letters, $, _, and digits (0-9), but may not start with a digit, and should not be one of the reserved JavaScript keywords.\nThere can be at most 100 bands.\nMulti-band COGs in chunky format can have at most 10 bands.\nThe file names need to be consistent for all tiles in a collection. For example, if you have B1.tiff in one tile then you also need B1.tiff in all the other tiles in your collection.\nAll files of each tile needs to have consistent extension (so a tile cannot contain both B1.tiff and B2.TIF).\nThe maximum allowable difference between the intersection of all file bounding boxes and each individual file is one pixel of that file [1].\nAll files of each band need to have the same bit depth.\nFiles can be compressed with DEFLATE, ZLIB, PIXTIFF_ZIP, PACKBITS or LZW compression method. JPEG compression is not supported.\nSupported sample types and bit depths are the same as those supported for outputs, as well as reading unsigned integer 1, 2, 4 bit files. See also sampleType.\n\nBands can have different resolutions.\nFor best performance we recommend the following setting for COGs: deflate compressed with 1024x1024 pixel internal tiling.\n\n[1]: Here's one example of files with slightly different bounding boxes. One file has the bounding box [0, 0, 10, 10] and resolution of one meter per pixel, and the other file has the bounding box [0.5, 0.5, 10.5, 10.5] and 0.5 meter resolution. The intersection [0.5, 0.5, 10, 10] is not more than one pixel away from each individual file, therefore such files are valid for BYOC.\n\n\n\nGDAL example command\nCOGs can be generated in a single step with GDAL 3.1 or newer using the COG raster driver. For older GDAL versions or if you want planar multi-band COGs, see below. Even though you can use any GDAL version, we highly recommend you use v3.1 or newer, as older versions have issues with average downsampling (see https://gdal.org/programs/gdaladdo.html).\nThe input file must conform to the constraints regarding the projection, units per pixel, and pixel formats. To generate a COG from an input file:\ngdal_translate -of COG -co COMPRESS=DEFLATE -co BLOCKSIZE=1024 -co RESAMPLING=AVERAGE -co OVERVIEWS=IGNORE_EXISTING input.extension output.tiff\nAdditional parameters may be needed:\n\nif the input file contains multiple bands, but you only need one or only some of them, add -b &lt;bandA&gt; -b &lt;bandB&gt; ..., where &lt;bandX&gt; is the band number, starting from 1.\nif your input data has nodata values, add them to this command using: -a_nodata NO_DATA_VALUE, e.g. for zero: -a_nodata 0.\nfor many types of data adding a predictor can further reduce the file size. It is best to test this on your own data, to enable the predictor add -co PREDICTOR=YES.\n\nMulti-band COGs generated this way, are encoded in chunky format and you cannot change it to planar format. To get a COG in planar format, follow the next chapter.\n\nOlder GDAL versions or planar multi-band COGs\nFor GDAL older than 3.1 or if you want planar multi-band COGs, multiple commands are needed. To extract individual bands, add -b &lt;band&gt;, where &lt;band&gt; is the band number, starting from 1, to the first command.\ngdal_translate -of GTIFF input.extension intermediate.tiff\n\n\n\n\n\n\nNote\n\n\n\nIf your input data has nodata values, add them to this command using: -a_nodata NO_DATA_VALUE, e.g. for zero: -a_nodata 0.\n\n\ngdaladdo -r average --config GDAL_TIFF_OVR_BLOCKSIZE 1024 intermediate.tiff 2 4 8 16 32\n(The number of overview levels you need depends on your source data. A good rule of thumb is to have as many overview levels as necessary for the entire source image to fit on one 1024x1024 tile).\ngdal_translate -co TILED=YES -co COPY_SRC_OVERVIEWS=YES --config GDAL_TIFF_OVR_BLOCKSIZE 1024 -co BLOCKXSIZE=1024 -co BLOCKYSIZE=1024 -co COMPRESS=DEFLATE intermediate.tiff output.tiff\nTo generate a planar multi-band COG, add -co INTERLEAVE=BAND. For chunky format, you don't need to pass anything, as this is the default format.\n\n\n\n\n\n\nNote\n\n\n\nfor many types of data adding a predictor can further reduce the file size. It is best you test this on your own data. To enable the predictor, add to the above command -co PREDICTOR=2 for integers, and -co PREDICTOR=3 for floating points.\n\n\nOnce the commands finish, you can delete the intermediate.tiff file.\nFor more information about each command see the GDAL documentation:\n\ngdal_translate\ngdaladdo"
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#bucket-settings",
    "href": "APIs/SentinelHub/Byoc.html#bucket-settings",
    "title": "Bring Your Own COG API",
    "section": "Bucket settings",
    "text": "Bucket settings\nIf you do not yet have a bucket at Copernicus Data Space Ecosystem, please follow these steps to get one.\nYou will have to configure your bucket to allow read access to Sentinel Hub. To do this, update your bucket policy to include the following statement (don’t forget to replace &lt;bucket_name&gt; with your actual bucket name):\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::ddf4c98b5e6647f0a246f0624c8341d9:root\"\n            },\n            \"Action\": [\n                \"s3:GetBucketLocation\",\n                \"s3:ListBucket\",\n                \"s3:GetObject\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;\",\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}\nA python script to set a bucket policy can be downloaded here."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#configuring-collections",
    "href": "APIs/SentinelHub/Byoc.html#configuring-collections",
    "title": "Bring Your Own COG API",
    "section": "Configuring collections",
    "text": "Configuring collections\nWhen creating a collection:\n\nyou need to provide the S3 bucket where you data is; if you have data in CreoDIAS or CODE-DE, prefix the bucket name by your CreoDIAS or CODE-DE Project ID as follows: PROJECT_ID:bucket_name ,\nyou can define bands, but only using BYOC API,\nyou can provide the no data value using Dashboard or BYOC API.\n\nThe no data value cannot be configured to NaN (not a number). However, there is no need to do this, as NaNs are by default treated as no data value.\n\nAutomatic configuration\nIf bands are not configured, BYOC service automatically configures them based on the files of the first ingested tile. In this case the bands are named after the files, while for multi-band files the band index in 1-based numbering is also added at the end. For example, the bands in a multi-band file named RGB.tiff would be named RGB_1, RGB_2, etc. You can rename any band later.\nIn this process, the service also configures the \"no data\" value, if it's not set by the user. The service automatically extracts \"no data\" values from the TIFF tag GDAL_NODATA (TIFF entry ID = 42113) of the files of the first ingested tile, and sets the value as the collection \"no data\" value, if all files have the exactly same value and if the value is a number. Otherwise, it sets values per band.\n\n\nManual band configuration\nThe below example shows how to configure manually instead of relying on the automatic configuration described above. Suppose your tiles are composed of two files - \"RGB.tiff\" with three 16-bit bands and \"CLOUD_MASK.tiff\" with a single 8-bit band. You would provide such configuration in additionalData.bands field of a new collection:\n{\n  \"Red\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 16\n  },\n  \"Green\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 2,\n    \"bitDepth\": 16\n  },\n  \"Blue\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 3,\n    \"bitDepth\": 16\n  },\n  \"CloudMask\": {\n    \"source\": \"CLOUD_MASK\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 8\n  }\n}\nThe keys \"Red\", \"Green\", \"Blue\", and \"CloudMask\" are the names of the bands that you are going to use in evalscripts. These names can be changed at any time. Inside each band specification you specify where the band is stored using the fields source and bandIndex. The source, together with tile path, defines the file (see below for details), while bandIndex is the band index in 1-based numbering.\n\n\nBand renaming\nBands can be easily renamed in Dashboard. To do this using API, you need to provide the same band specs, but with new names. To obtain the current band specs, use this endpoint. For example, let's say your bands are defined like this, and you would like to rename bands \"RGB_1\", \"RGB_2\", \"RGB_3\" to \"Red\", \"Green\", and \"Blue\", respectively:\n{\n  \"RGB_1\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 16\n  },\n  \"RGB_2\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 2,\n    \"bitDepth\": 16\n  },\n  \"RGB_3\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 3,\n    \"bitDepth\": 16\n  },\n  \"CLOUD_MASK\": {\n    \"source\": \"CLOUD_MASK\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 8\n  }\n}\nTo achieve this, you need to use this endpoint. You need to provide the new names at the top level, but leave the band properties (\"source\", \"bandIndex\", etc) and values the same. So the content of additionalData.bands would be:\n{\n  \"Red\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 16\n  },\n  \"Green\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 2,\n    \"bitDepth\": 16\n  },\n  \"Blue\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 3,\n    \"bitDepth\": 16\n  },\n  \"CLOUD_MASK\": {\n    \"source\": \"CLOUD_MASK\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 8\n  }\n}\nKeep in mind:\n\nthat the bucket cannot be changed after the collection is created,\nthat once bands have been configured you can only change band names or remove bands,\nand that the no data value can be changed at anytime using Dashboard or BYOC API.\n\n\n\nConfiguring band sample format\nThe sample format is TIFF info that defines the band data type. It can be set to signed integers, unsigned integers, or floating points. Learn more about sample format here. These values are in BYOC defined as INT, UINT and FLOAT, respectively.\nYou can configure format manually in BYOC using API or Dashboard. If not set, it will get set to the value of the first ingested tile.\nTo configure it manually, set sampleFormat field for each band like this:\n{\n  \"Red\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 16,\n    \"sampleFormat\": \"INT\"\n  },\n  \"Green\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 2,\n    \"bitDepth\": 16,\n    \"sampleFormat\": \"INT\"\n  },\n  \"Blue\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 3,\n    \"bitDepth\": 16,\n    \"sampleFormat\": \"INT\"\n  },\n  \"CLOUD_MASK\": {\n    \"source\": \"CLOUD_MASK\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 8,\n    \"sampleFormat\": \"UINT\"\n  }\n}\nAfter formats are set, the formats of all new files must match the formats defined in BYOC. If they do not match, files do not get ingested."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#ingesting-the-tiles",
    "href": "APIs/SentinelHub/Byoc.html#ingesting-the-tiles",
    "title": "Bring Your Own COG API",
    "section": "Ingesting the tiles",
    "text": "Ingesting the tiles\nThere are two ways of doing this. The easier version is using the dashboard.\nTo create a new collection click the New collection button. The name can be anything and is there for your own reference. The S3 bucket name is the bucket name containing your data.\nOnce the collection is created you can add tiles. Note that only a single tile can be added in one step.\nTo add a tile, click the Add tile button. Provide a path to the COG files inside the s3 bucket. For example, if your files are stored in s3://bucket-name/folder/, simply set folder as the tile path. Optionally, set the sensing time of the tile here as well.\nWhen the tile is ingested its path will be automatically changed to folder/(BAND).tiff or similar, depending on the extension of the files in folder. Note that (BAND) is a placeholder that is replaced by the source of a band to obtain the actual file where the band is stored. In the example above your collection uses sources \"RGB\" and \"CLOUD_MASK\", thus the two files of the tile will be folder/RGB.tiff and folder/CLOUD_MASK.tiff.\nFor more complicated cases you must provide the path with the (BAND) placeholder and extension. For example, suppose your folder contains the files for multiple tiles:\n\ns3://bucket-name/folder/tile_1_B1_2019.tif,\ns3://bucket-name/folder/tile_1_B2_2019.tif,\ns3://bucket-name/folder/tile_2_B1_2019.tif,\ns3://bucket-name/folder/tile_2_B2_2019.tif.\n\nCreate the first tile with the path folder/tile_1_(BAND)_2019.tif to use the first two files and the second tile with the path folder/tile_2_(BAND)_2019.tif to use the next two files.\nDo not forget that all tiles must contain the same set of files (with different data of course); that is, if a tile is missing one or more files it will fail to ingest.\nTo ingest tiles via API requests instead of the dashboard, see BYOC API reference or Python examples.\n\nA note about changing files\nWhile you may freely modify the data in your buckets, for it to continue to work reliably through Sentinel Hub you need to reingest tiles with changed data. You can do this in Dashboard, by clicking the \"Refresh\" button next to the tile, or using the API, by calling the reingest endpoint with the collection and tile id. This is needed as it will update metadata required for processing and failing to do so can result in odd behavior.\n\n\nA note about cover geometries\nEach tile ingested also requires a cover geometry. A cover geometry is a geometry which outlines the valid data part of the tile. Nodata therefore should not be contained in the cover geometry. In the simplest case, the cover geometry will equal the bounding box of the file being ingested.\nThe cover geometry is important because it tells the system where it can expect to find data. As a consequence, this determines how data is rendered where tiles overlap. If you have tiles with overlapping cover geometries, only the data from one tile can be rendered where two (or more) cover geometries intersect. This is true even if this data is nodata or if it lies outside the tile bounding box. Having quality cover geometries is therefore important for collections where many tiles containing nodata overlap. Not all cases need precise cover geometries, however. A single tile or a regularly gridded collection with a single date and coordinate reference system can get away with cover geometries equalling the bounding box.\n\n\n\n\nOverlapping tiles\n\n\nIf the cover geometry is not specified during ingestion it will automatically be set to the tile bounding box. Sentinel Hub will not attempt to generate a more precise geometry as it is impossible to prepare such a process which will work well for all users. It is therefore your responsibility to provide quality cover geometries and in doing so allow you to extract the most out of your data. If ingesting tiles using the API, set the cover geometry using the coverGeometry field in the API request. It must be in the GeoJSON format and in a projected or geodetic coordinate reference system which is supported by Sentinel Hub. Cover geometries in practice mean one polygon or multipolygon. They must also contain no more than 100 points.\n\nGenerating cover geometries\n\nGDAL\nOne way of getting a cover geometry is using the GDAL utility script gdal_trace_outline which takes a raster and returns a cover geometry in the WKT format. This then needs to be converted to GeoJSON. In this example a single band file is traced:\ngdal_trace_outline band.tif -out-cs en -wkt-out wkt.txt\nThe process might take a while if you have a large file. To speed up the process you can pass a subsampled file which you can get with gdal_translate. To get a file that is 1% of the original size:\ngdal_translate band.tif subsampled.tif -outsize 1% 1%\nor if it's stored on AWS S3:\ngdal_translate /vsis3/bucket-name/folder/band.tif subsampled.tif -outsize 1% 1%\nNote that calculating the cover geometry on subsampled rasters may not be sufficiently accurate for touching but not intersecting tiles as the imprecision caused by downsampling may leave gaps.\nFinally, you need to convert the WKT file to GeoJSON and specify the CRS under crs.properties.name (except when WGS84 when it can be omitted). CRSs with the EPSG code &lt;EpsgCode&gt; should be specified as urn:ogc:def:crs:EPSG::&lt;EpsgCode&gt;. Here is a GeoJSON example in ESPG:32633.\n{\n    \"type\": \"MultiPolygon\",\n    \"crs\": {\n        \"type\": \"name\",\n        \"properties\": {\n            \"name\": \"urn:ogc:def:crs:EPSG::32633\"\n        }\n    },\n    \"coordinates\": [\n        [\n            [\n                [\n                    370270.52147506207,\n                    5085707.891369364\n                ],\n                ...\n            ]\n        ]\n    ]\n}\n\n\nSentinel Hub BYOC Tool\nThe Sentinel Hub BYOC Tool can also help you update the cover geometry of existing tiles on Sentinel Hub. Use the set-coverage command. On Docker, get help and parameters by running: docker run sentinelhub/byoc-tool set-coverage --help\n\n\n\nWorkarounds\nIn case your input data is complex and cannot be adequately simply outlined it is nevertheless possible to obtain pixel-precise rendering. In this case, set the cover geometry to any which covers all the valid input pixels. The file bounding box as the default is such an example. What follows is doing the mosaicking in the custom script with the help of dataMask.\nFirst, set the mosaicking parameter within setup to TILE (mosaicking: Mosaicking.TILE) and add the dataMask to the array of input bands.\nThen use something like the following as your evalscript. Since dataMask precisely determines which pixels are valid and which ones are not, the moment a valid pixel is found this can be returned, alternatively the next scene should be checked.\nfunction evaluatePixel(samples, scenes) {\n  for (let i = 0; i &lt; samples.length; i++) {\n    let sample = samples[i];\n    if (sample.dataMask == 1) {\n      return someCombination(sample);\n    }\n  }\n  return someNodataValueArray;\n}\nOptionally, you may additionally use the preProcessScenes function to potentially reduce the number of tiles which will be processed. This is useful to set an upper limit for the number of processing units which will be used. The following limits the maximum number of tiles to 5, for example.\nfunction preProcessScenes (collections) {\n  collections.scenes.tiles = collections.scenes.tiles.splice(5);\n  return collections;\n}\nNote that getting data in such a manner will use more processing units than SIMPLE mosaicking with precise cover geometries."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#collection-metadata",
    "href": "APIs/SentinelHub/Byoc.html#collection-metadata",
    "title": "Bring Your Own COG API",
    "section": "Collection metadata",
    "text": "Collection metadata\nCollections have the following metadata available under additionalData:\n\nextent: the collection extent in WGS84\nhasSensingTimes: information if tiles have sensing time\nfromSensingTime the sensing time in ISO 8601 of the least recent tile\ntoSensingTime: the sensing time in ISO 8601 of the most recent tile\n\nThe metadata is updated in a few minutes after a tile is added or removed. To find out if your collection requires metadata updates, check out the flag requiresMetadataUpdate."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#tutorials-and-other-related-materials",
    "href": "APIs/SentinelHub/Byoc.html#tutorials-and-other-related-materials",
    "title": "Bring Your Own COG API",
    "section": "Tutorials and Other Related Materials",
    "text": "Tutorials and Other Related Materials\nSee our beginner BYOC webinar, where you will learn step-by-step how to prepare and ingest raster data with Sentinel Hub, make API requests to your data and visualize it.\nThis BYOC tutorial notebook is a simple walk-through on creating, updating, listing, and deleting your data collections through Python using Sentinel Hub Python package."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#examples",
    "href": "APIs/SentinelHub/Byoc.html#examples",
    "title": "Bring Your Own COG API",
    "section": "Examples",
    "text": "Examples\nBYOC API Examples"
  },
  {
    "objectID": "Roadmap/APITable.html",
    "href": "Roadmap/APITable.html",
    "title": "APIs",
    "section": "",
    "text": "API\n            Type\n            Jan-23\n            Mar-23\n            Apr-23\n            Jul-23\n            Oct-23\n            Nov-23\n            Dec-23\n            May-24\n            Jul-24\n        \n        \n        \n        \n            Product search and download\n            OData\n            Search and full product download\n            \n            \n            Search and product download(full and partial)\n            \n            \n            \n            \n            \n        \n        \n\n            OpenSearch (Resto)\n            Search and full product download\n            \n            \n            Search and product download(full and partial)\n            \n            \n            \n            \n            \n        \n        \n\n            STAC items\n            \n            \n            Fully available\n            \n            \n            \n            \n            \n            \n        \n        \n\n            STAC API\n            \n            \n            Fully available\n            \n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Catalog API\n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n            \n        \n        \n\n            S3\n            \n            \n            Fully available\n            \n            \n            \n            \n            \n            \n        \n        \n\n            S3fs\n            \n            \n            \n            Fully available\n            \n            \n            \n            \n            \n        \n        \n            Data processing\n            Sentinel Hub data collection support\n            \n            \n            Sentinel-1 GRD, Sentinel-2 L1C/L2A, Sentinel-3 OLCI and SLSTR Level 1, Sentinel-5p\n            Sentinel-1 and Sentinel-2 cloudless mosaics, Bring your own COG/Zarr.\n            \n            Landsat Collection 2, MODIS, Third party data\n            \n            \n            Sentinel-3 OLCI and SLSTR Level 2\n        \n        \n\n            Sentinel Hub OGC API\n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Process API\n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Asynchronous Process API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Batch Processing API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Statistical API\n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Batch Statistical API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Bring your own COG API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Bring your own Zarr API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n        \n\n            openEO API\n            \n            \n            \n            Available for Sentinel-1 GRD, Sentinel-2 L1C/L2A, Sentinel-3 OLCI Level 1, Sentinel-5p NTC Level 2\n            \n            Available for all data collections supported by Sentinel Hub, SPOT-VGT, PROBA-V and ESA WorldCover.\n            \n            \n            \n        \n        \n        \n            On Demand Production\n            Sentinel 1 Production\n            \n            \n            \n            \n            The on-demand processing software will be available for the users, integrated with the data interfaces, data catalog and ordering mechanism. \n            \n            \n            \n            \n        \n        \n            Sentinel 2 Production\n            \n            \n            \n            \n            The on-demand processing software will be available for the users, integrated with the data interfaces, data catalog and ordering mechanism. \n            \n            \n            \n            \n        \n        \n            Sentinel 3 Production\n            \n            \n            \n            \n            The on-demand processing software will be available for the users, integrated with the data interfaces, data catalog and ordering mechanism. \n            \n            \n            \n            \n        \n        \n        \n        \n            Traceability\n            Traceability\n            \n            Start of registering of traces of published fresh data available for new ingested data.\n            \n            Traceability Service operational for the Data Access.Registered traces for all published User Level Data (excluding historical data). Service is operational for verification for any user. Traces service for registering traces is available only for DAS services\n            \n            \n            Traceability service is operational also for registering traces for all ESA GS services allowing to register and verify traces\n            Registered traces for all historical User Level data"
  },
  {
    "objectID": "Applications/JupyterHub.html",
    "href": "Applications/JupyterHub.html",
    "title": "Jupyter Hub",
    "section": "",
    "text": "JupyterHub is a platform that provides an environment for creating, managing, and terminating Jupyter Notebooks. It acts as a central hub or server that handles the setup of user-specific notebook instances. Users access their notebooks through Jupyterlab or Jupyter Notebooks. The hub itself handles the underlying management tasks, such as allocating resources, handling user authentication, and starting or stopping notebook instances as needed.\nRegistered Copernicus Data Space Users have access to JupyterLab and Jupyter Notebooks free of charge at a limited capacity of resources beneath."
  },
  {
    "objectID": "Applications/JupyterHub.html#jupyter-notebook-and-jupyterlab",
    "href": "Applications/JupyterHub.html#jupyter-notebook-and-jupyterlab",
    "title": "Jupyter Hub",
    "section": "Jupyter Notebook and JupyterLab",
    "text": "Jupyter Notebook and JupyterLab\nJupyter Notebooks serve as an accessible entry point for both non-programmers and developers who want to quickly prototype their EO data processing. They provide a user-friendly interface, integrating well with Python SDK services like Sentinel Hub and OpenEO. Each Notebook has direct access to the EO Data repository, and example notebooks are available to facilitate data interaction. To handle tool dependencies and library versions, multiple notebook kernels are provided and regularly updated with the provided samples. This eliminates the need for users to handle dependency installations, enabling immediate prototyping without technical obstacles.\nJupyterLab is an advanced interactive development environment (IDE) that offers a flexible and feature-rich interface for working with Jupyter notebooks, code, and data. It surpasses the traditional Jupyter Notebook interface, providing a modern and comprehensive user experience. JupyterLab allows users to organize their workspaces using a flexible layout system with panels, views, and tabs for various activities. It supports various document formats, including Jupyter notebooks, text files, code files, and markdown files. With its modular and extensible architecture, JupyterLab enables customization through extensions, additional functionalities, and integration with external tools. It enhances the user experience with features like a file browser, command palette, debugger, and console, making it a versatile tool for interactive data exploration, analysis, and scientific computing.\nUser can access the Jupyter environment when clicked on this link: https://jupyterhub.dataspace.copernicus.eu/\n\nWhen you click the “SIGN IN WITH KEYCLOAK” button, you will be directed to the Copernicus Dataspace login window. Here you can use your Copernicus Dataspace Ecosystem Credentials."
  },
  {
    "objectID": "Applications/JupyterHub.html#notebook-flavors",
    "href": "Applications/JupyterHub.html#notebook-flavors",
    "title": "Jupyter Hub",
    "section": "Notebook flavors",
    "text": "Notebook flavors\nWhen you log in to Jupyter Hub you are presented with a choice of 3 flavors of the Jupyter instances: Small, Medium and Large. The size of the instance is determined by number of resources available to the notebook kernels run by the user - CPU cores and memory. All flavors are suitable for performing typical tasks and will be capable of running all samples provided in /samples folder. To ensure fair use of resources by the CDSE users, it is recommended to start with the Small flavor and switch to a bigger only when you experience issues with kernel crashing due to the lack of available memory."
  },
  {
    "objectID": "Applications/JupyterHub.html#jupyterlab-user-interface",
    "href": "Applications/JupyterHub.html#jupyterlab-user-interface",
    "title": "Jupyter Hub",
    "section": "JupyterLab User Interface",
    "text": "JupyterLab User Interface\nOnce you have successfully signed in, you will be presented with a launcher that offers various Python environments to work in, including Python 3, Geo science, OpenEO, and Sentinel Hub. Each environment is equipped with specific Python packages tailored to different requirements. You can choose to run your code either in a notebook or a console, depending on your preference. Additionally, the launcher provides options to create text files, markdown files, or Python files, allowing you to work with different types of documents as needed.\n\n\nMain Work Area: The main work area in JupyterLab is the central portion of the interface where users perform their tasks. It consists of tabs representing open documents like notebooks, code files, and markdown files. These tabs can be arranged and docked within the work area, allowing users to customize their workspace to suit their needs and preferences.\nSidebar: The sidebar, located on the left side of the interface, provides additional functionality and information. It houses various panels, including a file browser for easy navigation through files and folders, a list of running kernels and terminals, and a table of contents for quick access to different sections of a notebook or document.\nLauncher: The launcher is a central component that enables users to create new documents and launch different activities. Users can access other useful activities such as a command palette for executing commands, a file finder for quickly locating specific files, and a help panel for accessing documentation and assistance.\nMenu Bar: The menu bar, located at the top of the interface, provides a set of menus with various options. Users can perform file operations, edit documents, configure the appearance and behavior of JupyterLab, manage kernels for code execution, and access other advanced features.\nContextual Tabs: Contextual tabs are dynamic and appear top of each notebook, as in the above figure for the .ipynb file. These tabs provide relevant options and settings specific to the selected item, allowing users to perform actions and configurations directly within the interface.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nUsers can drag files from the file browser and drop them into notebooks or code files to import them seamlessly. Additionally, cells within a notebook can be rearranged by simply dragging and dropping them to different positions, facilitating the organization and structuring of notebook content.\n\n\n\nThese components collectively form the JupyterLab user interface, providing users with a flexible and customizable workspace for working with notebooks, code, and data."
  },
  {
    "objectID": "Applications/JupyterHub.html#creating-and-managing-notebooks",
    "href": "Applications/JupyterHub.html#creating-and-managing-notebooks",
    "title": "Jupyter Hub",
    "section": "Creating and Managing Notebooks",
    "text": "Creating and Managing Notebooks\nBy default, sample notebooks are provided in the folder samples.\nTo create a notebook in JupyterLab, you can easily select your desired kernel from the Notebook section in the launcher. Simply click on the kernel you want, and a new notebook named “Untitled. ipynb” will be created. If you wish to rename the notebook, you can do so by right-clicking on the notebook name in the sidebar and selecting the “rename” option. This gives your notebook a more meaningful and descriptive name for better organisation and clarity."
  },
  {
    "objectID": "Applications/JupyterHub.html#installing-additional-packages",
    "href": "Applications/JupyterHub.html#installing-additional-packages",
    "title": "Jupyter Hub",
    "section": "Installing additional packages",
    "text": "Installing additional packages\nYou can install additional Python packages if necessary. This can be done both from the Notebook Terminal, which is located in the Launcher tab or within a Notebook cell. For e.g.:\n\nTerminalNotebook\n\n\npip install required_package\n\n\n!pip install required_package"
  },
  {
    "objectID": "Applications/JupyterHub.html#markdown-and-rich-text",
    "href": "Applications/JupyterHub.html#markdown-and-rich-text",
    "title": "Jupyter Hub",
    "section": "Markdown and Rich Text",
    "text": "Markdown and Rich Text\nIn JupyterLab, you can create Markdown and rich text content either in a separate file or directly within Jupyter notebooks.\nIf you prefer to work with a separate file, you can create a new Markdown (.md) or text (.txt) from the launcher or right click on the side bar and New file. Open the file and start writing your Markdown content using the Markdown syntax. Once you’ve written your content, you can save the file and preview it by double-clicking on it in the file browser, which will open a preview pane showing the rendered Markdown.\nAlternatively, you can include Markdown and rich text directly within Jupyter Notebooks. In a notebook, you can create a new cell and change its type to “Markdown” using the cell type dropdown in the toolbar or by pressing M. Then, you can write your Markdown content in the cell using the Markdown syntax. To preview the rendered Markdown, you can either run the cell by pressing Shift + Enter, or use the “Preview” option from the cell’s context menu to see the rendered content without executing the cell’s code."
  },
  {
    "objectID": "Applications/JupyterHub.html#collaboration-and-sharing",
    "href": "Applications/JupyterHub.html#collaboration-and-sharing",
    "title": "Jupyter Hub",
    "section": "Collaboration and Sharing",
    "text": "Collaboration and Sharing\nJupyterLab allows collaborative work with the functionality to share it with multiple users. They can edit and view the same notebooks or projects in real-time. JupyterLab also offers various sharing options, including exporting notebooks to different formats (HTML, PDF, Markdown) and publishing them on platforms like GitHub or JupyterHub. These features empower users to easily share their work, communicate findings, and collaborate with a broader audience, promoting efficient collaboration and seamless knowledge dissemination.."
  },
  {
    "objectID": "Applications/JupyterHub.html#basic-notebook-commands",
    "href": "Applications/JupyterHub.html#basic-notebook-commands",
    "title": "Jupyter Hub",
    "section": "Basic notebook commands",
    "text": "Basic notebook commands\nWorking with a Notebook is pretty convenient and the supporting text should enable a quick understanding of the presented code. Some basic Notebook commands are listed below:\n\n\n\nKeyboard Shortcut\nCommand\n\n\n\n\nCtrl + Enter\nRun cell\n\n\nA\nInsert cell above current cell\n\n\nB\nInsert cell below current cell\n\n\nC\nCopy cell code\n\n\nV\nPaste cell code\n\n\nDD\nDelete selected cell\n\n\nM\nChange cell to Markdown (text) mode"
  },
  {
    "objectID": "Applications/JupyterHub.html#storage",
    "href": "Applications/JupyterHub.html#storage",
    "title": "Jupyter Hub",
    "section": "Storage",
    "text": "Storage\nWhen you start the notebook, in the file navigation pane (the sidebar - #2) you will see three folders:\n\nmystorage\nsamples\n\n\nThe availability of all other folders will be limited to your current session only. See the next chapter on more information on session persistence.\n\n\nmystorage\nThis is a persistent storage with 10GB of space, which is automatically created for each user during the first login to Jupyter Hub. The storage is hosted in the CloudFerro cloud and can be used to save notebooks between the sessions, store the results or uploaded data files. This storage area is preserved when you logout and the Jupyter kernel is shut down due to inactivity. It will be kept for up to 15 days from your last login, and you will receive a notification to log in to Jupyter Hub to reset the timer and keep the data preserved. If you do not log in, then after 15 days your files will be deleted from CloudFerro cloud storage.\n\n\nsamples\nThese folders are recreated with every start of the Jupyter kernel. The samples folder is always up-to-date with the latest version of notebooks. If you make changes to the samples please make sure to save the updated notebook in the mystorage area to make sure you can use it when you get back after period of incativity."
  },
  {
    "objectID": "Applications/JupyterHub.html#session-persistence",
    "href": "Applications/JupyterHub.html#session-persistence",
    "title": "Jupyter Hub",
    "section": "Session persistence",
    "text": "Session persistence\nThe Jupyter instance will be running as long as you interact with it, and will be kept alive for another 8 hours after your last activity. After this time the instance will be shut-off and you will need to launch it during the next log in. All data saved in mystorage will be preserved but all other files will be deleted and additional packages (dependencies) which were installed using pip need to be reinstalled."
  },
  {
    "objectID": "Applications/JupyterHub.html#tips-and-tricks",
    "href": "Applications/JupyterHub.html#tips-and-tricks",
    "title": "Jupyter Hub",
    "section": "Tips and tricks",
    "text": "Tips and tricks\n\nSwitching from Jupyter Lab to Jupyter Notebook\nIf you would like to switch to the Jupyter Notebook interface, you can modify the URL in your home directory. Simply change the last part of the URL address from “lab” to “tree”. For example, you can change https://jupyterhub.dataspace.copernicus.eu/user/username/lab/ to https://jupyterhub.dataspace.copernicus.eu/user/username/tree/. This way, you can easily access the Jupyter Notebook interface if desired."
  },
  {
    "objectID": "Applications/JupyterHub.html#resources-and-references",
    "href": "Applications/JupyterHub.html#resources-and-references",
    "title": "Jupyter Hub",
    "section": "Resources and References:",
    "text": "Resources and References:\nHere are some helpful links for effectively using Jupyter Lab in Copernicus Dataspace Ecosystem:\n\nJupyterLab Documentation\nJupyter Notebook Documentation\nJupyter Notebook Documentation\nBasic Notebook Tutorials"
  },
  {
    "objectID": "Applications/PlazaDetails/CreateAccount.html",
    "href": "Applications/PlazaDetails/CreateAccount.html",
    "title": "Create an account",
    "section": "",
    "text": "If you haven’t previously registered and created an account, you need to click on the Register navigation option on the main openEO algorithm plaza portal landing page and this will launch the registration flow."
  },
  {
    "objectID": "Applications/PlazaDetails/CreateAccount.html#sign-up",
    "href": "Applications/PlazaDetails/CreateAccount.html#sign-up",
    "title": "Create an account",
    "section": "",
    "text": "If you haven’t previously registered and created an account, you need to click on the Register navigation option on the main openEO algorithm plaza portal landing page and this will launch the registration flow."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageProfile.html",
    "href": "Applications/PlazaDetails/ManageProfile.html",
    "title": "Manage your profile",
    "section": "",
    "text": "As a user, you want to be able to view and update your profile settings, including the security aspects (Passphrase).\n\nYou arrive at this page by clicking on the user’s avatar (top right-hand corner of the openEO algorithm plaza portal screen). You will be able to see a sub-navigation menu with options (Overview, Security, Team, Organization) and a logout icon."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html",
    "href": "Applications/PlazaDetails/ServiceMaturity.html",
    "title": "Service Maturity",
    "section": "",
    "text": "All the services on the openEO algorithm plaza are assigned a maturity level that indicates what users can expect from the service in regard to its performance and metadata. Currently, we have five different maturity levels for each service, namely Prototype being the primary and default level, followed by Incubating, Verified, Validated and Operational as advanced services. These levels are determined solely based on software readiness and user documentation criteria. These criteria are generally designed to ensure that the service meets specific standards and provides customers with a certain level of quality."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-1-prototype",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-1-prototype",
    "title": "Service Maturity",
    "section": "Level 1: Prototype",
    "text": "Level 1: Prototype\nBy default, every published service will have a prototype level. It is expected that service providers consider the following points when publishing a service:\n\nThe service is executable, and basic logging information is supported.\nA possible reference or a general overview of what it tries to implement is provided as service metadata.\n\n\nIf your service satisfies the criteria for a higher level, you can request an upgrade anytime once your service is published. Nevertheless, please note that every criterion must be satisfied for an upgrade."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-2-incubating",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-2-incubating",
    "title": "Service Maturity",
    "section": "Level 2: Incubating",
    "text": "Level 2: Incubating\nIn addition to the criteria for prototype level, a few additional criteria, as mentioned below, need to be satisfied to be upgraded to incubating service.\n\nService metadata should also include an example of executing the service along with the expected output format.\nAn approximate assumption on how much user credit is required to execute a service should be provided.\n\n\nNote that no added value will be associated with services with a prototype or incubating levels. In other words, approximate credit will include added value cost only on services that are either verified, validated or operational."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-3-verified-or-validated",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-3-verified-or-validated",
    "title": "Service Maturity",
    "section": "Level 3: Verified or Validated",
    "text": "Level 3: Verified or Validated\nWhen a service is labelled as either verified or validated, they mark the same level of maturity. Users can expect the same level of performance from them, but the naming difference is due to its irrelevance/relevance to software validation reports as a part of user documentation.\n\nLevel 3a: Verified\n\nA comprehensive functional and integration test should be possible.\nThere should be advanced logging that could help while debugging.\nService metadata should include information on detailed descriptions of the services, their parameters and a link to a publication that supports the methodology adopted. An example of executing service expected outcome should be provided in a similar manner to that of incubating service.\nApproximate cost estimation on a larger scale should be presented.\n\n\nPlease mention or provide a report to the support team if there exist any constraints/limitations with the services that should be considered.\n\n\n\nLevel 3b: Validated\n\nAll the criteria mentioned for the verified level are applicable to this level, along with the additional criteria that the validation report should be provided either as a separate document to the support team or a non-expiring link.\n\n\nAlthough services can be either of verified or validated type, i.e. if a service satisfies all the criteria mentioned under verified but does not provide a validation report despite being relevant to them will be labelled as incubating."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-4-operational",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-4-operational",
    "title": "Service Maturity",
    "section": "Level 4: Operational",
    "text": "Level 4: Operational\nA highly improved service can only be marked with the highest level of maturity i.e. operational, when it fully satisfies the following criteria:\n\nAll the conditions to be either verified or validated should be satisfied.\nThe service has been shown to fit large-scale production and integration in an operating system.\nRules and constraints for estimating resource usage should be provided as a document to the support team.\nService lifecycle management policy should be available for the end users.\nAn article summarising the process used for the service should be available on a peer-reviewed website or journal or a conference article (There is no limitation to a specific journal, but proof that the article was peer-reviewed should be provided to the openEO algorithm plaza support service)."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#requesting-a-change-of-the-maturity-level",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#requesting-a-change-of-the-maturity-level",
    "title": "Service Maturity",
    "section": "Requesting a change of the maturity level",
    "text": "Requesting a change of the maturity level\nBased on the fulfilment of the above criteria, service providers can request an upgrade of the service by submitting a ticket at our help center."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html",
    "href": "Applications/PlazaDetails/ManageService.html",
    "title": "Manage your services",
    "section": "",
    "text": "You arrive here by clicking on Services on the sub-navigation options of the portal. In addition to the main navigation for the portal, and the sub-navigation for the portal, you can see a Call to Action (CTA) button for Register your first service in the main body of the page. On first use, you won’t have created any services, so you will be presented with the first use screen. You can click on the CTA button to load the Add service page or click on the Learn how link to load the documentation page. If you have already created at least 1 service previously, you will see the screen below.\n\nThe services are shared within your oganization. If you are a member of multiple organizations, navigate to the profile page to change your Linked Organization.\n\n\nIn the Services area, you can see cards for the services you have created, together with a card area with a Register service CTA button. On already created services, you can see an avatar (at this stage, just a colour and initials from the service name), the service name and a service status indication. As a user, you can click on the avatar or the service’s name to load its detail page. In addition, you can click on the Register service CTA button to load the add service page to create a new service.\n\n\n\nA good integration in openEO algorithm plaza already starts when programming your algorithm.\nIn openEO, a ‘datacube’ view is used, which hides a lot of the complexity when working with huge EO data archives. It provides full archive access to the most popular datasets. You will have to get familiar with the Application Programming Interface (API), which provides a lot of predefined processes. To integrate existing code, you will have to use the concept of ‘User Defined Functions’ (UDFs). Parallelization and scalability are taken care of.\n\n\nA basic introduction on using openEO can be found here. To deploy your openEO algorithm as a service, we rely on the ‘user defined process’ functionality.\n\n\n\nA good description of your service is key to attract users. Try to give a concise overview of the use cases your service was built for. Higher level services (Level-3 and -4) should also, when available, reference scientific literature and/or validation reports.\nExamples of invocations and images of resulting output are a good way to help people getting started. Finally, a user may want to have an idea of the resource consumption and time required to run your service for a given input.\n\n\n\n\nThe final step as an algorithm/service developer is to publish the service on openEO algorithm plaza. This will make the service visible to other openEO algorithm plaza users, allowing them to incorporate and use the new service in their own workflows. The following sections will guide you through the publishing process.\n\n\nThe next step is to create a new entry on openEO algorithm plaza. This can be done in the Dashboard by selecting Services. The page provides an overview of all the services that are created within your organisation.\n\nTo register your service, click the Register your first service button. You will now be presented with a wizard to enter the necessary information regarding your service.\nThe first step requires you to select the type of service that you want to publish. Currently, the following types are supported:\n\nopenEO - A service that is integrated through the openEO orchestrator\n\n\nIn the next step you can register the basic information for the service. The table below provides an overview of the different required fields:\n\n\n\n\n\n\n\n\nField\nRequired\nDescription\n\n\n\n\nService name\nYes\nTitle of your service, as it will be displayed in the openEO algorithm plaza.\n\n\nSummary\nNo\nShort description of your service. The summary will be visible in the openEO algorithm plaza overview.\n\n\nDescription\nNo\nFull description of your service. The description supports full Markdown syntax.\n\n\nAvatar\nNo\nURL to an image that can be used an avatar of your service. The avatar will be visible in the openEO algorithm plaza overview.\n\n\n\nClick Register Service to finish the basic registration. Finishing the basic registration allows you to provide more details on the service by either clicking the Next button or using one of the shortcuts on the navigation menu.\nIn the Media Files and Links section you can upload image that will be shown when a user views your service on the catalogue. You can add images by dragging and dropping files into the designated area or click the plus icon. Next to images, you can also specify the different multiple URLs that will be shown in the detailed information of the service.\nThe openEO Settings can be used to specify the openEO namespace and service ID of your service. Entering this information will enable the Access Service button, allowing visitors of openEO algorithm plaza to execute your service through the openEO Web Editor. The required information is represented in the following table:\n\n\n\nField\nRequired\nDescription\n\n\n\n\nNamespace\nYes\nNamespace of openEO service. When the service was created through a User Defined Process (UDP), the namespace is formatted as u:&lt;publisher username/id&gt;. This information can be extracted from the public URL when creating and sharing the UDP through openEO.\n\n\nService name\nYes\nName of the service as shared within openEO. For a User Defined Process (UDP), the service name corresponds with the ID of the service.\n\n\n\n\n\n\n\nIn order to upgrade the level of service, service providers should improve their services and documentation in such a way that it meets the criteria (here) for the desired levels. Then a request can be made at our help center for upgrading the service.\n\n\n\nBoth the openEO algorithm plaza and orchestrators provide several procedures to operate your service. The following sections describe the different actions that can be taken to hide, suspend, and delete a service from openEO algorithm plaza.\n\n\nChanging the visibility of a service to private ensures that the service is not visible on openEO algorithm plaza. This can be useful to do some bug fixing, developments, and testing before publishing it to openEO algorithm plaza.\nChanging a service’s visibility can be done by navigating to openEO algorithm plaza’s Dashboard. Select the Services submenu to get a list of all services that your organisation manages on openEO algorithm plaza. Next, select the service for which you want to change the visibility by clicking the corresponding entry in the list. This will open the service details. Scroll down to the Publishing settings where you can set the service’s visibility to private.\n\nIt is important to note that setting the visibility to private only hides the service in openEO algorithm plaza. Users are still able to view and execute the service through the orchestrators. The following sections provide additional information on how to remove your service from the openEO algorithm plaza and orchestrators.\n\n\n\nSimilar to making a service private, a TPS can remove a service from openEO algorithm plaza. This will remove it from the openEO algorithm plaza service catalogue and delete all of its related data.\nRemoving a service is done by navigating to the service list on the Dashboard. Click the Services submenu to open a list of all services managed by your organisation. Next, select the service you would like to remove by clicking on its corresponding tile in the list. This will show the window to edit the service. At the bottom of the page, click the Remove button. A popup window will request your confirmation of deleting the service. Clicking Yes will remove the service from the openEO algorithm plaza and your organisation.\n\nIt is important to note that removing the service from the openEO algorithm plaza does not remove it from the orchestrators. Users are still able to execute the service through the orchestrators. The next section provides additional information on how to remove your service from the orchestrators.\n\n\n\nRemoving a service from the orchestrators will disable its execution by any of the orchestrator’s users. The process of removing a service is depending on the orchestrator that was used to onboard the service.\n\n\nopenEO provides two ways to remove a service (also known as a user-defined process in openEO):\n\nUsing the OpenEO APIThe process_graphs endpoint allows users to remove a service based on its ID. More information is available in the official API documentation.\nUsing the openEO Python ClientThe openEO Python Client supplies a delete function that can be executed for any user defined process that is managed by the authenticated user. More information is available in the official Python Client documentation."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#services-overview",
    "href": "Applications/PlazaDetails/ManageService.html#services-overview",
    "title": "Manage your services",
    "section": "",
    "text": "You arrive here by clicking on Services on the sub-navigation options of the portal. In addition to the main navigation for the portal, and the sub-navigation for the portal, you can see a Call to Action (CTA) button for Register your first service in the main body of the page. On first use, you won’t have created any services, so you will be presented with the first use screen. You can click on the CTA button to load the Add service page or click on the Learn how link to load the documentation page. If you have already created at least 1 service previously, you will see the screen below.\n\nThe services are shared within your oganization. If you are a member of multiple organizations, navigate to the profile page to change your Linked Organization.\n\n\nIn the Services area, you can see cards for the services you have created, together with a card area with a Register service CTA button. On already created services, you can see an avatar (at this stage, just a colour and initials from the service name), the service name and a service status indication. As a user, you can click on the avatar or the service’s name to load its detail page. In addition, you can click on the Register service CTA button to load the add service page to create a new service."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#develop-your-service",
    "href": "Applications/PlazaDetails/ManageService.html#develop-your-service",
    "title": "Manage your services",
    "section": "",
    "text": "A good integration in openEO algorithm plaza already starts when programming your algorithm.\nIn openEO, a ‘datacube’ view is used, which hides a lot of the complexity when working with huge EO data archives. It provides full archive access to the most popular datasets. You will have to get familiar with the Application Programming Interface (API), which provides a lot of predefined processes. To integrate existing code, you will have to use the concept of ‘User Defined Functions’ (UDFs). Parallelization and scalability are taken care of.\n\n\nA basic introduction on using openEO can be found here. To deploy your openEO algorithm as a service, we rely on the ‘user defined process’ functionality.\n\n\n\nA good description of your service is key to attract users. Try to give a concise overview of the use cases your service was built for. Higher level services (Level-3 and -4) should also, when available, reference scientific literature and/or validation reports.\nExamples of invocations and images of resulting output are a good way to help people getting started. Finally, a user may want to have an idea of the resource consumption and time required to run your service for a given input."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#register-and-publish-your-service",
    "href": "Applications/PlazaDetails/ManageService.html#register-and-publish-your-service",
    "title": "Manage your services",
    "section": "",
    "text": "The final step as an algorithm/service developer is to publish the service on openEO algorithm plaza. This will make the service visible to other openEO algorithm plaza users, allowing them to incorporate and use the new service in their own workflows. The following sections will guide you through the publishing process.\n\n\nThe next step is to create a new entry on openEO algorithm plaza. This can be done in the Dashboard by selecting Services. The page provides an overview of all the services that are created within your organisation.\n\nTo register your service, click the Register your first service button. You will now be presented with a wizard to enter the necessary information regarding your service.\nThe first step requires you to select the type of service that you want to publish. Currently, the following types are supported:\n\nopenEO - A service that is integrated through the openEO orchestrator\n\n\nIn the next step you can register the basic information for the service. The table below provides an overview of the different required fields:\n\n\n\n\n\n\n\n\nField\nRequired\nDescription\n\n\n\n\nService name\nYes\nTitle of your service, as it will be displayed in the openEO algorithm plaza.\n\n\nSummary\nNo\nShort description of your service. The summary will be visible in the openEO algorithm plaza overview.\n\n\nDescription\nNo\nFull description of your service. The description supports full Markdown syntax.\n\n\nAvatar\nNo\nURL to an image that can be used an avatar of your service. The avatar will be visible in the openEO algorithm plaza overview.\n\n\n\nClick Register Service to finish the basic registration. Finishing the basic registration allows you to provide more details on the service by either clicking the Next button or using one of the shortcuts on the navigation menu.\nIn the Media Files and Links section you can upload image that will be shown when a user views your service on the catalogue. You can add images by dragging and dropping files into the designated area or click the plus icon. Next to images, you can also specify the different multiple URLs that will be shown in the detailed information of the service.\nThe openEO Settings can be used to specify the openEO namespace and service ID of your service. Entering this information will enable the Access Service button, allowing visitors of openEO algorithm plaza to execute your service through the openEO Web Editor. The required information is represented in the following table:\n\n\n\nField\nRequired\nDescription\n\n\n\n\nNamespace\nYes\nNamespace of openEO service. When the service was created through a User Defined Process (UDP), the namespace is formatted as u:&lt;publisher username/id&gt;. This information can be extracted from the public URL when creating and sharing the UDP through openEO.\n\n\nService name\nYes\nName of the service as shared within openEO. For a User Defined Process (UDP), the service name corresponds with the ID of the service."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#upgrade-your-service",
    "href": "Applications/PlazaDetails/ManageService.html#upgrade-your-service",
    "title": "Manage your services",
    "section": "",
    "text": "In order to upgrade the level of service, service providers should improve their services and documentation in such a way that it meets the criteria (here) for the desired levels. Then a request can be made at our help center for upgrading the service."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#operate-your-services",
    "href": "Applications/PlazaDetails/ManageService.html#operate-your-services",
    "title": "Manage your services",
    "section": "",
    "text": "Both the openEO algorithm plaza and orchestrators provide several procedures to operate your service. The following sections describe the different actions that can be taken to hide, suspend, and delete a service from openEO algorithm plaza.\n\n\nChanging the visibility of a service to private ensures that the service is not visible on openEO algorithm plaza. This can be useful to do some bug fixing, developments, and testing before publishing it to openEO algorithm plaza.\nChanging a service’s visibility can be done by navigating to openEO algorithm plaza’s Dashboard. Select the Services submenu to get a list of all services that your organisation manages on openEO algorithm plaza. Next, select the service for which you want to change the visibility by clicking the corresponding entry in the list. This will open the service details. Scroll down to the Publishing settings where you can set the service’s visibility to private.\n\nIt is important to note that setting the visibility to private only hides the service in openEO algorithm plaza. Users are still able to view and execute the service through the orchestrators. The following sections provide additional information on how to remove your service from the openEO algorithm plaza and orchestrators.\n\n\n\nSimilar to making a service private, a TPS can remove a service from openEO algorithm plaza. This will remove it from the openEO algorithm plaza service catalogue and delete all of its related data.\nRemoving a service is done by navigating to the service list on the Dashboard. Click the Services submenu to open a list of all services managed by your organisation. Next, select the service you would like to remove by clicking on its corresponding tile in the list. This will show the window to edit the service. At the bottom of the page, click the Remove button. A popup window will request your confirmation of deleting the service. Clicking Yes will remove the service from the openEO algorithm plaza and your organisation.\n\nIt is important to note that removing the service from the openEO algorithm plaza does not remove it from the orchestrators. Users are still able to execute the service through the orchestrators. The next section provides additional information on how to remove your service from the orchestrators.\n\n\n\nRemoving a service from the orchestrators will disable its execution by any of the orchestrator’s users. The process of removing a service is depending on the orchestrator that was used to onboard the service.\n\n\nopenEO provides two ways to remove a service (also known as a user-defined process in openEO):\n\nUsing the OpenEO APIThe process_graphs endpoint allows users to remove a service based on its ID. More information is available in the official API documentation.\nUsing the openEO Python ClientThe openEO Python Client supplies a delete function that can be executed for any user defined process that is managed by the authenticated user. More information is available in the official Python Client documentation."
  },
  {
    "objectID": "Applications/PlazaDetails/Introduction.html",
    "href": "Applications/PlazaDetails/Introduction.html",
    "title": "About openEO Algorithm plaza",
    "section": "",
    "text": "The openEO algorithm plaza allows you to share an algorithm or workflow that you developed with our user community. It takes away the IT aspects of publishing a service, so that you can entirely focus on the algorithm’s development. Publishing your algorithm as a service will give it greater visibility and expose it to a larger audience that can give feedback.\nThe openEO algorithm plaza relies on standardized web interfaces, so our users can access your service in an easy manner. A visual description of your service is published, to give an attractive overview of the capabilities.\n\n\n\n\nWithin the context of Earth Observation, a service can do anything, from computing a simple Normalized Difference Vegetation Index (NDVI) for a bounding box, to exposing a complex peer-reviewed algorithm with numerous parameters. Of course, you want to keep your target audience in mind, so you may want to hold back on hard to interpret options when you are trying to reach a non-scientific audience.\nOnce your algorithm is exposed as a service, users will be able to ‘invoke’ it with a given set of parameters. Within EO, an area of interest and/or time period are very common parameter sets to filter on.\n\n\n\nEach of the advertised services in the openEO algorithm plaza will be assigned a maturity level. This level indicates what end users can expect from the services with regards to:\n\nValidation of the results\nStability\nScalability\nDocumentation\n\nThe table below provides an overview of the different maturity levels that are applied within the openEO algorithm plaza.\n\n\n\n\n\n\n\nLevel\nDescription\n\n\n\n\nPrototype\nService is provided ‘as-is’, with a short description and possibly a reference to what it tries to implement.\n\n\nIncubating\nQuality of the service is documented with example requests (sets of parameters) and the corresponding output, as well as the resources required to generate that output. Allowing interested users to self-assess whether this service is suitable for usage.\n\n\nVerified\nThe service is labelled verified based on its software readiness and irrelevance to the scientific validation report.\n\n\nValidated\nThe service is validated, and validation reports are available in addition to being verified.\n\n\nOperational\nThe service has been shown to be fit for larger scale production and integration in operational systems. Rules for estimating resource usage are available, or a unit cost is established. (€ per hectare, € per request, etc.)\n\n\n\n\nDetailed descriptions of the criteria for each maturity level are explained here.\n\n\n\n\n\n\nGuide for openEO algorithm plaza users\nGuide for third party service providers\n\n\n\n\n\nopenEO algorithm plaza overview\nSigning in\nManage your services\nManage your billing information\nExecute a service"
  },
  {
    "objectID": "Applications/PlazaDetails/Introduction.html#concepts",
    "href": "Applications/PlazaDetails/Introduction.html#concepts",
    "title": "About openEO Algorithm plaza",
    "section": "",
    "text": "Within the context of Earth Observation, a service can do anything, from computing a simple Normalized Difference Vegetation Index (NDVI) for a bounding box, to exposing a complex peer-reviewed algorithm with numerous parameters. Of course, you want to keep your target audience in mind, so you may want to hold back on hard to interpret options when you are trying to reach a non-scientific audience.\nOnce your algorithm is exposed as a service, users will be able to ‘invoke’ it with a given set of parameters. Within EO, an area of interest and/or time period are very common parameter sets to filter on.\n\n\n\nEach of the advertised services in the openEO algorithm plaza will be assigned a maturity level. This level indicates what end users can expect from the services with regards to:\n\nValidation of the results\nStability\nScalability\nDocumentation\n\nThe table below provides an overview of the different maturity levels that are applied within the openEO algorithm plaza.\n\n\n\n\n\n\n\nLevel\nDescription\n\n\n\n\nPrototype\nService is provided ‘as-is’, with a short description and possibly a reference to what it tries to implement.\n\n\nIncubating\nQuality of the service is documented with example requests (sets of parameters) and the corresponding output, as well as the resources required to generate that output. Allowing interested users to self-assess whether this service is suitable for usage.\n\n\nVerified\nThe service is labelled verified based on its software readiness and irrelevance to the scientific validation report.\n\n\nValidated\nThe service is validated, and validation reports are available in addition to being verified.\n\n\nOperational\nThe service has been shown to be fit for larger scale production and integration in operational systems. Rules for estimating resource usage are available, or a unit cost is established. (€ per hectare, € per request, etc.)\n\n\n\n\nDetailed descriptions of the criteria for each maturity level are explained here."
  },
  {
    "objectID": "Applications/PlazaDetails/Introduction.html#guides",
    "href": "Applications/PlazaDetails/Introduction.html#guides",
    "title": "About openEO Algorithm plaza",
    "section": "",
    "text": "Guide for openEO algorithm plaza users\nGuide for third party service providers"
  },
  {
    "objectID": "Applications/PlazaDetails/Introduction.html#quicklinks",
    "href": "Applications/PlazaDetails/Introduction.html#quicklinks",
    "title": "About openEO Algorithm plaza",
    "section": "",
    "text": "openEO algorithm plaza overview\nSigning in\nManage your services\nManage your billing information\nExecute a service"
  },
  {
    "objectID": "Applications/PlazaDetails/Strength.html",
    "href": "Applications/PlazaDetails/Strength.html",
    "title": "Credit Strength",
    "section": "",
    "text": "The following mentioned are among the popular services available in openEO algorithm plaza. Here we have presented an average credit strength for these services. Please note that depending on the time interval and area of interest, the credits can slightly vary.\nThe purpose of this document is to solely provide users with an assumption on how these credits work and their strength for varying services.\n\nNDVI\nFor the calculation of Normalized Difference Vegetation Index (NDVI), you can acquire ~250 NDVI images, each with an area of 1 hectare, i.e. 1 NDVI image patch of 1 hectare cost 3-5 credits.\nNDII\nComputation of the Normalized Difference Infrared Index (NDII) provides the user with an indication of the water content in the plant canopies. A straightforward calculation of the NDII can be achieved from openEO algorithm plaza NDII service with the use of 4-8 credits per hectare area, i.e. you can use your 1000 credits for computing NDII in a given area of ~117 hectares.\nBiomass\nThe Biomass service provided by openEO algorithm plaza can be a critical component in tracking and quantifying carbon capture in agriculture and natural vegetation. Users can use this service with approximately 20-40 credits per hectare, i.e. ~33-hectare area with a total of 1000 credits.\nCropSAR\nThe operational agricultural monitoring can be a key use case for this service as it uses Sentinel-1 radar observations to augment those of Sentinel-2. By doing so, more continuous vegetation properties monitoring can be performed, including vegetation information for situations where these properties cannot be retrieved from Sentinel-2 observations due to cloud occurrence. Users can use this service with approximately 40-60 credits per hectare, i.e. ~20-hectare area with a total of 1000 credits.\n\n\nThough the required credit for direct download of the output data is two credits for all the services, it has a time limitation of 10 seconds to run the entire process. Otherwise, the download process will fail."
  },
  {
    "objectID": "Applications/PlazaDetails/Reporting.html",
    "href": "Applications/PlazaDetails/Reporting.html",
    "title": "Reporting",
    "section": "",
    "text": "This documentation section demonstrates how to use the reporting function within the openEO algorithm plaza. Individuals using the platform can track the services they have used and see how credits have been deducted for each service. The purpose of this guide is to help users efficiently track and document their service consumption while also keeping an eye on their credit balance.\nPlease check that you are logged in to your account for accessing the reporting functionality. Once logged in, select the “Reporting” option from the navbar, that will take you to the screen shown in the figure below:\n\nIf you haven’t executed anything yet, there may not be much information displayed on the screen. However, as you start utilizing openEO and the services on the plaza, the screen will populate with relevant data that can be visualized in the following manner:\n\nFiltering Reports: You will have the option to filter the reports based on a specific time interval. This allows you to view the openEO usage and credit deductions within a desired timeframe, providing a more targeted analysis.\nCredit Usage Display: A section will be available to display the credits used, showcasing both the synchronous and batch job execution methods. This information helps you understand how your credits are being utilized for different types of job executions. Hovering over the credit usage details will provide additional information on the specific service used.\nJobs List: The screen will include a list of the jobs that have been executed. This list provides a comprehensive overview of the services that have been utilized. Each job entry will typically include details such as job ID, execution time, and any relevant metadata associated with the job.\n\n\n\nOn the top right corner of the screen, you will notice an “Export” button. By clicking on this button, you will have the option to download the report in either PDF or CSV file format. This feature enables you to save and archive the report for future reference or share it with others as needed.\n\nNext to the “Personal” section, you will find the “Service” tab, specifically designed for service providers to monitor and track reports on the services published by their organisation. If you haven’t provided service, this tab will appear empty, as mentioned earlier. However, if you have published services, the page will populate with a similar layout. Additionally a “Service Execution” section is shown, displaying the number of times each service within your organization was executed."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html",
    "href": "Applications/AlgorithmPlaza.html",
    "title": "openEO algorithm plaza",
    "section": "",
    "text": "This section of the document provides a comprehensive overview of essential links related to the openEO algorithm plaza. These links serve as valuable resources for individuals seeking to gain further knowledge about the platform. Included are references to a guide tailored for general users, a guide designed specifically for developers and service providers, as well as additional links pertaining to various services offered by openEO."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#getting-started",
    "href": "Applications/AlgorithmPlaza.html#getting-started",
    "title": "openEO algorithm plaza",
    "section": "Getting Started",
    "text": "Getting Started\nAre you new to the openEO algorithm plaza? Get started by exploring the following guides:\n\nopenEO algorithm plaza Introduction\nGuide for openEO algorithm plaza users\nGuide for third party service providers"
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#popular-links",
    "href": "Applications/AlgorithmPlaza.html#popular-links",
    "title": "openEO algorithm plaza",
    "section": "Popular links",
    "text": "Popular links\n\nopenEO algorithm plaza overview\nSigning in\nManage your services\nManage your billing information\nExecute a service"
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#support",
    "href": "Applications/AlgorithmPlaza.html#support",
    "title": "openEO algorithm plaza",
    "section": "Support",
    "text": "Support\n\nExecuting services\nIf you are experiencing issues with executing your service, feel free to contact our support team by creating a ticket.\n\n\nPublishing services\nAre you having trouble publishing your service onto the openEO algorithm plaza? Our support team is ready to assist! Feel free to create a ticket."
  },
  {
    "objectID": "404-not-found.html",
    "href": "404-not-found.html",
    "title": "Page not found",
    "section": "",
    "text": "Page not found"
  },
  {
    "objectID": "Roadmap.html",
    "href": "Roadmap.html",
    "title": "Service description and evolution roadmap",
    "section": "",
    "text": "The Service description and evolution document provides a comprehensive view of all data products and services available in the frame of the Copernicus Data Space Ecosystem, both the “Copernicus Free Services” as well as the services operated by third parties.\n\n\n\n\n\n\nRoadmap Summary\n\n\n\n\n\nMore detailed information on the timelines for Copernicus Data Space Ecosystem data, APIs and Application updates can be found here:\n\nData timeline overview\nAPIs timeline overview\nApplications timeline overview"
  },
  {
    "objectID": "Roadmap.html#roadmap",
    "href": "Roadmap.html#roadmap",
    "title": "Service description and evolution roadmap",
    "section": "",
    "text": "Roadmap Summary"
  },
  {
    "objectID": "Roadmap.html#details",
    "href": "Roadmap.html#details",
    "title": "Service description and evolution roadmap",
    "section": "",
    "text": "More detailed information on the timelines for Copernicus Data Space Ecosystem data, APIs and Application updates can be found here:\n\nData timeline overview\nAPIs timeline overview\nApplications timeline overview"
  }
]