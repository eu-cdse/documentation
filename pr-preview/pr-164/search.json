[
  {
    "objectID": "Support.html",
    "href": "Support.html",
    "title": "Support",
    "section": "",
    "text": "If you don’t find answer to your questions in the documentation portal, this page describes how to ask for support.\n\n\nImportant to know is that only users with a Copernicus Data Space Ecosystem account can ask for support. If you don’t have one yet, you can register here. If you have an issue with registering or you want to deregister, please contact us directly.\n\n\n\nNavigate to the following website.\nIn case you’re not logged in, click on LOGIN.\n\nYou will now get the Copernicus Data Space Ecosystems login form.\n\nEnter your credentials and click LOG IN.\n\n\n\nOnce you have logged in you should see this window, click SUBMIT A REQUEST.\n\nThe form used to create tickets should now appear.\n\nFrom the dropdown select what the question is about.\nEnter the subject.\nDescribe your problem in detail in the field Description.\nYou can also upload attachments such as screenshots in the Attachments section.\nOnce you’ve finished, click SUBMIT.\nYour ticket should now be submitted.\n\nYou can see its status here. You can also post additional comments and attachments.\n\n\n\nAfter logging in (as described in Step 1), you can see the status of your requests under your account. Select Requests from the drop-down.\n\nYou will now see all your requests.\n\nIf you can’t see your request here, make sure that Status “Any” is selected from the drop-down.\nYou should now see your request."
  },
  {
    "objectID": "Support.html#prerequisites",
    "href": "Support.html#prerequisites",
    "title": "Support",
    "section": "",
    "text": "Important to know is that only users with a Copernicus Data Space Ecosystem account can ask for support. If you don’t have one yet, you can register here. If you have an issue with registering or you want to deregister, please contact us directly."
  },
  {
    "objectID": "Support.html#step-1-navigate-to-the-help-center",
    "href": "Support.html#step-1-navigate-to-the-help-center",
    "title": "Support",
    "section": "",
    "text": "Navigate to the following website.\nIn case you’re not logged in, click on LOGIN.\n\nYou will now get the Copernicus Data Space Ecosystems login form.\n\nEnter your credentials and click LOG IN."
  },
  {
    "objectID": "Support.html#step-2-submit-a-request",
    "href": "Support.html#step-2-submit-a-request",
    "title": "Support",
    "section": "",
    "text": "Once you have logged in you should see this window, click SUBMIT A REQUEST.\n\nThe form used to create tickets should now appear.\n\nFrom the dropdown select what the question is about.\nEnter the subject.\nDescribe your problem in detail in the field Description.\nYou can also upload attachments such as screenshots in the Attachments section.\nOnce you’ve finished, click SUBMIT.\nYour ticket should now be submitted.\n\nYou can see its status here. You can also post additional comments and attachments."
  },
  {
    "objectID": "Support.html#accessing-your-submitted-requests",
    "href": "Support.html#accessing-your-submitted-requests",
    "title": "Support",
    "section": "",
    "text": "After logging in (as described in Step 1), you can see the status of your requests under your account. Select Requests from the drop-down.\n\nYou will now see all your requests.\n\nIf you can’t see your request here, make sure that Status “Any” is selected from the drop-down.\nYou should now see your request."
  },
  {
    "objectID": "Roadmap/DataTable.html",
    "href": "Roadmap/DataTable.html",
    "title": "Data",
    "section": "",
    "text": "Open Data\nType\nJan-23\nApr-23\nJul-23\nOct-23\nNov-23\n\n\n\n\nSentinel-1\nUser Level Data\nSee here\nSee here\nSee here\n\n\n\n\nEngineering data\n\n\n\nWorld: Last 2: weeks IAD\n\n\n\nAuxiliary data\n\n\n\nFull archive\n\n\n\nSentinel-2\nUser Level Data\nSee here\nSee here\nSee here\n\n\n\n\nEngineering data\n\n\n\nWorld: Last 2: weeks IAD\n\n\n\nAuxiliary data\n\n\n\nFull archive\n\n\n\nSentinel-3\nUser Level Data\nSee here\nSee here\nSee here\n\n\n\n\nEngineering data\n\n\n\nWorld: Last 2: weeks IAD\n\n\n\nAuxiliary data\n\n\n\nFull archive\n\n\n\nsentinel-5P\nUser Level Data\nSee here\nSee here\nSee here\n\n\n\n\nEngineering data\n\n\n\nWorld: Last 2: weeks IAD\n\n\n\nAuxiliary data\n\n\n\nFull archive\n\n\n\nPOD\nAuxiliary data\n\n\n\nFull archive\n\n\n\nCopernicus contributing mission\nDEM\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nVHR\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nVHR Urban Atlas\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nOptical HR\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nOptical HR2\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nOptical MR\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nSAR\n\n\nStart of gradual publication\n\nFull CCM coverage\n\n\nComplementary open data\nSMOS\n\n\nMIRAS\n\n\n\n\nEnvisat\n\n\nMERIS, ASAR\n\n\n\n\nCAMS\n\n\nCopernicus Atmosphere Monitoring Service\n\n\n\n\nCEMS\n\n\nCopernicus Emergency Management Service\n\n\n\n\nCLMS\n\n\nCopernicus Land Monitoring Service\n\n\n\n\nCMEMS\n\n\nCopernicus Marine Service\n\n\n\n\nS2GLC\n\n\nHigh resolution Land Cover Map of Europe\n\n\n\n\nESA WorldCover\n\n\nHigh resolution Land Cover Map of the world for 2020 and 2021, in COG\n\n\n\n\n\n\n\n\n\nThird Party Service Data\nType\nJan-23\nApr-23\nJul-23\nOct-23\nNov-23\n\n\n\n\nCreodias commercial offer\nAirbus Pleiades\n\n\nAvailable to users from selected countries, payable.\n\n\n\n\nAirbus Spot 6/7\n\n\nAvailable to users from selected countries, payable.\n\n\n\n\nWorldview\n\n\nAvailable to users from selected countries, payable.\n\n\n\n\nPlanetScope\n\n\nPayable, \"Area under management\" model\n\n\n\n\nPlanet SkySat\n\n\nPayable\n\n\n\n\nKompsat \n\n\nPayable"
  },
  {
    "objectID": "Roadmap/AppTable.html",
    "href": "Roadmap/AppTable.html",
    "title": "Applications",
    "section": "",
    "text": "Open Services\nType\nJan-23\nMar-23\nApr-23\nJul-23\nNov-23\n\n\n\n\nIdentity service\nUser Registration and identity management\nStart of registration of users allowing to access first free services on CDE. Management of user and organization.\n\n\nFull functionality, access to all integrated applications with SSO.\n\n\n\nBrowser\nCopernicus Data Space Ecosystem Browser\nAvailable for registered users, visualisation limited to Sentinel-2 L1C/L2A, simple querying capabilities\nVisualisation of Sentinel-1 GRD added.\nAvailable also for non-registered users, with limited functionality.\nAdvanced querying capabilities.\nVisualization of Sentinel 3 and Sentinel 5p.\nVisualisation support extented to additional data collections.\nVisualisation support extended to Landsat Collection 2 and MODIS.\n\n\nData Workspace\n\n\nAvailable for registered users.\nAvailable, supporting on-demand services.\n\n\n\nopenEO Web Editor\n\n\n\nAvailable, supporting Sentinel-1 GRD, Sentinel-2 L1C/L2A, Sentinel-3 OLCI Level 1 and Sentinel-5p NTC Level 2\nAdditional data collections available.\n\n\nJupyterLab\n\n\n\nAvailable\n\n\n\nWeb Portal\nWeb portal\nLanding page available with road map, registration, browser, documentation, news section\n\nContent on additional data, services and documentation (STAC, S3, OGC and Sentinel Hub APIs, traceability service and on demand)\nNew data, services and documentation (marketplace, user forum, Jupyter lab, processing APIs)\nAdditional information and CTA to new data and services\n\n\nPublic dashboard\n\n\n\nAvailable with all relevant metrics\n\n\n\nHelpdesk\nService desk\nMail support\n\nWeb form in web portal\n\n\n\n\nUser forum\n\n\n\nAvailable\n\n\n\nMarketplace\nEO Marketplace\n\n\n\nIntegration into web portal. Provision of engineering support on Marketplace services\n\n\n\n\n\n\n\n\nThird Party Services\nType\nJan-23\nMar-23\nApr-23\nJul-23\nNov-23\n\n\n\n\nInfrastructure as a Service (IaaS)\nCloud Ferro IaaS\nReady to use\n\n\n\n\n\n\nT-System Open Telekom Cloud IaaS\nReady to use"
  },
  {
    "objectID": "Roadmap/APITable.html",
    "href": "Roadmap/APITable.html",
    "title": "APIs",
    "section": "",
    "text": "API\n            Type\n            Jan-23\n            Mar-23\n            Apr-23\n            Jul-23\n            Oct-23\n            Nov-23\n            Dec-23\n            May-24\n            Jul-24\n        \n        \n        \n        \n            Product search and download\n            OData\n            Search and full product download\n            \n            \n            Search and product download(full and partial)\n            \n            \n            \n            \n            \n        \n        \n\n            OpenSearch (Resto)\n            Search and full product download\n            \n            \n            Search and product download(full and partial)\n            \n            \n            \n            \n            \n        \n        \n\n            STAC items\n            \n            \n            Fully available\n            \n            \n            \n            \n            \n            \n        \n        \n\n            STAC API\n            \n            \n            Fully available\n            \n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Catalog API\n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n            \n        \n        \n\n            S3\n            \n            \n            Fully available\n            \n            \n            \n            \n            \n            \n        \n        \n\n            S3fs\n            \n            \n            \n            Fully available\n            \n            \n            \n            \n            \n        \n        \n            Data processing\n            Sentinel Hub data collection support\n            \n            \n            Sentinel-1 GRD, Sentinel-2 L1C/L2A, Sentinel-3 OLCI and SLSTR Level 1, Sentinel-5p\n            Sentinel-1 and Sentinel-2 cloudless mosaics, Bring your own COG/Zarr.\n            \n            Landsat Collection 2, MODIS, Third party data\n            \n            \n            Sentinel-3 OLCI and SLSTR Level 2\n        \n        \n\n            Sentinel Hub OGC API\n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Process API\n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Asynchronous Process API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Batch Processing API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Statistical API\n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Batch Statistical API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Bring your own COG API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n\n            Sentinel Hub Bring your own Zarr API\n            \n            \n            \n            Available for supported data collections\n            \n            \n            \n            \n            \n        \n        \n        \n\n            openEO API\n            \n            \n            \n            Available for Sentinel-1 GRD, Sentinel-2 L1C/L2A, Sentinel-3 OLCI Level 1, Sentinel-5p NTC Level 2\n            \n            Available for all data collections supported by Sentinel Hub, SPOT-VGT, PROBA-V and ESA WorldCover.\n            \n            \n            \n        \n        \n        \n            On Demand Production\n            Sentinel 1 Production\n            \n            \n            \n            \n            The on-demand processing software will be available for the users, integrated with the data interfaces, data catalog and ordering mechanism. \n            \n            \n            \n            \n        \n        \n            Sentinel 2 Production\n            \n            \n            \n            \n            The on-demand processing software will be available for the users, integrated with the data interfaces, data catalog and ordering mechanism. \n            \n            \n            \n            \n        \n        \n            Sentinel 3 Production\n            \n            \n            \n            \n            The on-demand processing software will be available for the users, integrated with the data interfaces, data catalog and ordering mechanism. \n            \n            \n            \n            \n        \n        \n        \n        \n            Traceability\n            Traceability\n            \n            Start of registering of traces of published fresh data available for new ingested data.\n            \n            Traceability Service operational for the Data Access.Registered traces for all published User Level Data (excluding historical data). Service is operational for verification for any user. Traces service for registering traces is available only for DAS services\n            \n            \n            Traceability service is operational also for registering traces for all ESA GS services allowing to register and verify traces\n            Registered traces for all historical User Level data"
  },
  {
    "objectID": "APIs/STAC.html",
    "href": "APIs/STAC.html",
    "title": "STAC product catalog",
    "section": "",
    "text": "STAC API endpoint: https://catalogue.dataspace.copernicus.eu/stac/\nSTAC (Spatio-Temporal Asset Catalog) is a relatively new web service specification for catalogs that is increasingly used and supported.\nThe version exposed in the Copernicus Dataspace is still subject to change as the quality of STAC metadata is still improving. Nevertheless, it already supports basic product search.\n\n\nTo query the catalog, you can use a library for your language of choice. For Python, we recommend PySTAC."
  },
  {
    "objectID": "APIs/STAC.html#querying-the-catalog",
    "href": "APIs/STAC.html#querying-the-catalog",
    "title": "STAC product catalog",
    "section": "",
    "text": "To query the catalog, you can use a library for your language of choice. For Python, we recommend PySTAC."
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html",
    "href": "APIs/SentinelHub/Process/Crs.html",
    "title": "CRS support",
    "section": "",
    "text": "The list of coordinate reference systems supported by Sentinel Hub API is provided below. The coordinate reference system must be set with an URL starting with http://www.opengis.net/def/crs/ and it must be set under the field input.bounds.properties.crs, e.g. request in WGS 84 reference system, defined with the URL http://www.opengis.net/def/crs/EPSG/0/4326:"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#wgs-84",
    "href": "APIs/SentinelHub/Process/Crs.html#wgs-84",
    "title": "CRS support",
    "section": "WGS 84:",
    "text": "WGS 84:\n\nhttp://www.opengis.net/def/crs/OGC/1.3/CRS84\nhttp://www.opengis.net/def/crs/EPSG/0/4326"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#wgs-84--pseudo-mercator",
    "href": "APIs/SentinelHub/Process/Crs.html#wgs-84--pseudo-mercator",
    "title": "CRS support",
    "section": "WGS 84 / Pseudo-Mercator:",
    "text": "WGS 84 / Pseudo-Mercator:\n\nhttp://www.opengis.net/def/crs/EPSG/0/3857"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#utm-northern-hemisphere",
    "href": "APIs/SentinelHub/Process/Crs.html#utm-northern-hemisphere",
    "title": "CRS support",
    "section": "UTM northern hemisphere:",
    "text": "UTM northern hemisphere:\n\nhttp://www.opengis.net/def/crs/EPSG/0/32601\nhttp://www.opengis.net/def/crs/EPSG/0/32602\n...\nhttp://www.opengis.net/def/crs/EPSG/0/32660\n\nThe last two digits of EPSG codes above represent the number of corresponding UTM zone in northern hemisphere, e.g. use http://www.opengis.net/def/crs/EPSG/0/32612 for UTM zone 12N."
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#utm-southern-hemisphere",
    "href": "APIs/SentinelHub/Process/Crs.html#utm-southern-hemisphere",
    "title": "CRS support",
    "section": "UTM southern hemisphere:",
    "text": "UTM southern hemisphere:\n\nhttp://www.opengis.net/def/crs/EPSG/0/32701\nhttp://www.opengis.net/def/crs/EPSG/0/32702\n...\nhttp://www.opengis.net/def/crs/EPSG/0/32760\n\nThe last two digits of EPSG codes above represent the number of corresponding UTM zone in southern hemisphere, e.g. use http://www.opengis.net/def/crs/EPSG/0/32712 for UTM zone 12S."
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#others",
    "href": "APIs/SentinelHub/Process/Crs.html#others",
    "title": "CRS support",
    "section": "Others:",
    "text": "Others:\n\nhttp://www.opengis.net/def/crs/EPSG/0/2154\nhttp://www.opengis.net/def/crs/EPSG/0/2180\nhttp://www.opengis.net/def/crs/EPSG/0/2193\nhttp://www.opengis.net/def/crs/EPSG/0/3003\nhttp://www.opengis.net/def/crs/EPSG/0/3004\nhttp://www.opengis.net/def/crs/EPSG/0/3031\nhttp://www.opengis.net/def/crs/EPSG/0/3035\nhttp://www.opengis.net/def/crs/EPSG/0/3346\nhttp://www.opengis.net/def/crs/EPSG/0/3413\nhttp://www.opengis.net/def/crs/EPSG/0/3416\nhttp://www.opengis.net/def/crs/EPSG/0/3765\nhttp://www.opengis.net/def/crs/EPSG/0/3794\nhttp://www.opengis.net/def/crs/EPSG/0/3844\nhttp://www.opengis.net/def/crs/EPSG/0/3912\nhttp://www.opengis.net/def/crs/EPSG/0/3995\nhttp://www.opengis.net/def/crs/EPSG/0/4026\nhttp://www.opengis.net/def/crs/EPSG/0/5514\nhttp://www.opengis.net/def/crs/EPSG/0/28992"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S3SLSTR.html",
    "href": "APIs/SentinelHub/Process/Examples/S3SLSTR.html",
    "title": "Examples for S3SLSTR",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nFalse Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                8.558382,\n                41.359678,\n                9.579525,\n                43.055688,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color, resolution (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 250,\n        \"resy\": 250,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nThermal IR fire emission band, gradient visualizer (K)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"F1\"],\n    output: {\n      bands: 3,\n    },\n  }\n}\n\n// Create a Red gradient visualiser from 274-450 K\nvar viz = ColorGradientVisualizer.createRedTemperature(274, 450)\n\nfunction evaluatePixel(sample) {\n  return viz.process(sample.F1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -120.141,\n                37.5282,\n                -119.4131,\n                37.8716,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-08-06T00:00:00Z\",\n                        \"to\": \"2018-08-06T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color and metadata (multi-part GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"INT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n    mosaicking: \"TILE\",\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.tiles }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [sample[0].S3 * 10000, sample[0].S2 * 10000, sample[0].S1 * 10000] //the values are multiplied by 10000 because output sampleType is UINT16\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                8.558382,\n                41.359678,\n                9.579525,\n                43.055688,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bouds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S2\", \"S3\"],\n    output: {\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let NDVI = index(sample.S3, sample.S2)\n  const viz = ColorGradientVisualizer.createWhiteGreen(-0.1, 1.0)\n  return viz.process(NDVI)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                        [\n                            542559.6872296461,\n                            4744749.907737136,\n                        ],\n                        [\n                            550448.1401370098,\n                            4660606.41005859,\n                        ],\n                        [\n                            521523.8128100095,\n                            4570327.449007649,\n                        ],\n                        [\n                            474193.0953658272,\n                            4600128.271102134,\n                        ],\n                        [\n                            461045.67385355436,\n                            4630805.5879641045,\n                        ],\n                        [\n                            453157.22094619065,\n                            4698295.685060439,\n                        ],\n                        [\n                            497858.45408791833,\n                            4741243.928667196,\n                        ],\n                        [\n                            520647.3180425246,\n                            4744749.907737136,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/jpeg\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S2\", \"S3\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: \"INT16\",\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: \"AUTO\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let NDVI = index(sample.S3, sample.S2)\n  const viz = ColorGradientVisualizer.createWhiteGreen(-0.1, 1.0)\n  return {\n    default: [NDVI * 10000],\n    ndvi_image: viz.process(NDVI),\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                        [\n                            542559.6872296461,\n                            4744749.907737136,\n                        ],\n                        [\n                            550448.1401370098,\n                            4660606.41005859,\n                        ],\n                        [\n                            521523.8128100095,\n                            4570327.449007649,\n                        ],\n                        [\n                            474193.0953658272,\n                            4600128.271102134,\n                        ],\n                        [\n                            461045.67385355436,\n                            4630805.5879641045,\n                        ],\n                        [\n                            453157.22094619065,\n                            4698295.685060439,\n                        ],\n                        [\n                            497858.45408791833,\n                            4741243.928667196,\n                        ],\n                        [\n                            520647.3180425246,\n                            4744749.907737136,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nVNIR and SWIR bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      bands: 6,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance or BT values, simply divide the resulting pixel values by 10000.\n  return [\n    10000 * sample.S1,\n    10000 * sample.S2,\n    10000 * sample.S3,\n    10000 * sample.S4,\n    10000 * sample.S5,\n    10000 * sample.S6,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 500,\n        \"resy\": 500,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTIR bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S7\", \"S8\", \"S9\", \"F1\", \"F2\"],\n      },\n    ],\n    output: {\n      bands: 5,\n      sampleType: \"UINT16\",\n    },\n  }\n}\n\nfunction multiplyband(sample) {\n  // Multiply by 100\n  return 100 * sample\n}\n\nfunction evaluatePixel(sample) {\n  // Return the bands multiplied by 100 as integers to save processing units.\n  // To obtain reflectance or BT values, simply divide the resulting pixel values by 100.\n  return [\n    multiplyband(sample.S7),\n    multiplyband(sample.S8),\n    multiplyband(sample.S9),\n    multiplyband(sample.F1),\n    multiplyband(sample.F2),\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 500,\n        \"resy\": 500,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S3OLCI.html",
    "href": "APIs/SentinelHub/Process/Examples/S3OLCI.html",
    "title": "Examples for S3OLCI",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the data from 0-255.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    },\n                    \"processing\": {\"upsampling\": \"BILINEAR\"},\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 150,\n        \"resy\": 150,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTiff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B06\", \"B08\"],\n        units: \"REFLECTANCE\", // default value\n      },\n    ],\n    output: {\n      bands: 3,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [10000 * sample.B08, 10000 * sample.B06, 10000 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B06\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    mosaicking: Mosaicking.SIMPLE,\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.tiles }\n}\n\nfunction evaluatePixel(samples) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [10000 * samples.B08, 10000 * samples.B06, 10000 * samples.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nOTCI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B10\", \"B11\", \"B12\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\n// Create a new visualiser to represent data\nvar cm = new ColorMapVisualizer([\n  [0, [0, 0, 0.5]],\n  [1, [0, 0.3, 0.8]],\n  [1.8, [1, 0.2, 0.2]],\n  [2.5, [1, 0.9, 0]],\n  [4, [0, 0.8, 0.1]],\n  [4.5, [0, 0.6, 0.2]],\n  [5, [1, 1, 1]],\n])\n\nfunction evaluatePixel(sample) {\n  let OTCI = (sample.B12 - sample.B11) / (sample.B11 - sample.B10)\n  return cm.process(OTCI)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                        [\n                            8.6956787109375,\n                            42.370720143531976,\n                        ],\n                        [\n                            8.7890625,\n                            42.238685347536496,\n                        ],\n                        [\n                            8.60504150390625,\n                            42.20614200929954,\n                        ],\n                        [\n                            8.70391845703125,\n                            42.15322331239858,\n                        ],\n                        [\n                            8.83575439453125,\n                            41.97991089691236,\n                        ],\n                        [\n                            8.81378173828125,\n                            41.797935707842974,\n                        ],\n                        [\n                            8.9208984375,\n                            41.777456667491066,\n                        ],\n                        [\n                            8.94012451171875,\n                            41.68316883525891,\n                        ],\n                        [\n                            9.0472412109375,\n                            41.52297326747377,\n                        ],\n                        [\n                            9.35760498046875,\n                            41.70777900286713,\n                        ],\n                        [\n                            9.33013916015625,\n                            42.06764572379527,\n                        ],\n                        [\n                            9.48394775390625,\n                            42.261049162113856,\n                        ],\n                        [\n                            9.47021484375,\n                            42.51462626746592,\n                        ],\n                        [\n                            9.33837890625,\n                            42.62385465855651,\n                        ],\n                        [\n                            9.1900634765625,\n                            42.6844544397102,\n                        ],\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 90,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nOTCI image and value (multi-part response png and GeoTIFF containing floats)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B10\", \"B11\", \"B12\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: \"FLOAT32\",\n      },\n      {\n        id: \"otci_image\",\n        bands: 3,\n        sampleType: \"AUTO\",\n      },\n    ],\n  }\n}\n\n// Create a new visualiser to represent data\nvar cm = new ColorMapVisualizer([\n  [0, [0, 0, 0.5]],\n  [1, [0, 0.3, 0.8]],\n  [1.8, [1, 0.2, 0.2]],\n  [2.5, [1, 0.9, 0]],\n  [4, [0, 0.8, 0.1]],\n  [4.5, [0, 0.6, 0.2]],\n  [5, [1, 1, 1]],\n])\n\nfunction evaluatePixel(sample) {\n  let OTCI = (sample.B12 - sample.B11) / (sample.B11 - sample.B10)\n  return {\n    default: [OTCI],\n    otci_image: cm.process(OTCI),\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                        [\n                            8.6956787109375,\n                            42.370720143531976,\n                        ],\n                        [\n                            8.7890625,\n                            42.238685347536496,\n                        ],\n                        [\n                            8.60504150390625,\n                            42.20614200929954,\n                        ],\n                        [\n                            8.70391845703125,\n                            42.15322331239858,\n                        ],\n                        [\n                            8.83575439453125,\n                            41.97991089691236,\n                        ],\n                        [\n                            8.81378173828125,\n                            41.797935707842974,\n                        ],\n                        [\n                            8.9208984375,\n                            41.777456667491066,\n                        ],\n                        [\n                            8.94012451171875,\n                            41.68316883525891,\n                        ],\n                        [\n                            9.0472412109375,\n                            41.52297326747377,\n                        ],\n                        [\n                            9.35760498046875,\n                            41.70777900286713,\n                        ],\n                        [\n                            9.33013916015625,\n                            42.06764572379527,\n                        ],\n                        [\n                            9.48394775390625,\n                            42.261049162113856,\n                        ],\n                        [\n                            9.47021484375,\n                            42.51462626746592,\n                        ],\n                        [\n                            9.33837890625,\n                            42.62385465855651,\n                        ],\n                        [\n                            9.1900634765625,\n                            42.6844544397102,\n                        ],\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"otci_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S3OLCI reflectance bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B09\",\n          \"B10\",\n          \"B11\",\n          \"B12\",\n          \"B13\",\n          \"B14\",\n          \"B15\",\n          \"B16\",\n          \"B17\",\n          \"B18\",\n          \"B19\",\n          \"B20\",\n          \"B21\",\n        ],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      bands: 21,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [\n    10000 * sample.B01,\n    10000 * sample.B02,\n    10000 * sample.B03,\n    10000 * sample.B04,\n    10000 * sample.B05,\n    10000 * sample.B06,\n    10000 * sample.B07,\n    10000 * sample.B08,\n    10000 * sample.B09,\n    10000 * sample.B10,\n    10000 * sample.B11,\n    10000 * sample.B12,\n    10000 * sample.B13,\n    10000 * sample.B14,\n    10000 * sample.B15,\n    10000 * sample.B16,\n    10000 * sample.B17,\n    10000 * sample.B18,\n    10000 * sample.B19,\n    10000 * sample.B20,\n    10000 * sample.B21,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 300,\n        \"resy\": 300,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S5PL2.html",
    "href": "APIs/SentinelHub/Process/Examples/S5PL2.html",
    "title": "Examples for S5PL2",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCarbon Monoxide, CO (RGB visualization and transparency with dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CO\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 0.1\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CO)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNitrogen Dioxide, NO2 (NRTI timeliness, RGB visualization and transparency with dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"NO2\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 0.0001\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.NO2)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    },\n                    \"timeliness\": \"NRTI\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFormaldehyde, HCHO (float32 format, specific value for no data, GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"HCHO\", \"dataMask\"],\n    output: { bands: 1, sampleType: \"FLOAT32\" },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1) {\n    return [sample.HCHO]\n  } else {\n    return [-9999]\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nOzone, O3 (RPRO timeliness, streched values and dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"O3\", \"dataMask\"],\n    output: { bands: 2 },\n  }\n}\n\nfunction evaluatePixel(sample, scene) {\n  var maxVal = 0.36\n  return [sample.O3 / maxVal, sample.dataMask]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-22T00:00:00Z\",\n                        \"to\": \"2019-04-23T00:00:00Z\",\n                    },\n                    \"timeliness\": \"RPRO\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nSulfur Dioxide, SO2 (minQa=20 applied, streched values)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"SO2\", \"dataMask\"],\n    output: { bands: 2 },\n  }\n}\n\nfunction evaluatePixel(sample, scene) {\n  var maxVal = 0.01\n  return [sample.SO2 / maxVal, sample.dataMask]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"minQa\": 20},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nMethane, CH4\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CH4\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 1600.0\nconst maxVal = 2000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CH4)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                10,\n                20,\n                15,\n                25,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nAER AI 340 and 380\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"AER_AI_340_380\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = -1.0\nconst maxVal = 5.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.AER_AI_340_380)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nAER AI 354 and 388\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"AER_AI_354_388\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = -1.0\nconst maxVal = 5.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.AER_AI_354_388)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud base height\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_BASE_HEIGHT\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0\nconst maxVal = 20000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_BASE_HEIGHT)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud base pressure\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_BASE_PRESSURE\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 10000.0\nconst maxVal = 110000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_BASE_PRESSURE)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nEffective radiometric cloud fraction\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_FRACTION\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 1.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_FRACTION)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud optical thickness\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_OPTICAL_THICKNESS\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 250.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_OPTICAL_THICKNESS)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud top height\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_TOP_HEIGHT\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 20000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_TOP_HEIGHT)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud top pressure\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_TOP_PRESSURE\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 10000.0\nconst maxVal = 110000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_TOP_PRESSURE)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S2L1C.html",
    "href": "APIs/SentinelHub/Process/Examples/S2L1C.html",
    "title": "Examples for S2L1C",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 100,\n        \"resy\": 100,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTIff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue Color, preview mode\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                18.55963134765625,\n                48.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-11T00:00:00Z\",\n                        \"to\": \"2018-11-18T00:00:00Z\",\n                    },\n                    \"previewMode\": \"PREVIEW\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, mosaicking with leastRecent\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-11T00:00:00Z\",\n                        \"to\": \"2018-11-18T00:00:00Z\",\n                    },\n                    \"mosaickingOrder\": \"leastRecent\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    mosaicking: Mosaicking.ORBIT,\n    output: { id: \"default\", bands: 3 },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.orbits }\n}\n\nfunction evaluatePixel(samples) {\n  return [2.5 * samples[0].B04, 2.5 * samples[0].B03, 2.5 * samples[0].B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ]\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-27T00:00:00Z\",\n                        \"to\": \"2018-12-27T23:59:59Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nTrue color multi-part-reponse (different formats and SampleType)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B03\", \"B02\"],\n        units: \"REFLECTANCE\", // default units\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 3,\n        sampleType: \"AUTO\", // default  - scales the output values from input values [0,1] to [0,255].\n      },\n      {\n        id: \"true_color_8bit\",\n        bands: 3,\n        sampleType: \"UINT8\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_16bit\",\n        bands: 3,\n        sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_32float\",\n        bands: 3,\n        sampleType: \"FLOAT32\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return {\n    // output band values are scaled from [0,1] to [0,255]. Multiply by 2.5 to increase brightness\n    default: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n\n    // Multiply input reflectance values by 2.5 to increase brighness and by 255 to return the band values clamped to [0, 255] unsigned 8 bit range.\n    true_color_8bit: [\n      2.5 * sample.B04 * 255,\n      2.5 * sample.B03 * 255,\n      2.5 * sample.B02 * 255,\n    ],\n\n    // Multiply input reflectance values by 2.5 to increase brightness and by 65535 to return the band values clamped to [0, 65535] unsigned 16 bit range.\n    true_color_16bit: [\n      2.5 * sample.B04 * 65535,\n      2.5 * sample.B03 * 65535,\n      2.5 * sample.B02 * 65535,\n    ],\n\n    // Returns band reflectance.\n    true_color_32float: [sample.B04, sample.B03, sample.B02],\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                12.206251,\n                41.627351,\n                12.594042,\n                41.856879,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-06-01T00:00:00Z\",\n                        \"to\": \"2018-08-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/jpeg\"},\n            },\n            {\n                \"identifier\": \"true_color_8bit\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"true_color_16bit\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"true_color_32float\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) return [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) return [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) return [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) return [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) return [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) return [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) return [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) return [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) return [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) return [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) return [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) return [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) return [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) return [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) return [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) return [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) return [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) return [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) return [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) return [0.06, 0.33, 0.04]\n  else return [0, 0.27, 0]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 80,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nExact NDVI values using a floating point GeoTIFF\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  return [ndvi]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI values as INT16 raster\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.INT16, //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  // Return NDVI multiplied by 10000 as integers to save processing units. To obtain NDVI values, simply divide the resulting pixel values by 10000.\n  return [ndvi * 10000]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: SampleType.FLOAT32,\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: SampleType.AUTO,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) image = [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) image = [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) image = [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) image = [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) image = [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) image = [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) image = [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) image = [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) image = [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) image = [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) image = [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) image = [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) image = [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) image = [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) image = [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) image = [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) image = [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) image = [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) image = [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) image = [0.06, 0.33, 0.04]\n  else image = [0, 0.27, 0]\n\n  return {\n    default: [ndvi],\n    ndvi_image: image,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S2L1C raw bands, original data (no harmonization)\nLearn about harmonization here.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B8A\",\n          \"B09\",\n          \"B10\",\n          \"B11\",\n          \"B12\",\n        ],\n        units: \"DN\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 13,\n      sampleType: SampleType.UINT16,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [\n    sample.B01,\n    sample.B02,\n    sample.B03,\n    sample.B04,\n    sample.B05,\n    sample.B06,\n    sample.B07,\n    sample.B08,\n    sample.B8A,\n    sample.B09,\n    sample.B10,\n    sample.B11,\n    sample.B12,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"false\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S2L2A.html",
    "href": "APIs/SentinelHub/Process/Examples/S2L2A.html",
    "title": "Examples for S2L2A",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 100,\n        \"resy\": 100,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTIff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue Color, cloudy pixels masked out\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"SCL\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if ([8, 9, 10].includes(sample.SCL)) {\n    return [1, 0, 0]\n  } else {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-11T00:00:00Z\",\n                        \"to\": \"2018-11-18T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    mosaicking: Mosaicking.ORBIT,\n    output: { id: \"default\", bands: 3 },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.orbits }\n}\n\nfunction evaluatePixel(samples) {\n  return [2.5 * samples[0].B04, 2.5 * samples[0].B03, 2.5 * samples[0].B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ]\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-27T00:00:00Z\",\n                        \"to\": \"2018-12-27T23:59:59Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 200,\n        \"height\": 100,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nTrue color multi-part-reponse (different formats and SampleType)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B03\", \"B02\"],\n        units: \"REFLECTANCE\", // default units\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 3,\n        sampleType: \"AUTO\", // default  - scales the output values from input values [0,1] to [0,255].\n      },\n      {\n        id: \"true_color_8bit\",\n        bands: 3,\n        sampleType: \"UINT8\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_16bit\",\n        bands: 3,\n        sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_32float\",\n        bands: 3,\n        sampleType: \"FLOAT32\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return {\n    // output band values are scaled from [0,1] to [0,255]. Multiply by 2.5 to increase brightness\n    default: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n\n    // Multiply input reflectance values by 2.5 to increase brighness and by 255 to return the band values clamped to [0, 255] unsigned 8 bit range.\n    true_color_8bit: [\n      2.5 * sample.B04 * 255,\n      2.5 * sample.B03 * 255,\n      2.5 * sample.B02 * 255,\n    ],\n\n    // Multiply input reflectance values by 2.5 to increase brightness and by 65535 to return the band values clamped to [0, 65535] unsigned 16 bit range.\n    true_color_16bit: [\n      2.5 * sample.B04 * 65535,\n      2.5 * sample.B03 * 65535,\n      2.5 * sample.B02 * 65535,\n    ],\n\n    // Returns band reflectance.\n    true_color_32float: [sample.B04, sample.B03, sample.B02],\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                12.206251,\n                41.627351,\n                12.594042,\n                41.856879,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-06-01T00:00:00Z\",\n                        \"to\": \"2018-08-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/jpeg\"},\n            },\n            {\n                \"identifier\": \"true_color_8bit\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"true_color_16bit\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"true_color_32float\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) return [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) return [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) return [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) return [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) return [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) return [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) return [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) return [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) return [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) return [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) return [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) return [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) return [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) return [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) return [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) return [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) return [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) return [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) return [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) return [0.06, 0.33, 0.04]\n  else return [0, 0.27, 0]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 80,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nExact NDVI values using a floating point GeoTIFF\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  return [ndvi]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI values as INT16 raster\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.INT16, //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  // Return NDVI multiplied by 10000 as integers to save processing units. To obtain NDVI values, simply divide the resulting pixel values by 10000.\n  return [ndvi * 10000]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: SampleType.FLOAT32,\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: SampleType.AUTO,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) image = [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) image = [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) image = [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) image = [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) image = [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) image = [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) image = [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) image = [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) image = [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) image = [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) image = [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) image = [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) image = [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) image = [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) image = [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) image = [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) image = [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) image = [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) image = [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) image = [0.06, 0.33, 0.04]\n  else image = [0, 0.27, 0]\n\n  return {\n    default: [ndvi],\n    ndvi_image: image,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S2L2A raw bands, original data (no harmonization)\nLearn about harmonization here.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B8A\",\n          \"B09\",\n          \"B11\",\n          \"B12\",\n        ],\n        units: \"DN\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 12,\n      sampleType: SampleType.UINT16,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [\n    sample.B01,\n    sample.B02,\n    sample.B03,\n    sample.B04,\n    sample.B05,\n    sample.B06,\n    sample.B07,\n    sample.B08,\n    sample.B8A,\n    sample.B09,\n    sample.B11,\n    sample.B12,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-01T00:00:00Z\",\n                        \"to\": \"2018-12-20T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"false\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nOther S2L2A specific data (Aerosol Optical Thickness, Scene Classification, Snow and Cloud probabilities, Sun and View angles)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"AOT\",\n          \"SCL\",\n          \"SNW\",\n          \"CLD\",\n          \"sunAzimuthAngles\",\n          \"sunZenithAngles\",\n          \"viewAzimuthMean\",\n          \"viewZenithMean\",\n        ],\n      },\n    ],\n    output: [\n      { id: \"TrueColor\", bands: 3, sampleType: SampleType.FLOAT32 },\n      { id: \"AOT\", bands: 1, sampleType: SampleType.UINT16 },\n      { id: \"SCL\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"SNW\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"CLD\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"SAA\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"SZA\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"VAM\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"VZM\", bands: 1, sampleType: SampleType.FLOAT32 },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  var truecolor = [sample.B04, sample.B03, sample.B02]\n  var aot = [sample.AOT]\n  var scl = [sample.SCL]\n  var snw = [sample.SNW]\n  var cld = [sample.CLD]\n  var saa = [sample.sunAzimuthAngles]\n  var sza = [sample.sunZenithAngles]\n  var vam = [sample.viewAzimuthMean]\n  var vzm = [sample.viewZenithMean]\n\n  return {\n    TrueColor: truecolor,\n    AOT: aot,\n    SCL: scl,\n    SNW: snw,\n    CLD: cld,\n    SAA: saa,\n    SZA: sza,\n    VAM: vam,\n    VZM: vzm,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-01T00:00:00Z\",\n                        \"to\": \"2019-03-22T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"TrueColor\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"AOT\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SCL\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SNW\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"CLD\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SAA\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SZA\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"VAM\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"VZM\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})"
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ErrorHandling.html",
    "href": "APIs/SentinelHub/Overview/ErrorHandling.html",
    "title": "Error handling",
    "section": "",
    "text": "Whenever an error occurs, whether it be the fault of the user or an internal system, an error object will be returned. HTTP response codes of 4xx suggest a bad request. If you receive a 4xx response, we recommend reviewing the API docs for more context to help you troubleshoot. 5xx errors suggest a problem on Sentinel Hub's end, so if you receive a 5xx error, please contact support."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html",
    "title": "Processing Unit definition",
    "section": "",
    "text": "⚠ Costs marked with ** are not yet applied. These will come in effect by June 1st 2023."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#general-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#general-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "title": "Processing Unit definition",
    "section": "General data processing - applicable to Process API, OGC API, Statistical API",
    "text": "General data processing - applicable to Process API, OGC API, Statistical API\nEach request costs a proportional amount of processing unit(s), depending on what data and processing is requested. One processing unit (PU) is defined as a request for:\n\nan output (image) size of 512 x 512 pixels,\n3 collection input bands,\none data sample per pixel (see sample),\nan output (image) format not exceeding 16 bits per pixel,\nwithout additional processing (e.g. orthorectification) applied,\n\nIn addition to this:\n\nMinimal cost of a request is\n\n0.005 PU for Process API and OGC API,\n0.01 PU for Statistical API.\n\nThe number of remaining processing units is reduced only when a request successfully executes, i.e. when the response code is 2XX.\n\n\"Multiplication factors\" are used to calculate how many processing units are required for each request. The definition of 1 processing unit and the calculation rules are summarized in the following tables:\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\nArea of interest\n512 x 512 px\nThe multiplication factor is calculated by dividing requested input size (BBOX) by 512 x 512 (pixel size depends on the user-defined resolution of the request execution).  The minimum value of this multiplication factor is 0.01. This corresponds to an area of 0.25 km^2 for Sentinel-2 data at 10 m spatial resolution.\n\n\nNumber of input bands\n3\nThe multiplication factor is calculated by dividing the requested number of input bands by 3. An exception is requesting dataMask which is not counted, unless it is the only band included.\n\n\nOutput format\n8 bit or 16 bit TIFF/JPG/PNG\nRequesting 32 bit float TIFF will result in a multiplication factor of 2 due to larger memory consumption and data traffic.  Requesting application/octet-stream will result in a multiplication factor of 1.4 due to additional integration costs (This is used for integration with external tools such as xcube.).\n\n\nNumber of data samples\n1\nThe multiplication factor equals the number of data samples per pixel.\n\n\n** Data fusion\nN/A\n** The multiplication is only applied when data fusion is used. Multiplication factor is calculated as a sum of all collections within the same endpoint location and twice the sum of all remote collections, i.e. count(local_collections) + 2x count(remote_collections). Example: data fusion request executed on services.sentinel-hub.com endpoint, which includes Sentinel-2 L1C, Sentinel-2 L2A and Landsat-9 would have a multiplication factor of 4 (1 + 1 + 2)."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#sentinel-1-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#sentinel-1-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "title": "Processing Unit definition",
    "section": "Sentinel-1 data processing - applicable to Process API, OGC API, Statistical API",
    "text": "Sentinel-1 data processing - applicable to Process API, OGC API, Statistical API\nIn addition to General data processing rules defined above, the following optional multiplicators apply as well:\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\n** Orthorectification\nN/A\n** Requesting orthorectification will result in a multiplication factor of 2 due to additional processing requirements .\n\n\n** Radiometric Terrain Correction\nN/A\n** Requesting radiometric terrain correction will result in a multiplication factor of 2.5 due to additional processing requirements. The orthorectification factor is not additionally applied as it is a prerequisite.\n\n\n** Speckle Filtering\nN/A\n** Requesting speckle filtering will result in a multiplication factor of 2 due to additional processing requirements."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-querying---applicable-to-catalog-api-ogc-wfs",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-querying---applicable-to-catalog-api-ogc-wfs",
    "title": "Processing Unit definition",
    "section": "Data querying - applicable to Catalog API, OGC WFS",
    "text": "Data querying - applicable to Catalog API, OGC WFS\nEach request costs a proportional amount of processing unit(s) depending on what data and processing is requested. One processing unit (PU) is defined as a request for:\n\narea of 1000 x 1000 km\ntime period up to one month\n\nIn addition to this:\n\nMinimal cost of a request is 0.01 PU.\nMaximal cost of a request is 1 PU.\nThe number of remaining processing units is reduced only when a request successfully executes, i.e. when the response code is 2XX.\n\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\nArea of interest\n1 000 000 km2\nThe multiplication factor is calculated by dividing requested input area of interest (BBOX) by 1 000 000.The minimum value of this multiplication factor is 0.01. This corresponds to an area of 10 000 km2\n\n\nTime period\n1 month\nThe multiplication factor is calculated by ceiling requested time period in months."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-processing-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-processing-api",
    "title": "Processing Unit definition",
    "section": "Batch Processing API",
    "text": "Batch Processing API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\n** Minimal cost of a request is 100 PU.\nProcessing with batch processing API will result in a multiplication factor of 1/3. Thus, three times more data can be processed comparing to process API for the same amount of PUs.\n** When data is delivered to a bucket in other region within the same system (i.e. CDAS, AWS) there is additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#asynchronous-processing-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#asynchronous-processing-api",
    "title": "Processing Unit definition",
    "section": "Asynchronous Processing API",
    "text": "Asynchronous Processing API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\nMinimal cost of a request is 10 PU.\n** When data is delivered to a bucket in other region within the same system (i.e. CDAS, AWS) there is an additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-statistical-api",
    "title": "Processing Unit definition",
    "section": "Batch Statistical API",
    "text": "Batch Statistical API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\nMinimal cost of a request is 100 PU.\n** When data is delivered to a bucket in other region within the same system (i.e. CDAS, AWS) there is an additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#third-party-data-order---applicable-to-third-party-data-import-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#third-party-data-order---applicable-to-third-party-data-import-api",
    "title": "Processing Unit definition",
    "section": "Third party data order - applicable to Third Party Data Import API",
    "text": "Third party data order - applicable to Third Party Data Import API\n\n** Each search request costs 1 PU.\n** Each thumbnail request costs 1 PU.\n** Each created order/subscription costs 5 PU.\n** Each processed order delivery costs 5 PU.\n** Each processed subscription delivery costs 2 PU."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-ingestion---applicable-to-bring-your-own-cog-api-and-zarr-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-ingestion---applicable-to-bring-your-own-cog-api-and-zarr-api",
    "title": "Processing Unit definition",
    "section": "Data ingestion - applicable to Bring your own COG API and Zarr API",
    "text": "Data ingestion - applicable to Bring your own COG API and Zarr API\n\nEach request to BYOC or Zarr API costs 1 PU.\nUsage of your BYOC and Zarr collections is billed the same as usage of public collections."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#request-cost-calculation-examples",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#request-cost-calculation-examples",
    "title": "Processing Unit definition",
    "section": "Request cost calculation examples",
    "text": "Request cost calculation examples\n\nSentinel-1 change detection\nAn example of calculation of processing units for a Sentinel-1 change detection request (e.g. comparison of two time slices) is presented in the table below.\n\n\n\nParameter\nQuantity\nMultiplication factor\nDetails\n\n\n\n\nOutput size (width x height)\n1024 x 1024 px\nx 4\nThe requested output size is 1024 x 1024 px which is 4 times larger than the output size for one PU (512 x 512 px). Hence the multiplication factor is 4.\n\n\nNumber of input bands\n4\nx 4/3\n4 input bands are requested, which is 4/3 times more than 3 input bands, which are included in one PU. The multiplication factor is thus 4/3.\n\n\nOutput format\n32-bit float\nx 2\nThe requested 32 bit float TIFF has a multiplication factor of 2.\n\n\nNumber of data samples\n2\nx 2\n2 data samples (one for each time slice) were requested for each pixel. Thus the multiplication factor is 2.\n\n\nOrthorectification\nYes\nx 2\nOrtorectification is requested, which results in a multiplication factor of 2.\n\n\n\nTotal\n42.667 processing units\nTo calculate the number of processing units for this request multiply all the individual multiplication factors: 4 x 4/3 x 2 x 2 x 2 = 42.667\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nStatistical API is also a multi-temporal request. The same rules for calculating multiplication factors apply.\n\n\n\n\nNDVI calculation for a parcel\nAn example of calculation of processing units of NDVI value over a 4 hectare large parcel at 10 m spatial resolution is presented in the table below.\n\n\n\nParameter\nQuantity\nMultiplication factor\nDetails\n\n\n\n\nOutput size (width x height)\n20 x 20 px\nx 0.01\nThe requested output size is 20 x 20 px which is smaller than the minimum area, thus the multiplication factor is 0.01.\n\n\nNumber of input bands\n2\nx 2/3\n2 input bands are requested, thus the multiplication factor is 2/3.\n\n\nOutput format\n16-bit tiff\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\nNumber of data samples\n1\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\nOrthorectification\nNo\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\n\nTotal\n0.0067 processing units\nTo calculate the number of processing units for this request multiply all the individual multiplication factors:  0.01 x 2/3 x 1 x 1 = 0.0067"
  },
  {
    "objectID": "APIs/SentinelHub/Overview/Authentication.html",
    "href": "APIs/SentinelHub/Overview/Authentication.html",
    "title": "Authentication",
    "section": "",
    "text": "The Sentinel Hub API uses OAuth2 Authentication and requires that you have an access token. In essence, this is a piece of information you add to your requests so the server knows it's you. These tokens do not last forever for a multitude of reasons, but you can get new ones and when they expire from the Sentinel-Hub OAuth2 server at the token endpoint listed below. But first, if you do not have one already, you need to register an OAuth Client in your account settings. This is so the server can expect you to make such token requests.\n\nHow to use tokens\nOnce you have a token, do use it for authenticating all your requests within its validity period. While tokens do not last forever, they do last a reasonable amount of time, and sufficiently long that they can be reused. The information of how long each token lasts is embedded in the token itself in the exp claim, and can be read from there.\nDo not fetch a new token for each API request you make. Token requests are rate limited, so if you are getting an HTTP 429 error, that means you are requesting too many tokens.\nTokens are JSON Web Tokens (JWT), more information about them here or here.\n\n\nRegistering OAuth client\nTo register an OAuth client, open the \"User Settings\" tab in your dashboard, then click the Create new button (1) in the \"OAuth client\" section. Give your OAuth client a name (2), set the Client grant type to Client Credentials, and click the Create client button (3). Your client secret will be displayed. Copy the secret value (4) and paste it locally, as it will not be visible after the pop-up window closes! When you are finished, click Close (5). You should now see the newly created OAuth client name and ID (6) in the list of your OAuth clients. With client ID and client secret, you are now ready to request tokens.\n\nTo request tokens the easiest way is to have some software which understands OAuth2 and can make the proper request. For example, REST clients like Postman and Insomnia have support for OAuth2 Client credentials already included. See the Token Request Examples section below.\n\n\nOAuth2 Endpoints\nToken Endpoint - for requesting tokens\nhttps://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\n\n\nToken Request Examples\n\ncURL\nThe following cURL request will return an access token, just make sure to replace &lt;your client id&gt; with your client ID and &lt;your client secret&gt; with your client secret:\ncurl --request POST --url https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token --header \"content-type: application/x-www-form-urlencoded\" --data \"grant_type=client_credentials&client_id=&lt;your client id&gt;\" --data-urlencode \"client_secret=&lt;your client secret&gt;\"\n\n\nPostman\nIn the Postman request Authorization tab set the Type to OAuth 2.0 and Add the authorization data to Request Headers. Then click the Get New Access Token button. Set the Grant Type to Client Credentials, the access token URL to the token endpoint, then set the Client ID and Client Secret to the values of your OAuth Client. Scope can be blank. Keep Client Authentication as Send As Basic Auth Header. Click Request Token. You should get a new one immediately. To use this token to authorize your request, click Use Token. For more information see the Postman authorization documentation\n\n\nPython\nIn python the requests-oauthlib library can handle the retrieval of access tokens using your OAuth Client configuration.\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Your client credentials\nclient_id = '&lt;client_id&gt;'\nclient_secret = '&lt;secret&gt;'\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token',\n                          client_secret=client_secret)\n\n# All requests using this session will have an access token automatically added\nresp = oauth.get(\"...\")\nprint(resp.content)\nrequests-oauthlib doesn't check for status before checking if the response is ok. In case there's a server error, the user can receive an incorrect error, which falsely makes it seem as if the issue is on client side. Library's compliance hooks will prevent the invalid status response from being ignored, returning the correct error. To use them, add the following code:\ndef sentinelhub_compliance_hook(response):\n    response.raise_for_status()\n    return response\n\noauth.register_compliance_hook(\"access_token_response\", sentinelhub_compliance_hook)\n\n\nJavascript\nExample using axios.\nimport axios from \"axios\"\nimport qs from \"qs\"\n\nconst client_id = \"&lt;client_id&gt;\"\nconst client_secret = \"&lt;secret&gt;\"\n\nconst instance = axios.create({\n  baseURL: \"https://sh.dataspace.copernicus.eu\"\n})\n\nconst config = {\n  headers: {\n    'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8'\n  }\n}\n\nconst body = qs.stringify({\n  client_id,\n  client_secret,\n  grant_type: \"client_credentials\"\n})\n\n\n// All requests using this instance will have an access token automatically added\ninstance.post(\"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\", body, config).then(resp =&gt; {\n  Object.assign(instance.defaults, {headers: {authorization: `Bearer ${resp.data.access_token}`}})\n})"
  },
  {
    "objectID": "APIs/SentinelHub/Overview/RateLimiting.html",
    "href": "APIs/SentinelHub/Overview/RateLimiting.html",
    "title": "Rate limiting",
    "section": "",
    "text": "In order to ensure the stability of the system and to guarantee good performance for all users we have to protect it against deliberate attacks or runaway scripts. Every request which reaches our system will therefore go through a rate limiting filter. As long as the agreed upon rate limiting policies are conformed to, responses by our services shall be delivered in timely fashion. On the other hand, requests which violate any of the agreed upon policies will be responded to with a HTTP 429 response.\nWe are able to adjust rate limit policies for each individual user so do contact our Support for specific requirements.\n\nRate limiting policy\nA rate limiting policy defines either how many processing units or HTTP requests can be used per given time period or in total. Both processing units and requests are rate limited and the level of rate limiting depends on your account (see pricing plans).\nAn API is usually protected by multiple rate limiting policies. For example, Processing API has both a processing unit and request rate limiting policies. To conform to the rate limiter, all rate limiting policies have to be satisfied. For example, lets say you have a policy of 100 requests per minute and a policy of 100 processing units per minute. By issuing 100 requests from each every request is valued at 2 processing units in one minute, only 50 requests will pass, all others will fail with HTTP status 429. Even though you have a limit of 100 requests per minute, 50 requests would violate the 100 processing units per minute policy and thus be rate limited.\nUnused processing units and requests do not accumulate. If you have a rate limit policy with 100 request per minute and you don't consume any request for a longer period you are still able to do just 100 requests within the next minute.\n\n\nRate limiting ramp up\nFor all SH subscriptions, the rate limiting is configured also on a \"per minute\" basis (i.e. 600 requests per minute and 1000 processing units per minute for the Enterprise S subscription). For optimal performance, it is best to spread this number of requests over a whole minute, i.e. to send one request every 0.1 seconds. As we understand that this might be difficult to do, we allow some variation from this optimum. However, if you will burst the full number of requests at once, some of them will be rate limited. For such requests, we recommend that you simply resend them - the process should reach the optimal level in a few minutes.\n\n\nResponse Headers\nAll requests going through rate limiting include headers to allow for programmatic adaption to Rate Limiting:\n\nRetry-After: Time in milliseconds until the next request is available.\n\n\nExample:\n\nResponse code and message\n{\n  \"status\": 429,\n  \"reason\": \"Too Many Requests\",\n  \"message\": \"You have exceeded your rate limit\",\n  \"code\": \"RATE_LIMIT_EXCEEDED\"\n}\n\n\nResponse header\n{\n  \"Date\": \"Tue, 16 Aug 2022 13:15:02 GMT\",\n  \"retry-after\": \"3398\",\n  ...\n}\nThe HTTP status code in this example is 429 meaning that the request was rate limited. The value of the Retry-After header is 3398, which means that next request will be available in 3398 ms.\n\n\n\n\nTry it out\nWe have set up a test user with two very restrictive rate limiting policies:\n\n10 requests per minute and\n10 processing units per minute\n\nYou can use its instance (for OGC requests) or Oauth client credentials (for API requests) to test how our rate limiting works and for integration purposes.\nAn example of a WMS request using the test user's instance:\n\n[https://services.sentinel-hub.com/ogc/wms/7702fda8-f583-4ae0-a581-1b34e7a6d350](https://services.sentinel-hub.com/ogc/wms/7702fda8-f583-4ae0-a581-1b34e7a6d350){target=“_blank”}?\n\nThe test user's Oauth client credentials below can be used to get an access token, which can then be included in header of a process API requests (for examples of requests see here):\n\nClient id: fa02a066-fc80-4cb4-af26-aae0af26cbf1 Client secret: rate_limit_secret\n\nNote that many people may be using it at the same moment so there is a chance that it will be over the limit more or less all the time. Its purpose is to evaluate response headers anyway.\n\n\nTips to Avoid Being Rate Limited\n\nCaching\nStore API responses that you expect to use a lot. For example, don’t call same requests on every page load but try to store responses in local storage.\n\n\nRequest only what you need\nBe defensive in fetching and try to request only the data that you actually need.\n\n\nExponential backoff\nWhen your limits have been exceeded, we recommend implementing retries with a exponential backoff. An exponential backoff means that you wait for exponentially longer intervals between each retry of a single failing request."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog/Examples.html",
    "href": "APIs/SentinelHub/Catalog/Examples.html",
    "title": "Catalog API examples",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCatalog API Entry page\nCatalog API Entry page with link to other catalog API endpoints and available collections.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/\"\nresponse = oauth.get(url)\n\n\nList collections\nList all available collections. The list will include deployment specific collections and collections available to users through BYOC, Batch or Third Party Data Import functionalities.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections\"\nresponse = oauth.get(url)\n\n\nSentinel 2 L1C collection\nList single collection, in this case Sentinel 2 L1C collection.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections/sentinel-2-l1c/\"\nresponse = oauth.get(url)\n\n\nSimple GET search\nSimple version of search available via GET request is also available. The only query parameters that can be specified in this simpler version are: bbox, datetime, collections, limit and next.\nquery = {\n    \"bbox\": \"13,45,14,46\",\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": \"sentinel-1-grd\",\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.get(url, params=query)\n\n\nSimple POST search\nThe same parameters can also be specified a POST request, query parameters need to be specified as json formatted body and sent to server like:\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSimple POST search with pagination\nnext token can be specified in the request to get back the next page of results.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"next\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with GeoJSON\nInstead of bbox it is possible to add intersects attribute, which can be any type of GeoJSON object (Point, LineString, Polygon, MultiPoint, MultiPolygon).\ndata = {\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"intersects\": {\n        \"type\": \"Point\",\n        \"coordinates\": [\n            13,\n            45,\n        ],\n    },\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Filter\nfilter object can be used to instruct server to only return a specific subset of data.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"filter\": \"sat:orbit_state='ascending'\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nGet Filter parameters for collection\nList all available filter parameters represented as JSON Schema.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections/sentinel-1-grd/queryables\"\nresponse = oauth.get(url)\n\n\nSearch with Fields: No fields\nDefault outputs from the server can be quite verbose for some collections. By default, all available item properties are included in the response.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Empty fields\nfields attribute can be specific to return less information. When fields object is empty only a default set of properties is included: id, type, geometry, bbox, links, assets.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Include\nBy specifying additional attributes in the include list, those attributes are added to the output along with the default ones.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {\"include\": [\"properties.gsd\"]},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Exclude\nexlude list can be used to exclude even the default ones from the output.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {\"exclude\": [\"properties.datetime\"]},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with distinct\nUsing distinct it is possible to get some overview of the data available inside the specified query. For example specifying date as an option will return a list of dates where data is available.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-01T00:00:00Z/2020-01-01T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 100,\n    \"distinct\": \"date\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\nOr see different Sentinel 1 instrument modes used.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-01T00:00:00Z/2020-01-01T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 100,\n    \"distinct\": \"sar:instrument_mode\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch on BYOC/BATCH collections\nYou can search for features on your own BYOC or Batch collections. The functionality described above regarding GET and POST search is the same. The only difference is that you have to specify the collection id with the appropriate prefix on collections parameter (e.g: byoc-&lt;your-collection-id&gt; for byoc or batch-&lt;your-collection-id&gt; for batch). Remember that you will have to use the appropriate deployment endpoint depending on where your collection is hosted.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"byoc-&lt;byoc-collection-id&gt;\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\nOr using GET simple search endpoint:\nquery = {\n    \"bbox\": \"13,45,14,46\",\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": \"batch-&lt;batch-collection-id&gt;\",\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.get(url, params=query)"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html",
    "href": "APIs/SentinelHub/Evalscript/V3.html",
    "title": "Evalscript V3",
    "section": "",
    "text": "Start your evalscript with //VERSION=3 so the system will interpret it as such.\nFor evalscript V3 you need to specify two functions (described in detail below):\nThis is an example of a simple V3 evalscript which returns a true color image:"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#setup-function",
    "href": "APIs/SentinelHub/Evalscript/V3.html#setup-function",
    "title": "Evalscript V3",
    "section": "setup function",
    "text": "setup function\nThis function is required as it sets up the input and output settings.\n\nSpecifics\nSetup needs to return a javascript object with the following properties:\n\ninput - an array of strings representing band names or an array of input objects.\noutput - a single output object or an array of output objects.\nmosaicking (optional) -  defines input sample preparation, see mosaicking. Defaults to SIMPLE.\n\n\nInput object properties\n\nbands - an array of strings representing band names\nunits (optional) - a string (all bands will use this unit) or an array of strings listing the units of each band. For a description of units see the documentation of the collection you are querying. Defaults to the default units for each band.\nmetadata (optional) - an array of strings representing properties which can be added to the metadata. Options:\n\n\"bounds\" - specifying this will add dataGeomtery and dataEnvelope to tiles\n\n\n\n\nOutput object properties\n\nid (optional) - any string of your choosing. Must be unique if multiple output objects are defined. Defaults to default.\nbands - the number of bands in this output.\nsampleType (optional) - sets the SampleType constant defining the returned raster sample type. Defaults to AUTO.\nnodataValue (optional) - sets the GDAL nodata metadata tag to the specified value. Only applicable for tiff files.\n\nNote that the number of bands represent the number of components in the output image. JPEG and PNG, for example, can only support 1 or 3 color components (plus an alpha channel for PNG, if set). The sampleType also needs to be compatible with the output raster format.\n\n\nMosaicking\nMosaicking defines how the source data is mosaicked. Not all collections support all these mosaicking types as it depends on how the source data is distributed. See the collection information pages to determine which ones are supported. It is a constant which is specified by a string. To use, for example, set: mosaicking: \"SIMPLE\".\n\nSIMPLE (default) - the simplest method, it flattens the mosaicked image so only a single sample is passed to evaluation. \nORBIT - the mosaicked image is flattened for each orbit so that there is only one sample per pixel per orbit. Multiple samples can therefore be present if there is more than one orbit for the selected time range at the pixel location.\nTILE - this is essentially the unflattened mosaic. It contains all data available for the selected time range. Multiple samples can be present as each sample comes from a single scene. What a scene is is defined by the datasource. \n\n\n\n\n\n\n\nNote\n\n\n\nORBIT mosaicking currently does not work exactly as described but generates a single scene for each day containing satellite data. For most requests this should not be an issue, however high latitude regions may have more than one acquisition per day. For these consider using TILE mosaicking if getting all available data is paramount. This will be corrected in future releases.\n\n\n\n\nSampleType\nSampleType defines the sample type of the output raster. This needs to be compatible with the raster format (e.g. JPEG cannot be FLOAT32). It is a constant which is specified by a string. To use, for example, set: sampleType: \"AUTO\".\n\nINT8 - signed 8-bit integer (values should range from -128 to 127)\nUINT8 - unsigned 8-bit integer (values should range from 0 to 255)\nINT16 - signed 16-bit integer (values should range from -32768 to\n\n\n\nUINT16 - unsigned 16-bit integer (values should range from 0 to\n\n\n\nFLOAT32 - 32-bit floating point (values have effectively no limits)\nAUTO (default) - values should range from 0-1, which will then automatically be stretched from the interval [0, 1] to [0, 255] and written into an UINT8 raster. Values below 0 and above 1 will be clamped to 0 and 255, respectively. This is the default if sampleType is not set in the output object.\n\nHandling SampleType in an Evalscript\nIt is the responsibility of the evalscript to return the values in the interval expected for the chosen sampleType. For integer SampleTypes, any floating point values will be rounded to the nearest integer and clamped to the value range of the SampleType. There is no need to do this yourself. For example, in case of UINT8 output, a value of 40.6 will be saved as 41, and a value of 310 will be saved as 255. If no sampleType is specified, AUTO is selected and the evalscript should return values ranging from 0-1. This is convenient as handling reflectance (e.g. Sentinel-2) data can be more intuitive.\n\n\n\nExamples\nThis simple Sentinel-2 setup() function gets bands B02, B03, B04 and returns (UINT16) 16 bit unsigned raster values.\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"B02\", \"B03\", \"B04\"], // this sets which bands to use\n      units: \"DN\" // here we optionally set the units. All bands will be in this unit (in this case Digital numbers)\n    }],\n    output: { // this defines the output image type\n      bands: 3, // the output of this evalscript will have RGB colors\n      sampleType: \"UINT16\" // raster format will be UINT16\n    }\n  };\n}\nThis Sentinel-2 setup() function gets bands B02, B03, B04 and returns a single raster with 8-bit integer values. To return values in the correct interval for the UINT8 sampleType, the evaluatePixel() function multiplies the reflectance values by 255. A true color image is returned.\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"B02\", \"B03\", \"B04\"], // this sets which bands to use\n    }],\n    output: {\n      bands: 3,\n      sampleType: \"UINT8\" // raster format will be UINT8\n    }\n  };\n}\nfunction evaluatePixel(sample) {\n  return [sample.B04 * 255, sample.B03 * 255, sample.B02 * 255]; // bands need to be multiplied by 255\n}\nIn case of UINT16, the multiplication factor in evaluatePixel() would be 65535 instead of 255.\nThe following example uses bands with different units and produces two rasters:\nfunction setup() {\n    return {\n      input: [{\n          bands: [\"B02\", \"B03\", \"B04\", \"B08\"],\n          units: [\"reflectance\", \"reflectance\", \"reflectance\", \"DN\"] // B08 will be in digital numbers, the rest reflectance\n      }],\n      output: [{ // this is now an array since there are multiple output objects\n          id: \"rgb\"\n          bands: 3\n      }, {\n          id: \"falseColor\"\n          bands: 3\n      }]\n    }\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#evaluatepixel-function",
    "href": "APIs/SentinelHub/Evalscript/V3.html#evaluatepixel-function",
    "title": "Evalscript V3",
    "section": "evaluatePixel function",
    "text": "evaluatePixel function\nThe evaluatePixel function is a mapping which maps the input bands in their input units to the values in the output raster(s). The function is executed once for each output pixel.\n\nParameters\nThe evaluatePixel function has five positional parameters:\nfunction evaluatePixel(samples, scenes, inputMetadata, customData, outputMetadata)\nThe first two parameters can be objects or arrays depending on requested mosaicking as explained below. They are additionally changed for data fusion requests, which is documented separately here. The remaining parameters are always objects.\n\nsamples\n\nWhen mosaicking is SIMPLE:\n\nsamples - an object containing the band values of the single mosaicked sample, in the specified units, as its properties. The property names equal the names of all the input bands, pixel values of a band can be accessed as e.g. samples.B02.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen using mosaicking SIMPLE we usually call this parameter sample in our examples to emphasize that it is an object and not an array.\n\n\n\nWhen mosaicking is TILE or ORBIT:\n\nsamples - an array of samples as defined in the SIMPLE case. None1, one or multiple samples can therefore be present depending on how many orbits/tiles there are for the selected time range and area of interest. Pixel values of a band can be accessed for each sample as an item of the array, e.g. samples[0].B02.\n\n\n\n\nscenes\n\nWhen mosaicking is SIMPLE:\n\nscenes object is empty.\n\nWhen mosaicking is ORBIT:\n\nscenes - an object containing a property orbits. scenes.orbits is an array of objects, where each of them contains metadata for one orbit (day). The length of scenes.orbits array is always the same as the length of samples array. A property, for example dateFrom, can be accessed as scenes.orbits[0].dateFrom. Each object's properties include:\n\ndateFrom (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. Together with orbits.dateTo it represents the time interval of one day. All tiles acquired on this day are mosaicked into this scene.\ndateTo (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. Together with orbits.dateFrom it represents the time interval of one day. All tiles acquired on this day are mosaicked into this scene.\ntiles (array) - an array of metadata for each tile used for mosaicking of this orbit. Each element has the same properties as elements of scenes.tiles (listed just below for mosaicking TILE).\n\n\nWhen mosaicking is TILE:\n\nscenes - an object containing a property tiles. scenes.tiles is an array of objects, where each of them contains metadata for one tile. The length of scenes.tiles array is always the same as the length of samples array. A property, for example cloudCoverage, can be accessed as scenes.tiles[0].cloudCoverage. Which properties are available for each tiles element depends on requested data and is documented in the \"Scenes Object\" chapter for each data collection, e.g. here for Sentinel-2 L1C. All possible properties are:\n\ndate (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. It represents a date when the tile was acquired.\ncloudCoverage (number) - Estimated percentage of pixels covered by clouds in the tile. This field is not available for all data collections. A value 2.09 means that 2.09% of pixels in the tile are cloudy.\ndataPath (string) - Path to where the tile is stored on a cloud. For example \"s3://sentinel-s2-l2a/tiles/33/T/VM/2020/9/15/0\".\ntileOriginalId (string) - Original filename of the tile or (in case of Sentinel-3 and -5p) a relative path containing the original filename. For example \"S2A_OPER_MSI_L2A_TL_VGS2_20200915T130644_A027332_T33TVM_N02.14\".\ndataGeometry (geojson - like object, see example) - an optional property, added only when requested. Represents a geometry of data coverage within the tile.\ndataEnvelope (geojson - like object, see example) - an optional property, added only when requested. Represents a bbox of dataGeometry.\nshId (number) - Sentinel Hub internal identifier of the tile. For example 11583048.\n\n\n\nNOTE 1: Objects may contain also fields prefixed by __ (double underscore). Such fields are used internally by Sentinel Hub services. Evalscripts should not make use of them because they can be changed or removed at any time and must never modify or delete such fields. Doing so may cause your request to fail or return incorrect results.\nNOTE 2: In the first implementation, scenes was an array of objects, where each of them contained metadata for one orbit or tile (depending on selected mosaicking). It was possible to access metadata as e.g. scenes[0].date. This approach is now deprecated and we strongly advise to use scenes as described above.\n\n\ninputMetadata\ninputMetadata is an object containing metadata used for processing by Sentinel Hub. Its properties are:\n\nserviceVersion - the version of Sentinel Hub which was used for processing.\nnormalizationFactor - the factor used by Sentinel Hub to convert digital numbers (DN) to reflectance using REFLECTANCE = DN * normalizationFactor. This is useful when requesting bands for which both units - DN and REFLECTANCE - are supported.\n\n\n\ncustomData\ncustomData is an object reserved for possible future use.\n\n\noutputMetadata\noutputMetadata is an object which can be used to output any user defined metadata including passing scenes objects, user defined thresholds or ids of original tiles used for processing. It contains:\n\nuserData - is a property to which you can assign a generic object that can contain any data. This can be pushed to the API response by adding a userdata identified output response object to your API request (see this for details or an example here).\n\n\n\n\nReturns\nThe evaluatePixel function can return:\n\nAn object whose keys are the output ids and its values are arrays of numbers. The length of the array is bound by the output object bands number and the values by sampleType.\nAn array of numbers with the same rules as above. This option can be used only when a single image output is defined.\nNothing; the return statement is not specified. This is useful when only information in outputMetadata.userData is needed.\n\n\nInput Units and Output Values\nThe values of each sample is the units specified in the input object. See the input object documentation for more information. How the output values are written to the output raster depends on the sample type. AUTO will stretch values in the interval [0, 1] to [0, 255] and then write those values into an UINT8 raster. The remaining sample types expect values within the range of the sample format.\n\n\n\nExamples\nExample evaluatePixel script returns a simple True Color image based on bands B04, B03, B02:\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02];\n}\nWhen we have multiple outputs in the setup function we can provide them as such:\nfunction evaluatePixel(sample) {\n  return {\n    trueColor: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n    falseColor: [2.5 * sample.B08, 2.5 * sample.B04, 2.5 * sample.B03]\n  };\n}\nCalculate the average value of band B04 when using ORBIT or TILE mosaicking:\nfunction evaluatePixel(samples) {\n  var sum = 0;\n  var nonZeroSamples = 0;\n  for (var i = 0; i &lt; samples.length; i++) {\n    var value = samples[i].B04;\n    if (value != 0) {\n      sum += value;\n      nonZeroSamples++;\n    }\n  }\n  return [sum / nonZeroSamples];\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#updateoutput-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#updateoutput-function-optional",
    "title": "Evalscript V3",
    "section": "updateOutput function (optional)",
    "text": "updateOutput function (optional)\nThis function can be used to adjust the number of output bands. This is useful, for example, to request all observations in a given time period as bands of an output file. The function is executed after the setup and preProcessScenes functions but before the evaluatePixel.\n\nParameters\n\noutput - an object containing ids of all outputs and their number of bands as specified in the setup function (Note: This is not the same object as output in the setup function.). The number of bands of each output is stored under output.&lt;output id&gt;.bands where &lt;output id&gt; is equal to values in the setup.output object. For example:\n\n{\n    \"default\": {\n        \"bands\": 2\n    },\n    \"my_output\": {\n        \"bands\": 3\n    }\n}\n\ncollection - an object containing one array per requested data collection. The length of each array equals the number of scenes available for processing. If only one data collection is requested, use collection.scenes.length to get the number of available scenes. For data fusion requests, use collection.&lt;data collection identifier&gt;.scenes.length. Each element in an array has a property:\n\ndate (type Date) - the date when the corresponding scene was acquired.\n\n\n\n\nReturns\nThis function updates the number of output bands and does not return anything.\n\n\nExample\nSuppose we request sentinel-2-l1c data from January 2020 with a maximum of 50% cloud coverage. All of this is specified in the body of a request. We would then like to return all available scenes as bands of an output file. Since we generally do not know how many scenes are available, we can not set the number of output bands directly in a setup function. Using the updateOutput function we can get the number of available scenes from collection and assign it as the value of output.&lt;output id&gt;.bands:\n//VERSION=3\nfunction setup() {\n    return {\n        input: [{\n                bands: [\"B02\"],\n            }\n        ],\n        output: [{\n                id: \"my_output\",\n                bands: 1,\n                sampleType: SampleType.UINT16\n            }\n        ],\n        mosaicking: Mosaicking.ORBIT\n    }\n}\n\nfunction updateOutput(output, collection) {\n    output.my_output.bands = collection.scenes.length\n}\n\nfunction evaluatePixel(samples) {\n    var n_scenes = samples.length\n    let band_b02 = new Array(n_scenes)\n\n    // Arrange values of band B02 in an array\n    for (var i = 0; i &lt; n_scenes; i++){\n        band_b02[i] = samples[i].B02\n    }\n\n    return {\n        my_output: band_b02\n    }\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#updateoutputmetadata-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#updateoutputmetadata-function-optional",
    "title": "Evalscript V3",
    "section": "updateOutputMetadata function (optional)",
    "text": "updateOutputMetadata function (optional)\nThis function is optional and if present is called at the end of evalscript evaluation. It provides a convenient way to forward information pertaining to the returned data as a whole (as opposed to evaluatePixel which is run for each pixel) into an output object. Do this by assigning any object you require to the userData property of the outputMetadata parameter.\n\nParameters\nThese are the full parameters of the updateOutputMetadata function:\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata)\nSee description of parameters in the \"evaluatePixel function\" chapter:\n\nscenes - scenes\ninputMetadata - inputMetadata\noutputMetadata - outputMetadata"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#preprocessscenes-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#preprocessscenes-function-optional",
    "title": "Evalscript V3",
    "section": "preProcessScenes function (optional)",
    "text": "preProcessScenes function (optional)\n\n\n\n\n\n\nNote\n\n\n\nThis function shall be used instead of filterScenes function.\n\n\nThis function is optional, and if present is called at the beginning of the script evaluation before the actual satellite data is processed. Use it when mosaicking is set to ORBIT or TILE. It provides additional filtering functionality for scenes, after the constraints set in the request parameters are already applied. This is useful, for example, to reduce the number of scenes needed, thereby reducing processing time and the number of processing units for the request.\n\nParameters\nThese are the full parameters of the preProcessScenes function:\nfunction preProcessScenes(collections)\n\ncollections\ncollections is an object, which contains different properties depending on which mosaicking option is selected.\n\nIf mosaicking is ORBIT, collections contains:\n\nfrom (type Date) - the value given as timeRange.from in the body of the request, representing the start of the search interval\nto (type Date) - the value given as timeRange.to in the body of the request, representing the end of the search interval\nscenes.orbits - corresponds to scenes.orbits as described for evalautePixel function and mosaicking ORBIT here but it doesn't contain tiles.\n\nIf mosaicking is TILE, collections contains:\n\nscenes.tiles - corresponds to scenes.tiles as described for evalautePixel function and mosaicking TILE here.\n\n\n\n\n\nReturns\nThe preProcessScenes function must return an objects of the same type as collections. Most often, a sub-set of the input collections will be returned, e.g. to keep only the data acquired before 1.2.2019:\nfunction preProcessScenes(collections){\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (scene) {\n        return new Date(scene.dateFrom) &lt; new Date(\"2019-02-01T00:00:00Z\")\n    });\n    return collections\n}\n\n\nExamples\n\nFilter scenes by particular days\nIn this example, we use preProcessScenes function to select images acquired on two particular dates within the requested timeRange. This example was taken (and adopted) from the evalscript for delineation of burned areas, based on the comparison of Sentinel-2 images acquired before (i.e. on \"2017-05-15\") and after (i.e. on \"2017-06-24\") the event.\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    var allowedDates = [\"2017-05-15\", \"2017-06-24\"]; //before and after Knysna fires\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var orbitDateFrom = orbit.dateFrom.split(\"T\")[0];\n        return allowedDates.includes(orbitDateFrom);\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    var allowedDates = [\"2017-05-15\", \"2017-06-24\"]; //before and after Knysna fires\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (tile) {\n        var tileDate = tile.date.split(\"T\")[0];\n        return allowedDates.includes(tileDate);\n    })\n    return collections\n}\n\n\n\nFilter scenes by time interval\nHere, we filter out (= remove) all the scenes acquired between the two selected dates, which both fall within the requested time range.\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        return (new Date(orbit.dateFrom) &lt; new Date(\"2019-01-31T00:00:00Z\")) ||\n               (new Date(orbit.dateFrom) &gt;= new Date(\"2019-06-01T00:00:00Z\"))\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (tile) {\n        return (new Date(tile.date) &lt; new Date(\"2019-01-31T00:00:00Z\")) ||\n               (new Date(tile.date) &gt;= new Date(\"2019-06-01T00:00:00Z\"))\n    })\n    return collections\n}\n\n\n\nSpecify the number of months taken into account\nValues of timeRange.from and timeRange.to parameters as given in the request, are available in the preProcessScenes function as collections.to and collections.from, respectively. Mosaicking must be ORBIT to use these parameters. They can be used to e.g. filter out scenes acquired more than 3 months before the given to date and time.\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var orbitDateFrom = new Date(orbit.dateFrom)\n        return orbitDateFrom.getTime() &gt;= (collections.to.getTime()-3*31*24*3600*1000);\n    })\n    return collections\n}\nThe 3*31*24*3600*1000 represents the 3 months converted to milliseconds. This is needed, so that a 3-month time span can be compared to scene.dateFrom and collections.to, which are all returned as milliseconds since 1970-1-1 by the getTime() function. Note: The result is the same as if the timeRange.from parameter in the body of the request is set to 3 months prior to the timeRange.to.\n\n\nSelect one image per month\nIn this example, we filter the available scenes, so that only the first scene acquired in each month is sent to the evaluatePixel function:\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits.sort(function (s1, s2) {\n            var date1 = new Date(s1.dateFrom);\n            var date2 = new Date(s2.dateFrom);\n            return date1 - date2}) // sort the scenes by dateFrom in ascending order\n\n    firstOrbitDate = new Date(collections.scenes.orbits[0].dateFrom)\n    var previousOrbitMonth = firstOrbitDate.getMonth() - 1\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var currentOrbitDate = new Date(orbit.dateFrom)\n        if (currentOrbitDate.getMonth() != previousOrbitMonth){\n            previousOrbitMonth = currentOrbitDate.getMonth();\n            return true;\n        } else return false;\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    collections.scenes.tiles.sort(function (s1, s2) {\n            var date1 = new Date(s1.date);\n            var date2 = new Date(s2.date);\n            return date1 - date2}) // sort the scenes by dateFrom in ascending order\n\n    firstTileDate = new Date(collections.scenes.tiles[0].date)\n    var previousTileMonth = firstTileDate.getMonth() - 1\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (scene) {\n        var currentTileDate = new Date(scene.date)\n        if (currentTileDate.getMonth() != previousTileMonth){\n            previousTileMonth = currentTileDate.getMonth();\n            return true;\n        } else return false;\n    })\n    return collections\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#ogc-services-specifics",
    "href": "APIs/SentinelHub/Evalscript/V3.html#ogc-services-specifics",
    "title": "Evalscript V3",
    "section": "OGC services specifics",
    "text": "OGC services specifics\nThere are some specifics when using evalscript V3 with WMS, WTS, WCS services:\n\nThese services return only the default output. Only one image can be returned with each request and it is not possible to request metadata in JSON format.\nTRANSPARENCY and BGCOLOR parameters are ignored. You can use dataMask band in evalscript V3 to handle transparency, as described here.\nBit depth, which is given as the part of a FORMAT parameter (e.g. FORMAT=image/tiff;depth=8) is ignored. You can use sampleType in evalscript V3 to request the bit depth of your choice."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#footnotes",
    "href": "APIs/SentinelHub/Evalscript/V3.html#footnotes",
    "title": "Evalscript V3",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn case samples is an empty array, calling samples[0].B02 will raise an error and it is up to users to handle this in their evalscript.↩︎"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html",
    "href": "APIs/SentinelHub/Evalscript/Functions.html",
    "title": "Utility Functions",
    "section": "",
    "text": "Visualizers are JavaScript classes with a method process which evaluates the representation value for a pixel from pixel’s band values.\n\n\nSets the color from a discrete color map.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\n\n\n\n\nconst map = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorMapVisualizer(map);\nvisualizer.process(199); // returns [ 1, 0, 0 ]\nvisualizer.process(200); // returns [ 1, 0, 0 ]\nvisualizer.process(250); // returns [ 1, 0, 0 ]\nvisualizer.process(299); // returns [ 1, 0, 0 ]\nvisualizer.process(300); // returns [ 0, 0, 1 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorMapVisualizer with following valColPairs\n[\n  [-1.0, 0x000000],\n  [-0.2, 0xff0000],\n  [-0.1, 0x9a0000],\n  [0.0, 0x660000],\n  [0.1, 0xffff33],\n  [0.2, 0xcccc33],\n  [0.3, 0x666600],\n  [0.4, 0x33ffff],\n  [0.5, 0x33cccc],\n  [0.6, 0x006666],\n  [0.7, 0x33ff33],\n  [0.8, 0x33cc33],\n  [0.9, 0x006600]\n]\n\n\n\n\nInterpolates a color based on interval.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\nminVal number (optional, default 0.0)\nmaxVal number (optional, default 1.0)\n\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs redTemperature\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createRedTemperature(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0.43137254901960786, 0, 0 ]\nvisualizer.process(0.5); // returns [ 0.7176470588235294, 0.047058823529411764, 0 ]\nvisualizer.process(0.8); // returns [ 1, 0.6196078431372549, 0.2 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs greenWhite\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createWhiteGreen(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0, 0.2980392156862745, 0 ]\nvisualizer.process(0.5); // returns [ 0.16862745098039217, 0.5019607843137255, 0 ]\nvisualizer.process(0.8); // returns [ 0.6666666666666666, 0.8, 0.3333333333333333 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs blueRed\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createBlueRed(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0.5019607843137255 ]\nvisualizer.process(0.3); // returns [ 0, 0.7019607843137254, 1 ]\nvisualizer.process(0.5); // returns [ 0.5019607843137255, 1, 0.5019607843137255 ]\nvisualizer.process(0.8); // returns [ 1, 0.2980392156862745, 0 ]\nvisualizer.process(1.0); // returns [ 0.5019607843137255, 0, 0 ]\nReturns ColorGradientVisualizer\n\n\n\n\n\nInterpolates a color based on the given color ramps.\n\n\n\nramps Array&lt;[number, number]&gt; Array of color ramps, which are defined as a pair of numbers - the ramp start and the ramp starting color.\n\n\n\n\nconst ramps = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorRampVisualizer(ramps);\nvisualizer.process(199); // [ 1, 0, 0 ]\nvisualizer.process(200); // [ 1, 0, 0 ]\nvisualizer.process(250); // [ 0.5019607843137255, 0, 0.5019607843137255 ]\nvisualizer.process(299); // [ 0.011764705882352941, 0, 0.9882352941176471 ]\nvisualizer.process(300); // [ 0, 1, 0 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nvalue number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\n\nThis is a piecewise linear function which compresses highlights. The minValue and maxValue will be mapped inside the interval [ 0, 1 ]. However, if maxValue lies in (0, 1) a second function which increases much more slowly will be used to further map the values which are mapped to 0.92 and above (see the figure below). This increases the visualized dynamic range while keeping most of the interval of interest linear. Useful, for example, for true color, with a maxValue of 0.4 to still keep some detail in clouds.\n\n\n\nPiecewise linear function which compresses highlights\n\n\n\n\n\nminValue number the value which will be mapped to 0. All values smaller than minValue will also be mapped to 0. (optional, default 0.0)\nmaxValue number the value which controls the position of the boundary point between both linear functions. It will be mapped to approx. 0.9259, while values greater than or equal to (2*maxValue - minValue) will be mapped to 1 (see the figure above). (optional, default 1.0)\ngain (optional, default 1.0)\noffset (optional, default 0.0)\ngamma (optional, default 1.0)\n\n\n\n\nconst visualizer = new HighlightCompressVisualizer(0.1, 0.4)\n\nvisualizer.process(0); // will return 0\nvisualizer.process(0.1); // will return 0\nvisualizer.process(0.25); // will return 0.5\nvisualizer.process(0.376); // will return 0.92. Note: 0.376 = minValue + 0.92*(maxValue - minValue)\nvisualizer.process(0.4); // will return 0.9259\nvisualizer.process(0.7); // will return 1 Note: 0.7 is the smallest value mapped to 1.\nvisualizer.process(1.1); // will return 1\n\n\n\nReturns mapped value.\n\n\n\nval number the input value to be mapped.\ni number the index of val. This is EO Browser specific.\n\nReturns [number] mapped value."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#visualizers",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#visualizers",
    "title": "Utility Functions",
    "section": "",
    "text": "Visualizers are JavaScript classes with a method process which evaluates the representation value for a pixel from pixel’s band values.\n\n\nSets the color from a discrete color map.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\n\n\n\n\nconst map = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorMapVisualizer(map);\nvisualizer.process(199); // returns [ 1, 0, 0 ]\nvisualizer.process(200); // returns [ 1, 0, 0 ]\nvisualizer.process(250); // returns [ 1, 0, 0 ]\nvisualizer.process(299); // returns [ 1, 0, 0 ]\nvisualizer.process(300); // returns [ 0, 0, 1 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorMapVisualizer with following valColPairs\n[\n  [-1.0, 0x000000],\n  [-0.2, 0xff0000],\n  [-0.1, 0x9a0000],\n  [0.0, 0x660000],\n  [0.1, 0xffff33],\n  [0.2, 0xcccc33],\n  [0.3, 0x666600],\n  [0.4, 0x33ffff],\n  [0.5, 0x33cccc],\n  [0.6, 0x006666],\n  [0.7, 0x33ff33],\n  [0.8, 0x33cc33],\n  [0.9, 0x006600]\n]\n\n\n\n\nInterpolates a color based on interval.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\nminVal number (optional, default 0.0)\nmaxVal number (optional, default 1.0)\n\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs redTemperature\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createRedTemperature(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0.43137254901960786, 0, 0 ]\nvisualizer.process(0.5); // returns [ 0.7176470588235294, 0.047058823529411764, 0 ]\nvisualizer.process(0.8); // returns [ 1, 0.6196078431372549, 0.2 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs greenWhite\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createWhiteGreen(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0, 0.2980392156862745, 0 ]\nvisualizer.process(0.5); // returns [ 0.16862745098039217, 0.5019607843137255, 0 ]\nvisualizer.process(0.8); // returns [ 0.6666666666666666, 0.8, 0.3333333333333333 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs blueRed\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createBlueRed(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0.5019607843137255 ]\nvisualizer.process(0.3); // returns [ 0, 0.7019607843137254, 1 ]\nvisualizer.process(0.5); // returns [ 0.5019607843137255, 1, 0.5019607843137255 ]\nvisualizer.process(0.8); // returns [ 1, 0.2980392156862745, 0 ]\nvisualizer.process(1.0); // returns [ 0.5019607843137255, 0, 0 ]\nReturns ColorGradientVisualizer\n\n\n\n\n\nInterpolates a color based on the given color ramps.\n\n\n\nramps Array&lt;[number, number]&gt; Array of color ramps, which are defined as a pair of numbers - the ramp start and the ramp starting color.\n\n\n\n\nconst ramps = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorRampVisualizer(ramps);\nvisualizer.process(199); // [ 1, 0, 0 ]\nvisualizer.process(200); // [ 1, 0, 0 ]\nvisualizer.process(250); // [ 0.5019607843137255, 0, 0.5019607843137255 ]\nvisualizer.process(299); // [ 0.011764705882352941, 0, 0.9882352941176471 ]\nvisualizer.process(300); // [ 0, 1, 0 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nvalue number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\n\nThis is a piecewise linear function which compresses highlights. The minValue and maxValue will be mapped inside the interval [ 0, 1 ]. However, if maxValue lies in (0, 1) a second function which increases much more slowly will be used to further map the values which are mapped to 0.92 and above (see the figure below). This increases the visualized dynamic range while keeping most of the interval of interest linear. Useful, for example, for true color, with a maxValue of 0.4 to still keep some detail in clouds.\n\n\n\nPiecewise linear function which compresses highlights\n\n\n\n\n\nminValue number the value which will be mapped to 0. All values smaller than minValue will also be mapped to 0. (optional, default 0.0)\nmaxValue number the value which controls the position of the boundary point between both linear functions. It will be mapped to approx. 0.9259, while values greater than or equal to (2*maxValue - minValue) will be mapped to 1 (see the figure above). (optional, default 1.0)\ngain (optional, default 1.0)\noffset (optional, default 0.0)\ngamma (optional, default 1.0)\n\n\n\n\nconst visualizer = new HighlightCompressVisualizer(0.1, 0.4)\n\nvisualizer.process(0); // will return 0\nvisualizer.process(0.1); // will return 0\nvisualizer.process(0.25); // will return 0.5\nvisualizer.process(0.376); // will return 0.92. Note: 0.376 = minValue + 0.92*(maxValue - minValue)\nvisualizer.process(0.4); // will return 0.9259\nvisualizer.process(0.7); // will return 1 Note: 0.7 is the smallest value mapped to 1.\nvisualizer.process(1.1); // will return 1\n\n\n\nReturns mapped value.\n\n\n\nval number the input value to be mapped.\ni number the index of val. This is EO Browser specific.\n\nReturns [number] mapped value."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#helper-functions",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#helper-functions",
    "title": "Utility Functions",
    "section": "Helper functions",
    "text": "Helper functions\nHelper functions that can be used in custom scripts.\n\nint2rgb\nTransforms a color as integer into RGB triplet.\n\nParameters\n\ncolor number as integer\n\n\n\nExamples\nint2rgb(255);    // returns [ 0, 0, 255 ]\nint2rgb(256);    // returns [ 0, 1, 0 ]\nint2rgb(65537);  // returns [ 1, 0, 1 ]\nReturns [number, number, number]\n\n\n\nrgb2int\nInverse of the int2rgb function. Transforms a RGB triplet into integer.\n\nParameters\n\ncolor [number, number, number] as RGB triplet\n\n\n\nExamples\nrgb2int([0, 0, 255]);  // returns 255\nrgb2int([0, 1, 0]);    // returns 256\nrgb2int([1, 0, 1]);    // returns 65537\nReturns number\n\n\n\ncombine\nCombines two colors.\n\nParameters\n\ncolor1 number The first color defined as an array of values.\ncolor2 number The second color defined as an array of values.\nalpha number A share of the first color defined as a floating point between 0 and\n\n\n\n\n\n\nExamples\ncombine([100, 0, 0], [0, 100, 0], 1);   // returns [ 100, 0, 0 ]\ncombine([100, 0, 0], [0, 100, 0], 0);   // returns [ 0, 100, 0 ]\ncombine([100, 0, 0], [0, 100, 0], 0.5); // returns [ 50, 50, 0 ]\nReturns number The combined color defined as an array of values.\n\n\n\nindex\nCalculate difference divided by sum\n\nParameters\n\nx number first value\ny number second value\n\n\n\nExamples\nindex(0.6, 0.4); // returns 0.2\nindex(0.5, -0.5); //returns 0.0\nReturns number (x - y) / (x + y), if sum is 0 returns 0\n\n\n\ninverse\nCalculate inverse value\n\nParameters\n\nx number value\n\n\n\nExamples\ninverse(2.0); // returns 0.5\ninverse(5.0); // returns 0.2\ninverse(0); // returns 1.7976931348623157E308\nReturns number inverse of value of x (1 / x), if x is 0 returns JAVA_DOUBLE_MAX_VAL\n\n\n\nvalueMap\nMaps a value to another value bound by an interval (from,to].\nintervals = [-10, -5, 0, 5, 10], values = [-100,-50, 0, 50, 100]\ndefines the following mapping:\n(-inf, -10]  =&gt; -100\n(-10, -5] =&gt; -50\n(-5,0] =&gt; 0\n(0, 5] =&gt; 50\n(5, +inf) =&gt; 100\n\nParameters\n\nvalue number input value\nintervals [number] array of numbers in ascending order defining intervals\nvalues [number] output value for the given interval\n\n\n\nExamples\nvalueMap(5, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 500\nvalueMap(1, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 100\nvalueMap(2, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 300\nvalueMap(12, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 900\nvalueMap(50); // returns 50\nReturns number\n\n\n\nvalueInterpolate\nInterpolates a value to another value bound by an interval (from,to]. Values at far ends of defined intervals are clamped to min/max value. This function is a replacement for the deprecated colorBlend function.\nintervals = [-10, -5, 0, 5, 10], values = [-1000,-50, 0, 50, 1000]\ndefines the following mapping:\n(-inf, -10]  =&gt; -1000\n(-10, -5] =&gt; (-1000, -50]\n(-5,0] =&gt; (-50,0]\n(0, 5] =&gt; (0,50]\n(5, 10] =&gt; (50,1000]\n(10, +inf) =&gt; 1000\n\nParameters\n\nvalue number input value\nintervals Array&lt;number&gt; array of numbers in ascending order defining intervals\nvalues (Array&lt;number&gt; | Array&lt;Array&lt;number&gt;&gt;) output interval for the given value/interval of the intervals array\n\n\n\nExamples\nvalueInterpolate(0, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns 0\nvalueInterpolate(-10, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns -1000\nvalueInterpolate(9, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns 810\nvalueInterpolate(50); // returns 50\nvalueInterpolate(0.1, [0, 0.2, 0.4, 0.6, 0.8, 1], [\n  [0, 0, 0],\n  [0.1, 0.2, 0.5],\n  [0.25, 0.4, 0.5],\n  [0.4, 0.6, 0.5],\n  [0.75, 0.8, 0.5],\n  [1, 1, 0.5]\n]); // return [0.05, 0.1, 0.25]\nReturns (number | Array&lt;number&gt;)"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#constants",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#constants",
    "title": "Utility Functions",
    "section": "Constants",
    "text": "Constants\n\nJAVA_DOUBLE_MAX_VAL\n const JAVA_DOUBLE_MAX_VAL = 1.7976931348623157E308;\nType: number\n\n\nblueRed\nconst blueRed = [\n  [1.000, 0x000080],\n  [0.875, 0x0000FF],\n  [0.625, 0x00FFFF],\n  [0.375, 0xFFFF00],\n  [0.125, 0xFF0000],\n  [0.000, 0x800000]\n]\nType: Array&lt;[number, number]&gt;\n\n\nredTemperature\nconst redTemperature = [\n  [1.000, 0x000000],\n  [0.525, 0xAE0000],\n  [0.300, 0xFF6E00],\n  [0.250, 0xFF8600],\n  [0.000, 0xFFFFFF]\n]\nType: Array&lt;[number, number]&gt;\n\n\ngreenWhite\nconst greenWhite = [\n  [1.000, 0x000000],\n  [0.600, 0x006600],\n  [0.300, 0x80B300],\n  [0.000, 0xFFFFFF]\n]\nType: Array&lt;[number, number]&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#colorblend",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#colorblend",
    "title": "Utility Functions",
    "section": "colorBlend",
    "text": "colorBlend\n\nParameters\n\nvalue number input value\nlimits Array&lt;number&gt; array of numbers in ascending order defining intervals\ncolors (Array&lt;number&gt; | Array&lt;Array&lt;number&gt;&gt;) output interval for the given value/interval of the intervals array\n\nReturns (number | Array&lt;number&gt;)\nMeta\n\ndeprecated: See valueInterpolate"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#landsat8c2qabandconditions",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#landsat8c2qabandconditions",
    "title": "Utility Functions",
    "section": "Landsat8C2QaBandConditions",
    "text": "Landsat8C2QaBandConditions\nCloud confidence, cloud shadow confidence, snow ice confidence and cirrus confidence represent levels of confidence that a condition exists:\n\n0 = “Not Determined”\n1 = “Low” = Low confidence.\n2 = “Medium / Reserved” = Medium only for cloud confidence.\n3 = “High” = High confidence.\n\nType: Object\n\nProperties\n\nfill number 0 for image data, 1 for fill data\ndilatedCloud number 0 for cloud is not dilated or no cloud, 1 for cloud dilation\ncirrus number 0 for no confidence level or low confidence, 1 for high confidence cirrus\ncloud number 0 for cloud confidence is not high, 1 for high confidence cloud\ncloudShadow number 0 for cloud shadow confidence is not high, 1 for high confidence cloud shadow\nsnow number 0 for snow/ice confidence is not high, 1 for high confidence snow cover\nclear number 0 if cloud or dilated cloud, or else 1\nwater number 0 for land or cloud, 1 for water\ncloudConfidence number\ncloudShadowConfidence number\nsnowIceConfidence number\ncirrusConfidence number"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#decodel8c2qa",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#decodel8c2qa",
    "title": "Utility Functions",
    "section": "decodeL8C2Qa",
    "text": "decodeL8C2Qa\nDecodes Landsat 8 Collection 2 Quality Assessment band conditions.\n\nParameters\n\nvalue integer band pixel (16-bit value)\n\n\n\nExamples\ndecodeL8C2Qa(55052);\n// returns {\n//   cirrus: 1, cirrusConfidence: 3,\n//   clear: 0,\n//   cloud: 1,\n//   cloudConfidence: 3,\n//   cloudShadow: 0,\n//   cloudShadowConfidence: 1,\n//   dilatedCloud: 0,\n//   fill: 0,\n//   snow: 0,\n//   snowIceConfidence: 1,\n//   water: 0\n// }\nReturns Landsat8C2QaBandConditions"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#decodes3olciqualityflags",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#decodes3olciqualityflags",
    "title": "Utility Functions",
    "section": "decodeS3OLCIQualityFlags",
    "text": "decodeS3OLCIQualityFlags\nUnpacks bit-packed Sentinel 3 OLCI Quality Flags values.\n\nParameters\n\nvalue integer QUALITY_FLAGS band DN value (32-bit value)\n\nReturns object An object containing the following keys with either 0 or 1 values: land, coastline, fresh_inland_water, tidal_region, bright, straylight_risk, invalid, cosmetic, duplicated, sun_glint_risk, dubious, saturatedBxy (where xy is the band number, e.g. saturatedB01)."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/Examples.html",
    "href": "APIs/SentinelHub/OGC/Examples.html",
    "title": "Examples of OGC API",
    "section": "",
    "text": "Below are examples for all our OGC APIs. To run the examples yourself, replace &lt;INSTANCE_ID&gt; in the URLs with your own configuration instance id and paste the url in any web browser. Your configuration must be based on the \"Simple WMS template\", which can be found when you create new configuration in the Dashboard in \"Configuration Utility\" tab.\nIf you want to check interactive example use this link.\n\nWMS #1\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetMap&BBOX=3238005,5039853,3244050,5045897&LAYERS=NATURAL-COLOR&MAXCC=20&WIDTH=320&HEIGHT=320&FORMAT=image/jpeg&TIME=2018-03-29/2018-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2018-03-29/2018-05-29\n\n\n\n\n\nResult\n\n\n\n\nWMS #2\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetMap&BBOX=3238005,5039853,3244050,5045897&FORMAT=image/jpeg&LAYERS=NATURAL-COLOR&MAXCC=20&WIDTH=320&HEIGHT=320&TIME=2017-01-29/2017-02-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2017-01-29/2017-02-29\n\n\n\n\n\nResult\n\n\n\n\nWCS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;?SERVICE=WCS&REQUEST=GetCoverage&COVERAGE=NATURAL-COLOR&BBOX=3238005,5039853,3244050,5045897&MAXCC=20&WIDTH=320&HEIGHT=320&FORMAT=image/jpeg&TIME=2019-03-29/2019-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2019-03-29/2019-05-29\n\n\n\n\n\nResult\n\n\n\n\nWMTS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;?REQUEST=GetTile&BBOX=3238005,5039853,3244050,5045897&RESOLUTION=10&TILEMATRIXSET=PopularWebMercator512&LAYER=FALSE-COLOR&MAXCC=20&TILEMATRIX=14&TILEROW=3065&TILECOL=4758&TIME=2018-03-29/2018-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nFALSE-COLOR\n\n\nMAXCC\n20\n\n\nRESOLUTION\n10\n\n\nTILEMATRIXSET\nPopularWebMercator512\n\n\nTILEMATRIX\n14\n\n\nTILEROW\n3065\n\n\nTILECOL\n4758\n\n\nTIME\n2018-03-29/2018-05-29\n\n\n\n\n\nResult\n\n\n\n\nWFS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;?REQUEST=GetFeature&srsName=EPSG:3857&TYPENAMES=DSS2&BBOX=3238005,5039853,3244050,5045897&TIME=2019-02-11/2019-02-12\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nREQUEST\nGetFeature\n\n\nsrsName\nEPSG:3857\n\n\nTYPENAMES\nDSS2\n\n\nBBOX\n3238005,5039853,3244050,5045897\n\n\nTIME\n2019-02-11/2019-02-12\n\n\n\n\n\nResult\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\n&lt;wfs:FeatureCollection xsi:schemaLocation=\"http://www.opengis.net/wfs/2.0 http://schemas.opengis.net/wfs/2.0/wfs.xsd http://www.opengis.net/gml/3.2 http://schemas.opengis.net/gml/3.2.1/gml.xsd\"\n    xmlns:sh=\"https://www.sentinel-hub.com/\" xmlns:gml=\"http://www.opengis.net/gml/3.2\" xmlns:wfs=\"http://www.opengis.net/wfs/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n  &lt;wfs:boundedBy&gt;\n    &lt;gml:Box srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n      &lt;gml:coordinates&gt;\n        3137112.369571343,4944408.712920986 3285542.013115577,5093151.414429454\n      &lt;/gml:coordinates&gt;\n    &lt;/gml:Box&gt;\n  &lt;/wfs:boundedBy&gt;\n  &lt;wfs:member&gt;\n    &lt;DSS2&gt;\n      &lt;gml:boundedBy&gt;\n        &lt;gml:Box srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n          &lt;gml:coordinates&gt;\n            3137112.369571343,4944408.712920986 3285542.013115577,5093151.414429454\n          &lt;/gml:coordinates&gt;\n        &lt;/gml:Box&gt;\n      &lt;/gml:boundedBy&gt;\n      &lt;id&gt;S2A_OPER_MSI_L2A_TL_SGS__20190212T133228_A019023_T35TPF_N02.11&lt;/id&gt;\n      &lt;date&gt;2019-02-12&lt;/date&gt;\n      &lt;time&gt;09:08:52&lt;/time&gt;\n      &lt;path&gt;s3://sentinel-s2-l2a/tiles/35/T/PF/2019/2/12/0&lt;/path&gt;\n      &lt;crs&gt;EPSG:32635&lt;/crs&gt;\n      &lt;mbr&gt;600000,4490220 709800,4600020&lt;/mbr&gt;\n      &lt;cloudCoverPercentage&gt;97.48&lt;/cloudCoverPercentage&gt;\n      &lt;geometryProperty&gt;\n        &lt;gml:MultiPolygon srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n          &lt;gml:polygonMember&gt;\n            &lt;gml:Polygon&gt;\n              &lt;gml:outerBoundaryIs&gt;\n                &lt;gml:LinearRing&gt;\n                  &lt;gml:coordinates&gt;\n                    3139096.254297407,5093151.414429454 3137112.369571343,4947176.295365512 3272770.2640233915,4944408.712920986 3273149.797764646,4946283.966865066 3273655.8785869186,4947972.618733139 3274080.280822489,4949071.057870209 3275105.522264074,4952896.767191993 3275390.8923655148,4953708.980760984 3275718.486013052,4955098.598468996 3282365.302587746,4979008.234912587\n                    3285542.013115577,5089991.454384799 3139096.254297407,5093151.414429454\n                  &lt;/gml:coordinates&gt;\n                &lt;/gml:LinearRing&gt;\n              &lt;/gml:outerBoundaryIs&gt;\n            &lt;/gml:Polygon&gt;\n          &lt;/gml:polygonMember&gt;\n        &lt;/gml:MultiPolygon&gt;\n      &lt;/geometryProperty&gt;\n    &lt;/DSS2&gt;\n  &lt;/wfs:member&gt;\n&lt;/wfs:FeatureCollection&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html",
    "href": "APIs/SentinelHub/OGC/WFS.html",
    "title": "Web Feature Service",
    "section": "",
    "text": "The Sentinel Hub WFS (Web Feature Service) service conforms to the WFS standard. It provides access to the geometric (vector) metadata about the available data collection tiles. As with the WMS service, WFS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WFS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WFS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;\nThe service supports many vector formats, including GML, XML, JSON and also raw HTML and plain text. Check GetCapabilities for a list of all supported formats. It supports WFS version 2.0.0."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html#wfs-request",
    "href": "APIs/SentinelHub/OGC/WFS.html#wfs-request",
    "title": "Web Feature Service",
    "section": "",
    "text": "The Sentinel Hub WFS (Web Feature Service) service conforms to the WFS standard. It provides access to the geometric (vector) metadata about the available data collection tiles. As with the WMS service, WFS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WFS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WFS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;\nThe service supports many vector formats, including GML, XML, JSON and also raw HTML and plain text. Check GetCapabilities for a list of all supported formats. It supports WFS version 2.0.0."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html#wfs-url-parameters",
    "href": "APIs/SentinelHub/OGC/WFS.html#wfs-url-parameters",
    "title": "Web Feature Service",
    "section": "WFS URL Parameters",
    "text": "WFS URL Parameters\nStandard common WFS URL parameters (parameter names are case insensitive):\n\n\n\nWFS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WFS\".\n\n\nVERSION\nWFS version standard. Optional, default: \"2.0.0\". Supported values: \"2.0.0\".\n\n\nREQUEST\nWhat is requested, valid values: DescribeFeatureType, GetFeature or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WFS URL parameters, the WFS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetFeature request URL parameters:\n\n\n\nWFS parameter\nInfo\n\n\n\n\nTYPENAMES\nMore information found below.\n\n\nMAXFEATURES\nThe maximum number of features to be returned by a single request. Default value: 100. Valid range: 0..100.\n\n\nBBOX\nThe bounding box area for which to return the features.\n\n\nSRSNAME\nThe CRS in which the BBOX is specified.\n\n\nFEATURE_OFFSET\nOffset controls the starting point within the returned features.\n\n\nOUTPUTFORMAT\nThe MIME format of the returned features.\n\n\n\nStandard DescribeFeatureType request URL parameters:\n\n\n\nWFS parameter\nInfo\n\n\n\n\nTYPENAMES\nMore information found below.\n\n\nOUTPUTFORMAT\nThe MIME format of the returned features.\n\n\n\n\nTypenames\n\n\n\nData collection\nTYPENAMES for AWS services\n\n\n\n\nSENTINEL-2 L1C\nDSS1\n\n\nSENTINEL-2 L2A\nDSS2\n\n\nSENTINEL-1 IW\nDSS3\n\n\nSENTINEL-1 EW\nDSS3\n\n\nSENTINEL-1 EW SH\nDSS3\n\n\nSENTINEL 3 OLCI\nDSS8\n\n\nSENTINEL 3 SLSTR\nDSS9\n\n\nSENTINEL 5P\nDSS7\n\n\nLANDSAT 8 L1 (from Collection 2)1\nDSS12\n\n\nLANDSAT 8 L2 (from Collection 2)\nDSS13\n\n\nLANDSAT 4-5 TM Level 1\nDSS15\n\n\nLANDSAT 4-5 TM Level 2\nDSS16\n\n\nLANDSAT 7 ETM Level 1\nDSS17\n\n\nLANDSAT 7 ETM Level 2\nDSS18\n\n\nLANDSAT 1-5 MSS Level 1\nDSS14\n\n\nHarmonized Landsat Sentinel\nDSS21\n\n\nLANDSAT 72\n/\n\n\nLANDSAT 53\n/\n\n\nMODIS\nDSS5\n\n\nENVISAT MERIS\n/\n\n\nBYOC\nbyoc-&lt;collectionId&gt;\n\n\nBATCH\nbatch-&lt;collectionId&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html#footnotes",
    "href": "APIs/SentinelHub/OGC/WFS.html#footnotes",
    "title": "Web Feature Service",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that Landsat 8 Level 1 from collection 1, known as L8L1C with a typename DSS6, has been deprecated and removed↩︎\nNote that Landsat 5 is a different collection than the Landsat 4-5TM. The former is only supported in OGC, while the↩︎\nNote that Landsat 5 is a different collection than the Landsat 4-5TM. The former is only supported in OGC, while the↩︎"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html",
    "title": "Output Formats",
    "section": "",
    "text": "For the requests that provide image output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\nimage/png - lossless image format for 1 (grayscale) or 3 (RGB) components\nimage/jpeg - lossy image format for 1 (grayscale) or 3 (RGB) components, without alpha channel. The quality can be controlled via the \"QUALITY\" URL parameter.\nimage/tiff - lossless image format for any number of the components.\n\nFind out more on how the values are reflected in the output.\n\n\nTo generate the output as jpeg, use the following example. Please replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=image/jpeg"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html#output-image-formats",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html#output-image-formats",
    "title": "Output Formats",
    "section": "",
    "text": "For the requests that provide image output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\nimage/png - lossless image format for 1 (grayscale) or 3 (RGB) components\nimage/jpeg - lossy image format for 1 (grayscale) or 3 (RGB) components, without alpha channel. The quality can be controlled via the \"QUALITY\" URL parameter.\nimage/tiff - lossless image format for any number of the components.\n\nFind out more on how the values are reflected in the output.\n\n\nTo generate the output as jpeg, use the following example. Please replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=image/jpeg"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html#output-vector-formats",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html#output-vector-formats",
    "title": "Output Formats",
    "section": "Output Vector Formats",
    "text": "Output Vector Formats\nFor the requests that provide vector output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\napplication/x-esri-shape - zip containing shape files\napplication/json - GeoJSON file\n\nBoth formats are returning polygons in vector format only in case when the image does not consists of more than 10 different values. Therefore, this formats only work with custom script layers.\n\nExample requests for vector formats:\nTo generate the output as GeoJSON file, follow the example below. Replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=application/json\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"properties\": {\n        \"COLOR_HEX\": \"FFFFFF\",\n        \"ID\": 0\n      },\n      \"geometry\": {\n        \"type\": \"MultiPolygon\",\n        \"crs\": {\n            \"type\": \"name\",\n            \"properties\": {\n                \"name\": \"urn:ogc:def:crs:OGC::CRS84\"\n            }\n        },\n        \"coordinates\": [[[\n            [16.225567302, 46.698948044],\n            [16.225567302, 46.6989451],\n            [16.225561399, 46.6989451],\n            [16.225561399, 46.698942156],\n            ...\n        ]]]\n      }\n    },\n    ...\n  ]\n}\nTo generate the output as x-esri-shape, replace the FORMAT with application/x-esri-shape, which will enable you to get the zip containing shape files."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html",
    "href": "APIs/SentinelHub/OGC/WCS.html",
    "title": "Web Coverage Service",
    "section": "",
    "text": "The Sentinel Hub WCS (Web Coverage Service) service conforms to the WCS standard. Provides access to the same bands product and additional informational layers as the WMS service except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. In addition to raster products, the WCS service can also return the vector features of the Sentinel-2 tiles' metadata. As with the WMS service, WCS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WCS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WCS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request (with addition of vector output formats, when \"TILE\" is selected as the COVERAGE) and supports the standard WCS requests: GetCoverage, DescribeCoverage and GetCapabilities. It supports WCS versions 1.0.0 and 1.1.2."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html#wcs-request",
    "href": "APIs/SentinelHub/OGC/WCS.html#wcs-request",
    "title": "Web Coverage Service",
    "section": "",
    "text": "The Sentinel Hub WCS (Web Coverage Service) service conforms to the WCS standard. Provides access to the same bands product and additional informational layers as the WMS service except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. In addition to raster products, the WCS service can also return the vector features of the Sentinel-2 tiles' metadata. As with the WMS service, WCS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WCS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WCS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request (with addition of vector output formats, when \"TILE\" is selected as the COVERAGE) and supports the standard WCS requests: GetCoverage, DescribeCoverage and GetCapabilities. It supports WCS versions 1.0.0 and 1.1.2."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html#wcs-url-parameters",
    "href": "APIs/SentinelHub/OGC/WCS.html#wcs-url-parameters",
    "title": "Web Coverage Service",
    "section": "WCS URL Parameters",
    "text": "WCS URL Parameters\nStandard common WCS URL parameters (parameter names are case insensitive):\n\n\n\nWCS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WCS\".\n\n\nVERSION\nWCS version standard. Optional, default: \"1.1.2\". Supported values: \"1.0.0\" and \"1.1.2\".\n\n\nREQUEST\nWhat is requested, valid values: GetCoverage, DescribeCoverage or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WCS URL parameters, the WCS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetCoverage request URL parameters:\n\n\n\nWCS parameter\nInfo\n\n\n\n\nCOVERAGE\nThe preconfigured (in the instance) layer for which to generate the output image, or \"TILE\" to return the vector format features.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values.\n\n\n\nStandard DescribeCoverage request URL parameters:\n\n\n\nWCS parameter\nInfo\n\n\n\n\nComing soon..."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html",
    "href": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html",
    "title": "Additional Request Parameters",
    "section": "",
    "text": "WMS/WMTS/WFS/WCS services support many custom parameters which affect the generation of the service responses. In the following table, all the available custom parameters, such as preview modes, are listed. All these parameters are optional.\nFor the examples on how to use them, see this documentation.\nNote that atmospheric correction is not a parameter anymore, as we now only support L2A atmospheric correction. Read more about it here.\n\n\n\nCustom parameter\nInfo\nDefault value\nValid value range\nAvailable for\n\n\n\n\nMAXCC\nThe maximum allowable cloud coverage in percent. Cloud coverage is a product average and not viewport accurate hence images may have more cloud cover than specified here.\n100.0\n0.0 - 100.0\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nPRIORITY\nThe priority by which to select and sort the overlapping valid tiles from which the output result is made. For example, using mostRecent will place newer tiles over older ones therefore showing the latest image possible. Using leastCC will place the least cloudy tiles available on top.\nmostRecent\nmostRecent, leastRecent, leastCC, leastTimeDifference, maximumViewingElevation\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nEVALSCRIPT\nThis parameter allows for a custom evaluation script or formula specifying how the output image will be generated from the input bands. See Custom evaluation script usage for details.   EVALSCRIPT parameter has to be BASE64 encoded before it is passed to the service.\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nEVALSCRIPTURL\nThis parameter allows for a custom evaluation script or formula to be passed as an URL parameter, where the script itself is located (it should be on HTTPS).\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nPREVIEW\nSee Preview modes for details.\n0\n0, 1, 2\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nGEOMETRY\nOutputs imagery only within the given geometry and cropped to the geometry's minimum bounding box.\n\none WKT string, one WKB hex string, or a list of coordinate pairs representing a polygon (pairs separated by semicolons, components by comma, i.e. 1 1, 2 2;...) Coordinates should be specified using the CRS of the request (i.e. same CRS as BBOX).\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nQUALITY\nUsed only when requesting JPEGs.\n90\n0 - 100; where 0 is the lowest and 100 the highest quality\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nUPSAMPLING\nSets the image upsampling method. Used when the requested resolution is higher than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nDOWNSAMPLING\nSets the image downsampling method. Used when the requested resolution is lower than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC, BOX\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nWARNINGS\nEnables or disables the display of in-image warnings, like \"No data available for the specified area\".\nYES\nYES, NO\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\n\n\n\nPreview modes make it possible to receive data from across all zoom levels. Sentinel Hub is optimised for full resolution data access as this is what most users need. There are, however, some cases when lower resolution previews of the data make sense as well. This is done by adding the URL parameter PREVIEW. Optional, default=\"0\". Supported values:\n\n\n\nValues\nInfo\n\n\n\n\nPREVIEW=0\nOnly high resolution data from Sentinel-2 is used. This corresponds to real world distances up to 200m/pixel. This is the default.\n\n\nPREVIEW=1\nAllows zooming further out, up to a point. Up to 200m/pixel it displays the same data as PREVIEW=0. In addition to this it uses lower resolution data for real world distances up to 1500m/pixel.   With resolutions between 200m/pixel and 1500m/pixel cloud filtering is no longer applied.\n\n\nPREVIEW=2\nAllows any zoom level but is limited to a maximum of one month of data when most zoomed out. Up to 1500m/pixel it displays the same data as PREVIEW=1. With resolutions lower than 1500m/pixel (more zoomed out) it limits the data to one month prior to the \"TO\" date.   With resolutions less than 200m/pixel (more zoomed out) cloud filtering is no longer applied.\n\n\n\n\n\n\nSatellite images sometimes seem washed out or foggy, as atmosphere absorbs and scatters light on its way to the ground. We can correct for this to get clearer images using atmospheric correction. ESA provides a Sen2Cor processor, that applies atmospheric correction to the input Sentinel-2 L1C data with global coverage. The resulting product is called S2L2A data. To use Atmospheric correction, use the Sentinel-2 L2A (S2L2A) data collection.\nBelow, you can see the difference atmospheric correction makes. The first image of Marseille was made in EO Browser using S2L1C data, and the lower image was made using S2L2A atmospheric correction."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html#additional-request-parameters",
    "href": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html#additional-request-parameters",
    "title": "Additional Request Parameters",
    "section": "",
    "text": "WMS/WMTS/WFS/WCS services support many custom parameters which affect the generation of the service responses. In the following table, all the available custom parameters, such as preview modes, are listed. All these parameters are optional.\nFor the examples on how to use them, see this documentation.\nNote that atmospheric correction is not a parameter anymore, as we now only support L2A atmospheric correction. Read more about it here.\n\n\n\nCustom parameter\nInfo\nDefault value\nValid value range\nAvailable for\n\n\n\n\nMAXCC\nThe maximum allowable cloud coverage in percent. Cloud coverage is a product average and not viewport accurate hence images may have more cloud cover than specified here.\n100.0\n0.0 - 100.0\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nPRIORITY\nThe priority by which to select and sort the overlapping valid tiles from which the output result is made. For example, using mostRecent will place newer tiles over older ones therefore showing the latest image possible. Using leastCC will place the least cloudy tiles available on top.\nmostRecent\nmostRecent, leastRecent, leastCC, leastTimeDifference, maximumViewingElevation\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nEVALSCRIPT\nThis parameter allows for a custom evaluation script or formula specifying how the output image will be generated from the input bands. See Custom evaluation script usage for details.   EVALSCRIPT parameter has to be BASE64 encoded before it is passed to the service.\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nEVALSCRIPTURL\nThis parameter allows for a custom evaluation script or formula to be passed as an URL parameter, where the script itself is located (it should be on HTTPS).\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nPREVIEW\nSee Preview modes for details.\n0\n0, 1, 2\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nGEOMETRY\nOutputs imagery only within the given geometry and cropped to the geometry's minimum bounding box.\n\none WKT string, one WKB hex string, or a list of coordinate pairs representing a polygon (pairs separated by semicolons, components by comma, i.e. 1 1, 2 2;...) Coordinates should be specified using the CRS of the request (i.e. same CRS as BBOX).\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nQUALITY\nUsed only when requesting JPEGs.\n90\n0 - 100; where 0 is the lowest and 100 the highest quality\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nUPSAMPLING\nSets the image upsampling method. Used when the requested resolution is higher than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nDOWNSAMPLING\nSets the image downsampling method. Used when the requested resolution is lower than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC, BOX\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nWARNINGS\nEnables or disables the display of in-image warnings, like \"No data available for the specified area\".\nYES\nYES, NO\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\n\n\n\nPreview modes make it possible to receive data from across all zoom levels. Sentinel Hub is optimised for full resolution data access as this is what most users need. There are, however, some cases when lower resolution previews of the data make sense as well. This is done by adding the URL parameter PREVIEW. Optional, default=\"0\". Supported values:\n\n\n\nValues\nInfo\n\n\n\n\nPREVIEW=0\nOnly high resolution data from Sentinel-2 is used. This corresponds to real world distances up to 200m/pixel. This is the default.\n\n\nPREVIEW=1\nAllows zooming further out, up to a point. Up to 200m/pixel it displays the same data as PREVIEW=0. In addition to this it uses lower resolution data for real world distances up to 1500m/pixel.   With resolutions between 200m/pixel and 1500m/pixel cloud filtering is no longer applied.\n\n\nPREVIEW=2\nAllows any zoom level but is limited to a maximum of one month of data when most zoomed out. Up to 1500m/pixel it displays the same data as PREVIEW=1. With resolutions lower than 1500m/pixel (more zoomed out) it limits the data to one month prior to the \"TO\" date.   With resolutions less than 200m/pixel (more zoomed out) cloud filtering is no longer applied.\n\n\n\n\n\n\nSatellite images sometimes seem washed out or foggy, as atmosphere absorbs and scatters light on its way to the ground. We can correct for this to get clearer images using atmospheric correction. ESA provides a Sen2Cor processor, that applies atmospheric correction to the input Sentinel-2 L1C data with global coverage. The resulting product is called S2L2A data. To use Atmospheric correction, use the Sentinel-2 L2A (S2L2A) data collection.\nBelow, you can see the difference atmospheric correction makes. The first image of Marseille was made in EO Browser using S2L1C data, and the lower image was made using S2L2A atmospheric correction."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html",
    "href": "APIs/SentinelHub/OGC/WMTS.html",
    "title": "Web Mapping Tile Service",
    "section": "",
    "text": "The Sentinel Hub WMTS (Web Map Tile Service) service conforms to the WMTS standard. It provides access to Sentinel-2's 13 unprocessed bands (B01 through B12, with B8A following B08) as well as processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration. Provides access to the same bands product and additional informational layers as the WMS request except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. As with the WMS service, WMTS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMTS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WMTS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request and supports the standard WMTS requests GetTile, GetCapabilities. It supports WMTS version 1.0.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nCheck GetCapabilities for a list of supported coordinate reference systems and tile matrix sets which can be used for the TILEMATRIX and TILEMATRIXSET parameters."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html#wmts-request",
    "href": "APIs/SentinelHub/OGC/WMTS.html#wmts-request",
    "title": "Web Mapping Tile Service",
    "section": "",
    "text": "The Sentinel Hub WMTS (Web Map Tile Service) service conforms to the WMTS standard. It provides access to Sentinel-2's 13 unprocessed bands (B01 through B12, with B8A following B08) as well as processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration. Provides access to the same bands product and additional informational layers as the WMS request except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. As with the WMS service, WMTS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMTS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WMTS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request and supports the standard WMTS requests GetTile, GetCapabilities. It supports WMTS version 1.0.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nCheck GetCapabilities for a list of supported coordinate reference systems and tile matrix sets which can be used for the TILEMATRIX and TILEMATRIXSET parameters."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html#wmts-parameters",
    "href": "APIs/SentinelHub/OGC/WMTS.html#wmts-parameters",
    "title": "Web Mapping Tile Service",
    "section": "WMTS Parameters",
    "text": "WMTS Parameters\nStandard common WMTS URL parameters (names are case insensitive):\n\n\n\nWMTS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WMTS\".\n\n\nVERSION\nWMTS version standard. Optional, default: \"1.0.0\". Supported values: \"1.0.0\".\n\n\nREQUEST\nWhat is requested, valid values: GetTile or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WMS URL parameters, the WMS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetTile request URL parameters:\n\n\n\nWMTS parameter\nInfo\n\n\n\n\nTILEMATRIXSET\nThe matrix set to be used for the output tile. Check GetCapabilities for a list of supported matrix sets.\n\n\nTILEMATRIX\nThe matrix to be used for the output tile. Check GetCapabilities for a list of supported matrices.\n\n\nTILECOL\nThe column index of the output tile. Check GetCapabilities for a list of supported matrix widths.\n\n\nTILEROW\nThe row index of the output tile. Check GetCapabilities for a list of supported matrix heights.\n\n\nLAYER\nThe preconfigured (in the instance) layer for which to generate the output tile.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html",
    "href": "APIs/SentinelHub/OGC/WMS.html",
    "title": "Web Mapping Service",
    "section": "",
    "text": "The Sentinel Hub WMS service conforms to the WMS standard. It not only provides access to raw satellite data but also to processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMS, help you understand the structure, show you how to run the requests in different environments and how it can be integrated with QGIS, ArcGIS and web applications.\nIt is possible to obtain multiple separate instances (which act as separate WMS services) each with their own configuration and list of layers which will likely be useful to advanced users.\nThe base URL for the WMS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;\nFor example, a GetCapabilities request can be done by changing the &lt;INSTANCE_ID&gt; to your provided instance ID and opening the following URL:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetCapabilities\nSome of the most common provided products:\n\nTRUE_COLOR - a brightened RGB image\nFALSE_COLOR - uses near-infrared instead of the blue band\nNDVI - Normalized Difference Vegetation Index\nEVI - Enhanced Vegetation Index\n\nList of all available products.\nThe service supports standard WMS requests: GetMap, GetCapabilities, GetFeatureInfo, and also some custom requests. Supported WMS versions are 1.1.1 and 1.3.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nFor a list of supported coordinate reference systems check the GetCapabilities result."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html#wms-request",
    "href": "APIs/SentinelHub/OGC/WMS.html#wms-request",
    "title": "Web Mapping Service",
    "section": "",
    "text": "The Sentinel Hub WMS service conforms to the WMS standard. It not only provides access to raw satellite data but also to processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMS, help you understand the structure, show you how to run the requests in different environments and how it can be integrated with QGIS, ArcGIS and web applications.\nIt is possible to obtain multiple separate instances (which act as separate WMS services) each with their own configuration and list of layers which will likely be useful to advanced users.\nThe base URL for the WMS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;\nFor example, a GetCapabilities request can be done by changing the &lt;INSTANCE_ID&gt; to your provided instance ID and opening the following URL:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetCapabilities\nSome of the most common provided products:\n\nTRUE_COLOR - a brightened RGB image\nFALSE_COLOR - uses near-infrared instead of the blue band\nNDVI - Normalized Difference Vegetation Index\nEVI - Enhanced Vegetation Index\n\nList of all available products.\nThe service supports standard WMS requests: GetMap, GetCapabilities, GetFeatureInfo, and also some custom requests. Supported WMS versions are 1.1.1 and 1.3.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nFor a list of supported coordinate reference systems check the GetCapabilities result."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html#wms-url-parameters",
    "href": "APIs/SentinelHub/OGC/WMS.html#wms-url-parameters",
    "title": "Web Mapping Service",
    "section": "WMS URL Parameters",
    "text": "WMS URL Parameters\nStandard common WMS URL parameters (parameter names are case insensitive, values are case sensitive):\n\n\n\nWMS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WMS\".\n\n\nVERSION\nWMS version standard. Optional, default: \"1.3.0\". Supported values: \"1.1.1\" and \"1.3.0\".\n\n\nREQUEST\nWhat is requested, valid values: GetMap, GetFeatureInfo, GetCapabilities or a custom request's name. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WMS URL parameters, the WMS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetMap request URL parameters:\n\n\n\nWMS parameter\nInfo\n\n\n\n\nBBOX\nSpecifies the bounding box of the requested image. Coordinates must be in the specified coordinate reference system. The four coordinates representing the top-left and bottom-right of the bounding box must be separated by commas. Required. Example: BBOX=-13152499,4038942,-13115771,4020692\n\n\nCRS\n(when VERSION 1.3.0 or higher) the coordinate reference system in which the BBOX is specified and in which to return the image. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nSRS\n(when VERSION 1.1.1 or lower) the coordinate reference system in which the BBOX is specified and in which to return the image. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values.\n\n\nWIDTH\nReturned image width in pixels. Required, unless RESX is used. If WIDTH is used, HEIGHT is also required.\n\n\nHEIGHT\nReturned image height in pixels. Required, unless RESY is used. If HEIGHT is used, WIDTH is also required.\n\n\nRESX\nReturned horizontal image resolution in UTM units (if m is added, e.g. 10m, in metrical units). (optional instead of WIDTH). If used, RESY is also required.\n\n\nRESY\nReturned vertical image resolution in UTM units (if m is added, e.g. 10m, in metrical units). (optional instead of HEIGHT). If used, RESX is also required.\n\n\nLAYERS\nThe preconfigured layer (image) to be returned. You must specify exactly one layer and optionally add additional overlays. Required. Example: LAYERS=TRUE_COLOR,OUTLINE\n\n\nEXCEPTIONS\nThe exception format. Optional, default: \"XML\". Supported values: \"XML\", \"INIMAGE\", \"BLANK\" (all three for version &gt;= 1.3.0), \"application/vnd.ogc.se_xml\", \"application/vnd.ogc.se_inimage\", \"application/vnd.ogc.se_blank\" (all three for version &lt; 1.3.0).\n\n\n\nStandard GetFeatureInfo request URL parameters:\n\n\n\nWMS parameter\nInfo\n\n\n\n\nBBOX\nSpecifies the bounding box of the area which contains the queried point. Coordinates are in the specified CRS/SRS. Four coordinates representing the top-left and bottom-right of the bounding box must be separated by comma. Required. Example: BBOX=-13152499,4038942,-13115771,4020692\n\n\nCRS\n(when VERSION 1.3.0 or higher) the coordinate reference system in which the BBOX is specified. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nSRS\n(when VERSION 1.1.1 or lower) the coordinate reference system in which the BBOX is specified. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nWIDTH\nThe image-space width containing the queried point, in pixels. Required.\n\n\nHEIGHT\nThe image-space height containing the queried point, in pixels. Required.\n\n\nINFO_FORMAT\nThe output format of the feature info content. Check GetCapabilities for a list of supported formats.\n\n\nRESY\nThe layers for which the feature info is requested.\n\n\nI and J\n(when VERSION 1.3.0 or higher) The X and Y coordinates in the output image space in pixels of the feature queried.\n\n\nX and Y\n(when VERSION 1.1.1 or lower) The X and Y coordinates in the output image space in pixels of the feature queried."
  },
  {
    "objectID": "APIs/SentinelHub/OGC.html",
    "href": "APIs/SentinelHub/OGC.html",
    "title": "OGC service",
    "section": "",
    "text": "Our OGC services offer the access to the Sentinel Hub functionalists via interfaces, which conform to the Open Geospatial Consortium (OGC) standards: WMS, WCS, WFS, and WMTS.\nUsing the OGC services you can avoid the complexities of preprocessing of satellite data. No need to download the data, no dealing with the JP2 format, no re-projecting, or mosaicking. No need for large storage volumes and lots of processing power. Simply add a new data collection in your GIS application (ArcGIS, QGIS, OpenLayers, Google Earth or any other app supporting standard services) and start using the data right away! Find more information on:\n\nWMS - Web Mapping Service\nWCS - Web Coverage Service\nWFS - Web Feature Service\nWMTS - Web Mapping Tile Service\n\n\nConfiguration Instance and Authentication\nTo use any of our OGC services you will need a \"configuration instance\" (or shortly \"instance\"). A configuration instance defines which layers are part of your OGC service, how the data shall be processed and visualized for each of these layers, and its id is used to authenticate your OGC requests. You can create a configuration instance using our Configuration API or in the Sentinel Hub Dashboard in the \"Configuration Utility\" tab. \"Simple WMS Instance\" is a pre-created configuration instance, which comes with your Sentinel Hub account and you can use its id (\"9d559...\" in the example below but yours will have a different id) to run the OGC examples.\n\n\n\nTutorials and Other Related Materials\nTo get you started, we have prepared a webinar on OGC API with QGIS integration, explaining the structure of OGC requests, how to run them in web browser, Postman and Python and integrate them into your own GIS. November 4, 2020"
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html",
    "href": "APIs/SentinelHub/Statistical.html",
    "title": "Statistical API",
    "section": "",
    "text": "The Statistical API (or shortly \"Stats API\") enables you to get statistics calculated based on satellite imagery without having to download images. In your Statistical API request, you can specify your area of interest, time period, evalscript and which statistical measures should be calculated. The requested statistics are returned in the API response. Using Statistical API you can calculate the percentage of cloudy pixels for a given area of interest and time period, or calculate mean, standard deviation, and histogram of band values for a parcel in a given time period. Find more examples here.\nTo familiarise yourself with the Statistical API, we recommend checking the Requests builder, our API reference and our Statistical API webinar."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#general-approach",
    "href": "APIs/SentinelHub/Statistical.html#general-approach",
    "title": "Statistical API",
    "section": "General approach",
    "text": "General approach\nBased on parameters specified by users in requests (e.g. area of interest, time range, evalscript) the Statistical API processes satellite data in a similar way as Processing API. Instead of returning images, it calculates requested statistics and returns the results in a json format."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#statistical-api-and-evalscript",
    "href": "APIs/SentinelHub/Statistical.html#statistical-api-and-evalscript",
    "title": "Statistical API",
    "section": "Statistical API and evalscript",
    "text": "Statistical API and evalscript\nAll general rules for building evalscripts apply. However, there are some specifics when using evalscripts with the Statistical API:\n\nThe evaluatePixel() function must, in addition to other output, always return also dataMask output. This output defines which pixels are excluded from calculations. For more details and an example, see here.\nThe default value of sampleType is FLOAT32.\nThe output.bands parameter in the setup() function can be an array. This makes it possible to specify custom names for the output bands and different output dataMask for different outputs, see this example."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#apis-features",
    "href": "APIs/SentinelHub/Statistical.html#apis-features",
    "title": "Statistical API",
    "section": "API's features",
    "text": "API's features\n\nSplit requested timeRange into multiple time intervals\nThe Statistical API supports requesting statistics for multiple time intervals with only one request. For example, requesting the aggregationInterval and timeRange as:\n...\n\"timeRange\": {\n    \"from\": \"2020-06-01T00:00:00Z\",\n    \"to\": \"2020-07-31T00:00:00Z\"\n    },\n\"aggregationInterval\": {\n    \"of\": \"P10D\"\n}\n...\nreturns the requested statistics calculated for multiple 10-day intervals, see this example. The aggregation intervals should be at least one day long (e.g. \"P5D\", \"P30D\"). You can only use period OR time designator not both.\nIf a timeRange is not divisible by an aggregationInterval, the last (\"not full\") time interval will be dismissed by default (SKIP option). The user can instead set the lastIntervalBehavior to SHORTEN (shortens the last interval so that it ends at the end of the provided time range) or EXTEND (extends the last interval over the end of the provided time range so that all the intervals are of equal duration).\nNote that the data is mosaicked for each of the time intervals (as defined with the mosaicking parameter in an evalscript) before the statistics are calculated. To calculate statistics over time (for example, the maximum NDVI value in a month), you should set mosaicking to ORBIT or TILE and calculate the required value in an evalscript, see this example. If you use mosaicking SIMPLE, one mosaicked output for each time interval is a basis for calculating statistics.\n\n\nHistogram\nRequesting histograms is optional. A variety of histogram customisations are available. Users can specify:\n\nnumber of bins nBins or\nwidth of bins binWidthor\narbitrary bins.\n\nThis example demonstrates all three options.\n\n\nPercentile calculations\nIt is possible to get values for any percentile. For example, to get values for 33%, 75%, and 90% percentile, add the \"percentiles\" parameter to your requests as:\n...\n{\n  \"percentiles\": {\n    \"k\": [33, 75, 90]\n  }\n}\n...\nSee also this example.\n\n\nExclude pixels from calculations (dataMask output)\nIt is possible to exclude certain pixels from the calculation of the statistics. The most common use cases are excluding no data and cloudy pixels.\nWith the Statistical API, this is achieved by defining a special output called \"dataMask\". This output should have value \"0\" assigned for the pixels that should be excluded from the calculations, and a value of \"1\" elsewhere. The values of the \"dataMask\" output are defined by the user in an evalscript. An illustrative example is excluding water pixels from statistics of NDVI, see this example.\nNote that the Statistical API does not automatically exclude the no data pixels from calculating the statistics. We recommend that you always exclude those unless there is a good reason not to. This is especially important when you are requesting statistics for a polygon, as it will ensure that pixels outside of the polygon (and inside of the bounding box) are excluded. To exclude no data pixels you need to pass input dataMask band to the dataMask output, e.g.:\nfunction evaluatePixel(samples) {\n    return {\n        ...,\n        dataMask: [samples.dataMask]\n        }\n}\nAll evalscripts in the examples here exclude no data pixels.\n\n\nMultiple outputs and multi bands outputs\nStatistics can be requested for multiple outputs. This is useful when we need to use different dataMasks or different sampleTypes for each output. Additionally, each output can have multiple bands. It is possible to request different statistics for each band and for each output. This example demonstrates how to do all this.\n\n\nExamples\nExamples of Statistical API\n\n\nTutorials and Other Related Materials\n\nTo get you started, we created a detailed beginner webinar on statistical API, where you can learn how to get statistics for your data, how to manipulate the evalscript to return several outputs, each with its own statistical information, how to make use of powerful aggregations, exclude pixels from the calculation, make custom histograms and visualize your statistics in Python."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript.html",
    "href": "APIs/SentinelHub/Evalscript.html",
    "title": "Evalscript (custom script)",
    "section": "",
    "text": "An evalscript (or \"custom script\") is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return. It is a required part of any process, batch processing or OGC request.\nEvalscripts can use any JavaScript function or language structures, along with certain utility functions we provide for your convenience. For running evalscripts we use the Chrome V8 JavaScript engine.\nIn the Evalscript V3 section you will find a technical documentation with detailed explanations of parameters and functions you can use in your evalscripts.\n\nExamples\nExamples of various evalscritps can be found on our Custom Scripts Repository.\n\n\nTutorials and Other Related Materials\n\nA PDF tutorial on writing simple evalscripts for beginners: Custom scripts tutorial\nA webinar on writing evalscripts for beginners: Custom Scripts, September 28, 2020\nA webinar on multi-temporal scripts and data fusion: Multi-temporal Scripts and Data Fusion, March 3, 2021\nA blog on good scripting practices: Custom Scripts: Faster, Cheaper, Better!, November 18, 2019\nA blog post on color maps: PUCK - Perceptually Uniform Color Maps in Satellite Imagery, January 28, 2021\nA blog post on sampleType: SampleType: what’s all the fuss about?, February 15, 2022\nMore blog posts and useful links can be found on our Sentinel Hub website."
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Transparency.html",
    "href": "APIs/SentinelHub/UserGuides/Transparency.html",
    "title": "Transparency",
    "section": "",
    "text": "Parts of the image can be made fully or partially transparent by including the fourth output channel, also known as the alpha channel. The value 0 in the alpha channel makes a pixel fully transparent, while the maximum value in the alpha channel makes it fully opaque (not transparent). Values in between will make the pixel proportionally transparent. Maximum value in alpha channel depends on an image bit depth which is in SH specified by sampleType:\n\nfor sampleType AUTO or FLOAT32: values in alpha channel should be from the interval [0, 1]\nfor sampleType UINT8: values in alpha channel should be from the interval [0, 255]\nfor sampleType UINT16: values in alpha channel should be from the interval [0, 65535]\n\nOutput file formats which support transparency are PNG and TIFF. Note that the JPEG format does not support alpha channel.\n\n\nNo-data pixels are marked by the value 0 in the dataMask band. In the evalscript below, we return value 0 in the forth band for such pixels, which made them transparent. This evalscript can be used as part of any request for Sentinel-2 data and it will display a true color image with transparent background.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    if (samples.dataMask == 1){\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 1]\n    } else if (samples.dataMask == 0) {\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 0]\n    }\n}\nIn the example above we see that the value of dataMask band is exactly the value we want to use for the alpha channel (i.e. fourth channel) of the output. We can thus simplify the evalscript and return dataMask as the fourth band for all pixels.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, samples.dataMask]\n}\nExamine in EO Browser\nElegant! This will work whenever you request sampleType AUTO or FLOAT32. However, for other sampleTypes, you will have to scale the output values to achieve the same transparency. Let us check how to do this in the examples below.\n\n\nWhen using sampleType UINT16 the range of output values in an image becomes [0, 65535] and we must return value 65535 in the alpha channel for pixels which should not be transparent. The above example, if using sampleType UINT16, would be:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT16\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 65535, samples.B03 * 3.5 * 65535, samples.B02 * 3.5 * 65535, samples.dataMask * 65535]\n}\n\n\n\nThe same logic applies also for sampleType UINT8 except that the range of output values in this case is [0, 255]. The same evalscript as above but for sampleType UINT8 is:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT8\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 255, samples.B03 * 3.5 * 255, samples.B02 * 3.5 * 255, samples.dataMask * 255]\n}\n\n\n\n\nTo use some other condition for turning pixels transparent, simply return the condition in the fourth channel, while also outputting four bands in the function setup(). In the example below, we are returning the Sentinel-2 L1C NDVI index larger than 0.6 as transparent. We also leave the no-data pixels non-transparent and thus do not need to use the the dataMask input band.\n//VERSION=3\nfunction setup () {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"B08\"],\n    output: {bands: 4}\n  }\n}\nfunction evaluatePixel(samples, scenes) {\n  var NDVI = (samples.B08 - samples.B04) / (samples.B08 + samples.B04)\n  return [samples.B04 * 2.5, samples.B03 * 2.5, samples.B02 * 2.5, NDVI &lt; 0.6]\n}\nExamine in EO Browser\n\n\n\n  \n      \n         Cloud Masks\n                \n  \n  \n      \n        Time Series"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Transparency.html#transparency-and-background-color",
    "href": "APIs/SentinelHub/UserGuides/Transparency.html#transparency-and-background-color",
    "title": "Transparency",
    "section": "",
    "text": "Parts of the image can be made fully or partially transparent by including the fourth output channel, also known as the alpha channel. The value 0 in the alpha channel makes a pixel fully transparent, while the maximum value in the alpha channel makes it fully opaque (not transparent). Values in between will make the pixel proportionally transparent. Maximum value in alpha channel depends on an image bit depth which is in SH specified by sampleType:\n\nfor sampleType AUTO or FLOAT32: values in alpha channel should be from the interval [0, 1]\nfor sampleType UINT8: values in alpha channel should be from the interval [0, 255]\nfor sampleType UINT16: values in alpha channel should be from the interval [0, 65535]\n\nOutput file formats which support transparency are PNG and TIFF. Note that the JPEG format does not support alpha channel.\n\n\nNo-data pixels are marked by the value 0 in the dataMask band. In the evalscript below, we return value 0 in the forth band for such pixels, which made them transparent. This evalscript can be used as part of any request for Sentinel-2 data and it will display a true color image with transparent background.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    if (samples.dataMask == 1){\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 1]\n    } else if (samples.dataMask == 0) {\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 0]\n    }\n}\nIn the example above we see that the value of dataMask band is exactly the value we want to use for the alpha channel (i.e. fourth channel) of the output. We can thus simplify the evalscript and return dataMask as the fourth band for all pixels.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, samples.dataMask]\n}\nExamine in EO Browser\nElegant! This will work whenever you request sampleType AUTO or FLOAT32. However, for other sampleTypes, you will have to scale the output values to achieve the same transparency. Let us check how to do this in the examples below.\n\n\nWhen using sampleType UINT16 the range of output values in an image becomes [0, 65535] and we must return value 65535 in the alpha channel for pixels which should not be transparent. The above example, if using sampleType UINT16, would be:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT16\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 65535, samples.B03 * 3.5 * 65535, samples.B02 * 3.5 * 65535, samples.dataMask * 65535]\n}\n\n\n\nThe same logic applies also for sampleType UINT8 except that the range of output values in this case is [0, 255]. The same evalscript as above but for sampleType UINT8 is:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT8\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 255, samples.B03 * 3.5 * 255, samples.B02 * 3.5 * 255, samples.dataMask * 255]\n}\n\n\n\n\nTo use some other condition for turning pixels transparent, simply return the condition in the fourth channel, while also outputting four bands in the function setup(). In the example below, we are returning the Sentinel-2 L1C NDVI index larger than 0.6 as transparent. We also leave the no-data pixels non-transparent and thus do not need to use the the dataMask input band.\n//VERSION=3\nfunction setup () {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"B08\"],\n    output: {bands: 4}\n  }\n}\nfunction evaluatePixel(samples, scenes) {\n  var NDVI = (samples.B08 - samples.B04) / (samples.B08 + samples.B04)\n  return [samples.B04 * 2.5, samples.B03 * 2.5, samples.B02 * 2.5, NDVI &lt; 0.6]\n}\nExamine in EO Browser\n\n\n\n  \n      \n         Cloud Masks\n                \n  \n  \n      \n        Time Series"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Datamask.html",
    "href": "APIs/SentinelHub/UserGuides/Datamask.html",
    "title": "Data Mask",
    "section": "",
    "text": "With evalscript v3 we are now providing full control to you over what is to be returned for image parts (pixels) where there is “no data”. In the setup function, you can request dataMask as an element of the input array and then use it in the evaluatePixel function in the same manner as any other input band.\n\n\ndataMask has value 0 for “no data” pixels and 1 elsewhere.\nBy “no data” pixels we mean:\n\nAll pixels which lay outside of the requested polygon (if specified).\nAll pixels for which no source data was found.\nAll pixels for which source data was found and is explicitly “no data”.\n\nThings to note:\n\nAll “no data” pixels as defined above have a dataMask value of 0. All band values for these pixels are also 0, except for Landsat data collections, where band values for no data pixels are NaN.\n\"No data\" pixels are treated like any other in the evalscript. Their value, namely zero (or NaN in case of Landsat data collections), is applied to your evalscript just like any other other pixel. E.g. return [sample.B04*sample.B03] will return 0 for “no data” pixels, while return [sample.B04/sample.B03] would return \"Infinity\" (if requested sampleType is FLOAT32) due to division by zero (or \"NaN\" for Landsat data collection where the division would be by \"NaN\"). To treat \"no data\" pixels differently, explicitly handle them in your evalscript. See the examples below.\n\n\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1)  {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  } else {\n    return [99, 99, 99]\n  }\n}\n\n\n\n//VERSION=3\nif (dataMask == 1)  {\n  return [2.5 * B04, 2.5 * B03, 2.5 * B02]\n} else {\n  return [99/255, 99/255, 99/255] //normalized with 255 for visualization in EO Browser\n}\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you'd like to use this example, you must set the output.responses.format.type parameter of your process API request to image/png or image/tiff. The png format will automatically interpret the fourth band as transparency.\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 4 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02, sample.dataMask]\n}\n\n\n\n//VERSION=3\nreturn [2.5 * B04, 2.5 * B03, 2.5 * B02, dataMask]"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Datamask.html#datamask---handling-of-pixels-with-no-data",
    "href": "APIs/SentinelHub/UserGuides/Datamask.html#datamask---handling-of-pixels-with-no-data",
    "title": "Data Mask",
    "section": "",
    "text": "With evalscript v3 we are now providing full control to you over what is to be returned for image parts (pixels) where there is “no data”. In the setup function, you can request dataMask as an element of the input array and then use it in the evaluatePixel function in the same manner as any other input band.\n\n\ndataMask has value 0 for “no data” pixels and 1 elsewhere.\nBy “no data” pixels we mean:\n\nAll pixels which lay outside of the requested polygon (if specified).\nAll pixels for which no source data was found.\nAll pixels for which source data was found and is explicitly “no data”.\n\nThings to note:\n\nAll “no data” pixels as defined above have a dataMask value of 0. All band values for these pixels are also 0, except for Landsat data collections, where band values for no data pixels are NaN.\n\"No data\" pixels are treated like any other in the evalscript. Their value, namely zero (or NaN in case of Landsat data collections), is applied to your evalscript just like any other other pixel. E.g. return [sample.B04*sample.B03] will return 0 for “no data” pixels, while return [sample.B04/sample.B03] would return \"Infinity\" (if requested sampleType is FLOAT32) due to division by zero (or \"NaN\" for Landsat data collection where the division would be by \"NaN\"). To treat \"no data\" pixels differently, explicitly handle them in your evalscript. See the examples below.\n\n\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1)  {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  } else {\n    return [99, 99, 99]\n  }\n}\n\n\n\n//VERSION=3\nif (dataMask == 1)  {\n  return [2.5 * B04, 2.5 * B03, 2.5 * B02]\n} else {\n  return [99/255, 99/255, 99/255] //normalized with 255 for visualization in EO Browser\n}\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you'd like to use this example, you must set the output.responses.format.type parameter of your process API request to image/png or image/tiff. The png format will automatically interpret the fourth band as transparency.\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 4 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02, sample.dataMask]\n}\n\n\n\n//VERSION=3\nreturn [2.5 * B04, 2.5 * B03, 2.5 * B02, dataMask]"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/CloudMasks.html",
    "href": "APIs/SentinelHub/UserGuides/CloudMasks.html",
    "title": "Cloud Masks",
    "section": "",
    "text": "Cloud masks and probabilites computed using s2cloudless are available at a fixed resolution of 160m per pixel. Sentinel Hub implements the 10-band version. These are meant as convenience bands with the purpose of speeding up processing. Cloud masks are generated in a very slightly different way than the implementation above but for most applications this should not matter.\nThey are available as Sentinel-2 bands named CLP (cloud probabilities) and CLM (cloud masks) and have the following return values:\n\nCLM: 0 (no clouds), 1 (clouds), 255 (no data)\nCLP: 0–255 (divide by 255 to get to the [0-1] range)\n\nThe CLM no data value of 255 is also returned if a tile has missing CLM and CLP bands, for example due to errors. This ensures that values of 0 and 1 can be used with confidence for each pixel. CLP will in such a case return 0. Consider using CLM alongside CLP in your evalscript if this is an issue.\n\n\nCLP is generated per tile using the s2cloudless product at 160m resolution. Due to the 60m Sentinel-2 bands this means that a perfect match between CLP and s2cloudless is not possible for all requests. In case you require identical data, there are a few constraints which must be met. These are:\n\nrequesting data in the native UTM zone of each tile\nnearest neighbor interpolation\n160m resolution or slightly less (more zoomed out)\nthe request origin is a multiple of 480m away from the tile origin (the top left point of the source tile)\nrequesting a single tile only; no mosaicking (mosaicking violates the previous point)\n\nIf any of these are not met you can expect slight differences. For exact values the s2cloudless product may be used without these constraints, at a cost of requiring more processing time and processing units; for most applications, however, we do not expect this to be necessary.\n\n\n\nRead our blog posts and articles on cloud masks and cloud probabilities:\n\nCloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2 - Our s2cloudless algorithm was validated together with 9 other cloud detection algorithms and it was found to be on the Pareto front in all the test cases. June 1, 2022\nCloud Masks at Your Service, May 5, 2020\nOn cloud detection with multi-temporal data, October 14, 2019\nSentinel Hub Cloud Detector — s2cloudless, January 22, 2018"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/CloudMasks.html#cloud-masks-and-cloud-probabilities",
    "href": "APIs/SentinelHub/UserGuides/CloudMasks.html#cloud-masks-and-cloud-probabilities",
    "title": "Cloud Masks",
    "section": "",
    "text": "Cloud masks and probabilites computed using s2cloudless are available at a fixed resolution of 160m per pixel. Sentinel Hub implements the 10-band version. These are meant as convenience bands with the purpose of speeding up processing. Cloud masks are generated in a very slightly different way than the implementation above but for most applications this should not matter.\nThey are available as Sentinel-2 bands named CLP (cloud probabilities) and CLM (cloud masks) and have the following return values:\n\nCLM: 0 (no clouds), 1 (clouds), 255 (no data)\nCLP: 0–255 (divide by 255 to get to the [0-1] range)\n\nThe CLM no data value of 255 is also returned if a tile has missing CLM and CLP bands, for example due to errors. This ensures that values of 0 and 1 can be used with confidence for each pixel. CLP will in such a case return 0. Consider using CLM alongside CLP in your evalscript if this is an issue.\n\n\nCLP is generated per tile using the s2cloudless product at 160m resolution. Due to the 60m Sentinel-2 bands this means that a perfect match between CLP and s2cloudless is not possible for all requests. In case you require identical data, there are a few constraints which must be met. These are:\n\nrequesting data in the native UTM zone of each tile\nnearest neighbor interpolation\n160m resolution or slightly less (more zoomed out)\nthe request origin is a multiple of 480m away from the tile origin (the top left point of the source tile)\nrequesting a single tile only; no mosaicking (mosaicking violates the previous point)\n\nIf any of these are not met you can expect slight differences. For exact values the s2cloudless product may be used without these constraints, at a cost of requiring more processing time and processing units; for most applications, however, we do not expect this to be necessary.\n\n\n\nRead our blog posts and articles on cloud masks and cloud probabilities:\n\nCloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2 - Our s2cloudless algorithm was validated together with 9 other cloud detection algorithms and it was found to be on the Pareto front in all the test cases. June 1, 2022\nCloud Masks at Your Service, May 5, 2020\nOn cloud detection with multi-temporal data, October 14, 2019\nSentinel Hub Cloud Detector — s2cloudless, January 22, 2018"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/TimeSeries.html",
    "href": "APIs/SentinelHub/UserGuides/TimeSeries.html",
    "title": "Time series",
    "section": "",
    "text": "Processing API uses a timeRange parameter, where a user can select from-to dates. When such a request is ran, only one image is returned. timeRange is used to specify the scenes that are going to be considered for mosaicking (for example all the scenes from April 1 to June 1). Which one will be chosen for the output depends on the mosaicking type and order specified. If the user specified SIMPLE mosaicking order to be mostRecent, the first image considered for mosaicking would be the most recent image available from April 1 to June 1. If a user selected a mosaicking type TILE, and requested second samples (sample[1]), the samples of the second available scene in the specified time range would be returned. Learn more about mosaicking here and mosaicking orders here.\nIf you would like to return all the scenes in a given time range, the recommended approach is to first search for all the available scenes using our Catalog service API, which you can use to view detailed geospatial information, such as the acquisition date and time, for each of the available scenes of your specified BBOX, collection and time range. You can control your Catalog search by specifying fields, limits and other properties. See the Catalog API examples to learn how to do so. It's also possible to search the available scenes using the OGC WFS request, which might be a bit easier to use, but gives you much less search control. See a WFS request example here.\nWhen you have a list of the available scenes, you can then request each by using a separate Processing API call. To do so, limit time-range to only allow for the desired time frame, which matches the acquisition time of your scene."
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/TimeSeries.html#working-with-time-series",
    "href": "APIs/SentinelHub/UserGuides/TimeSeries.html#working-with-time-series",
    "title": "Time series",
    "section": "",
    "text": "Processing API uses a timeRange parameter, where a user can select from-to dates. When such a request is ran, only one image is returned. timeRange is used to specify the scenes that are going to be considered for mosaicking (for example all the scenes from April 1 to June 1). Which one will be chosen for the output depends on the mosaicking type and order specified. If the user specified SIMPLE mosaicking order to be mostRecent, the first image considered for mosaicking would be the most recent image available from April 1 to June 1. If a user selected a mosaicking type TILE, and requested second samples (sample[1]), the samples of the second available scene in the specified time range would be returned. Learn more about mosaicking here and mosaicking orders here.\nIf you would like to return all the scenes in a given time range, the recommended approach is to first search for all the available scenes using our Catalog service API, which you can use to view detailed geospatial information, such as the acquisition date and time, for each of the available scenes of your specified BBOX, collection and time range. You can control your Catalog search by specifying fields, limits and other properties. See the Catalog API examples to learn how to do so. It's also possible to search the available scenes using the OGC WFS request, which might be a bit easier to use, but gives you much less search control. See a WFS request example here.\nWhen you have a list of the available scenes, you can then request each by using a separate Processing API call. To do so, limit time-range to only allow for the desired time frame, which matches the acquisition time of your scene."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical/Examples.html",
    "href": "APIs/SentinelHub/Statistical/Examples.html",
    "title": "Examples of Statistical API",
    "section": "",
    "text": "The requests below are written in Python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples. Jupyter notebook with all examples can be downloaded here.\n\nStatistics for one single-band output on a given day\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        },\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-04T00:00:00Z\",\n            \"to\": \"2020-07-05T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-04T00:00:00Z',\n    'to': '2020-07-05T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nStatistics, histogram and percentiles for one single-band output\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        },\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-04T00:00:00Z\",\n            \"to\": \"2020-07-05T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  },\n  \"calculations\": {\n    \"default\": {\n      \"histograms\": {\n        \"default\": {\n          \"nBins\": 5,\n          \"lowEdge\": 0.0,\n          \"highEdge\": 0.3\n        }\n      },\n      \"statistics\": {\n        \"default\": {\n          \"percentiles\": {\n            \"k\": [ 33, 50, 75, 90 ]\n          }\n        }\n      }\n    }\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-04T00:00:00Z',\n    'to': '2020-07-05T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.09709999710321426,\n         '50.0': 0.10360000282526016,\n         '75.0': 0.11940000206232071,\n         '90.0': 0.16040000319480896}},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.06, 'count': 0},\n         {'lowEdge': 0.06, 'highEdge': 0.12, 'count': 2458},\n         {'lowEdge': 0.12, 'highEdge': 0.18, 'count': 558},\n         {'lowEdge': 0.18, 'highEdge': 0.24, 'count': 177},\n         {'lowEdge': 0.24, 'highEdge': 0.3, 'count': 44}],\n        'overflowCount': 3,\n        'underflowCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nStatistics for one single-band output for two months with 10 days aggregation period\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-06-01T00:00:00Z\",\n            \"to\": \"2020-07-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P10D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-06-01T00:00:00Z',\n    'to': '2020-06-11T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.7892000079154968,\n        'max': 0.8303999900817871,\n        'mean': 0.804223583473102,\n        'stDev': 0.0067066009561434865,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-06-11T00:00:00Z', 'to': '2020-06-21T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.016300000250339508,\n        'max': 0.5956000089645386,\n        'mean': 0.06240126554233315,\n        'stDev': 0.06266500670629409,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-06-21T00:00:00Z', 'to': '2020-07-01T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.026000000536441803,\n        'max': 0.43799999356269836,\n        'mean': 0.06872379640174772,\n        'stDev': 0.056520330692016944,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-01T00:00:00Z', 'to': '2020-07-11T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-11T00:00:00Z', 'to': '2020-07-21T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.017400000244379044,\n        'max': 0.4187999963760376,\n        'mean': 0.062194598779473156,\n        'stDev': 0.06317700445712106,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-21T00:00:00Z', 'to': '2020-07-31T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.13920000195503235,\n        'max': 0.4927999973297119,\n        'mean': 0.3146395680115182,\n        'stDev': 0.054700527707146035,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nPercentage of cloudy pixels for selected area of interest\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"CLM\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"data\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        data: [samples.CLM],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"bbox\": [\n          413307.629466,\n          4957434.513693,\n          415152.151806,\n          4958814.807431\n        ],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-11-01T00:00:00Z\",\n            \"to\": \"2020-12-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n   'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-11-01T00:00:00Z',\n    'to': '2020-11-02T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 1.0,\n        'max': 1.0,\n        'mean': 1.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-11-06T00:00:00Z', 'to': '2020-11-07T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.0,\n        'mean': 0.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-11-11T00:00:00Z', 'to': '2020-11-12T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.0,\n        'mean': 0.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-11-21T00:00:00Z', 'to': '2020-11-22T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.0,\n        'mean': 0.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-11-26T00:00:00Z', 'to': '2020-11-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 1.0,\n        'mean': 0.31253938248267044,\n        'stDev': 0.46352833449533853,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-01T00:00:00Z', 'to': '2020-12-02T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 1.0,\n        'mean': 0.2800882167611853,\n        'stDev': 0.44904210002261963,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-06T00:00:00Z', 'to': '2020-12-07T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 1.0,\n        'max': 1.0,\n        'mean': 1.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-11T00:00:00Z', 'to': '2020-12-12T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 1.0,\n        'mean': 0.9844439193446739,\n        'stDev': 0.12375010711094206,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-16T00:00:00Z', 'to': '2020-12-17T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 1.0,\n        'max': 1.0,\n        'mean': 1.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-21T00:00:00Z', 'to': '2020-12-22T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 1.0,\n        'max': 1.0,\n        'mean': 1.0,\n        'stDev': 0.0,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-12-26T00:00:00Z', 'to': '2020-12-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 1.0,\n        'mean': 0.1512287334593577,\n        'stDev': 0.35827168969322143,\n        'sampleCount': 25392,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\ndates_without_clouds = [(data[\"interval\"], int(100 * data[\"outputs\"][\"data\"]['bands']['B0']['stats']['mean']) ) for data in sh_statistics[\"data\"]]\n\nfor item in dates_without_clouds:\n    print( item )\n({'from': '2020-11-01T00:00:00Z', 'to': '2020-11-02T00:00:00Z'}, 100)\n({'from': '2020-11-06T00:00:00Z', 'to': '2020-11-07T00:00:00Z'}, 0)\n({'from': '2020-11-11T00:00:00Z', 'to': '2020-11-12T00:00:00Z'}, 0)\n({'from': '2020-11-21T00:00:00Z', 'to': '2020-11-22T00:00:00Z'}, 0)\n({'from': '2020-11-26T00:00:00Z', 'to': '2020-11-27T00:00:00Z'}, 31)\n({'from': '2020-12-01T00:00:00Z', 'to': '2020-12-02T00:00:00Z'}, 28)\n({'from': '2020-12-06T00:00:00Z', 'to': '2020-12-07T00:00:00Z'}, 100)\n({'from': '2020-12-11T00:00:00Z', 'to': '2020-12-12T00:00:00Z'}, 98)\n({'from': '2020-12-16T00:00:00Z', 'to': '2020-12-17T00:00:00Z'}, 100)\n({'from': '2020-12-21T00:00:00Z', 'to': '2020-12-22T00:00:00Z'}, 100)\n({'from': '2020-12-26T00:00:00Z', 'to': '2020-12-27T00:00:00Z'}, 15)\n\n\nBasic statistics of NDVI with water pixels excluded (custom output dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"data\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\n\nfunction evaluatePixel(samples) {\n    let ndvi = (samples.B08 - samples.B04)/(samples.B08 + samples.B04)\n    \n    var validNDVIMask = 1\n    if (samples.B08 + samples.B04 == 0 ){\n        validNDVIMask = 0\n    }\n    \n    var noWaterMask = 1\n    if (samples.SCL == 6 ){\n        noWaterMask = 0\n    }\n\n    return {\n        data: [ndvi],\n        // Exclude nodata pixels, pixels where ndvi is not defined and water pixels from statistics:\n        dataMask: [samples.dataMask * validNDVIMask * noWaterMask]\n    }\n}\n\"\"\"\n\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"geometry\": {\n          \"type\": \"Polygon\",\n          \"coordinates\": [\n            [\n              [\n                458085.878866,\n                5097236.833044\n              ],\n              [\n                457813.834156,\n                5096808.351383\n              ],\n              [\n                457979.897062,\n                5096313.767184\n              ],\n              [\n                458146.639373,\n                5096405.411294\n              ],\n              [\n                458085.878866,\n                5097236.833044\n              ]\n            ]\n          ]\n        },\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastCC\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n        \"from\": \"2020-01-01T00:00:00Z\",\n        \"to\": \"2020-12-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P30D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-01-01T00:00:00Z',\n    'to': '2020-01-31T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.24306687712669373,\n        'max': 0.6244725584983826,\n        'mean': 0.4123224201824293,\n        'stDev': 0.055874589607421886,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-01-31T00:00:00Z', 'to': '2020-03-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.2451941967010498,\n        'max': 0.4233206510543823,\n        'mean': 0.3160828609431641,\n        'stDev': 0.0280772593636271,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-01T00:00:00Z', 'to': '2020-03-31T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.4236144721508026,\n        'max': 0.8021259307861328,\n        'mean': 0.5844831434836089,\n        'stDev': 0.05766820795482124,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-31T00:00:00Z', 'to': '2020-04-30T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.4647541046142578,\n        'max': 0.8266128897666931,\n        'mean': 0.6615912824901472,\n        'stDev': 0.05539347152437238,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-04-30T00:00:00Z', 'to': '2020-05-30T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.1761743128299713,\n        'max': 0.870899498462677,\n        'mean': 0.6880682412526884,\n        'stDev': 0.18833356676740057,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-05-30T00:00:00Z', 'to': '2020-06-29T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.6883189082145691,\n        'max': 0.8775584697723389,\n        'mean': 0.8230951517303176,\n        'stDev': 0.026851310273968688,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-06-29T00:00:00Z', 'to': '2020-07-29T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.8124191164970398,\n        'max': 0.9270430207252502,\n        'mean': 0.8977047195274247,\n        'stDev': 0.01321883825220214,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-07-29T00:00:00Z', 'to': '2020-08-28T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.750795304775238,\n        'max': 0.8925060033798218,\n        'mean': 0.8437445996058478,\n        'stDev': 0.017705930134783242,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-08-28T00:00:00Z', 'to': '2020-09-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.7094070315361023,\n        'max': 0.8823529481887817,\n        'mean': 0.8138526516467535,\n        'stDev': 0.020639924263070358,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-09-27T00:00:00Z', 'to': '2020-10-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.6416097283363342,\n        'max': 0.8256189227104187,\n        'mean': 0.7368144742384923,\n        'stDev': 0.02884084473079313,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-10-27T00:00:00Z', 'to': '2020-11-26T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.5131579041481018,\n        'max': 0.9108409285545349,\n        'mean': 0.6912739742345253,\n        'stDev': 0.06273793790576106,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-11-26T00:00:00Z', 'to': '2020-12-26T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': -0.01446416787803173,\n        'max': 0.015364916995167732,\n        'mean': 0.0018048733875211391,\n        'stDev': 0.004322122712106793,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}}],\n 'status': 'OK'}\n\n\nStatistics of maximum monthly NDVI for a parcel in 2020\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    mosaicking: \"ORBIT\",\n    output: [\n      {\n        id: \"data\",\n        bands: [\"monthly_max_ndvi\"]\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\n\nfunction evaluatePixel(samples) {\n    var max = 0;\n    var hasData = 0;\n    for (var i=0;i&lt;samples.length;i++) {\n      if (samples[i].dataMask == 1 && samples[i].SCL != 6 && samples[i].B04+samples[i].B08 != 0 ){\n        hasData = 1\n        var ndvi = (samples[i].B08 - samples[i].B04)/(samples[i].B08 + samples[i].B04);\n        max = ndvi &gt; max ? ndvi:max;\n      }\n    }\n    \n    return {\n        data: [max],\n        dataMask: [hasData]\n    }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"geometry\": {\n          \"type\": \"Polygon\",\n          \"coordinates\": [\n            [\n              [\n                458085.878866,\n                5097236.833044\n              ],\n              [\n                457813.834156,\n                5096808.351383\n              ],\n              [\n                457979.897062,\n                5096313.767184\n              ],\n              [\n                458146.639373,\n                5096405.411294\n              ],\n              [\n                458085.878866,\n                5097236.833044\n              ]\n            ]\n          ]\n        },\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastCC\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-01-01T00:00:00Z\",\n            \"to\": \"2021-01-01T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1M\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n   'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-01-01T00:00:00Z',\n    'to': '2020-02-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.4755639135837555,\n        'max': 0.881286084651947,\n        'mean': 0.6396090604381046,\n        'stDev': 0.06844923487502963,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-02-01T00:00:00Z', 'to': '2020-03-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.3580246865749359,\n        'max': 0.8721038103103638,\n        'mean': 0.5956351390500386,\n        'stDev': 0.07367438999713516,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-01T00:00:00Z', 'to': '2020-04-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.4486735761165619,\n        'max': 0.8021259307861328,\n        'mean': 0.5871563556072766,\n        'stDev': 0.057052289003643133,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-04-01T00:00:00Z', 'to': '2020-05-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7103235721588135,\n        'max': 0.9151291251182556,\n        'mean': 0.8202670164519443,\n        'stDev': 0.029936259510749567,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-05-01T00:00:00Z', 'to': '2020-06-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7955418825149536,\n        'max': 0.9187881350517273,\n        'mean': 0.8889340774162204,\n        'stDev': 0.013139359632348635,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-06-01T00:00:00Z', 'to': '2020-07-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.6883189082145691,\n        'max': 0.8775584697723389,\n        'mean': 0.8258738168990016,\n        'stDev': 0.025802682912912194,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-07-01T00:00:00Z', 'to': '2020-08-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.8329545259475708,\n        'max': 0.9370484948158264,\n        'mean': 0.9037947789513383,\n        'stDev': 0.01278601507445675,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-08-01T00:00:00Z', 'to': '2020-09-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.750795304775238,\n        'max': 0.8925060033798218,\n        'mean': 0.843880225772972,\n        'stDev': 0.017580399946741675,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-09-01T00:00:00Z', 'to': '2020-10-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7121148109436035,\n        'max': 0.8823529481887817,\n        'mean': 0.8138710224835326,\n        'stDev': 0.02056652680651673,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-10-01T00:00:00Z', 'to': '2020-11-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.6416097283363342,\n        'max': 0.8256189227104187,\n        'mean': 0.7368144742384923,\n        'stDev': 0.02884084473079313,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-11-01T00:00:00Z', 'to': '2020-12-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.5424679517745972,\n        'max': 0.9108409285545349,\n        'mean': 0.7069293897671695,\n        'stDev': 0.05380689467103403,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-12-01T00:00:00Z', 'to': '2021-01-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.0683102235198021,\n        'max': 0.23551543056964874,\n        'mean': 0.1444664227123698,\n        'stDev': 0.027443079533455306,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}}],\n 'status': 'OK'}\n\n\nMultiple outputs with different dataMasks, multi-band output with custom bands' names and different histogram types\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_my_bands\",\n        bands: [\"only_band_B04\", \"only_band_B08\"],\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"output_my_indices\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"output_scl\",\n        bands: 1,\n        sampleType: \"UINT8\"\n      },\n      {\n        id: \"dataMask\",\n        bands: [\"output_my_bands\", \"output_my_indices\"]\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    let ndvi = (samples.B08 - samples.B04)/(samples.B08 + samples.B04)\n    \n    var validNDVIMask = 1\n    if (samples.B08 + samples.B04 == 0 ){\n        validNDVIMask = 0\n    }\n    \n    var noWaterMask = 1\n    if (samples.SCL == 6 ){\n        noWaterMask = 0\n    }\n    \n    return {\n        output_my_bands: [samples.B04, samples.B08],\n        output_my_indices: [ndvi],\n        output_scl: [samples.SCL],\n        dataMask: [samples.dataMask, samples.dataMask * noWaterMask * validNDVIMask]\n    }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n      \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n      }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-01T00:00:00Z\",\n            \"to\": \"2020-07-15T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P5D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 20,\n    \"resy\": 20\n  },\n  \"calculations\": {\n    \"output_my_bands\": {\n      \"histograms\": {\n        \"only_band_B08\": {\n          \"nBins\": 3,\n          \"lowEdge\": 0.0,\n          \"highEdge\": 0.3\n        }\n      },\n      \"statistics\": {\n        \"only_band_B04\": {\n          \"percentiles\": {\n            \"k\": [33, 66,100],\n          }\n        }\n      }\n    },    \n    \"output_scl\": {\n      \"histograms\": {\n        \"default\": {\n          \"bins\": [0,1,2,3,4,5,6,7,8,9,10,11]\n        }\n      }\n    },\n    \"default\": {\n      \"histograms\": {\n        \"default\": {\n          \"binWidth\": 0.05,\n          \"lowEdge\": 0.0\n        }\n      }\n    }\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-01T00:00:00Z',\n    'to': '2020-07-06T00:00:00Z'},\n   'outputs': {'output_my_bands': {'bands': {'only_band_B04': {'stats': {'min': 0.0803999975323677,\n        'max': 0.2939999997615814,\n        'mean': 0.11451061716602186,\n        'stDev': 0.032769790113614555,\n        'sampleCount': 810,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.09719999879598618,\n         '66.0': 0.11169999837875366,\n         '100.0': 0.2939999997615814}}},\n      'only_band_B08': {'stats': {'min': 0.0860000029206276,\n        'max': 0.34290000796318054,\n        'mean': 0.16518679009175594,\n        'stDev': 0.07128630441809644,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0,\n          'highEdge': 0.09999999999999999,\n          'count': 199},\n         {'lowEdge': 0.09999999999999999,\n          'highEdge': 0.19999999999999998,\n          'count': 270},\n         {'lowEdge': 0.19999999999999998, 'highEdge': 0.3, 'count': 332}],\n        'overflowCount': 9,\n        'underflowCount': 0}}}},\n    'output_scl': {'bands': {'B0': {'stats': {'min': 8.0,\n        'max': 10.0,\n        'mean': 9.75432098765432,\n        'stDev': 0.6555648554361158,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0, 'highEdge': 1, 'count': 0},\n         {'lowEdge': 1, 'highEdge': 2, 'count': 0},\n         {'lowEdge': 2, 'highEdge': 3, 'count': 0},\n         {'lowEdge': 3, 'highEdge': 4, 'count': 0},\n         {'lowEdge': 4, 'highEdge': 5, 'count': 0},\n         {'lowEdge': 5, 'highEdge': 6, 'count': 0},\n         {'lowEdge': 6, 'highEdge': 7, 'count': 0},\n         {'lowEdge': 7, 'highEdge': 8, 'count': 0},\n         {'lowEdge': 8, 'highEdge': 9, 'count': 99},\n         {'lowEdge': 9, 'highEdge': 10, 'count': 1},\n         {'lowEdge': 10, 'highEdge': 11, 'count': 710}],\n        'overflowCount': 0,\n        'underflowCount': 0}}}},\n    'output_my_indices': {'bands': {'B0': {'stats': {'min': -0.04050104320049286,\n        'max': 0.5338308215141296,\n        'mean': 0.14599402473584097,\n        'stDev': 0.15671216615792566,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.05, 'count': 340},\n         {'lowEdge': 0.05, 'highEdge': 0.1, 'count': 71},\n         {'lowEdge': 0.1, 'highEdge': 0.15000000000000002, 'count': 50},\n         {'lowEdge': 0.15000000000000002, 'highEdge': 0.2, 'count': 26},\n         {'lowEdge': 0.2, 'highEdge': 0.25, 'count': 23},\n         {'lowEdge': 0.25, 'highEdge': 0.30000000000000004, 'count': 33},\n         {'lowEdge': 0.30000000000000004,\n          'highEdge': 0.35000000000000003,\n          'count': 64},\n         {'lowEdge': 0.35000000000000003, 'highEdge': 0.4, 'count': 81},\n         {'lowEdge': 0.4, 'highEdge': 0.45, 'count': 53},\n         {'lowEdge': 0.45, 'highEdge': 0.5, 'count': 6},\n         {'lowEdge': 0.5, 'highEdge': 0.55, 'count': 9}],\n        'overflowCount': 0,\n        'underflowCount': 54}}}}}},\n  {'interval': {'from': '2020-07-06T00:00:00Z', 'to': '2020-07-11T00:00:00Z'},\n   'outputs': {'output_my_bands': {'bands': {'only_band_B04': {'stats': {'min': 0.007499999832361937,\n        'max': 0.3788999915122986,\n        'mean': 0.05566148159990979,\n        'stDev': 0.060176196853468686,\n        'sampleCount': 810,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.022700000554323196,\n         '66.0': 0.04439999908208847,\n         '100.0': 0.3788999915122986}}},\n      'only_band_B08': {'stats': {'min': 0.006500000134110451,\n        'max': 0.46369999647140503,\n        'mean': 0.12869839533864502,\n        'stDev': 0.1266643048401008,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0,\n          'highEdge': 0.09999999999999999,\n          'count': 450},\n         {'lowEdge': 0.09999999999999999,\n          'highEdge': 0.19999999999999998,\n          'count': 27},\n         {'lowEdge': 0.19999999999999998, 'highEdge': 0.3, 'count': 254}],\n        'overflowCount': 79,\n        'underflowCount': 0}}}},\n    'output_scl': {'bands': {'B0': {'stats': {'min': 2.0,\n        'max': 9.0,\n        'mean': 5.1716049382715985,\n        'stDev': 1.09834157450977,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0, 'highEdge': 1, 'count': 0},\n         {'lowEdge': 1, 'highEdge': 2, 'count': 0},\n         {'lowEdge': 2, 'highEdge': 3, 'count': 29},\n         {'lowEdge': 3, 'highEdge': 4, 'count': 0},\n         {'lowEdge': 4, 'highEdge': 5, 'count': 235},\n         {'lowEdge': 5, 'highEdge': 6, 'count': 103},\n         {'lowEdge': 6, 'highEdge': 7, 'count': 428},\n         {'lowEdge': 7, 'highEdge': 8, 'count': 13},\n         {'lowEdge': 8, 'highEdge': 9, 'count': 1},\n         {'lowEdge': 9, 'highEdge': 10, 'count': 1},\n         {'lowEdge': 10, 'highEdge': 11, 'count': 0}],\n        'overflowCount': 0,\n        'underflowCount': 0}}}},\n    'output_my_indices': {'bands': {'B0': {'stats': {'min': -0.18976545333862305,\n        'max': 0.858506441116333,\n        'mean': 0.47965881587323095,\n        'stDev': 0.25189343011256504,\n        'sampleCount': 810,\n        'noDataCount': 428},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.05, 'count': 3},\n         {'lowEdge': 0.05, 'highEdge': 0.1, 'count': 3},\n         {'lowEdge': 0.1, 'highEdge': 0.15000000000000002, 'count': 15},\n         {'lowEdge': 0.15000000000000002, 'highEdge': 0.2, 'count': 36},\n         {'lowEdge': 0.2, 'highEdge': 0.25, 'count': 28},\n         {'lowEdge': 0.25, 'highEdge': 0.30000000000000004, 'count': 20},\n         {'lowEdge': 0.30000000000000004,\n          'highEdge': 0.35000000000000003,\n          'count': 17},\n         {'lowEdge': 0.35000000000000003, 'highEdge': 0.4, 'count': 6},\n         {'lowEdge': 0.4, 'highEdge': 0.45, 'count': 9},\n         {'lowEdge': 0.45, 'highEdge': 0.5, 'count': 24},\n         {'lowEdge': 0.5, 'highEdge': 0.55, 'count': 22},\n         {'lowEdge': 0.55, 'highEdge': 0.6000000000000001, 'count': 18},\n         {'lowEdge': 0.6000000000000001, 'highEdge': 0.65, 'count': 32},\n         {'lowEdge': 0.65, 'highEdge': 0.7000000000000001, 'count': 46},\n         {'lowEdge': 0.7000000000000001, 'highEdge': 0.75, 'count': 37},\n         {'lowEdge': 0.75, 'highEdge': 0.8, 'count': 29},\n         {'lowEdge': 0.8, 'highEdge': 0.8500000000000001, 'count': 21},\n         {'lowEdge': 0.8500000000000001, 'highEdge': 0.9, 'count': 2}],\n        'overflowCount': 0,\n        'underflowCount': 14}}}}}}],\n 'status': 'OK'}\n\n\nStatistics for Sentinel-1\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"VV\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_VV\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_VV: [samples.VV],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-1-grd\",\n        \"dataFilter\": {\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-01T00:00:00Z\",\n            \"to\": \"2020-07-10T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P5D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-01T00:00:00Z',\n    'to': '2020-07-06T00:00:00Z'},\n   'outputs': {'output_VV': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.4447733759880066,\n        'mean': 0.046840328479290934,\n        'stDev': 0.05487441687888816,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nStatistics of NDVI using Sentinel-2 L2A as the source of NDVI and Sentinel-1 GRD VV channel as the mask of water bodies\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      // Specify input bands using the \"id\" of datasource set in the payload under data parameter\n      {datasource: \"s2\", bands: [\"B04\", \"B08\", \"dataMask\"]},\n      {datasource: \"s1\", bands: [\"VV\", \"dataMask\"]}\n    ],\n    output: [\n      {\n        id: \"ndvi\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }],\n    mosaicking: \"SIMPLE\"\n  };\n}\n\nfunction evaluatePixel(samples) {\n  let ndvi = (samples.s2[0].B08 - samples.s2[0].B04) / (samples.s2[0].B08+samples.s2[0].B04);\n  \n  // Create a mask for invalid ndvi value\n  let validNDVIMask = 1;\n  if (!isFinite(ndvi)) {\n    validNDVIMask = 0;\n  }\n  \n  // Create a mask for water\n  // The threshold comes from the result of exploring river flooding during the winter of 2020/21 on the River Severn in the United Kingdom \n  // (https://medium.com/euro-data-cube/exploring-time-and-space-a-guide-to-accessing-analysing-and-visualising-data-in-the-euro-data-e4a46f2bb55b)\n  let noWaterMask = 1;\n  if (toDB(samples.s1[0].VV) &lt;= -20) {\n    noWaterMask = 0;\n  }\n  return {\n      ndvi: [ndvi],\n      // Combine all the masks\n      dataMask: [samples.s2[0].dataMask * samples.s1[0].dataMask * validNDVIMask * noWaterMask]\n  };\n}\n\nfunction toDB(input){\n  return 10 * Math.log(input)/Math.LN10;\n}\n\"\"\"\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [16.72617,47.713689],\n            [16.72617,47.655444],\n            [16.816292,47.655444],\n            [16.816292,47.713689],\n            [16.72617,47.713689]\n          ]\n        ]\n      }\n    },\n    \"data\": [\n      {\n        \"dataFilter\": {},\n        \"id\": \"s2\",\n        \"type\": \"sentinel-2-l2a\"\n      },\n      {\n        \"dataFilter\": {\n          \"resolution\": \"HIGH\",\n          \"acquisitionMode\": \"IW\",\n          \"polarization\": \"DV\"\n        },\n        \"processing\": {\n          \"backCoeff\": \"GAMMA0_TERRAIN\",\n          \"orthorectify\": \"true\",\n          \"demInstance\": \"MAPZEN\",\n          \"speckleFilter\": {\n            \"type\": \"LEE\",\n            \"windowSizeX\": 5,\n            \"windowSizeY\": 5\n          }\n        },\n        \"id\": \"s1\",\n        \"type\": \"sentinel-1-grd\"\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n      \"from\": \"2021-08-08T00:00:00Z\",\n      \"to\": \"2021-08-11T23:59:59Z\"\n    },\n    \"aggregationInterval\": {\n      \"of\": \"P1D\"\n    },\n    \"resx\": 0.00009,\n    \"resy\": 0.00009,\n    \"evalscript\": evalscript\n  },\n  \"calculations\": {\n    \"default\": {}\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2021-08-08T00:00:00Z',\n    'to': '2021-08-09T00:00:00Z'},\n   'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': -0.6206604838371277,\n        'max': 0.8291770815849304,\n        'mean': 0.22080027097811286,\n        'stDev': 0.22071344421516914,\n        'sampleCount': 647647,\n        'noDataCount': 144372}}}}}},\n  {'interval': {'from': '2021-08-10T00:00:00Z', 'to': '2021-08-11T00:00:00Z'},\n   'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': -0.6909090876579285,\n        'max': 0.8982226252555847,\n        'mean': 0.6302106131139007,\n        'stDev': 0.28749024291873476,\n        'sampleCount': 647647,\n        'noDataCount': 220350}}}}}}],\n 'status': 'OK'}"
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html",
    "href": "APIs/SentinelHub/Catalog.html",
    "title": "Catalog API",
    "section": "",
    "text": "Sentinel Hub Catalog API (or shortly \"Catalog\") is an API implementing the STAC Specification, describing geospatial information about different data used with Sentinel Hub."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#api-reference",
    "href": "APIs/SentinelHub/Catalog.html#api-reference",
    "title": "Catalog API",
    "section": "API Reference",
    "text": "API Reference\nAPI Reference for Sentinel Hub Catalog is available as an OpenAPI description.\nSimple search request for Sentinel-1 GRD with a bounding box (the coordinate reference system of the values is WGS84 longitude/latitude), available on 10th December 2019.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = requests.post(url, json=data)"
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#authentication",
    "href": "APIs/SentinelHub/Catalog.html#authentication",
    "title": "Catalog API",
    "section": "Authentication",
    "text": "Authentication\nAuthentication for the Catalog API works completely the same as authentication for other Sentinel Hub services, see Authentication chapter."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#pagination",
    "href": "APIs/SentinelHub/Catalog.html#pagination",
    "title": "Catalog API",
    "section": "Pagination",
    "text": "Pagination\nExecuting the request specified above returns search context fields at the end of the response, looking like this:\n{\n  \"context\": {\n    \"next\": 5,\n    \"limit\": 5,\n    \"returned\": 5\n  }\n}\nThe presence of the next attribute indicates there is more data available for this query, but the server chose to only return 5 results, because the limit specified was 5 (if limit is not specified, default value is 10). To query the next page of items, our request needs to include the next attribute with its value in the query, like so:\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"next\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = requests.post(url, json=data)\nThe response now includes the next page of items; in this case there is no next token in context, meaning no more items exist for this query."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#extensions",
    "href": "APIs/SentinelHub/Catalog.html#extensions",
    "title": "Catalog API",
    "section": "Extensions",
    "text": "Extensions\n\nFilter\nThe search endpoint by default only accepts the parameters described in OpenAPI. The Filter extension enables users to specify an additional parameter to filter on, while searching through data.\nThe syntax for filter is CQL2:\n{\n  \"filter\": {\n    \"op\": \"&lt;operator&gt;\",\n    \"args\": [\n      {\n        \"property\": \"&lt;property_name&gt;\"\n      },\n      \"&lt;value&gt;\"\n    ]\n  },\n  \"filter-lang\": \"cql2-json\"\n}\nIt is also possible to use simple cql2-text:\n{\n  \"filter\": \"eo:cloud_cover &gt; 90\"\n}\nThe available operators are eq, neq, lt, lte, gt, gte, between and not. Only and is currently supported as a logical operator. Be careful - different collections have different properties for the query filter available. The information describing this is available inside the documentation for each specific collection (ex. Sentinel-1 GRD).\n\n\nFields\nBy default, the search endpoint returns all the available attributes of each item. The fields extension provides a way for the client to specify which attributes should not be part of the output, making it easy for the client to not have to deal with unnecessary data.\nSyntax for the fields is:\n{\n  \"fields\": {\n    \"include\": [\n      \"&lt;property_name_1&gt;\",\n      \"&lt;property_name_2&gt;\"\n    ],\n    \"exclude\": [\n      \"&lt;property_name_3&gt;\",\n      \"&lt;property_name_4&gt;\",\n      \"&lt;property_name_5&gt;\"\n    ]\n  }\n}\n\nInclude/Exclude behaviour\n\nWhen no fields attribute is specified in the request, all the available attributes will be included in the response.\nIf the fields attribute is specified with an empty object, or both include and exclude are set to null or an empty array is returned, the attributes for each item will be as if include was set to a default set of [\"id\", \"type\", \"geometry\", \"bbox\", \"links\", \"assets\", \"properties.datetime\"].\nIf only include is specified, the attributes in include will be merged with the default set above.\nIf only exclude is specified, the attributes in exclude will be removed from the default set above.\nIf both include and exclude are specified, the rule is that an attribute must be included in and not excluded from the response.\n\n\n\n\nDistinct\nSometimes we don't want to search for product metadata, but want some general information about the product, such as for example, which acquisition dates are available for Sentinel-1 inside the specified bbox and time interval. distinct attribute inside a search request makes this possible.\nSyntax for distinct attribute is:\n{\n  \"distinct\": \"&lt;property_name&gt;\"\n}\nAs with the filter attribute, distinct is also a collection limited to some specific properties. Information describing these properties can be found inside each collection's documentation (ex. Sentinel-1 GRD)."
  },
  {
    "objectID": "APIs/SentinelHub/Overview.html",
    "href": "APIs/SentinelHub/Overview.html",
    "title": "API Overview",
    "section": "",
    "text": "The Sentinel Hub API is a RESTful API interface to various satellite imagery archives. It provides access to raw satellite data, rendered images, statistical analysis and much more.\nThe Sentinel Hub API is annotated via OpenAPI. You can browse reference docs here:\n\nWeb preview\nYAML"
  },
  {
    "objectID": "APIs/SentinelHub/Overview.html#about-sentinel-hub-api",
    "href": "APIs/SentinelHub/Overview.html#about-sentinel-hub-api",
    "title": "API Overview",
    "section": "",
    "text": "The Sentinel Hub API is a RESTful API interface to various satellite imagery archives. It provides access to raw satellite data, rendered images, statistical analysis and much more.\nThe Sentinel Hub API is annotated via OpenAPI. You can browse reference docs here:\n\nWeb preview\nYAML"
  },
  {
    "objectID": "APIs/SentinelHub/Process.html",
    "href": "APIs/SentinelHub/Process.html",
    "title": "Processing API",
    "section": "",
    "text": "The Processing API (or shortly \"Process API\") is the most commonly used API in Sentinel Hub as it provides images based on satellite data. Users can request raw satellite data, simple band combinations such as false colour composites, calculations of simple remote sensing indices like NDVI, or more advanced processing such as calculation of Leaf area index (LAI).\nEven though satellite imagery data are often distributed in \"tiles\", we do not want users to be limited to these. Tiles are an artificially introduced entity to make data distribution easier to handle. However, users should not have to care about whether their AOI is on one tile or another, or perhaps on the border of two tiles. This is why Sentinel Hub API hides this complexity and simply makes the data available over chosen area of interest and temporal period of interest. Tiles are therefore automatically stitched together based on defined parameters (AOI, time period, cloud coverage, priority, etc., depending on the data type)."
  },
  {
    "objectID": "APIs/openEO/Glossary.html",
    "href": "APIs/openEO/Glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "The following glossary provides an introduction to the key technical terms commonly used when working with the openEO API."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#general-terms",
    "href": "APIs/openEO/Glossary.html#general-terms",
    "title": "Glossary",
    "section": "General terms",
    "text": "General terms\n\nEO: Earth Observation\nAPI: Application Programming Interface (wikipedia); a communication protocol between client and back-end\nclient: Software tool or environment that end-users directly interact with, e.g. R (RStudio), Python (Jupyter notebook), and JavaScript (web browser); R and Python are two major data science platforms; JavaScript is a major language for web development\n(cloud) back-end: server; computer infrastructure (one or more physical computers or virtual machines) used for storing EO data and processing it\nbig Earth observation cloud back-end: server infrastructure where industry and researchers analyse large amounts of EO data"
  },
  {
    "objectID": "APIs/openEO/Glossary.html#processes",
    "href": "APIs/openEO/Glossary.html#processes",
    "title": "Glossary",
    "section": "Processes",
    "text": "Processes\nA process is an operation that performs a specific task on a set of parameters and returns a result. An example is computing a statistical operation, such as mean or median, on selected EO data. A process is similar to a function or method in programming languages.\nA pre-defined process is a process provided by the back-end, often one of the ones centrally defined by openEO.\nA user-defined process is a process defined by the user. It can directly be part of another process graph or be stored as custom process on a back-end. Internally it is a process graph with optional additional metadata.\nA process graph chains specific process calls from the set of pre-defined and user-defined processes together. A process graph itself is a (user-defined) process again. Similarly to scripts in the context of programming, process graphs organize and automate the execution of one or more processes that could alternatively be executed individually. In a process graph, processes need to be specific, i.e. concrete values for input parameters need to be specified. These arguments can again be process graphs, scalar values, arrays or objects."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#eo-data-collections",
    "href": "APIs/openEO/Glossary.html#eo-data-collections",
    "title": "Glossary",
    "section": "EO data (Collections)",
    "text": "EO data (Collections)\nIn openEO, all collections can be requested using a client. These collection follows the STAC (SpatioTemporal Asset Catalog) metadata specification. Within openEO, a product (sometimes also called item or asset in the specification) typically refers to a limited area and a single overpass leading to a very short observation period (seconds) or a temporal aggregation of such data. A user can load (a subset of) a collection using a special process, which returns a (spatial) datacube. All further processing is then applied to the datacube on the back-end."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#spatial-datacubes",
    "href": "APIs/openEO/Glossary.html#spatial-datacubes",
    "title": "Glossary",
    "section": "Spatial datacubes",
    "text": "Spatial datacubes\nA spatiotemporal datacube is a multidimensional array with one or more spatial or temporal dimensions. In the EO domain, it is common to be implicit about the temporal dimension and just refer to them as spatial datacubes in short. Special cases are raster and vector datacubes. Learn more about datacubes in the datacube documentation."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#user-defined-function-udf",
    "href": "APIs/openEO/Glossary.html#user-defined-function-udf",
    "title": "Glossary",
    "section": "User-defined function (UDF)",
    "text": "User-defined function (UDF)\nThe abbreviation UDF stands for user-defined function. With this concept, users are able to upload custom code and have it executed e.g. for every pixel of a scene, or applied to a particular dimension or set of dimensions, allowing custom server-side calculations."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#data-processing-modes",
    "href": "APIs/openEO/Glossary.html#data-processing-modes",
    "title": "Glossary",
    "section": "Data Processing modes",
    "text": "Data Processing modes\nProcesses can run in three different ways:\n\nResults can be pre-computed by creating a batch job. They are submitted to the back-end’s processing system, but will remain inactive until explicitly put into the processing queue. They will run only once and store results after execution. Results can be downloaded. Batch jobs are typically time consuming and user interaction is not possible although log files are generated for them. This is the only mode that allows to get an estimate about time, volume and costs beforehand.\nProcesses can also be executed on-demand (i.e. synchronously). Results are delivered with the request itself and no job is created. Only lightweight computations, for example previews, should be executed using this approach as timeouts are to be expected for long-polling HTTP requests.\nThe third way of data processing in openEO is client-side processing. The client-side processing functionality allows to test and use openEO with its processes locally, i.e. without any connection to an openEO back-end. It relies on the projects openeo-pg-parser-networkx, which provides an openEO process graph parsing tool, and openeo-processes-dask, which provides an Xarray and Dask implementation of most openEO processes."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html",
    "title": "Getting started with JavaScript client",
    "section": "",
    "text": "This Getting Started guide will give you just a simple overview of the capabilities of the openEO JavaScript client library."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#installation",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#installation",
    "title": "Getting started with JavaScript client",
    "section": "Installation",
    "text": "Installation\nThe openEO JavaScript Client can be used in all modern browsers (excludes Internet Explorer) and all maintained Node.js versions (&gt;= 10.x). It can also been used for mobile app development with the Ionic Framework, for example.\nThe easiest way to try out the client is using one of the examples. Alternatively, you can create an HTML file and include the client with the following HTML script tags:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/axios@0.21/dist/axios.min.js\"&gt;&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/@openeo/js-client@2/openeo.min.js\"&gt;&lt;/script&gt;\nThis gives you a minified version for production environments. If you’d like a better development experience, use the following code:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/axios@0.21/dist/axios.js\"&gt;&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/@openeo/js-client@2/openeo.js\"&gt;&lt;/script&gt;\nIf you are working on a Node.js application or you are using a Node.js-based build tool for web development (e.g. Webpack), you can install the client via npm by using the following command:\n\nnpm install @openeo/js-client\nAfterwards you can load the library. Depending on whether you are directly working in Node.js or are just using a Node.js build tool, the import can be different. Please inform yourself which import is suited for your project.\nThis is usually used directly in Node.js:\nconst { OpenEO } = require('@openeo/js-client');\nThis may be used in build tools such as Webpack:\nimport { OpenEO } from '@openeo/js-client';\nNow that the installation was successfully finished, we can now connect to openEO compliant back-ends. In the following chapters we quickly walk through the main features of the JavaScript client.\nIf you have trouble installing the client, feel free to create a ticket or leave an issue at the GitHub project."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#exploring-a-back-end",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#exploring-a-back-end",
    "title": "Getting started with JavaScript client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO instance of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu.\nFirst we need to establish a connection to the back-end.\nvar con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n\n\n\n\n\n\nNote\n\n\n\nThe JavaScript client uses Promises (async/await). So there are two ways to express the code above:\nPromises:\nOpenEO.connect(\"https://openeo.dataspace.copernicus.eu\").then(function(con) {\n  // Success\n}).catch(function(error) {\n  // Error\n});\nasync/await:\ntry {\n  var con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n  // Success\n} catch (error) {\n  // Error\n}\n\n\nTo simplify the code here, we use async/await in all examples and don’t catch errors. So we assume you run the code in an async function and also in a try/catch block.\nAfter establishing the connection to the back-end, it can be explored using the Connection object returned. The basic service’s metadata (capabilities) can be accessed via\nvar info = con.capabilities();\nThis allows to request a couple of different information, like API version, description, related links or the billing plans. You can print some of these information to the console as follows:\nconsole.log(\"API Version: \", info.apiVersion());\nconsole.log(\"Description: \", info.description());\n\nconsole.log(\"Billing plans:\");\ninfo.listPlans().forEach(plan =&gt; {\n  console.log(`${plan.name}: ${plan.url}`);\n});\n\nconsole.log(\"Related links:\");\ninfo.links().forEach(link =&gt; {\n  console.log(`${link.title}: ${link.href}`);\n});\n\nCollections\nCollections represent the basic data the back-end provides (e.g. Sentinel 2 collection). Collections are used as input data for job executions (more info on collections). With the following code snippet you can print all 400+ available collection names and their summary.\nconsole.log(\"Available Collections:\");\nvar response = await con.listCollections();\nresponse.collections.forEach(collection =&gt; {\n  console.log(`${collection.id}: ${collection.summary}`);\n});\nTo get detailed information about a single collection, you can pass any of the collection IDs requested earlier to describeCollection and get a full object of STAC compliant Collection metadata back. In this example we request information about the Sentinel-2 Level 1C data from Google:\nconsole.log(await con.describeCollection(\"COPERNICUS/S2\"));\nTo get the full set of metadata you should always use describeCollection.\n\n\nProcesses\nProcesses in openEO are small tasks that can be applied on (EO) data. The input of a process might be the output of another process, so that several connected processes form a new (user-defined) process itself. Therefore, a process resembles the smallest unit of task descriptions in openEO (more details on processes). With the following code snippet you can print all available process IDs and their summaries.\nconsole.log(\"Available Collections:\");\nvar response = await con.listProcesses();\nresponse.processes.forEach(process =&gt; {\n  console.log(`${process.id}: ${process.summary}`);\n});\nIn contrast to the collections, the process descriptions returned by listProcesses are complete. There’s no need to call describeProcess to get the full set of metadata. describeProcess is just a convenience function to get a single process from listProcesses. In this example we request the process specification for the apply process:\nconsole.log(await con.describeProcess(\"apply\"));\nFor a graphical overview of the openEO processes, there is an online documentation for general process descriptions and the openEO Hub for back-end specific process descriptions."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#authentication",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#authentication",
    "title": "Getting started with JavaScript client",
    "section": "Authentication",
    "text": "Authentication\nIn the code snippets above we did not need to log in since we just queried publicly available back-end information. However, to run non-trivial processing queries one has to authenticate so that permissions, resource usage, etc. can be managed properly.\nTo authenticate your account on the backend of the Copernicus Data Space Ecosystem, it is necessary for you to complete the registration process. Once registered, the OIDC (OpenID Connect)authentication method will be employed to verify your identity using an external service.\n\n\n\n\n\n\nWarning\n\n\n\nIf you have included the library using HTML script tags, then you need to include the following OIDC client before the openEO client:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/oidc-client@1/lib/oidc-client.min.js\"&gt;&lt;/script&gt;\nNo further action is required, if you have installed the client via npm.\n\n\nAs OpenID Connect authentication is a bit more complex and depends on the environment your are using it in, please refer to the JavaScript client documentation for more information.\nCalling this method opens your system web browser, with which you can authenticate yourself on the back-end authentication system. After that the website will give you the instructions to go back to the JavaScript client, where your connection has logged your account in. This means that every call that comes after that via the con variable is executed by your user account."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#creating-a-user-defined-process",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#creating-a-user-defined-process",
    "title": "Getting started with JavaScript client",
    "section": "Creating a (user-defined) process",
    "text": "Creating a (user-defined) process\nNow that we know how to discover the back-end and how to authenticate, lets continue by creating a new batch job to process some data. First we need to create a user-defined process and for that a process builder is the easiest method.\n\nvar builder = await con.buildProcess();\nWith the builder, a datacube can be initialized by selecting a collection from the back-end with the process load_collection:\nvar datacube = builder.load_collection(\n        \"SENTINEL2_L2A\",\n        {west: 3.20, south: 51.19, east: 3.26, north: 51.21},\n        [\"2022-05-01\", \"2022-05-30\"],\n        [\"B04\", \"B03\", \"B02\"]\n);\nThis results in a datacube containing the “SENTINEL2_L2A” data restricted to the given spatial extent, the given temporal extend and the given bands .\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can also filter the datacube at a later stage by using the following filter methods:\ndatacube = builder.filter_bbox(datacube, {west: 3.20, south: 51.19, east: 3.26, north: 51.21});\ndatacube = builder.filter_temporal(datacube, [\"2022-05-01\", \"2022-05-30\"]);\ndatacube = builder.filter_bands(datacube, [\"B04\", \"B03\", \"B02\"]);\nStill, it is recommended to always use the filters in load_collection to avoid loading too much data upfront.\n\n\n\nHaving the input data ready, we want to apply a process on the datacube, which returns a datacube with the process applied:\n\nvar min = function(data) { return this.min(data); };\ndatacube = builder.reduce_dimension(datacube, min, \"t\");\nThe datacube is now reduced by the time dimension named t, by taking the minimum value of the timeseries values. Now the datacube has no time dimension left.\nOther so called “reducer” processes exist, e.g. for computing maximum and mean values.\n\n\n\n\n\n\nNote\n\n\n\nEverything applied to the datacube at this point is neither executed locally on your machine nor executed on the back-end. It just defines the input data and process chain the back-end needs to apply when it sends the datacube to the back-end and executes it there. How this can be done is the topic of the next chapter.\n\n\nAfter applying all processes you want to execute, we need to tell the back-end to export the datacube, for example as GeoTiff:\n\nvar result = builder.save_result(datacube, \"GTiff\");"
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#batch-job-management",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#batch-job-management",
    "title": "Getting started with JavaScript client",
    "section": "Batch Job Management",
    "text": "Batch Job Management\nAfter you finished working on your (user-defined) process, we can now send it to the back-end and start the execution. In openEO, an execution of a (user-defined) process (here defined using the process builder) is called a (batch) job. Therefore, we need to create a job at the back-end using our datacube, giving it the title Example Title.\n\nvar job = await con.createJob(result, \"Example Title\");\nThe createJob method sends all necessary information to the back-end and creates a new job, which gets returned. After this, the job is just created, but has not started the execution at the back-end yet. It needs to be queued for processing explicitly:\n\nawait job.startJob();\nNow the execution of the job can be monitored by requesting the job status and the log files every once in a while (30 seconds in this example):\n\nlet stopFn = job.monitorJob((job, logs) =&gt; {\n  console.log(job.status);\n  logs.forEach(log =&gt; console.log(`${log.level}: ${log.message}`));\n}, 30);\nThe monitoring stops automatically once the job has finished, was canceled or errored out. But with the return value of the monitorJob function, you can also stop monitoring the job manually:\n\nstopFn();\nWhen the job is finished, calling listResults gets you the URLs to the results.\n\nvar urls = await job.listResults();\n\n\n\n\n\n\nTip\n\n\n\n\n\nThis only works if the job execution has finished. We recommend to use listResults in combination with monitorJob, for example as follows:\n\nlet stopFn = job.monitorJob(async (job, logs) =&gt; {\n  if (job.status === \"finished\") {\n    var urls = await job.listResults();\n    urls.forEach(url =&gt; console.log(`Download result from: ${url.href}`));\n  }\n});\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere’s also the method downloadResults to download the results directly. Unfortunately, you can only download files from a Node.js environment where file access to your local drive is possible. In a Browser environment, it is also an option to download the STAC Item or Collection for the results using the getResultsAsStac method and point a STAC client to it for downloading.\n\n\nNow you know the general workflow of job executions."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#full-example",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#full-example",
    "title": "Getting started with JavaScript client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the JavaScript client in a Node.js environment. Instead of batch job processing, we compute the image synchronously. Synchronous processing means the result is directly returned in the response, which usually works only for smaller amounts of data.\nHere, we want to produce a monthly RGB composite of Sentinel 1 backscatter data over the area of Vienna, Austria for three months in 2017. This can be used for classification and crop monitoring.\nIn the following code example, we use inline code comments to describe what we are doing.\n// Make the client available to the Node.js script\n// Also include the Formula library for simple math expressions\nconst { OpenEO, Formula } = require('@openeo/js-client');\n\nasync function example() {\n  // Connect to the back-end\n  var con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n  // Authenticate \n  await con.authenticateOIDC();\n  // Create a process builder\n  var builder = await con.buildProcess();\n  // We are now loading the Sentinel-1 data over the Area of Interest\n  var datacube = builder.load_collection(\n    \"SENTINEL1_GRD\",\n    {west: 16.06, south: 48.06, east: 16.65, north: 48.35},\n    [\"2017-03-01\", \"2017-06-01\"],\n    [\"VV\"]\n  );\n\n  // Since we are creating a monthly RGB composite, we need three separated time ranges (March aas R, April as G and May as G).\n  // Therefore, we split the datacube into three datacubes using a temporal filter.\n  var march = builder.filter_temporal(datacube, [\"2017-03-01\", \"2017-04-01\"]);\n  var april = builder.filter_temporal(datacube, [\"2017-04-01\", \"2017-05-01\"]);\n  var may = builder.filter_temporal(datacube, [\"2017-05-01\", \"2017-06-01\"]);\n\n  // We aggregate the timeseries values into a single image by reducing the time dimension using a mean reducer.\n  var mean = function(data) {\n    return this.mean(data);\n  };\n  march = builder.reduce_dimension(march, mean, \"t\");\n  april = builder.reduce_dimension(april, mean, \"t\");\n  may = builder.reduce_dimension(may, mean, \"t\");\n\n  // Now the three images will be combined into the temporal composite.\n  // We rename the bands to R, G and B as otherwise the bands are overlapping and the merge process would fail.\n  march = builder.rename_labels(march, \"bands\", [\"R\"], [\"VV\"]);\n  april = builder.rename_labels(april, \"bands\", [\"G\"], [\"VV\"]);\n  may = builder.rename_labels(may, \"bands\", [\"B\"], [\"VV\"]);\n\n  datacube = builder.merge_cubes(march, april);\n  datacube = builder.merge_cubes(datacube, may);\n\n  // To make the values match the RGB values from 0 to 255 in a PNG file, we need to scale them.\n  // We can simplify expressing math formulas using the openEO Formula parser.\n  datacube = builder.apply(datacube, new Formula(\"linear_scale_range(x, -20, -5, 0, 255)\"));\n\n  // Finally, save the result as PNG file.\n  // In the options we specify which band should be used for \"red\", \"green\" and \"blue\" color.\n  datacube = builder.save_result(datacube, \"PNG\", {\n    red: \"R\",\n    green: \"G\",\n    blue: \"B\"\n  });\n\n  // Now send the processing instructions to the back-end for (synchronous) execution and save the file as result.png\n  await con.downloadResult(datacube, \"../_images/result.png\");\n}\n\n// Run the example, write errors to the console.\nexample().catch(error =&gt; console.error(error));\nNow the resulting PNG file of the RGB backscatter composite is stored as result.png in the node.JS working directory and should look as follows:"
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#user-defined-functions",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#user-defined-functions",
    "title": "Getting started with JavaScript client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function. Unfortunately, you can only create Python and R functions at the moment. Therefore, this guide doesn’t get into detail. For more information check out the Python or R tutorials on UDFs."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#useful-links",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#useful-links",
    "title": "Getting started with JavaScript client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO JavaScript Client Library:\n\nExamples\nDocumentation\nRepository"
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html",
    "href": "APIs/openEO/R_Client/R.html",
    "title": "Getting started with R client",
    "section": "",
    "text": "This Getting Started guide will give you just a simple overview of the capabilities of the openEO R client library."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#installation",
    "href": "APIs/openEO/R_Client/R.html#installation",
    "title": "Getting started with R client",
    "section": "Installation",
    "text": "Installation\nBefore you install the R client module into your R environment, please make sure that you have at least R version 3.6. Older versions might also work, but were not tested.\nStable releases can be installed from CRAN:\ninstall.packages(\"openeo\")\n\n\n\n\n\n\nInstalling the development version\n\n\n\n\n\nIf you want to install the development version, you can install from GitHub. It may contain more features, but may also be unstable.\nYou need to have the package ‘devtools’ installed. If it is not installed use install.packages(\"devtools\").\nNow you can use install_github from the devtools package to install the development version:\n\ndevtools::install_github(repo=\"Open-EO/openeo-r-client\", dependencies=TRUE, ref=\"develop\")\nIf this gives you an error, something went wrong with the installation so please check the requirements again.\n\n\n\nIf you have troubles installing the package, feel free to to create a ticket or leave an issue at the GitHub project.\nNow that the installation was successfully finished, we can load the package and connect to openEO compliant back-ends. In the following chapters we quickly walk through the main features of the R client."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#exploring-a-back-end",
    "href": "APIs/openEO/R_Client/R.html#exploring-a-back-end",
    "title": "Getting started with R client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO instance of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu.\nFirst we need to establish a connection to the back-end.\n\nlibrary(openeo)\nconnection = connect(host = \"https://openeo.dataspace.copernicus.eu\")\nThe capabilities of the back-end and the collections are generally publicly available, unless the data collections are proprietary and licensing issues prevent the back-end provider from publishing the collection. For the publicly available information you do not need to have an account on the back-end for reading them.\n\nCollections\nCollections represent the basic data the back-end provides (e.g. Sentinel 1 collection) and are therefore often used as input data for job executions (more info on collections). With the following code snippet you can get all available collection names and their description. The collection list and its entries have their own implementations of the print function. The collection list object is coerced into a data.frame only for printing purposes and the collection for the collection some key information are printed.\nTo get the collection list can be indexed by the collections ID to get the more details about the overview information. With the describe_collection function you can get an even more detailed information about the collection.\n\n# Dictionary of the full metadata of the \"COPERNICUS/S2\" collection (dict)\ns2 = describe_collection(\"SENTINEL2_L2A\") # or use the collection entry from the list, e.g. collections$`COPERNICUS/S2`\nprint(s2)\nIn general all metadata objects are based on lists, so you can use str() to get the structure of the list and address fields by the $ operator.\n\n\n\n\n\n\nTip\n\n\n\n\n\nIf the package is used with RStudio the metadata can also be nicely rendered as a web page in the viewer panel by running collection_viewer(x=\"SENTINEL2_L2A\").\n\n\n\n\n\nProcesses\nProcesses in openEO are tasks that can be applied to (EO) data. The input of a process might be the output of another process, so that several connected processes form a new (user-defined) process itself. Therefore, a process resembles the smallest unit of task descriptions in openEO (more details on processes). The following code snippet shows how to get the available processes.\n# List of available openEO processes with full metadata\nprocesses = list_processes()\n\n# List of available openEO processes by identifiers (string)\nprint(names(processes))\n\n# print metadata of the process with ID \"load_collection\"\nprint(processes$load_collection)\nThe list_processes() method returns a list of process metadata objects that the back-end provides. Each process list entry is a more complex list object (called ‘ProcessInfo’) and contains the process identifier and additional metadata about the process, such as expected arguments and return types.\n\n\n\n\n\n\nTip\n\n\n\n\n\nAs for the collection, processes can also be rendered as a web page in the viewer panel, if RStudio is used. In order to open the viewer use process_viewer() with either a particular process (process_viewer(\"load_collection\")) or you can pass on all processes (process_viewer(processes)). When all processes are chosen, there is also a search bar and a category tree.\n\n\n\nFor other graphical overviews of the openEO processes, there is an online documentation for general process descriptions and the openEO Hub for back-end specific process descriptions."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#authentication",
    "href": "APIs/openEO/R_Client/R.html#authentication",
    "title": "Getting started with R client",
    "section": "Authentication",
    "text": "Authentication\nIn the code snippets above we did not need to log in since we just queried publicly available back-end information. However, to run non-trivial processing queries one has to authenticate so that permissions, resource usage, etc. can be managed properly.\nTo authenticate your account on the backend of the Copernicus Data Space Ecosystem, it is necessary for you to complete the registration process. Once registered, the OIDC (OpenID Connect)authentication method will be employed to verify your identity using an external service.\nThe following code snippet shows how to log in via OIDC authentication if the back-end supports the simplified authentication method:\n\nlogin()\nThe following code snippet shows how to log in via OIDC authentication if the simplified authentication method doesn’t work and you need to provide a client ID and secret:\n\n# get supported OIDC providers which the back-end supports\noidc_providers = list_oidc_providers()\n\nlogin(provider = oidc_providers$some_provider,\n      config = list(\n        client_id= \"...\",\n        secret = \"...\"))\nCalling this method opens your system web browser, with which you can authenticate yourself on the back-end authentication system. After that the website will give you the instructions to go back to the R client, where your connection has logged your account in. This means, that every call that comes after that via the connection variable is executed by your user account."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#creating-a-user-defined-process",
    "href": "APIs/openEO/R_Client/R.html#creating-a-user-defined-process",
    "title": "Getting started with R client",
    "section": "Creating a (user-defined) process",
    "text": "Creating a (user-defined) process\nNow that we know how to discover the back-end and how to authenticate, lets continue by creating a new batch job to process some data.\nFirst we need to create a process builder object that carries all the available predefined openEO processes of the connected back-end as attached R functions with the parameters stated in the process metadata.\n\np = processes()\nThe functions of the builder return process nodes, which represent a particular result in the workflow. As one of the first steps we need to select the source data collection.\ndatacube = p$load_collection(\n  id = \"SENTINEL1_GRD\",\n  spatial_extent=list(west = 16.06, south = 48.06, east = 16.65, north = 48.35),\n  temporal_extent=c(\"2017-03-01\", \"2017-04-01\"),\n  bands=c(\"VV\", \"VH\")\n)\nThis results in a process node that represents a datacube and contains the “SENTINEL1_GRD” data restricted to the given spatial extent, the given temporal extent and the given bands .\n\n\n\n\n\n\nSample Data Retrieval\n\n\n\n\n\nIn order to get a better understanding about the processing mechanisms and the data structures used in openEO Platform, it helps to check the actual data from time to time. The function get_sample aids the user in downloading data for a very small spatial extent. It is automatically loaded into R so that you can directly inspect it with stars. Read the vignette on “Sample Data Retrieval” for more details.\n\n\n\nHaving the input data ready, we want to apply a process on the datacube. Therefore, we can call the process directly on the datacube object, which then returns a datacube with the process applied.\n\nmin_reducer = function(data,context) { \n  return(p$min(data = data))\n}\n\nreduced = p$reduce_dimension(data = datacube, reducer = min_reducer, dimension=\"t\")\nThe datacube is now reduced by the time dimension named t, by taking the minimum value of the timeseries values. Now the datacube has no time dimension left. Other so called “reducer” processes exist, e.g. for computing maximum and mean values.\n\n\n\n\n\n\nNote\n\n\n\nEverything applied to the datacube at this point is neither executed locally on your machine nor executed on the back-end. It just defines the input data and process chain the back-end needs to apply when it sends the datacube to the back-end and executes it there.\n\n\nAfter applying all processes you want to execute, we need to tell the back-end to export the datacube, for example as GeoTiff:\n\nformats = list_file_formats()\n\nresult = p$save_result(data = reduced, format = formats$output$`GTIFF-ZIP`)\nThe first line retrieves the back-ends offered input and output formats. The second line creates the result node, which stores the data as a zipped GeoTiff."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#batch-job-management",
    "href": "APIs/openEO/R_Client/R.html#batch-job-management",
    "title": "Getting started with R client",
    "section": "Batch Job Management",
    "text": "Batch Job Management\nAfter you have finished working on your (user-defined) process, we can now send it to the back-end and start the execution. In openEO, an execution of a (user-defined) process is called a (batch job). Therefore, we need to create a job at the back-end using our datacube, giving it the title Example Title.\n\njob = create_job(graph=result,title = \"Example Title\")\nThe create_job method sends all necessary information to the back-end and creates a new job, which gets returned. After this, the job is just created, but has not started the execution at the back-end yet. It needs to be queued for processing explicitly:\n\nstart_job(job = job)\nAfter the job was executed, status updates can be fetched by using the list_jobs() function. This function returns a list of job descriptions, which can be indexed with the jobs ID to limit the search results. But remember that only list_jobs() refreshes this list. So, to monitor a job you have to iteratively call the job (describe_job()) or the job list list_jobs().\n\njobs = list_jobs()\njobs # printed as a tibble or data.frame, but the object is a list\n\n# or use the job id (in this example 'cZ2ND0Z5nhBFNQFq') as index to get a particular job overview\njobs$cZ2ND0Z5nhBFNQFq\n\n# alternatively request detailed information about the job\ndescribe_job(job = job)\nWhen the job is finished, calling download_results() will download the results of a job. Using list_results() will return an overview about the created files and their download link or it states the error message, in case of an error.\n\n# list the processed results\nlist_results(job = job)\n\n# download all the files into a folder on the file system\ndownload_results(job = job, folder = \"/some/folder/on/filesystem\")\n\n\n\n\n\n\nNote\n\n\n\nThe printing behavior and the actual data structure might differ!\n\n\nNow you know the general workflow of job executions."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#full-example",
    "href": "APIs/openEO/R_Client/R.html#full-example",
    "title": "Getting started with R client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the R client. Instead of batch job processing, we compute the image synchronously. Synchronous processing means the result is directly returned in the response, which usually works only for smaller amounts of data.\nHere, we want to produce a monthly RGB composite of Sentinel 1 backscatter data over the area of Vienna, Austria for three months in 2017. This can be used for classification and crop monitoring.\nIn the following code example, we use inline code comments to describe what we are doing.\nlibrary(openeo)\nlibrary(tibble)\n\n\n# connect  to the back-end and login either via explicit call of login, or use your credentials in the connect function\nconnection = login(connect(host = \"https://openeo.dataspace.copernicus.eu\"))\n\n# get the process collection to use the predefined processes of the back-end\np = processes()\n\n# get the collection list to get easier access to the collection ids, via auto completion\ncollections = list_collections()\n\n# get the formats\nformats = list_file_formats()\n\n# load the initial data collection and limit the amount of data loaded\n# note: for the collection id and later the format you can also use the its character value\ndata = p$load_collection(id = collections$`SENTINEL1_GRD`,\n                         spatial_extent = list(west=16.06, \n                                               south=48.06,\n                                               east=16.65,\n                                               north=48.35),\n                         temporal_extent = c(\"2017-03-01\", \"2017-06-01\"),\n                         bands = c(\"VV\"))\n\n# create three monthly sub data sets, which will be merged back into a single data cube later\nmarch = p$filter_temporal(data = data,\n                          extent = c(\"2017-03-01\", \"2017-04-01\"))\n\napril = p$filter_temporal(data = data,\n                          extent = c(\"2017-04-01\", \"2017-05-01\"))\n\nmay = p$filter_temporal(data = data,\n                        extent = c(\"2017-05-01\", \"2017-06-01\"))\n\n# The aggregation function for the following temporal reducer\nagg_fun_mean = function(data, context) {\n  mean(data)\n}\n\nmarch_reduced = p$reduce_dimension(data = march,\n                                   reducer = agg_fun_mean,\n                                   dimension = \"t\")\n\napril_reduced = p$reduce_dimension(data = april,\n                                   reducer = agg_fun_mean,\n                                   dimension = \"t\")\n\nmay_reduced = p$reduce_dimension(data = may,\n                                 reducer = agg_fun_mean,\n                                 dimension = \"t\")\n\n# Each band is currently called VV. We need to rename at least the label of one dimension, \n# because otherwise identity of the data cubes is assumed. The bands dimension consists \n# only of one label, so we can rename this to be able to merge those data cubes.\nmarch_renamed = p$rename_labels(data = march_reduced,\n                                dimension = \"bands\",\n                                target = c(\"R\"),\n                                source = c(\"VV\"))\n\napril_renamed = p$rename_labels(data = april_reduced,\n                                dimension = \"bands\",\n                                target = c(\"G\"),\n                                source = c(\"VV\"))\n\nmay_renamed = p$rename_labels(data = may_reduced,\n                              dimension = \"bands\",\n                              target = c(\"B\"),\n                              source = c(\"VV\"))\n\n# combine the individual data cubes into one\n# this is done one by one, since the dimensionalities have to match between each of the data cubes\nmerge_1 = p$merge_cubes(cube1 = march_renamed,cube2 = april_renamed)\nmerge_2 = p$merge_cubes(cube1 = merge_1, cube2 = may_renamed)\n\n# rescale the the back scatter measurements into 8Bit integer to view the results as PNG\nrescaled = p$apply(data = merge_2,\n        process = function(data,context) {\n          p$linear_scale_range(x=data, inputMin = -20,inputMax = -5, outputMin = 0, outputMax = 255)\n        })\n\n# export shall be format PNG\n# look at the format description\nformats$output$PNG\n\n# store the results using the format and set the create options\nresult = p$save_result(data = rescaled,format = formats$output$PNG, options = list(red=\"R\",green=\"G\",blue=\"B\"))\n\n# create a job\njob = create_job(graph = result, title = \"S1 Example R\", description = \"Getting Started example on openeo.org for R-client\")\n\n# then start the processing of the job and turn on logging (messages that are captured on the back-end during the process execution)\nstart_job(job = job, log = TRUE)\nNow the resulting PNG file of the RGB backscatter composite is stored as a PNG file in the current working directory. It looks like this:"
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#user-defined-functions",
    "href": "APIs/openEO/R_Client/R.html#user-defined-functions",
    "title": "Getting started with R client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function.\nIn general the processing workflow works by uploading the Python or R script into the users file directory on the back-end and reference the script via its URL or by its relational name (e.g. /scripts/script1.R) in the function run_udf. The latter function is a predefined openEO process that the back-end might provide, if UDFs are supported.\nFind out more about UDFs in the respective Python UDF and R UDF repositories with their documentation and examples."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#useful-links",
    "href": "APIs/openEO/R_Client/R.html#useful-links",
    "title": "Getting started with R client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO R Client Library:\n\nDocumentation\nVignettes\nCode Repository\nfor function documentation, use R’s ? function or see the online documentation"
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html",
    "href": "APIs/openEO/Python_Client/Python.html",
    "title": "Getting started with Python client",
    "section": "",
    "text": "This Getting Started guide will give you just a simple overview of the capabilities of the openEO Python client library. More in-depth information can be found in its official documentation."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#installation",
    "href": "APIs/openEO/Python_Client/Python.html#installation",
    "title": "Getting started with Python client",
    "section": "Installation",
    "text": "Installation\nThe openEO Python client library is available on PyPI and can easily be installed with a tool like pip, for example:\npip install openeo\n\nTo upgrade the package to the latest release:\n\npip install --upgrade openeo\n\nThe client library is also available on Conda Forge and can be easily installed in a conda environment, for example:\n\nconda install -c conda-forge openeo\n\nIt’s recommended to work in a virtual environment of some kind (venv, conda, …), containing Python 3.8 or higher.\n\n\n\n\n\n\nTip\n\n\n\n\n\nFor more details, alternative installation procedures or troubleshooting tips: see the official openEO package installation documentation."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#exploring-a-back-end",
    "href": "APIs/openEO/Python_Client/Python.html#exploring-a-back-end",
    "title": "Getting started with Python client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO instance of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu.\nFirst we need to establish a connection to the back-end.\n\nimport openeo\n\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\")\nThe Connection object is your central gateway to - list data collections, available processes, file formats and other capabilities of the back-end - start building your openEO algorithm from the desired data on the back-end - execute and monitor (batch) jobs on the back-end - etc.\n\nCollections\nThe EO data available at a back-end is organised in so-called collections. For example, a back-end might provide fundamental satellite collections like “Sentinel 1” or “Sentinel 2”, or preprocessed collections like “NDVI”. Collections are used as input data for your openEO jobs.\n\n\n\n\n\n\nNote\n\n\n\nMore information on how openEO “collections” relate to terminology used in other systems can be found in (the openEO glossary).\n\n\nIf necessary, a more detailed metadata listing for a given collection can be obtained with describe_collection.\n\n\nProcesses\nProcesses in openEO are operations that can be applied on (EO) data (e.g. calculate the mean of an array, or mask out observations outside a given polygon). The output of one process can be used as the input of another process, and by doing so, multiple processes can be connected that way in a larger “process graph”: a new (user-defined) processes that implements a certain algorithm.\n\n\n\n\n\n\nNote\n\n\n\nCheck the openEO glossary for more details on pre-defined, user-defined processes and process graphs.\n\n\nFor other graphical overviews of the openEO processes, there is an online documentation for general process descriptions and the openEO Hub for back-end specific process descriptions."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#authentication",
    "href": "APIs/openEO/Python_Client/Python.html#authentication",
    "title": "Getting started with Python client",
    "section": "Authentication",
    "text": "Authentication\nIn the code snippets above we did not need to log in since we just queried publicly available back-end information. However, to run non-trivial processing queries one has to authenticate so that permissions, resource usage, etc. can be managed properly.\nA detailed description of why and how to use the authentication methods is on the official documentation.\nTo authenticate your account on the backend of the Copernicus Data Space Ecosystem, it is necessary for you to complete the registration process. Once registered, you will be authenticated for executing processes.\nThe following code snippet shows how to log in via OIDC authentication:\nprint(\"Authenticate with OIDC authentication\")\nconnection.authenticate_oidc()\nThe method is used to authenticate yourself on the back-end authentication system. Calling this method with either will print a URL to visit, that opens your system web browser where you can use your Copernicus Data Space Ecosystem credentials, or when there are refresh tokens, these will be used directly. After that the website will give you the instructions to go back to the python client, where your connection has logged your account in. This means that every call that comes after that via the connection variable is executed by your user account."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#working-with-datacube",
    "href": "APIs/openEO/Python_Client/Python.html#working-with-datacube",
    "title": "Getting started with Python client",
    "section": "Working with Datacube",
    "text": "Working with Datacube\nNow that we know how to discover the capabilities of the back-end and how to authenticate, let’s do some real work and process some EO data in a batch job. We’ll build the desired algorithm by working on so-called “Datacubes”, which is the central concept in openEO to represent EO data.\n\nCreating a Datacube\nThe first step is loading the desired slice of a data collection with Connection.load_collection:\ndatacube = connection.load_collection(\n      \"SENTINEL2_L2A\",\n      spatial_extent={\"west\": 5.14, \"south\": 51.17, \"east\": 5.17, \"north\": 51.19},\n      temporal_extent = [\"2021-02-01\", \"2021-04-30\"],\n      bands=[\"B02\", \"B04\", \"B08\"],\n      max_cloud_cover=85\n      )\nThis results in a Datacube object containing the “SENTINEL2_L2A” data restricted to the given spatial extent, the given temporal extend and the given bands .\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can also filter the datacube step by step or at a later stage by using the following filter methods:\ndatacube = datacube.filter_bbox(west=5.14, south=51.17, east=5.17, north=51.19)\ndatacube = datacube.filter_temporal(start_date=\"2021-02-01\", end_date=\"2021-04-30\")\ndatacube = datacube.filter_bands([\"B02\", \"B04\", \"B08\"])\nStill, it is recommended to always use the filters directly in load_collection to avoid loading too much data upfront.\n\n\n\n\n\nApplying processes\nBy applying an openEO process on a datacube, we create a new datacube object that represents the manipulated data. The standard way to do this with the Python client is to call the appropriate Datacube object method. The most common or popular openEO processes have a dedicated Datacube method (e.g. mask, aggregate_spatial, filter_bbox, …). Other processes without a dedicated method can still be applied in a generic way. An on top of that, there are also some convenience methods that implement openEO processes is a compact, Pythonic interface.\nFor example, the min_time method implements a reduce_dimension process along the temporal dimension, using the max process as reducer function:\ndatacube = datacube.max_time()\nThis creates a new datacube (we overwrite the existing variable), where the time dimension is eliminated and for each pixel we just have the minimum value of the corresponding timeseries in the original datacube.\nSee the Python client Datacube API for a more complete listing of methods that implement openEO processes.\n\n\n\n\n\n\nNote\n\n\n\nStill unsure on how to make use of processes with the Python client? Visit the official documentation on working with processes."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#execution",
    "href": "APIs/openEO/Python_Client/Python.html#execution",
    "title": "Getting started with Python client",
    "section": "Execution",
    "text": "Execution\nIt’s important to note that all the datacube processes we applied up to this point are not actually executed yet, neither locally nor remotely on the back-end. We just built an abstract representation of the algorithm (input data and processing chain), encapsulated in a local Datacube object (e.g. the result variable above). To trigger an actual execution (on the back-end) we have to explicitly send this representation to the back-end.\n\nBatch job execution\nMost of the simple, basic openEO usage examples show synchronous downloading of results. This only works properly if the processing doesn’t take too long and is focused on a smaller area of interest. However, you have to use batch jobs for the heavier work (larger regions of interest, larger time series, more intensive processing).\n# While not necessary, it is also recommended to give your batch job a descriptive title so it’s easier to identify in your job listing.\njob = cube.execute_batch()\n\nThis documentation mainly discusses how to programmatically create and interact with batch job using the openEO Python client library. The openEO API however does not enforce usage of the same tool for each step in the batch job life cycle.\nFor example: if you prefer a graphical, web-based interactive environment to manage and monitor your batch jobs, feel free to switch to an openEO web editor like openeo.dataspace.copernicus.eu/ at any time. After logging in with the same account you use in your Python scripts, you should see your batch jobs listed under the “Data Processing” tab. More information on using openEO web editor is discussed here.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe official openEO Python Client documentation has more information on batch job basics {target=“_blank”} or more detailed batch job (result) management"
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#full-example",
    "href": "APIs/openEO/Python_Client/Python.html#full-example",
    "title": "Getting started with Python client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the Python client.\nA common task in earth observation is to apply a formula to a number of spectral bands in order to compute an ‘index’, such as NDVI, NDWI, EVI, … In this tutorial we’ll go through a couple of steps to extract EVI (enhanced vegetation index) values and timeseries\nimport openeo\n\n# First, we connect to the back-end and authenticate. \ncon = openeo.connect(\"openeo.dataspace.copernicus.eu\")\ncon.authenticate_oidc()\n\n# Now that we are connected, we can initialize our datacube object with the area of interest \n# and the time range of interest using Sentinel 1 data.\ndatacube = connection.load_collection(\n      \"SENTINEL2_L2A\",\n      spatial_extent={\"west\": 5.14, \"south\": 51.17, \"east\": 5.17, \"north\": 51.19},\n      temporal_extent = [\"2021-02-01\", \"2021-04-30\"],\n      bands=[\"B02\", \"B04\", \"B08\"],\n      max_cloud_cover=85\n      )\n\n# By filtering as early as possible (directly in load_collection() in this case), \n# we make sure the back-end only loads the data we are interested in and avoid incurring unneeded costs.\n\n\n#From this data cube, we can now select the individual bands with the DataCube.band() method and rescale the digital number values to physical reflectances:\nblue = sentinel2_cube.band(\"B02\") * 0.0001\nred = sentinel2_cube.band(\"B04\") * 0.0001\nnir = sentinel2_cube.band(\"B08\") * 0.0001\n\n\n# We now want to compute the enhanced vegetation index and can do that directly with these band variables:\nevi_cube = 2.5 * (nir - red) / (nir + 6.0 * red - 7.5 * blue + 1.0)\n\n# Now we can use the compact “band math” feature again to build a binary mask with a simple comparison operation:\n# Select the \"SCL\" band from the data cube\nscl_band = s2_scl.band(\"SCL\")\n# Build mask to mask out everything but class 4 (vegetation)\nmask = (scl_band != 4)\n\n# Before we can apply this mask to the EVI cube we have to resample it, as the “SCL” layer has a “ground sample distance” of 20 meter, while it is 10 meter for the “B02”, “B04” and “B08” bands. We can easily do the resampling by referring directly to the EVI cube.\nmask_resampled = mask.resample_cube_spatial(evi_cube)\n\n# Apply the mask to the `evi_cube`\nevi_cube_masked = evi_cube.mask(mask_resampled)\n\n# Because GeoTIFF does not support a temporal dimension, we first eliminate it by taking the temporal maximum value for each pixel:\nevi_composite = evi_cube.max_time()\n\n# Now we can download this to a local file:\nevi_composite.download(\"evi-composite.tiff\")\nNow, you can inspect the result for the EVI map."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#user-defined-functions",
    "href": "APIs/openEO/Python_Client/Python.html#user-defined-functions",
    "title": "Getting started with Python client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function. Therefore, you can create a Python function that will be executed at the back-end and functions as a process in your process graph.\nDetailed information about Python UDFs can be found in the official documentation as well as examples in the Python client repository."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#useful-links",
    "href": "APIs/openEO/Python_Client/Python.html#useful-links",
    "title": "Getting started with Python client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO Python Client Library:\n\nExample scripts\nExample Jupyter Notebooks\nOfficial openEO Python Client Library Documentation\nRepository on GitHub"
  },
  {
    "objectID": "APIs/openEO/openEO.html",
    "href": "APIs/openEO/openEO.html",
    "title": "openEO",
    "section": "",
    "text": "openEO represents an innovative community standard that revolutionizes geospatial data processing and analysis. This groundbreaking framework provides a novel approach to accessing, processing, and analyzing diverse Earth observation data. By adopting openEO, developers, researchers, and data scientists gain access to a unified and interoperable platform, empowering them to harness distributed computing environments and leverage cloud-based resources for addressing complex geospatial challenges.\n\n\n\nWith openEO’s collaborative nature, users can seamlessly share code, workflows, and data processing methods across platforms and tools, fostering collaboration and advancing the accessibility, scalability, and reproducibility of Earth observation data. Additionally, openEO provides intuitive programming libraries that enable easy analysis of diverse Earth observation datasets. These libraries facilitate efficient access and processing of large-scale data across multiple infrastructures, supporting various applications, including exploratory research, detailed mapping, and information extraction from Earth observation. Moreover, this streamlined approach enhances the development process, enabling the utilization of Earth observation data for a wide range of applications and services."
  },
  {
    "objectID": "APIs/openEO/openEO.html#overview",
    "href": "APIs/openEO/openEO.html#overview",
    "title": "openEO",
    "section": "",
    "text": "openEO represents an innovative community standard that revolutionizes geospatial data processing and analysis. This groundbreaking framework provides a novel approach to accessing, processing, and analyzing diverse Earth observation data. By adopting openEO, developers, researchers, and data scientists gain access to a unified and interoperable platform, empowering them to harness distributed computing environments and leverage cloud-based resources for addressing complex geospatial challenges.\n\n\n\nWith openEO’s collaborative nature, users can seamlessly share code, workflows, and data processing methods across platforms and tools, fostering collaboration and advancing the accessibility, scalability, and reproducibility of Earth observation data. Additionally, openEO provides intuitive programming libraries that enable easy analysis of diverse Earth observation datasets. These libraries facilitate efficient access and processing of large-scale data across multiple infrastructures, supporting various applications, including exploratory research, detailed mapping, and information extraction from Earth observation. Moreover, this streamlined approach enhances the development process, enabling the utilization of Earth observation data for a wide range of applications and services."
  },
  {
    "objectID": "APIs/openEO/openEO.html#added-value-of-openeo-api",
    "href": "APIs/openEO/openEO.html#added-value-of-openeo-api",
    "title": "openEO",
    "section": "Added-value of openEO API",
    "text": "Added-value of openEO API\nThe key benefits of using openEO API can be summarized as follows:\n\nUnified and straightforward access to multiple Earth observation datasets.\nScalable and efficient processing capabilities.\nA standardized system that works across different platforms.\nIndependence from underlying technologies and software libraries.\nReproducibility through transparent workflows, supporting principles of FAIR (Findable, Accessible, Interoperable, and Reusable) and Open Science.\n\nWhen using the openEO API, users can choose JavaScript, Python, or R as their client library. This allows them to work with any back-end and compare them based on capacity, cost, and result quality.\nNevertheless, if you are not familiar with programming, you could start using the web-based editor for openEO. It supports visual modelling of your algorithms and simplified JavaScript-based access to the openEO workflows and providers. An overview of the openEO web-editor is available in the Application section of this documentation."
  },
  {
    "objectID": "APIs/openEO/openEO.html#datacubes",
    "href": "APIs/openEO/openEO.html#datacubes",
    "title": "openEO",
    "section": "Datacubes",
    "text": "Datacubes\nIn openEO, a datacube is a fundamental concept and a key component of the platform. Data is represented as datacubes in openEO, which are multi-dimensional arrays with additional information about their dimensionality. Datacubes can provide a nice and tidy interface for spatiotemporal data as well as for the operations you may want to execute on them. An in-depth introduction to datacubes and processing them with openEO can be found here"
  },
  {
    "objectID": "APIs/openEO/openEO.html#support",
    "href": "APIs/openEO/openEO.html#support",
    "title": "openEO",
    "section": "Support",
    "text": "Support\nUnable to locate your preferred programming language? Or you don’t find functionalities that you want to use. Then you have the option to report issues or feedbacks via the to be CDSE forum or also please feel free to create a ticket or actively propose API changes through Pull Requests."
  },
  {
    "objectID": "APIs/openEO/openEO.html#free-tier-limitations",
    "href": "APIs/openEO/openEO.html#free-tier-limitations",
    "title": "openEO",
    "section": "Free tier limitations",
    "text": "Free tier limitations\nThe following limitations need to be taken into account:\n\nSynchronous requests are limited to 2 concurrent requests\nBatch jobs are limited to 2 concurrent jobs\n\nThese limits are in place to avoid that individual users can overload the service, please contact support if they are problematic for your use case."
  },
  {
    "objectID": "APIs/openEO/openEO.html#collections",
    "href": "APIs/openEO/openEO.html#collections",
    "title": "openEO",
    "section": "Collections",
    "text": "Collections"
  },
  {
    "objectID": "APIs/openEO/openEO.html#file-formats",
    "href": "APIs/openEO/openEO.html#file-formats",
    "title": "openEO",
    "section": "File formats",
    "text": "File formats"
  },
  {
    "objectID": "APIs/openEO/openEO.html#processes",
    "href": "APIs/openEO/openEO.html#processes",
    "title": "openEO",
    "section": "Processes",
    "text": "Processes"
  },
  {
    "objectID": "APIs/openEO/job_config.html",
    "href": "APIs/openEO/job_config.html",
    "title": "Documentation",
    "section": "",
    "text": "Batch job results are accessible to the user via signed URLs stored in the result assets. Within the platform, these URLs have a validity (expiry time) of 7 days. Within these 7 days, the results of a batch job can be accessed by any person with the URL. Each time a user requests the results from the job endpoint (GET /jobs/{job_id}/results), a freshly signed URL (valid for 7 days) is created for the result assets."
  },
  {
    "objectID": "APIs/openEO/job_config.html#validity-of-signed-urls-in-batch-job-results",
    "href": "APIs/openEO/job_config.html#validity-of-signed-urls-in-batch-job-results",
    "title": "Documentation",
    "section": "",
    "text": "Batch job results are accessible to the user via signed URLs stored in the result assets. Within the platform, these URLs have a validity (expiry time) of 7 days. Within these 7 days, the results of a batch job can be accessed by any person with the URL. Each time a user requests the results from the job endpoint (GET /jobs/{job_id}/results), a freshly signed URL (valid for 7 days) is created for the result assets."
  },
  {
    "objectID": "APIs/openEO/job_config.html#customizing-batch-job-resources",
    "href": "APIs/openEO/job_config.html#customizing-batch-job-resources",
    "title": "Documentation",
    "section": "Customizing batch job resources",
    "text": "Customizing batch job resources\nJobs running on the cloud get assigned a default amount of CPU and memory resources. This may not always be enough for your job, for instance when using UDF’s. Also for very large jobs, you may want to tune your resource settings to optimize for cost.\nThe example below shows how to start a job with all options set to their default values. It is important to highlight that default settings are subject to change by the backend whenever needed.\njob_options = {\n        \"executor-memory\": \"2G\",\n        \"executor-memoryOverhead\": \"1800m\",\n        \"executor-cores\": 1,\n        \"task-cpus\": 1,\n        \"max-executors\": \"20\",\n        \"driver-memory\": \"2G\",\n        \"driver-memoryOverhead\": \"1G\",\n        \"driver-cores\": 1,\n        \"udf-dependency-archives\":[],\n        \"logging-threshold\": \"info\"\n    }\ncube.execute_batch(job_options=job_options)\nThis is a short overview of the various options:\n\nexecutor-memory: memory assigned to your workers, for the JVM that executes most predefined processes\nexecutor-memoryOverhead: memory assigned on top of the JVM, for instance to run UDF’s\nexecutor-cores: number of CPUs per worker (executor). The number of parallel tasks is executor-cores/task-cpus\ntask-cpus: CPUs assigned to a single task. UDF’s using libraries like Tensorflow can benefit from further parallellization on the level of individual tasks.\nexecutor-request-cores: this settings is only relevant for Kubernetes based backends, allows to overcommit CPU\nmax-executors: the maximum number of workers assigned to your job. Maximum number of parallel tasks is max-executors*executor-cores/task-cpus. Increasing this can inflate your costs, while not necessarily improving performance!\ndriver-memory: memory assigned to the spark ‘driver’ JVM that controls execution of your batch job\ndriver-memoryOverhead: memory assigned to the spark ‘driver’ on top of JVM memory, for Python processes.\nlogging-threshold: the threshold for logging, set to ‘info’ by default, can be set to ‘debug’ to generate much more logging\nudf-dependency-archives: an array of urls pointing to zip files with extra dependencies, see below\n\n\nCustom UDF dependencies\nUser defined functions often depend on (specific versions of) libraries or require small auxiliary data files. The UDF specifications do not yet define a standardized manner to provide this other than having the ability of selecting from a predefined set of ‘runtimes’ that than again have a predefined configuration.\nWe solve this via the udf-dependency-archives job option, that allows to specify a list of zip files that should be included in the working directory of the UDF.\nThis enables the following example workflow for Python UDF’s:\n\nCreate a Python ‘virtualenv’ with your dependencies\nBased on the ‘site-packages’ directory of the virtualenv, create a zip file with all dependencies\nUpload the zip to a url that can be reached by the backend.\nIn job options, add \"udf-dependency-archives\": ['https://yourhost.com/myEnv.zip#tmp/mydir'] The #tmp/mydir suffix indicates where you want to unzip your files, relative to the working directory.\nIn your UDF, before trying to import libraries, add your directory to the Python path: sys.path.insert(0, 'tmp/mydir')\nNow your libraries should be loaded before anything else!\n\nKnown limitations:\n\nYour dependencies need to be compatible with the Python version of the backend, currently 3.8.\nYour dependencies need to be compatible with the OS of the backend, currently AlmaLinux 8.\nThe backend has a limited set of Python dependences that are preloaded, and cannot be changed, such as numpy.\n\n\n\nLearning more\nThe topic of resource optimization is a complex one, and here we just give a short summary. The goal of openEO is to hide most of these details from the user, but we realize that advanced users sometimes want to have a bit more insight, so in the spirit of being open, we give some hints.\nTo learn more about these options, we point to the piece of code that handles this.\nMost memory related options are translated to Apache Spark configuration settings, which are documented here."
  },
  {
    "objectID": "APIs/Traceability.html",
    "href": "APIs/Traceability.html",
    "title": "Traceability Service",
    "section": "",
    "text": "Traceability Service provides the user with means to track the lifecycle of a data product. It acts as a historian of the product’s lifecycle, collecting the traces of all related events. These traces then can be used to check the integrity of the product, its current whereabouts, its impact on other products or ultimately its inadequacy for continued use in case of obsolescence. Digital signatures on the traces provide users with the ability to verify authenticity and integrity of the traces themselves – this also enables users to detect any alterations of the product during its lifecycle.\nUsers may interact with Traceability service by either curl command (on both Windows and Linux), directly via the Traceability Service API endpoint or via the Traceability Service API documentation.\nTraceability Service API endpoint: https://trace.dataspace.copernicus.eu/api\nDocumentation related to Traceability Service API: https://trace.dataspace.copernicus.eu/api/docs\n\n\nInteraction with Traceability Service by using curl command on Linux:\ncurl -X 'GET' 'https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip' -H 'accept: application/json'\nPlease be aware that curl command might have a different syntax on Windows. Please refer to curl official documentation if you have any questions (https://curl.se/docs/manual.html).\n\n\n\nInteraction with Traceability Service directly via the Traceability Service API: https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip"
  },
  {
    "objectID": "APIs/Traceability.html#example",
    "href": "APIs/Traceability.html#example",
    "title": "Traceability Service",
    "section": "",
    "text": "Interaction with Traceability Service by using curl command on Linux:\ncurl -X 'GET' 'https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip' -H 'accept: application/json'\nPlease be aware that curl command might have a different syntax on Windows. Please refer to curl official documentation if you have any questions (https://curl.se/docs/manual.html)."
  },
  {
    "objectID": "APIs/Traceability.html#direct-access",
    "href": "APIs/Traceability.html#direct-access",
    "title": "Traceability Service",
    "section": "",
    "text": "Interaction with Traceability Service directly via the Traceability Service API: https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip"
  },
  {
    "objectID": "APIs/OpenSearch.html",
    "href": "APIs/OpenSearch.html",
    "title": "OpenSearch Catalog web service",
    "section": "",
    "text": "The OpenSearch catalogue allows you to search through Copernicus data using a standardized web service. The OpenSearch specification can be consulted for technical details of the standard. This web service returns results as GeoJSON feature collections. Each feature in the collection represents an earth observation ‘product’, referencing where the actual data can be found.\nWe remark that this version does not implement the OGC OpenSearch standards, and a migration from other API’s named OpenSearch may require significant modifications. It mainly offers compatibility for existing users of a similar API on the CreoDIAS and Wekeo platforms and with client-side tools and workflows that have implemented support for this API. For new users looking for a more standardized API, a STAC alternative is being developed."
  },
  {
    "objectID": "APIs/OpenSearch.html#using-opensearch-interface-to-query-data-catalogue",
    "href": "APIs/OpenSearch.html#using-opensearch-interface-to-query-data-catalogue",
    "title": "OpenSearch Catalog web service",
    "section": "Using OpenSearch interface to query Data Catalogue",
    "text": "Using OpenSearch interface to query Data Catalogue\nDue to the fact that offset is not a recommended form of searching repository pages, we had to implement a limit to a maximum of 200k. The requests over the limit will be rejected with the code 400. Therefore, we encourage you to limit your inquiries by geographic or temporal area.\nAll queries may be executed as simple HTTP-Get calls by typing the query in the web browser address line, by using any HTTP client, e.g. curl or wget, or from inside of the users’ program. The database is accessible free and anonymously (open for anonymous access for everyone, no authorization is used). It may be accessed both from the internal network (virtual machines in Creodias) and from outside, e.g. your home computer. Note that the actual EO data are restricted to authorized users; only the Data Catalogue is open.\n\nGeneral Rules\nThe queries produce results in JSON format. Base url:\n\nHTTP RequestPython\n\n\nhttp://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?\n\n\n\n\nCode\njson = requests.get(\"http://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\nffc7c4ae-9cdf-56a7-981e-401f2cdd0a53\n{'type': 'Polygon', 'coordinates': [[[22.29859...\n{'collection': 'LANDSAT-5', 'status': 'ONLINE'...\n\n\n1\nFeature\n144c9de3-6c30-5062-8bab-add3d83aa76a\n{'type': 'Polygon', 'coordinates': [[[32.31033...\n{'collection': 'LANDSAT-5', 'status': 'ONLINE'...\n\n\n2\nFeature\nbd33aaca-c7d5-5f00-a005-00450cae37bf\n{'type': 'Polygon', 'coordinates': [[[33.90780...\n{'collection': 'LANDSAT-5', 'status': 'ONLINE'...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMost queries are case-sensitive.\n\n\n\n\nCollections\nThe data are organized in so-called collections corresponding to various satellites. A query may search for data in all collections or in one particular collection only. If only one satellite is in the field of interest, the second approach is faster and more efficient than filtering the general query. For example, to find the ten most recent Sentinel-2 products with cloud cover below 10%, the query should look like:\n\nCLI\n\n\n$ wget -O - \"http://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10\"\n\n\n\nwhile if the collection field is missing in the URL, the products from all the satellites are returned:\n\nCLI\n\n\n$ wget -O - \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10\"\n\n\n\nAs for today the following collections are defined and may be used:\n\nSentinel1 or SENTINEL-1\nSentinel2 or SENTINEL-2\nSentinel3 or SENTINEL-3\nSentinel5P or SENTINEL-5P\n\n\n\n\n\n\n\nNote\n\n\n\nNote, that collection names vary a bit from satellite names, as they are used in EO Data repository. For example, the collection is named Sentinel2, while in the repository its data are located within /eodata/Sentinel-2/…. branch of the repository tree.\n\n\n\n\nOutput sorting and limiting\nBy default, maximum of 20 products are returned. You may change the limit (beware of long execution time for queries about thousands of products) using the phrase:\n\nmaxRecords=nnn\n\nIf the query is very general and the number of matching products is large, the next pages of products can be retrieved using:\n\npage=nnn\n\nIt is also possible to alter the sequence in which the products are displayed by using a phrase similar to:\n\nsortParam=startDate\n\nThis will sort the output by observation date. The following orderings can be implemented:\n\nstartDate - the date when the observation was made (start)\ncompletionDate - the date when the observation was made (end)\npublished - the date when the product got published in our repository\n\nEeach of these ordering can be be accompanied by:\n\nsortOrder=ascending or sortOrder=descending\n\nFor example the query\n\nHTTP RequestPython\n\n\nhttp://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20\n\n\n\n\nCode\njson = requests.get(\"http://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n010f2ad1-0199-4bd8-850a-215b5c63b0b9\n{'type': 'Polygon', 'coordinates': [[[158.5965...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\n06ccfceb-938e-4bda-beff-3c2acae864b2\n{'type': 'Polygon', 'coordinates': [[[158.5288...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n229dd65c-399d-48bc-a116-14bb0e001742\n{'type': 'Polygon', 'coordinates': [[[157.1876...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\nThe above request will return 20 products from July 2021, whereas the next query will return the next 20:\n\nHTTP RequestPython\n\n\nhttp://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20&page=2\n\n\n\n\nCode\njson = requests.get(\"http://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20&page=2\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\ncdaed6e4-99c3-44db-89e6-efbd21276bef\n{'type': 'Polygon', 'coordinates': [[[156.7053...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\nd2a89e60-4b83-4cb6-a3d7-d926e2b804df\n{'type': 'Polygon', 'coordinates': [[[156.0567...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\nd4e341a1-719f-4297-a6f2-1c5d10098c12\n{'type': 'Polygon', 'coordinates': [[[158.1844...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\n\n\nFormal queries\nThe formal query is invoked as a sequence of sub phrases, separated by &. The result is a conjunction of all sub phrases. It is impossible to use an alternative in the question. The query must be specified as a formal query.\nThe example of formal query - about cloudless (cloud cover lower or equal to 10%) products for a specific location:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2021-06-21T00:00:00Z&completionDate=2021-09-22T23:59:59Z&lon=21.01&lat=52.22\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2021-06-21T00:00:00Z&completionDate=2021-09-22T23:59:59Z&lon=21.01&lat=52.22\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n8eeb4008-c8e9-4ddc-998c-b22f259d5de6\n{'type': 'Polygon', 'coordinates': [[[19.53152...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\ne31fc7f6-1e80-595f-ab6b-fe9a39d47d83\n{'type': 'Polygon', 'coordinates': [[[21.96037...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n8f531328-07ac-5e01-b484-f7cb6be6f392\n{'type': 'Polygon', 'coordinates': [[[19.53152...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\nThe queries are in form param=value or param=[minvalue,maxvalue]. Most of the parameters are common for all collections, but some are specific for some them (e.g. cloudCover applies to optical satellites, but polarisation applies to radar ones), or just single one.\n\n\nGeography and time-frame\nThe common set of parameters are:\n\nstartDate, completionDate - the date limits of the observation. The time may also be specified, e.g. 2021-10-01T21:37:00Z\npublishedAfter, publishedBefore - the date limits when the product was published in our repository\nlon, lat - geographical position, expressed in military style (EPSG:4326, as decimal fraction of degrees, positive for eastern latitude and northern longitude) radius - region of interest, defined as a circle with centre in point determined by the longitude and latitude with radius expressed in meters (it won’t work with point manually selected in EOFinder/Data Explorer)\ngeometry - region of interest, defined as WKT string (POINT, POLYGON, etc.)\nbox - region of interest, defined as the rectangle with given (west,south,east,north) values. It should be defined this way: &box=west,south,east,north\n\nFor example the query can be:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=-1,1,-1,1\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=-1,1,-1,1\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\nc33a50af-94a5-5342-bd10-b2595afcf318\n{'type': 'Polygon', 'coordinates': [[[-49.2582...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\ne70d8e55-fcc3-52bd-a47b-3a62b6d835db\n{'type': 'Polygon', 'coordinates': [[[28.79688...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\ne568bed5-6ff5-5483-a589-29f9a440a803\n{'type': 'Polygon', 'coordinates': [[[130.7971...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\nor\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=-21,23,-24,15\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=-21,23,-24,15\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\ndf2559e7-00c1-5d50-88fd-c6cec059336b\n{'type': 'Polygon', 'coordinates': [[[36.81347...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\na9ba5a9c-ae83-5e78-92e5-dfc998aa8abd\n{'type': 'Polygon', 'coordinates': [[[37.42252...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n540510f0-8300-5ae7-bc70-69041b10b2ed\n{'type': 'Polygon', 'coordinates': [[[39.09219...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\n\n\nVolatile features\nSome terrain-like feature masks are not permanent but describing a single scene only. The most commonly used such feature is cloudiness, or cloudCover, which is defined for most of the products coming from optical sensors. For example:\n\ncloudCover=[0,10]\n\nThis parameter selects only those scenes, which are covered by clouds by no more than 10%.\n\n\n\n\n\n\nCaution\n\n\n\nTo be meaningful, the cloudiness must be provided with each product, while in many products is missing. If the cloudiness is unknown for the scene, it is marked by a value of 0 or -1. cloudCover=0 is therefore ambiguous: it may either mean totally cloudless sky or the cloudy scene for which cloud cover had not been estimated during original data processing.\n\n\n\n\nSatellite features\n\ninstrument - meaningful only for satellites equipped with multiple instruments. The possible values are satellite specific.\nproductType - the actual types possible are specific for every satellite.\nsensorMode - also satellite and sensor specific. E.g. (for Sentinel-1): sensorMode=EW\norbitDirection - ASCENDING or DESCENDING. For most heliosynchronous satellites descending orbits means the day scenes, while ascending means night ones. For many optical satellites (e.g. Sentinel-2) only day scenes are published.\nresolution - expected spatial resolution of the product defined in meters.\nstatus:\n\n\n\nONLINE\nOFFLINE\n\n\nSome additional parameters are strictly satellite-specific, e.g. polarisation, which is defined only for Sentinel-1.\nFor every satellite (collection) its set of query-able parameters may be obtained by a query like:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/describe.xml\n\n\n\n\nCode\nurl = 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/describe.xml'\nresponse = requests.get(url)\n\nroot = ET.fromstring(response.content)\n\nfor child in root:\n    if child.tag.endswith('ShortName') or child.tag.endswith('Description'):\n        print(f\"{child.tag}: {child.text}\")\n\n\n{http://a9.com/-/spec/opensearch/1.1/}ShortName: Sentinel-1\n{http://a9.com/-/spec/opensearch/1.1/}Description: Sentinel-1 Collection\n\n\n\n\n\nThe resulting XML file provides full list of the parameters for the collection, with their very brief descriptions."
  },
  {
    "objectID": "APIs/On-Demand Production API.html",
    "href": "APIs/On-Demand Production API.html",
    "title": "Documentation",
    "section": "",
    "text": "On-demand processing capability for CARD-BS, CARD-COH6/12 is available on the Copernicus Data Space Ecosystem. This service is offered free to the use via a limited pool of resources, shared across all users, which can be used for processing the data free of charge. This is suitable for users who need to process smaller batches of products. There is no guarantee that processing will be completed in certain time.  For commercial use the price list is available from the Creodias portal https://creodias.eu/billing-models.The service is available via an On Demand Processing API allows the users to interact with the service to issue and control the orders. It provides functionalities like creation, update, cancellation, pausing and monitoring of orders. This allows the users to have a better control over the workflow execution process."
  },
  {
    "objectID": "APIs/On-Demand Production API.html#introduction",
    "href": "APIs/On-Demand Production API.html#introduction",
    "title": "Documentation",
    "section": "",
    "text": "On-demand processing capability for CARD-BS, CARD-COH6/12 is available on the Copernicus Data Space Ecosystem. This service is offered free to the use via a limited pool of resources, shared across all users, which can be used for processing the data free of charge. This is suitable for users who need to process smaller batches of products. There is no guarantee that processing will be completed in certain time.  For commercial use the price list is available from the Creodias portal https://creodias.eu/billing-models.The service is available via an On Demand Processing API allows the users to interact with the service to issue and control the orders. It provides functionalities like creation, update, cancellation, pausing and monitoring of orders. This allows the users to have a better control over the workflow execution process."
  },
  {
    "objectID": "APIs/On-Demand Production API.html#ondemand-processing-api-with-odata-interface",
    "href": "APIs/On-Demand Production API.html#ondemand-processing-api-with-odata-interface",
    "title": "Documentation",
    "section": "OnDemand Processing API with OData interface",
    "text": "OnDemand Processing API with OData interface\nThe OnDemand Processing API allows the users to interact with the service to issue and control the orders. It provides functionalities like creation, update, cancellation, pausing and monitoring of orders. This allows the users to have a better control over the workflow execution process."
  },
  {
    "objectID": "APIs/On-Demand Production API.html#general-information",
    "href": "APIs/On-Demand Production API.html#general-information",
    "title": "Documentation",
    "section": "General information",
    "text": "General information\nThis documentation provides an overview of the OnDemand Processing (ODP) API, which is based on the Open Data Protocol (OData) standard. The ODP API provides a RESTful interface for accessing data and metadata from the Copernicus data catalogue. Access to the API is limited by the Authentication service. Quotas are assigned according to the user typology and include limits on number of concurrent orders and available processing workflows. The API allows discovery of all available workflows which can be run in the CDSE platform, indicating which data types can be processed, what are the available parameters and output modes.\n\nAPI Endpoint\nThe ODP API endpoint is https://odp.dataspace.copernicus.eu/odata/v1. The endpoint supports both HTTP and HTTPS protocols.\nOpenAPI documentation is located at https://odp.dataspace.copernicus.eu/odata/docs\n\n\nAPI Operations\nThe ODP API supports the following operations: - GET: This operation is used to retrieve data and metadata from the ODP. The GET operation supports various query options to filter, order, and limit the data retrieved. - POST: This operation is used to create new entities in the ODP. The POST operation requires a payload in JSON format that specifies the properties of the new entity. - PATCH: This operation is used to update existing entities in the ODP. The PATCH operation requires a payload in JSON format that specifies the properties of the entity to update. - DELETE: This operation is used to delete existing entities from the ODP. The DELETE operation requires the URL of the entity to delete. - ### API Resources\nThe ODP API provides access to the following resources: - Workflow: predefined processor which creates a single output product or series of products based on the input parameters provided by the user. Typical inputs are name of the source product and parameters specific to the processing chain. - Production Order: request for production using a Workflow chosen by the user. - Batch Order: request for production of multiple products using a chosen Workflow. - Order Item: single processing job within and Production Order or Batch Order.\n\n\nAuthentication\nTo access the ODP API you need an authorization token as only authorized users are allowed to interact with the processing service. To get the token you can use the following script:\nexport KEYCLOAK_TOKEN=$(curl -d 'client_id=cdse-public' \\\n-d 'username=&lt;LOGIN&gt;' \\\n-d 'password=&lt;PASSWORD&gt;' \\\n-d 'grant_type=password' \\\n'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | \\\npython -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}')\nOnce you have your token, you can execute request to the API including the token in the request header. For example to list available Workflows you can use the following command:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ 'https://odp.dataspace.copernicus.eu/odata/v1/Workflows'\nMore information on the tokens and authentication can be found here: https://documentation.dataspace.copernicus.eu/APIs/OData.html#product-download"
  },
  {
    "objectID": "APIs/On-Demand Production API.html#querying-the-api",
    "href": "APIs/On-Demand Production API.html#querying-the-api",
    "title": "Documentation",
    "section": "Querying the API",
    "text": "Querying the API\n\nWorkflows\n\nListing available Workflows\nTo list all processing Workflows available to the user:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/Workflows\nTo search for specific Workflows you can use filters on the attributes. To find workflow named “coh”:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/Workflows?$filter=Name eq 'coh'\nIn a similar way to find all Workflows suitable for processing Sentinel-1 SLC products:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/Workflows?\n$filter=contains(InputProductType,'SL````C')\nDetails of the Workflow in the response list the parameters which are needed to create new Production Order:\n        {\n            \"Id\": \"47\",\n            \"Name\": \"card_coh12_public\",\n            \"DisplayName\": \"Sentinel-1: Coherence (12 days)\",\n            \"Documentation\": null,\n            \"Description\": \"The Sentinel-1 CARD COH12 (Copernicus Analysis Ready\n             Data Coherence) processor generates a Sentinel-1 Level 2 product describing \n             the coherence of a pair of images - 12 days apart. \n             Concurrently, a terrain-correction (using DEM) is performed. This processor \n             provided by the Joint Research Centre is based on a GPT graph that can be run \n             with ESA SNAP.\",\n            \"InputProductType\": \"SLC\",\n            \"InputProductTypes\": [\n                \"SLC\",\n                \"S1_SLC__1S\",\n                \"S2_SLC__1S\",\n                \"S3_SLC__1S\",\n                \"S4_SLC__1S\",\n                \"S5_SLC__1S\",\n                \"S6_SLC__1S\",\n                \"IW_SLC__1S\",\n                \"EW_SLC__1S\",\n                \"WV_SLC__1S\"\n            ],\n            \"OutputProductType\": \"CARD-COH12\",\n            \"WorkflowVersion\": \"3.1.0\"\n        }\n\n\n\nProduction Orders\n\nCreate a new Production Order\nTo submit a new processing job you need to use the POST method and send the parameters as a JSON message according to the requirements of a specific Workflows:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder/OData.CSC.Order \\\n-d '&lt;json_message&gt;'\nProduction orders accept the following general parameters: - WorkflowName: the identifier of the workflow – “Name” attribute in the /Workflows response - InputProductReference: information about the input data to be used by the processor - Reference: identifier of a single input product or multiple products (example – mosaicking processors) - ContentDate: time period which should be used by the Workflows (example - time-series based processors) - WorkflowOptions: parameters specific to the Workflows (example – DEM version, cloud coverage) - Priority: priority of the order in the users job queue. Orders with higher priority will be processed first - NotificationEndpoint: (not used) URL of the endpoint which should receive the information once the order is completed (done or failed) - Name: non-unique name for the order to help identify the orders The structure of the JSON message:\n{\n  \"WorkflowName\": \"string\",\n  \"InputProductReference\": {\n    \"Reference\": \"string\",\n    \"ContentDate\": {\n      \"Start\": \"YYYY-MM-DDTHH:mm:ss.SSSZ\",\n      \"End\": \"YYYY-MM-DDTHH:mm:ss.SSSZ\"\n    }\n  },\n  \"WorkflowOptions\": [\n    {\n      \"Name\": \"string\",\n      \"Value\": \"string\"\n    }\n  ],\n  \"Priority\": 0,\n  \"NotificationEndpoint\": \"string\",\n  \"Name\": \"string\"\n}\nExample: to submit an order for the Sentinel-1 CARD Backscatter product:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder/OData.CSC.Order \\\n-d '{ \\\n  \"WorkflowName\": \"card_bs\",\n  \"InputProductReference\": {\n    \"Reference\": \"S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\"\n  },\n  \"Priority\": 1,\n  \"Name\": \"card_bs_order_1\"\n}'\nSample response after successful submission of the order:\n{\n  \"@odata.context\": \"$metadata#OData.CSC.Order\",\n  \"value\": {\n    \"Id\": \"9999999\",\n    \"Status\": \"queued\",\n    \"StatusMessage\": \"queued\",\n    \"SubmissionDate\": \"2023-04-05T10:03:25.474Z\",\n    \"Name\": \"S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\",\n    \"EstimatedDate\": \"2023-04-05T10:33:16.161Z\",\n    \"InputProductReference\": {\n      \"Reference\": S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\",\n      \"ContentDate\": null\n    },\n    \"WorkflowOptions\": [],\n    \"WorkflowName\": \"card_bs\",\n    \"WorkflowId\": null,\n    \"Priority\": 1\n  }\n}\n\n\nCheck list of Production Orders\nTo list all Production Orders requested by the user:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\nhttps://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders\nWhen looking for completed orders for a specific processor:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https:// odp.dataspace.copernicus.eu/odata/v1/ProductionOrders?\n$filter=WorkflowName eq 'coh' and Status eq 'completed'\"\n\n\nCheck the status of a single Production Order\nTo check details of the single order using the order Id:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders(&lt;order_id&gt;)'\n\n\nCancel a Production Order\nTo cancel an existing order:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/\nOData.CSC.Cancel'\nThe orders which are in the queue and not yet processed will be removed instantly. For the orders in processing, the Order Items (single item within a Production Order) being processed will complete but the remaining part of the Order will be canceled. #### Display details of the result The order generates a new product which can be downloaded from the public repository or private storage. To check the details of the result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/Product\"\n\n\nDownload the result\nOnce the order is successfully processed the status changes to completed and the result is ready for download. The user may choose to instruct the service to put the results in a specified location (mandatory if custom parameters have been passed to the Workflow), and standard results (for Workflows like CARD-BS or CARD-COH12) are stored in the CDSE public repository and can be retrieved through the API. To download the result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/Product/$value' \\\n-o result.zip\n\n\n\nBatch Orders\n\nCreate a new Batch Order\nIn a way similar to single Production Order you can request processing of multiple input products as a Batch Order. The Batch Order will run a selected Workflow with the same parameters for all inputs and output the results to the same location. Using Batch Orders makes it easier to process time series or large AOIs. Batch Order endpoint uses the same mechanism as described for the Production Order:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/BatchOrder/OData.CSC.Order \\\n-d '&lt;json_message&gt;'\nBatch Orders accept the following general parameters: - WorkflowName: the identifier of the workflow – “Name” attribute in the /Workflows response - IdentifierList: information about the input data to be used by the processor - identifiers of products - WorkflowOptions: parameters specific to the Workflows (example – DEM version, cloud coverage) - Priority: priority of the order in the users job queue. Orders with higher priority will be processed first - Callback: (not used) URL of the endpoint which should receive the information once the order is completed (done or failed) - Name: non-unique name for the order to help identify the orders - BatchSize: maximum number of items in the batch - BatchVolume: maximum size of output data The structure of the JSON message:\n{\n  \"Name\": \"string\",\n  \"Priority\": 0,\n  \"WorkflowName\": \"string\",\n  \"Callback\": \"string\",\n  \"WorkflowOptions\": [\n    {\n      \"Name\": \"string\",\n      \"Value\": \"string\"\n    }\n  ],\n  \"IdentifierList\": [\n    \"string\"\n  ],\n  \"BatchSize\": 0,\n  \"BatchVolume\": 0\n}\n\n\nCheck list of Batch Orders\nTo list all Production Orders requested by the user:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \nhttps://odp.dataspace.copernicus.eu/odata/v1/BatchOrder\nWhen looking for batch orders for a specific processor:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https:// odp.dataspace.copernicus.eu/odata/v1/BatchOrder?$filter=WorkflowName eq 'coh'\n\n\nCheck the status of a single Batch Order\nTo check details of the single order using the order Id:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)'\n\n\nList products generated in a Batch Order\nWhen the batch order is processed, for each input product an output is generated. To list the output of a batch:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n'https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)/Products'\n\n\nDisplay details of the results\nEach item in the batch is an individual Production Order. To check the details of the single result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)/Product(&lt;order_id&gt;)\""
  },
  {
    "objectID": "APIs/Token.html",
    "href": "APIs/Token.html",
    "title": "Copernicus Data Space Ecosystem Token Generation",
    "section": "",
    "text": "In order to download products from CDSE catalogue using OData and OpenSearch API user are required to have an Keycloak token. This token can be generated in both Linux and Window OS using either cURL or python script."
  },
  {
    "objectID": "APIs/Token.html#by-query-with-curl",
    "href": "APIs/Token.html#by-query-with-curl",
    "title": "Copernicus Data Space Ecosystem Token Generation",
    "section": "By query with cURL",
    "text": "By query with cURL\nCURL is a tool to send data to the server using several protocols such as HTTP.\nOn Linux:\nIn this example, the output is being filtered by grep and awk commands to obtain a token. In the Linux operating system it’s being seen as environmental variable KEYCLOAK_TOKEN.\n\ncURL\n\n\nexport KEYCLOAK_TOKEN=$(curl -d 'client_id=cdse-public' \\\n                    -d \"username=&lt;username&gt;\" \\\n                    -d \"password=&lt;password&gt;\" \\\n                    -d 'grant_type=password' \\\n                    'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | \\\n                    python3 -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}')\n\n\n\n\nYou can use following command to print the token:\nprintenv KEYCLOAK_TOKEN\nOn Windows:\n\ncURL\n\n\ncurl -s -X POST https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token -H \"Content-Type: application/x-www-form-urlencoded\" -d \"username=&lt;username&gt;\" -d \"password=&lt;password&gt;\" -d \"grant_type=password\" -d \"client_id=cdse-public\"\n\n\n\n\nFor commands to work you need to replace “&lt;username&gt;” and “&lt;password&gt;” with your Copernicus Data Space Ecosystem login credentials"
  },
  {
    "objectID": "APIs/Token.html#by-python-script",
    "href": "APIs/Token.html#by-python-script",
    "title": "Copernicus Data Space Ecosystem Token Generation",
    "section": "By Python script",
    "text": "By Python script\n\nPython\n\n\n\nimport json\nimport requests\ndef get_keycloak(username: str, password: str) -&gt; str:\n    data = {\n        \"client_id\": \"cdse-public\",\n        \"username\": username,\n        \"password\": password,\n        \"grant_type\": \"password\",\n        }\n    try:\n        r = requests.post(\"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n        data=data,\n        )\n        r.raise_for_status()\n    except Exception as e:\n        raise Exception(\n            f\"Keycloak token creation failed. Reponse from the server was: {r.json()}\"\n            )\n    return r.json()[\"access_token\"]\n        \n\nkeycloak_token = get_keycloak(\"USERNAME\", \"PASSWORD\")\n\n\n\n\nPlease replace the USERNAME and PASSWORD text in the last line of the script with your Copernicus Data Space Ecosystem login credentials.\nIn case you have any questions, please contact our support."
  },
  {
    "objectID": "APIs/S3.html",
    "href": "APIs/S3.html",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "Access to EO data hosted on object storage is using API compatible with S3.\nS3 is an object storage service with which you can retrieve data over HTTP using REST API.\n\n\n\nTo generate the necessary credentials you must have a registered account on dataspace.copernicus.eu. If you don’t have an account, you can register here.\n\n\n\nIn order to obtain secrets, create a ticket to CDSE support. Our operators will provide you with the appropriate credentials. You must provide in such request the e-mail address of the registered CDSE user for whom the credentials will be generated.\n\n\n\nBelow example assumes the use of a Linux environment.\nHaving the access and secret key together with the endpoint s3.dataspace.copernicus.eu, you can use any tool to handle access via S3. Below is an example of how to access EO Data using the s3cmd.\nFirst, we recommend to create a configuration file. You can create it with tools like vi/vim or nano:\nvi .s3cfg\nvim .s3cfg\nnano .s3cfg\nCopy the following content to your configuration file, with your access and secret key:\n[default]\naccess_key = &lt;access_key&gt;\nhost_base = s3.dataspace.copernicus.eu\nhost_bucket = s3.dataspace.copernicus.eu\nhuman_readable_sizes = False\nsecret_key = &lt;secret_key&gt;\nuse_https = true\ncheck_ssl_certificate = true\nThen you can run any s3cmd command pointing to the previously created configuration file with parameter -c:\ns3cmd -c ~/.s3cfg ls\nBelow is an example of downloading a product from the EO data repository using s3cmd:\ns3cmd -c ~/.s3cfg get s3://DIAS/Sentinel-1/SAR/SLC/2016/12/28/S1A_IW_SLC__1SDV_20161228T044442_20161228T044509_014575_017AE8_4C26.SAFE/measurement/s1a-iw2-slc-vv-20161228t044442-20161228t044508-014575-017ae8-005.tiff\nIf the objects in the repository are archives, for example, such as S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE use the –recursive parameter to download whole product."
  },
  {
    "objectID": "APIs/S3.html#object-storage",
    "href": "APIs/S3.html#object-storage",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "Access to EO data hosted on object storage is using API compatible with S3.\nS3 is an object storage service with which you can retrieve data over HTTP using REST API."
  },
  {
    "objectID": "APIs/S3.html#registration",
    "href": "APIs/S3.html#registration",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "To generate the necessary credentials you must have a registered account on dataspace.copernicus.eu. If you don’t have an account, you can register here."
  },
  {
    "objectID": "APIs/S3.html#request-for-secrets",
    "href": "APIs/S3.html#request-for-secrets",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "In order to obtain secrets, create a ticket to CDSE support. Our operators will provide you with the appropriate credentials. You must provide in such request the e-mail address of the registered CDSE user for whom the credentials will be generated."
  },
  {
    "objectID": "APIs/S3.html#example-access-using-s3cmd",
    "href": "APIs/S3.html#example-access-using-s3cmd",
    "title": "Accces to EO data via S3",
    "section": "",
    "text": "Below example assumes the use of a Linux environment.\nHaving the access and secret key together with the endpoint s3.dataspace.copernicus.eu, you can use any tool to handle access via S3. Below is an example of how to access EO Data using the s3cmd.\nFirst, we recommend to create a configuration file. You can create it with tools like vi/vim or nano:\nvi .s3cfg\nvim .s3cfg\nnano .s3cfg\nCopy the following content to your configuration file, with your access and secret key:\n[default]\naccess_key = &lt;access_key&gt;\nhost_base = s3.dataspace.copernicus.eu\nhost_bucket = s3.dataspace.copernicus.eu\nhuman_readable_sizes = False\nsecret_key = &lt;secret_key&gt;\nuse_https = true\ncheck_ssl_certificate = true\nThen you can run any s3cmd command pointing to the previously created configuration file with parameter -c:\ns3cmd -c ~/.s3cfg ls\nBelow is an example of downloading a product from the EO data repository using s3cmd:\ns3cmd -c ~/.s3cfg get s3://DIAS/Sentinel-1/SAR/SLC/2016/12/28/S1A_IW_SLC__1SDV_20161228T044442_20161228T044509_014575_017AE8_4C26.SAFE/measurement/s1a-iw2-slc-vv-20161228t044442-20161228t044508-014575-017ae8-005.tiff\nIf the objects in the repository are archives, for example, such as S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE use the –recursive parameter to download whole product."
  },
  {
    "objectID": "APIs/SentinelHub.html",
    "href": "APIs/SentinelHub.html",
    "title": "Sentinel Hub",
    "section": "",
    "text": "Sentinel Hub\nSentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service, capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use APIs to retrieve satellite data over their AOI and specific time range from full archives in a matter of seconds."
  },
  {
    "objectID": "APIs/OData.html",
    "href": "APIs/OData.html",
    "title": "OData",
    "section": "",
    "text": "OData (Open Data Protocol) is a standard that specifies a variety of best practices for creating and using REST APIs. OData makes it possible to build REST-based data services that let Web clients publish and edit resources that are recognized by Uniform Resource Locators (URLs) and described in a data model using straightforward HTTP messages."
  },
  {
    "objectID": "APIs/OData.html#query-structure",
    "href": "APIs/OData.html#query-structure",
    "title": "OData",
    "section": "Query structure",
    "text": "Query structure\nAs a general note, OData query consists of elements which in this documentation are called “options”. Interface supports the following search options:\n\nfilter\norderby\ntop\nskip\ncount\nexpand\n\nSearch options should always be preceded with $ and consecutive options should be separated with &.\nConsecutive filters within filter option should be separated with and or or. Not operator can also be used e.g.:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=not contains(Name,'S2') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:10:00.000Z&$orderby=ContentDate/Start&$top=100\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=not contains(Name,'S2') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:10:00.000Z&$orderby=ContentDate/Start&$top=100\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nc6d30f04-e179-582e-82bb-bf8057a8247a\nS3B_SL_2_WST____20220503T000015_20220503T00031...\napplication/octet-stream\n0\n2022-05-03T01:38:51.200Z\n2022-05-03T02:43:42.265Z\n2022-05-03T02:43:42.265Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_2_WST/2022/05/03/S...\n[]\n{'Start': '2022-05-03T00:00:15.373Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-29.4495 -39.747...\n{'type': 'Polygon', 'coordinates': [[[-29.4495...\n\n\n1\napplication/octet-stream\n6f77dc3e-c918-5b42-911a-e8213eab8929\nS3A_SL_1_RBT____20220503T000040_20220503T00034...\napplication/octet-stream\n0\n2022-05-03T02:05:26.929Z\n2022-05-03T02:06:52.439Z\n2022-05-03T02:06:52.439Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2022/05/03/S...\n[]\n{'Start': '2022-05-03T00:00:39.649Z', 'End': '...\ngeography'SRID=4326;POLYGON ((140.111 -0.07485...\n{'type': 'Polygon', 'coordinates': [[[140.111,...\n\n\n2\napplication/octet-stream\n7f265639-547d-5826-93a5-a1be345add24\nS3A_SL_2_WST____20220503T000040_20220503T00034...\napplication/octet-stream\n0\n2022-05-03T02:29:00.617Z\n2022-05-03T03:38:18.142Z\n2022-05-03T03:38:18.142Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_2_WST/2022/05/03/S...\n[]\n{'Start': '2022-05-03T00:00:39.649Z', 'End': '...\ngeography'SRID=4326;POLYGON ((140.111 -0.07485...\n{'type': 'Polygon', 'coordinates': [[[140.111,...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo accelerate the query performance it is recommended to limit the query by acquisition dates e.g.:\nContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z"
  },
  {
    "objectID": "APIs/OData.html#filter-option",
    "href": "APIs/OData.html#filter-option",
    "title": "OData",
    "section": "Filter option",
    "text": "Filter option\n\nQuery by name\nTo search for a specific product by its exact name:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Name eq 'S1A_IW_GRDH_1SDV_20141031T161924_20141031T161949_003076_003856_634E.SAFE'\n\n\n\nTo search for products containing “S1A” in their names:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n9b248a46-b673-51b3-97ac-17c5131ffac0\nS1A_IW_RAW__0SSH_20220503T023424_20220503T0234...\napplication/octet-stream\n0\n2022-05-03T03:55:04.327Z\n2022-05-03T03:58:07.260Z\n2022-05-03T03:58:07.260Z\nTrue\n\n/eodata/Sentinel-1/SAR/RAW/2022/05/03/S1A_IW_R...\n[]\n{'Start': '2022-05-03T02:34:24.449Z', 'End': '...\ngeography'SRID=4326;POLYGON ((12.8671 -68.3681...\n{'type': 'Polygon', 'coordinates': [[[12.8671,...\n\n\n1\napplication/octet-stream\n84a512c0-72b7-5587-ace1-3795c6e88325\nS1A_IW_RAW__0SDV_20220503T002029_20220503T0021...\napplication/octet-stream\n0\n2022-05-03T03:50:08.811Z\n2022-05-03T04:02:26.943Z\n2022-05-03T04:02:26.943Z\nTrue\n\n/eodata/Sentinel-1/SAR/RAW/2022/05/03/S1A_IW_R...\n[]\n{'Start': '2022-05-03T00:20:29.453Z', 'End': '...\ngeography'SRID=4326;POLYGON ((87.3906 55.3996,...\n{'type': 'Polygon', 'coordinates': [[[87.3906,...\n\n\n2\napplication/octet-stream\nb9878dca-4aa9-5eca-8f40-272c5a4bdf9c\nS1A_IW_OCN__2SDV_20220503T102356_20220503T1024...\napplication/octet-stream\n0\n2022-05-03T11:25:06.433Z\n2022-05-03T11:26:35.296Z\n2022-05-03T11:26:35.296Z\nTrue\n\n/eodata/Sentinel-1/SAR/OCN/2022/05/03/S1A_IW_O...\n[]\n{'Start': '2022-05-03T10:23:56.109Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-67.170181 14.04...\n{'type': 'Polygon', 'coordinates': [[[-67.1701...\n\n\n\n\n\n\n\n\n\n\nAlternatively to contains, endswith and startswith can be used, to search for products ending or starting with provided string.\n\n\nQuery by list\nIn case a user desires to search for multiple products by name in one query, POST method can be used:\nPOST\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products/OData.CSC.FilterList\nRequest body:\n{\n  \"FilterProducts\":\n    [\n     {\"Name\": \"S1A_IW_GRDH_1SDV_20141031T161924_20141031T161949_003076_003856_634E.SAFE\"},\n     {\"Name\": \"S3B_SL_1_RBT____20190116T050535_20190116T050835_20190117T125958_0179_021_048_0000_LN2_O_NT_003.SEN3\"},\n     {\"Name\": \"xxxxxxxx.06.tar\"}\n    ]\n }\nTwo results are returned, as there is no product named xxxxxxxx.06.tar.\n\n\nQuery Collection of Products\nTo search for products within a specific collection:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:11:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:11:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n7e0f9557-d537-56bb-90a1-9b4a746f0f55\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XMQ_2...\napplication/octet-stream\n0\n2022-05-03T03:11:09.519Z\n2022-05-03T03:15:23.316Z\n2022-05-03T03:15:23.316Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-138.24152 80.05...\n{'type': 'Polygon', 'coordinates': [[[-138.241...\n\n\n1\napplication/octet-stream\n716d55e7-ee2a-5985-afed-4ca073864ca9\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XNQ_2...\napplication/octet-stream\n0\n2022-05-03T02:55:20.511Z\n2022-05-03T02:59:59.363Z\n2022-05-03T02:59:59.363Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-135.00116 81.06...\n{'type': 'Polygon', 'coordinates': [[[-135.001...\n\n\n2\napplication/octet-stream\n4ed5b9df-f559-51cf-8564-2f45e886d58a\nS2B_MSIL2A_20220503T000139_N0400_R016_T07XDK_2...\napplication/octet-stream\n0\n2022-05-03T02:58:50.682Z\n2022-05-03T03:02:27.353Z\n2022-05-03T03:02:27.353Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-140.45053 80.82...\n{'type': 'Polygon', 'coordinates': [[[-140.450...\n\n\n\n\n\n\n\n\n\n\nThe following collections are currently available:\n\nSENTINEL-1\nSENTINEL-2\nSENTINEL-3\nSENTINEL-5P\n\n\n\nQuery by Publication Date\nTo search for products published between two dates:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate gt 2019-05-15T00:00:00.000Z and PublicationDate lt 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate gt 2019-05-15T00:00:00.000Z and PublicationDate lt 2019-05-16T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nd04a4c2a-30e3-51a6-9706-d3dcf07a1ce6\nS3A_SL_1_RBT____20160429T140836_20160429T14113...\napplication/octet-stream\n0\n2019-03-20T18:25:19.702Z\n2019-05-15T00:01:01.985Z\n2019-05-15T00:01:01.985Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/29/S...\n[]\n{'Start': '2016-04-29T14:08:35.710Z', 'End': '...\ngeography'SRID=4326;POLYGON ((146.907 -55.5281...\n{'type': 'Polygon', 'coordinates': [[[146.907,...\n\n\n1\napplication/octet-stream\n989fd7a2-c67e-55be-ae63-5b911b600878\nS3A_SL_1_RBT____20160427T120458_20160427T12075...\napplication/octet-stream\n0\n2019-03-20T18:11:16.405Z\n2019-05-15T00:01:02.227Z\n2019-05-15T00:01:02.227Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/27/S...\n[]\n{'Start': '2016-04-27T12:04:58.305Z', 'End': '...\ngeography'SRID=4326;POLYGON ((153.039 33.665, ...\n{'type': 'Polygon', 'coordinates': [[[153.039,...\n\n\n2\napplication/octet-stream\nd34281f0-85bd-508a-a3fc-a9bb09d98f79\nS3A_SL_1_RBT____20160426T154708_20160426T15500...\napplication/octet-stream\n0\n2019-03-20T20:54:18.034Z\n2019-05-15T00:01:03.031Z\n2019-05-15T00:01:03.031Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/26/S...\n[]\n{'Start': '2016-04-26T15:47:07.654Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.745 12.6377, ...\n{'type': 'Polygon', 'coordinates': [[[99.745, ...\n\n\n\n\n\n\n\n\n\n\nTo define inclusive interval ge and le parameters can be used:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate ge 2019-05-15T00:00:00.000Z and PublicationDate le 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate ge 2019-05-15T00:00:00.000Z and PublicationDate le 2019-05-16T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nd04a4c2a-30e3-51a6-9706-d3dcf07a1ce6\nS3A_SL_1_RBT____20160429T140836_20160429T14113...\napplication/octet-stream\n0\n2019-03-20T18:25:19.702Z\n2019-05-15T00:01:01.985Z\n2019-05-15T00:01:01.985Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/29/S...\n[]\n{'Start': '2016-04-29T14:08:35.710Z', 'End': '...\ngeography'SRID=4326;POLYGON ((146.907 -55.5281...\n{'type': 'Polygon', 'coordinates': [[[146.907,...\n\n\n1\napplication/octet-stream\n989fd7a2-c67e-55be-ae63-5b911b600878\nS3A_SL_1_RBT____20160427T120458_20160427T12075...\napplication/octet-stream\n0\n2019-03-20T18:11:16.405Z\n2019-05-15T00:01:02.227Z\n2019-05-15T00:01:02.227Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/27/S...\n[]\n{'Start': '2016-04-27T12:04:58.305Z', 'End': '...\ngeography'SRID=4326;POLYGON ((153.039 33.665, ...\n{'type': 'Polygon', 'coordinates': [[[153.039,...\n\n\n2\napplication/octet-stream\nd34281f0-85bd-508a-a3fc-a9bb09d98f79\nS3A_SL_1_RBT____20160426T154708_20160426T15500...\napplication/octet-stream\n0\n2019-03-20T20:54:18.034Z\n2019-05-15T00:01:03.031Z\n2019-05-15T00:01:03.031Z\nTrue\n\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/04/26/S...\n[]\n{'Start': '2016-04-26T15:47:07.654Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.745 12.6377, ...\n{'type': 'Polygon', 'coordinates': [[[99.745, ...\n\n\n\n\n\n\n\n\n\n\n\n\nQuery by Sensing Date\nTo search for products acquired between two dates:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/Start lt 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/Start lt 2019-05-16T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nb76d70b2-7dd0-5b10-8727-a5979d828f57\nS1B_IW_RAW__0SDV_20190515T000001_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T04:38:19.893Z\n2019-05-15T04:45:10.989Z\n2019-05-15T04:45:10.989Z\nFalse\n\n/eodata/Sentinel-1/SAR/RAW/2019/05/15/S1B_IW_R...\n[]\n{'Start': '2019-05-15T00:00:01.539Z', 'End': '...\ngeography'SRID=4326;POLYGON ((95.0159 66.2881,...\n{'type': 'Polygon', 'coordinates': [[[95.0159,...\n\n\n1\napplication/octet-stream\n8bf7e312-2ea0-5288-abdb-01b1da9cc26b\nS1B_IW_SLC__1SDV_20190515T000004_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T00:00:04.000Z\n2019-05-15T05:39:50.376Z\n2019-05-15T05:39:50.376Z\nFalse\n\n/eodata/Sentinel-1/SAR/SLC/2019/05/15/S1B_IW_S...\n[]\n{'Start': '2019-05-15T00:00:04.536Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.446007 64.201...\n{'type': 'Polygon', 'coordinates': [[[99.44600...\n\n\n2\napplication/octet-stream\n4e4fddce-ad73-5b6c-94fc-04f721d96f94\nS1B_IW_GRDH_1SDV_20190515T000005_20190515T0000...\napplication/octet-stream\n0\n2019-05-15T04:57:32.023Z\n2019-05-15T05:10:44.189Z\n2019-05-15T05:10:44.189Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2019/05/15/S1B_IW_G...\n[]\n{'Start': '2019-05-15T00:00:05.238Z', 'End': '...\ngeography'SRID=4326;POLYGON ((99.487076 64.276...\n{'type': 'Polygon', 'coordinates': [[[99.48707...\n\n\n\n\n\n\n\n\n\n\nUsually, there are two parameters describing the ContentDate (Acquisition Dates) for a product - Start and End. Depending on what the user is looking for, these parameters can be mixed, e.g.,:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/End lt 2019-05-15T00:05:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/End lt 2019-05-15T00:05:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n7a73feba-1e23-505f-ac78-6207c4675c57\nS3A_SY_2_SYN____20190515T000114_20190515T00041...\napplication/octet-stream\n0\n2019-05-16T11:37:52.511Z\n2019-05-16T11:41:57.277Z\n2019-05-16T11:41:57.277Z\nTrue\n\n/eodata/Sentinel-3/SYNERGY/SY_2_SYN___/2019/05...\n[]\n{'Start': '2019-05-15T00:01:13.802Z', 'End': '...\ngeography'SRID=4326;POLYGON ((141.591 10.4037,...\n{'type': 'Polygon', 'coordinates': [[[141.591,...\n\n\n1\napplication/octet-stream\n937995e4-d37b-5c5c-bedc-531e5266f90e\nS3A_OL_1_EFR____20190515T000114_20190515T00041...\napplication/octet-stream\n0\n2019-05-16T03:51:27.421Z\n2019-05-16T03:59:41.341Z\n2019-05-16T03:59:41.341Z\nTrue\n\n/eodata/Sentinel-3/OLCI/OL_1_EFR/2019/05/15/S3...\n[]\n{'Start': '2019-05-15T00:01:13.801Z', 'End': '...\ngeography'SRID=4326;POLYGON ((141.591 10.4037,...\n{'type': 'Polygon', 'coordinates': [[[141.591,...\n\n\n2\napplication/octet-stream\n2e7d9c5d-e088-5248-80be-0c8453ce6556\nS3A_OL_2_WFR____20190515T000114_20190515T00041...\napplication/octet-stream\n0\n2019-05-16T10:54:52.642Z\n2019-05-16T10:59:49.013Z\n2019-05-16T10:59:49.013Z\nTrue\n\n/eodata/Sentinel-3/OLCI/OL_2_WFR/2019/05/15/S3...\n[]\n{'Start': '2019-05-15T00:01:13.801Z', 'End': '...\ngeography'SRID=4326;POLYGON ((141.591 10.4037,...\n{'type': 'Polygon', 'coordinates': [[[141.591,...\n\n\n\n\n\n\n\n\n\n\n\n\nQuery by Geographic Criteria\nTo search for products intersecting the specified polygon:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((12.655118166047592 47.44667197521409,21.39065656328509 48.347694733853245,28.334291357162826 41.877123516783655,17.47086198383573 40.35854475076158,12.655118166047592 47.44667197521409))') and ContentDate/Start gt 2022-05-20T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((12.655118166047592 47.44667197521409,21.39065656328509 48.347694733853245,28.334291357162826 41.877123516783655,17.47086198383573 40.35854475076158,12.655118166047592 47.44667197521409))') and ContentDate/Start gt 2022-05-20T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n8fc3f946-f617-5536-ba3a-1363547cbb04\nS2B_MSIL2A_20220520T100029_N0400_R122_T33UXP_2...\napplication/octet-stream\n0\n2022-05-20T16:14:30.866Z\n2022-05-20T16:20:08.549Z\n2022-05-20T16:20:08.549Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/20/S2B_MSIL...\n[]\n{'Start': '2022-05-20T10:00:29.025Z', 'End': '...\ngeography'SRID=4326;POLYGON ((17.629592462837 ...\n{'type': 'Polygon', 'coordinates': [[[17.62959...\n\n\n1\napplication/octet-stream\n0d3b8cf1-01fb-5f7e-820a-1d5442875575\nLC08_L1TP_180031_20220520_20220520_02_RT\napplication/octet-stream\n0\n2022-05-20T08:45:20.510Z\n2022-05-22T08:08:13.816Z\n2022-05-22T08:08:13.816Z\nTrue\n\n/eodata/Landsat-8/OLI_TIRS/L1TP/2022/05/20/LC0...\n[]\n{'Start': '2022-05-20T08:45:20.510Z', 'End': '...\ngeography'SRID=4326;POLYGON ((27.73522 42.821,...\n{'type': 'Polygon', 'coordinates': [[[27.73522...\n\n\n2\napplication/octet-stream\nd3b5fbd9-9ffd-579b-b327-4de3e8502591\nLC08_L2SP_180031_20220520_20220525_02_T1\napplication/octet-stream\n0\n2022-05-20T08:45:20.510Z\n2022-05-27T12:43:58.553Z\n2022-05-27T12:43:58.553Z\nTrue\n\n/eodata/Landsat-8/OLI_TIRS/L2SP/2022/05/20/LC0...\n[]\n{'Start': '2022-05-20T08:45:20.510Z', 'End': '...\ngeography'SRID=4326;POLYGON ((27.73522 42.821,...\n{'type': 'Polygon', 'coordinates': [[[27.73522...\n\n\n\n\n\n\n\n\n\n\nTo search for products intersecting the specified point:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography%27SRID=4326;POINT(-0.5319577002158441%2028.65487836189358)%27)\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography%27SRID=4326;POINT(-0.5319577002158441%2028.65487836189358)%27)\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n57b778d5-1caa-5731-a0d8-c08ec2881f3a\nLS05_RFUI_TM__GTC_1P_19841212T100352_19841212T...\napplication/octet-stream\n0\n2018-04-01T00:00:00.000Z\n2016-07-09T19:59:41.312Z\n2016-07-09T19:59:41.312Z\nTrue\n\n/eodata/Landsat-5/TM/L1T/1984/12/12/LS05_RFUI_...\n[]\n{'Start': '1984-12-12T10:04:06.279Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-1.9295636 29.80...\n{'type': 'Polygon', 'coordinates': [[[-1.92956...\n\n\n1\napplication/octet-stream\n8a7038bd-5726-5a01-a525-03c120a5f576\nLS05_RFUI_TM__GTC_1P_19841228T100400_19841228T...\napplication/octet-stream\n0\n2018-04-01T00:00:00.000Z\n2016-07-09T20:07:49.021Z\n2016-07-09T20:07:49.021Z\nTrue\n\n/eodata/Landsat-5/TM/L1T/1984/12/28/LS05_RFUI_...\n[]\n{'Start': '1984-12-28T10:04:15.198Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-1.9485325 29.80...\n{'type': 'Polygon', 'coordinates': [[[-1.94853...\n\n\n2\napplication/octet-stream\n0a1b561c-9e68-52db-977c-95a2c1894d40\nLS05_RFUI_TM__GTC_1P_19841110T100341_19841110T...\napplication/octet-stream\n0\n2018-04-01T00:00:00.000Z\n2016-07-09T20:20:01.402Z\n2016-07-09T20:20:01.402Z\nTrue\n\n/eodata/Landsat-5/TM/L1T/1984/11/10/LS05_RFUI_...\n[]\n{'Start': '1984-11-10T10:03:56.077Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-1.9362267 29.80...\n{'type': 'Polygon', 'coordinates': [[[-1.93622...\n\n\n\n\n\n\n\n\n\n\nDisclaimers:\n\nMULTIPOLYGON is currently not supported.\nPolygon must start and end with the same point.\nCoordinates must be given in EPSG 4326\n\n\n\nQuery by attributes\nTo search for products by attributes it is necessary to build a filter with the following structure:\nAttributes/OData.CSC.ValueTypeAttribute/any(att:att/Name eq ‘[Attribute.Name]’ and att/OData.CSC.ValueTypeAttribute/Value eq ‘[Attribute.Value]’)\nwhere\n\nValueTypeAttribute can take the following values:\n\nStringAttribute\nDoubleAttribute\nIntegerAttribute\nDateTimeOffsetAttribute\n\n[Attribute.Name] is the attribute name which can take multiple values, depending on collection (Attachment 1 - Coming soon)\neq before [Attribute.Value] can be substituted with le, lt, ge, gt in case of Integer, Double or DateTimeOffset Attributes\n[Attribute.Value] is the specific value that the user is searching for\n\nTo get products with CloudCover&lt;40% between two dates:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 40.00) and ContentDate/Start gt 2022-01-01T00:00:00.000Z and ContentDate/Start lt 2022-01-03T00:00:00.000Z&$top=10\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 40.00) and ContentDate/Start gt 2022-01-01T00:00:00.000Z and ContentDate/Start lt 2022-01-03T00:00:00.000Z&$top=10\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n3d0f3447-4b75-5115-8132-7047eab6ca22\nS2B_MSIL1C_20220101T000459_N0301_R130_T48CWU_2...\napplication/octet-stream\n0\n2022-01-01T01:45:48.687Z\n2022-01-01T01:47:21.168Z\n2022-01-01T01:47:21.168Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/01/01/S2B_MSIL...\n[]\n{'Start': '2022-01-01T00:04:59.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((109.65985459329 ...\n{'type': 'Polygon', 'coordinates': [[[109.6598...\n\n\n1\napplication/octet-stream\n13bf9e1e-e9e2-52fb-9274-5430131d3099\nS2B_MSIL1C_20220101T000459_N0301_R130_T52DDF_2...\napplication/octet-stream\n0\n2022-01-01T01:46:51.240Z\n2022-01-01T01:52:04.545Z\n2022-01-01T01:52:04.545Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/01/01/S2B_MSIL...\n[]\n{'Start': '2022-01-01T00:04:59.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((126.22039161156 ...\n{'type': 'Polygon', 'coordinates': [[[126.2203...\n\n\n2\napplication/octet-stream\n28c4740a-fffd-5646-8136-c7891cead3e8\nS2B_MSIL1C_20220101T000459_N0301_R130_T51DXB_2...\napplication/octet-stream\n0\n2022-01-01T01:50:34.918Z\n2022-01-01T01:52:04.235Z\n2022-01-01T01:52:04.235Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/01/01/S2B_MSIL...\n[]\n{'Start': '2022-01-01T00:04:59.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((125.71557922201 ...\n{'type': 'Polygon', 'coordinates': [[[125.7155...\n\n\n\n\n\n\n\n\n\n\nTo get products with cloudCover&lt; 10% and productType=S2MSI2A and ASCENDING orbitDirection between two dates:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value lt 10.00) and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'orbitDirection' and att/OData.CSC.StringAttribute/Value eq 'ASCENDING') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T04:00:00.000Z&$top=10\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value lt 10.00) and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'orbitDirection' and att/OData.CSC.StringAttribute/Value eq 'ASCENDING') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T04:00:00.000Z&$top=10\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n7e0f9557-d537-56bb-90a1-9b4a746f0f55\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XMQ_2...\napplication/octet-stream\n0\n2022-05-03T03:11:09.519Z\n2022-05-03T03:15:23.316Z\n2022-05-03T03:15:23.316Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-138.24152 80.05...\n{'type': 'Polygon', 'coordinates': [[[-138.241...\n\n\n1\napplication/octet-stream\n716d55e7-ee2a-5985-afed-4ca073864ca9\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XNQ_2...\napplication/octet-stream\n0\n2022-05-03T02:55:20.511Z\n2022-05-03T02:59:59.363Z\n2022-05-03T02:59:59.363Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-135.00116 81.06...\n{'type': 'Polygon', 'coordinates': [[[-135.001...\n\n\n2\napplication/octet-stream\n2b9fe2f4-b9d3-5a5d-99b9-96a1ed74ad8a\nS2B_MSIL2A_20220503T000139_N0400_R016_T09XWK_2...\napplication/octet-stream\n0\n2022-05-03T02:57:10.940Z\n2022-05-03T03:01:57.496Z\n2022-05-03T03:01:57.496Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n[]\n{'Start': '2022-05-03T00:01:39.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-129.00116 81.06...\n{'type': 'Polygon', 'coordinates': [[[-129.001...\n\n\n\n\n\n\n\n\n\n\n\n\nOrderby option\nOrderby option can be used to order the products in an ascending (asc) or descending (desc) direction. If asc or desc not specified, then the resources will be ordered in ascending order.\nTo order products by ContentDate/Start in a descending direction:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A_EW_GRD') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T03:00:00.000Z&$orderby=ContentDate/Start desc\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A_EW_GRD') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T03:00:00.000Z&$orderby=ContentDate/Start desc\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n6928b379-4f9a-5473-a12a-7e7e4b83f776\nS1A_EW_GRDM_1SSH_20220503T024410_20220503T0244...\napplication/octet-stream\n0\n2022-05-03T04:06:31.762Z\n2022-05-03T04:11:15.919Z\n2022-05-03T04:11:15.919Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T02:44:10.981Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-105.464699 -67....\n{'type': 'Polygon', 'coordinates': [[[-105.464...\n\n\n1\napplication/octet-stream\n9b4e3124-fa8e-4ea7-b43e-d5f08297ea8c\nS1A_EW_GRDM_1SSH_20220503T024410_20220503T0244...\napplication/octet-stream\n78609172\n2023-05-20T19:44:03.068Z\n2023-05-20T21:45:18.079Z\n2023-05-20T21:45:18.079Z\nTrue\n\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n[{}]\n{'Start': '2022-05-03T02:44:10.981Z', 'End': '...\ngeography'SRID=4326;MULTIPOLYGON (((-103.09848...\n{'type': 'MultiPolygon', 'coordinates': [[[[-1...\n\n\n2\napplication/octet-stream\n2abd9bf9-7a35-4916-8bf5-34727d71da1b\nS1A_EW_GRDM_1SSH_20220503T024310_20220503T0244...\napplication/octet-stream\n164573262\n2023-05-20T19:46:01.279Z\n2023-05-20T21:47:32.929Z\n2023-05-20T21:47:32.929Z\nTrue\n\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n[{}]\n{'Start': '2022-05-03T02:43:10.982Z', 'End': '...\ngeography'SRID=4326;MULTIPOLYGON (((-97.269363...\n{'type': 'MultiPolygon', 'coordinates': [[[[-9...\n\n\n\n\n\n\n\n\n\n\nBy default, if orderby option is not used, the results are not ordered. If orderby option is used, additional orderby by id is also used, so that the results are fully ordered and no products are lost while paginating through the results.\nThe acceptable arguments for this option: ContentDate/Start, ContentDate/End, PublicationDate, ModificationDate, in directions: asc, desc.\n\n\nTop option\nTop option specifies the maximum number of items returned from a query.\nTo limit the number of results:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$top=100\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$top=100\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nfe37ae5f-153b-511c-89b9-dcc059c86489\nS1A_EW_GRDM_1SDH_20220503T033034_20220503T0331...\napplication/octet-stream\n0\n2022-05-03T04:04:31.386Z\n2022-05-03T04:09:06.656Z\n2022-05-03T04:09:06.656Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:30:34.272Z', 'End': '...\ngeography'SRID=4326;POLYGON ((64.757805 76.819...\n{'type': 'Polygon', 'coordinates': [[[64.75780...\n\n\n1\napplication/octet-stream\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\napplication/octet-stream\n0\n2022-05-03T06:04:33.053Z\n2022-05-03T06:09:16.561Z\n2022-05-03T06:09:16.561Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T05:10:20.362Z', 'End': '...\ngeography'SRID=4326;POLYGON ((34.926594 74.394...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n\n\n2\napplication/octet-stream\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\napplication/octet-stream\n0\n2022-05-03T08:54:32.861Z\n2022-05-03T08:59:36.441Z\n2022-05-03T08:59:36.441Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T06:48:00.855Z', 'End': '...\ngeography'SRID=4326;POLYGON ((15.664783 76.959...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n\n\n\n\n\n\n\n\n\n\nThe default value is set to 20.\nThe acceptable arguments for this option: Integer &lt;0,1000&gt;"
  },
  {
    "objectID": "APIs/OData.html#skip-option",
    "href": "APIs/OData.html#skip-option",
    "title": "OData",
    "section": "Skip option",
    "text": "Skip option\nSkip option can be used to skip a specific number of results. Exemplary application of this option would be paginating through the results, however for performance reasons, we recommend limiting queries with small time intervals as a substitute of using skip in a more generic query.\nTo skip a specific number of results:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$skip=23\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$skip=23\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n47921038-e7ca-56d0-9a9a-7192dec36de0\nS1A_EW_GRDM_1SDH_20220503T114448_20220503T1145...\napplication/octet-stream\n0\n2022-05-03T13:00:31.219Z\n2022-05-03T13:07:21.059Z\n2022-05-03T13:07:21.059Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T11:44:48.791Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-62.467339 75.12...\n{'type': 'Polygon', 'coordinates': [[[-62.4673...\n\n\n1\napplication/octet-stream\n35d932b2-715f-521b-9dbe-612d6edc4d1c\nS1A_EW_GRDM_1SDH_20220503T033138_20220503T0332...\napplication/octet-stream\n0\n2022-05-03T04:05:38.338Z\n2022-05-03T04:08:53.810Z\n2022-05-03T04:08:53.810Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:31:38.586Z', 'End': '...\ngeography'SRID=4326;POLYGON ((58.356129 73.551...\n{'type': 'Polygon', 'coordinates': [[[58.35612...\n\n\n2\napplication/octet-stream\n81738432-1e5c-5419-9be9-4aada9160f7c\nS1A_EW_GRDM_1SDH_20220503T033338_20220503T0334...\napplication/octet-stream\n0\n2022-05-03T04:05:37.842Z\n2022-05-03T04:09:03.216Z\n2022-05-03T04:09:03.216Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:33:38.585Z', 'End': '...\ngeography'SRID=4326;POLYGON ((50.733326 66.705...\n{'type': 'Polygon', 'coordinates': [[[50.73332...\n\n\n\n\n\n\n\n\n\n\nThe default value is set to 0.\nWhenever a query results in more products than 20 (default top value), the API provides a nextLink at the bottom of the page:\n\"@OData.nextLink\":\n\nHTTP RequestPython\n\n\nhttp://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A_EW_GRD')+and+ContentDate/Start+gt+2022-05-03T00:00:00.000Z+and+ContentDate/Start+lt+2022-05-03T12:00:00.000Z&$skip=20\n\n\n\n\nCode\njson = requests.get(\"http://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A_EW_GRD')+and+ContentDate/Start+gt+2022-05-03T00:00:00.000Z+and+ContentDate/Start+lt+2022-05-03T12:00:00.000Z&$skip=20\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n01f4c791-29d8-528b-8d91-3de9b76c2f28\nS1A_EW_GRDM_1SDH_20220503T091826_20220503T0919...\napplication/octet-stream\n0\n2022-05-03T11:35:04.805Z\n2022-05-03T11:35:00.340Z\n2022-05-03T11:35:00.340Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T09:18:26.004Z', 'End': '...\ngeography'SRID=4326;POLYGON ((156.800079 -67.9...\n{'type': 'Polygon', 'coordinates': [[[156.8000...\n\n\n1\napplication/octet-stream\na46c4820-96f4-55f7-9ee0-bb897597ad20\nS1A_EW_GRDM_1SDH_20220503T115007_20220503T1150...\napplication/octet-stream\n0\n2022-05-03T12:54:33.343Z\n2022-05-03T12:58:57.926Z\n2022-05-03T12:58:57.926Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T11:50:07.829Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-77.549103 59.06...\n{'type': 'Polygon', 'coordinates': [[[-77.5491...\n\n\n2\napplication/octet-stream\nbf7bec9a-3b52-5923-933c-6167eeae8f23\nS1A_EW_GRDM_1SDH_20220503T114553_20220503T1147...\napplication/octet-stream\n0\n2022-05-03T13:05:39.033Z\n2022-05-03T13:06:05.763Z\n2022-05-03T13:06:05.763Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T11:45:53.092Z', 'End': '...\ngeography'SRID=4326;POLYGON ((-68.278107 71.26...\n{'type': 'Polygon', 'coordinates': [[[-68.2781...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: Integer &lt;0,10000&gt;"
  },
  {
    "objectID": "APIs/OData.html#count-option",
    "href": "APIs/OData.html#count-option",
    "title": "OData",
    "section": "Count option",
    "text": "Count option\nCount option enables users to get the exact number of products matching the query. This option is disabled by default to accelerate the query performance.\nTo get the exact number of products for a given query:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$count=True\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$count=True\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nfe37ae5f-153b-511c-89b9-dcc059c86489\nS1A_EW_GRDM_1SDH_20220503T033034_20220503T0331...\napplication/octet-stream\n0\n2022-05-03T04:04:31.386Z\n2022-05-03T04:09:06.656Z\n2022-05-03T04:09:06.656Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:30:34.272Z', 'End': '...\ngeography'SRID=4326;POLYGON ((64.757805 76.819...\n{'type': 'Polygon', 'coordinates': [[[64.75780...\n\n\n1\napplication/octet-stream\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\napplication/octet-stream\n0\n2022-05-03T06:04:33.053Z\n2022-05-03T06:09:16.561Z\n2022-05-03T06:09:16.561Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T05:10:20.362Z', 'End': '...\ngeography'SRID=4326;POLYGON ((34.926594 74.394...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n\n\n2\napplication/octet-stream\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\napplication/octet-stream\n0\n2022-05-03T08:54:32.861Z\n2022-05-03T08:59:36.441Z\n2022-05-03T08:59:36.441Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T06:48:00.855Z', 'End': '...\ngeography'SRID=4326;POLYGON ((15.664783 76.959...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: True, true, 1, False, false, 0."
  },
  {
    "objectID": "APIs/OData.html#expand-option",
    "href": "APIs/OData.html#expand-option",
    "title": "OData",
    "section": "Expand option",
    "text": "Expand option\nExpand option enables users to see full metadata of each returned result.\nTo see the metadata of the results:\n\nHTTP RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$expand=Attributes\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$expand=Attributes\").json()\npd.DataFrame.from_dict(json['value']).head(3)\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\nAttributes\n\n\n\n\n0\napplication/octet-stream\nfe37ae5f-153b-511c-89b9-dcc059c86489\nS1A_EW_GRDM_1SDH_20220503T033034_20220503T0331...\napplication/octet-stream\n0\n2022-05-03T04:04:31.386Z\n2022-05-03T04:09:06.656Z\n2022-05-03T04:09:06.656Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T03:30:34.272Z', 'End': '...\ngeography'SRID=4326;POLYGON ((64.757805 76.819...\n{'type': 'Polygon', 'coordinates': [[[64.75780...\n[{'@odata.type': '#OData.CSC.StringAttribute',...\n\n\n1\napplication/octet-stream\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\napplication/octet-stream\n0\n2022-05-03T06:04:33.053Z\n2022-05-03T06:09:16.561Z\n2022-05-03T06:09:16.561Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T05:10:20.362Z', 'End': '...\ngeography'SRID=4326;POLYGON ((34.926594 74.394...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n[{'@odata.type': '#OData.CSC.StringAttribute',...\n\n\n2\napplication/octet-stream\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\napplication/octet-stream\n0\n2022-05-03T08:54:32.861Z\n2022-05-03T08:59:36.441Z\n2022-05-03T08:59:36.441Z\nTrue\n\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n[]\n{'Start': '2022-05-03T06:48:00.855Z', 'End': '...\ngeography'SRID=4326;POLYGON ((15.664783 76.959...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n[{'@odata.type': '#OData.CSC.StringAttribute',...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: Attributes"
  },
  {
    "objectID": "APIs/OData.html#product-download",
    "href": "APIs/OData.html#product-download",
    "title": "OData",
    "section": "Product Download",
    "text": "Product Download\nFor downloading products you need an authorization token as only authorized users are allowed to download data products.\nTo get the token you can use the following scripts:\n\ncURL\n\n\ncurl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n  --header 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'grant_type=password' \\\n  --data-urlencode 'username=&lt;LOGIN&gt;' \\\n  --data-urlencode 'password=&lt;PASSWORD&gt;' \\\n  --data-urlencode 'client_id=cdse-public'\n\n\n\nor \n\ncURL\n\n\ncurl -d 'client_id=cdse-public' -d 'username=&lt;LOGIN&gt;' -d 'password=&lt;PASSWORD&gt;' -d 'grant_type=password' 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | python -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}'\n\n\n\nAlong with the Access Token you will be returned a Refresh Token, the latter is used to generate a new Access Token without the need to specify Username or Password, this helps to make requests less vulnerable to your credentials being exposed.\nTo re-generate the Access Token from the Refresh Token it can be done with the following request:\n\ncURL\n\n\ncurl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n  --header 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'grant_type=refresh_token' \\\n  --data-urlencode 'refresh_token=&lt;REFRESH_TOKEN&gt;' \\\n  --data-urlencode 'client_id=cdse-public'\n\n\n\n\n\nOnce you have your token, you require a product Id which can be found in the response of the products search: https://catalogue.dataspace.copernicus.eu/odata/v1/Products\nFinally, you can download the product using this script:\n\ncURL\n\n\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" 'https://catalogue.dataspace.copernicus.eu/odata/v1/Products(060882f4-0a34-5f14-8e25-6876e4470b0d)/$value' --location-trusted --output /tmp/product.zip\n\n\n\nor\n\nWget\n\n\n!wget  --header \"Authorization: Bearer $KEYCLOAK_TOKEN\" 'http://catalogue.dataspace.copernicus.eu/odata/v1/Products(db0c8ef3-8ec0-5185-a537-812dad3c58f8)/$value' -O example_odata.zip\n\n\n\n\nPython\n\n\nimport requests\nsession = requests.Session()\nsession.headers.update({'Authorization': 'Bearer KEYCLOAK_TOKEN'})\nurl = f\"http://catalogue.dataspace.copernicus.eu/odata/v1/Products(db0c8ef3-8ec0-5185-a537-812dad3c58f8)/$value\"\nresponse = session.get(url, allow_redirects=False)\nwhile response.status_code in (301, 302, 303, 307):\n    url = response.headers['Location']\n    response = session.get(url, allow_redirects=False)\n\nfile = session.get(url, verify=False, allow_redirects=True)\n\nwith open(f\"product.zip\", 'wb') as p:\n    p.write(file.content)"
  },
  {
    "objectID": "Data/Sentinel3.html",
    "href": "Data/Sentinel3.html",
    "title": "Sentinel-3",
    "section": "",
    "text": "The main objective of theCopernicus Sentinel-3 mission is to measure ocean and land surface colour, sea and land surface temperature, and sea surface topography with high accuracy and reliability to support ocean forecasting systems, environmental monitoring and climate monitoring. The mission definition is driven by the need for continuity in provision of ERS, ENVISAT and SPOT vegetation data, with improvements in instrument performance and coverage.\nSentinel-3 OLCI Level 1\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level 1 products provides calibrated, geolocated, and orthorectified data from the Ocean and Land Colour Instrument (OLCI). These products are delivered not later than 1 month (commitment) after acquisition or from long-term archives.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nOa01\n\n\nAerosol correction\n\n\n300\n\n\n0.4000\n\n\n\n\nOa02\n\n\nYellow substance and detrital pigments (turbidity)\n\n\n300\n\n\n0.4125\n\n\n\n\nOa03\n\n\nChlorophyll absorption maximum\n\n\n300\n\n\n0.4425\n\n\n\n\nOa04\n\n\nChlorophyll\n\n\n300\n\n\n0.4900\n\n\n\n\nOa05\n\n\nChlorophyll\n\n\n300\n\n\n0.5100\n\n\n\n\nOa06\n\n\nChlorophyll reference (minimum)\n\n\n300\n\n\n0.5600\n\n\n\n\nOa07\n\n\nSediment loading\n\n\n300\n\n\n0.6200\n\n\n\n\nOa08\n\n\n2nd Chlorophyll absorption maximum\n\n\n300\n\n\n0.6650\n\n\n\n\nOa09\n\n\nImproved fluorescence retrieval\n\n\n300\n\n\n0.6737\n\n\n\n\nOa010\n\n\nChlorophyll fluorescence peak\n\n\n300\n\n\n0.6813\n\n\n\n\nOa11\n\n\nChlorophyll fluorescence baseline\n\n\n300\n\n\n0.7087\n\n\n\n\nOa12\n\n\nO2 absorption / clouds\n\n\n300\n\n\n0.7538\n\n\n\n\nOa16\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.7788\n\n\n\n\nOa17\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.8650\n\n\n\n\nOa18\n\n\nWater vapour absorption\n\n\n300\n\n\n0.8850\n\n\n\n\nOa19\n\n\nWater vapour absorption\n\n\n300\n\n\n0.9000\n\n\n\n\nOa21\n\n\nWater vapour absorption\n\n\n300\n\n\n1.0200\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 OLCI Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level-2 product provides geophysical data that is derived from the Level-1 product. These products contains retrieved geophysical parameters, such as chlorophyll-a concentration, total suspended matter, and inherent optical properties of water.The Level-2 product also includes data quality flags that provide information on the reliability of the geophysical parameters, as well as information on the atmospheric correction applied to the data. These flags can be used to filter out data that is not of sufficient quality for a particular application.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json\n\n\n\n\n\n\n\n\nSentinel-3 OLCI Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level 0 is the reconstructed and time-sorted Instrument Source Packet (ISP) at full space-time resolution. The first part of the process involves unpacking the ISPs, performing a quality check and appending annotation data to them. Once the input raw data files are read, all necessary data are extracted and parsed. The ISPs are then sorted and checked, including missing and duplicated packet numbering. The final part of the processing is the Level-0 product generation. Several quality flags are computed and included in the associated metadata. Raw data, time sorted and annotated are included in the Level-0 package.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Feb 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nOa01\n\n\nAerosol correction\n\n\n300\n\n\n0.4000\n\n\n\n\nOa02\n\n\nYellow substance and detrital pigments (turbidity)\n\n\n300\n\n\n0.4125\n\n\n\n\nOa03\n\n\nChlorophyll absorption maximum\n\n\n300\n\n\n0.4425\n\n\n\n\nOa04\n\n\nChlorophyll\n\n\n300\n\n\n0.4900\n\n\n\n\nOa05\n\n\nChlorophyll\n\n\n300\n\n\n0.5100\n\n\n\n\nOa06\n\n\nChlorophyll reference (minimum)\n\n\n300\n\n\n0.5600\n\n\n\n\nOa07\n\n\nSediment loading\n\n\n300\n\n\n0.6200\n\n\n\n\nOa08\n\n\n2nd Chlorophyll absorption maximum\n\n\n300\n\n\n0.6650\n\n\n\n\nOa09\n\n\nImproved fluorescence retrieval\n\n\n300\n\n\n0.6737\n\n\n\n\nOa010\n\n\nChlorophyll fluorescence peak\n\n\n300\n\n\n0.6813\n\n\n\n\nOa11\n\n\nChlorophyll fluorescence baseline\n\n\n300\n\n\n0.7087\n\n\n\n\nOa12\n\n\nO2 absorption / clouds\n\n\n300\n\n\n0.7538\n\n\n\n\nOa16\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.7788\n\n\n\n\nOa17\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.8650\n\n\n\n\nOa18\n\n\nWater vapour absorption\n\n\n300\n\n\n0.8850\n\n\n\n\nOa19\n\n\nWater vapour absorption\n\n\n300\n\n\n0.9000\n\n\n\n\nOa21\n\n\nWater vapour absorption\n\n\n300\n\n\n1.0200\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 SLSTR Level 1\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level-1 product provides a valuable source of processed and calibrated data that is suitable for a wide range of applications. The product includes key parameters and data quality flags that provide important information on the reliability and accuracy of the data, and the product is generated offline with a delay of a few days after the acquisition of the Level-0 data.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543\n\n\n\n\nS2\n\n\nVegetation monitoring\n\n\n500\n\n\n0.6595\n\n\n\n\nS3\n\n\nNDVI, cloud flagging\n\n\n500\n\n\n0.8680\n\n\n\n\nS4\n\n\nCirrus detection over land\n\n\n500\n\n\n1.3748\n\n\n\n\nS5\n\n\nCloud clearing\n\n\n500\n\n\n1.6134\n\n\n\n\nS6\n\n\nVegetation state and cloud clearing\n\n\n500\n\n\n2.2557\n\n\n\n\nS7\n\n\nSST, LST, Active fire\n\n\n500\n\n\n3.7420\n\n\n\n\nS8\n\n\nSST, LST, Active fire\n\n\n500\n\n\n10.8540\n\n\n\n\nS9\n\n\nSST, LST\n\n\n1000\n\n\n12.0225\n\n\n\n\nF1\n\n\nActive fire\n\n\n500\n\n\n3.7420\n\n\n\n\nF2\n\n\nActive fire\n\n\n1000\n\n\n3.9400\n\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json\n\n\n\n\n\n\n\n\nSentinel-3 SLSTR Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level-2 product provides higher-level geophysical parameters, but with a longer processing time and coarser spatial resolution compared to the Level-1 product. The product also includes additional data quality flags to provide more information on the reliability and accuracy of the data.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 SLSTR Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level 0 product is the raw unprocessed data acquired by the SLSTR instrument on board the Sentinel-3 satellite. It consists of the uncalibrated digital counts received by the SLSTR detectors for each pixel in the image. It provides a valuable source of unprocessed data for researchers and advanced users who require access to the raw data for their applications.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Feb 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543\n\n\n\n\nS2\n\n\nVegetation monitoring\n\n\n500\n\n\n0.6595\n\n\n\n\nS3\n\n\nNDVI, cloud flagging\n\n\n500\n\n\n0.8680\n\n\n\n\nS4\n\n\nCirrus detection over land\n\n\n500\n\n\n1.3748\n\n\n\n\nS5\n\n\nCloud clearing\n\n\n500\n\n\n1.6134\n\n\n\n\nS6\n\n\nVegetation state and cloud clearing\n\n\n500\n\n\n2.2557\n\n\n\n\nS7\n\n\nSST, LST, Active fire\n\n\n500\n\n\n3.7420\n\n\n\n\nS8\n\n\nSST, LST, Active fire\n\n\n500\n\n\n10.8540\n\n\n\n\nS9\n\n\nSST, LST\n\n\n1000\n\n\n12.0225\n\n\n\n\nF1\n\n\nActive fire\n\n\n500\n\n\n3.7420\n\n\n\n\nF2\n\n\nActive fire\n\n\n1000\n\n\n3.9400\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 SYN Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SYN Level 2 product is a higher-level processed product that contains information about the Earth’s atmosphere and its constituents. It is derived from the Level-1 and Level-2 products of the OLCI and SLSTR instruments on board the Sentinel-3 satellite.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 SRAL Level 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SRAL Level-1 product provides corrected and validated geophysical parameters derived from the raw SRAL Level-0 data, along with metadata and data quality flags that enable the user to assess the reliability and suitability of the data for specific applications.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 SRAL Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SRAL Level-2 product is a higher-level processed product that contains more detailed and refined geophysical parameters suitable for scientific and research applications. It contains advanced geophysical parameters such as sea surface height, significant wave height, and wind speed, that are derived from the SRAL Level-1 products using advanced processing algorithms and quality control procedures.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 SRAL Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 Synthetic Aperture Radar Altimeter (SRAL) Level-0 product contains raw data acquired by the SRAL instrument onboard the Sentinel-3 satellite. The data contains raw, time-tagged radar echoes and instrument housekeeping data, along with metadata describing the acquisition parameters and instrument characteristics.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Feb 2016 - Present’]"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-olci-level-1",
    "href": "Data/Sentinel3.html#sentinel-3-olci-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI Level 1",
    "text": "Sentinel-3 OLCI Level 1\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level 1 products provides calibrated, geolocated, and orthorectified data from the Ocean and Land Colour Instrument (OLCI). These products are delivered not later than 1 month (commitment) after acquisition or from long-term archives.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nOa01\n\n\nAerosol correction\n\n\n300\n\n\n0.4000\n\n\n\n\nOa02\n\n\nYellow substance and detrital pigments (turbidity)\n\n\n300\n\n\n0.4125\n\n\n\n\nOa03\n\n\nChlorophyll absorption maximum\n\n\n300\n\n\n0.4425\n\n\n\n\nOa04\n\n\nChlorophyll\n\n\n300\n\n\n0.4900\n\n\n\n\nOa05\n\n\nChlorophyll\n\n\n300\n\n\n0.5100\n\n\n\n\nOa06\n\n\nChlorophyll reference (minimum)\n\n\n300\n\n\n0.5600\n\n\n\n\nOa07\n\n\nSediment loading\n\n\n300\n\n\n0.6200\n\n\n\n\nOa08\n\n\n2nd Chlorophyll absorption maximum\n\n\n300\n\n\n0.6650\n\n\n\n\nOa09\n\n\nImproved fluorescence retrieval\n\n\n300\n\n\n0.6737\n\n\n\n\nOa010\n\n\nChlorophyll fluorescence peak\n\n\n300\n\n\n0.6813\n\n\n\n\nOa11\n\n\nChlorophyll fluorescence baseline\n\n\n300\n\n\n0.7087\n\n\n\n\nOa12\n\n\nO2 absorption / clouds\n\n\n300\n\n\n0.7538\n\n\n\n\nOa16\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.7788\n\n\n\n\nOa17\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.8650\n\n\n\n\nOa18\n\n\nWater vapour absorption\n\n\n300\n\n\n0.8850\n\n\n\n\nOa19\n\n\nWater vapour absorption\n\n\n300\n\n\n0.9000\n\n\n\n\nOa21\n\n\nWater vapour absorption\n\n\n300\n\n\n1.0200"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-olci-level-2",
    "href": "Data/Sentinel3.html#sentinel-3-olci-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI Level 2",
    "text": "Sentinel-3 OLCI Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level-2 product provides geophysical data that is derived from the Level-1 product. These products contains retrieved geophysical parameters, such as chlorophyll-a concentration, total suspended matter, and inherent optical properties of water.The Level-2 product also includes data quality flags that provide information on the reliability of the geophysical parameters, as well as information on the atmospheric correction applied to the data. These flags can be used to filter out data that is not of sufficient quality for a particular application.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-olci-level-0",
    "href": "Data/Sentinel3.html#sentinel-3-olci-level-0",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI Level 0",
    "text": "Sentinel-3 OLCI Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level 0 is the reconstructed and time-sorted Instrument Source Packet (ISP) at full space-time resolution. The first part of the process involves unpacking the ISPs, performing a quality check and appending annotation data to them. Once the input raw data files are read, all necessary data are extracted and parsed. The ISPs are then sorted and checked, including missing and duplicated packet numbering. The final part of the processing is the Level-0 product generation. Several quality flags are computed and included in the associated metadata. Raw data, time sorted and annotated are included in the Level-0 package.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Feb 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nOa01\n\n\nAerosol correction\n\n\n300\n\n\n0.4000\n\n\n\n\nOa02\n\n\nYellow substance and detrital pigments (turbidity)\n\n\n300\n\n\n0.4125\n\n\n\n\nOa03\n\n\nChlorophyll absorption maximum\n\n\n300\n\n\n0.4425\n\n\n\n\nOa04\n\n\nChlorophyll\n\n\n300\n\n\n0.4900\n\n\n\n\nOa05\n\n\nChlorophyll\n\n\n300\n\n\n0.5100\n\n\n\n\nOa06\n\n\nChlorophyll reference (minimum)\n\n\n300\n\n\n0.5600\n\n\n\n\nOa07\n\n\nSediment loading\n\n\n300\n\n\n0.6200\n\n\n\n\nOa08\n\n\n2nd Chlorophyll absorption maximum\n\n\n300\n\n\n0.6650\n\n\n\n\nOa09\n\n\nImproved fluorescence retrieval\n\n\n300\n\n\n0.6737\n\n\n\n\nOa010\n\n\nChlorophyll fluorescence peak\n\n\n300\n\n\n0.6813\n\n\n\n\nOa11\n\n\nChlorophyll fluorescence baseline\n\n\n300\n\n\n0.7087\n\n\n\n\nOa12\n\n\nO2 absorption / clouds\n\n\n300\n\n\n0.7538\n\n\n\n\nOa16\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.7788\n\n\n\n\nOa17\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.8650\n\n\n\n\nOa18\n\n\nWater vapour absorption\n\n\n300\n\n\n0.8850\n\n\n\n\nOa19\n\n\nWater vapour absorption\n\n\n300\n\n\n0.9000\n\n\n\n\nOa21\n\n\nWater vapour absorption\n\n\n300\n\n\n1.0200"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-slstr-level-1",
    "href": "Data/Sentinel3.html#sentinel-3-slstr-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SLSTR Level 1",
    "text": "Sentinel-3 SLSTR Level 1\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level-1 product provides a valuable source of processed and calibrated data that is suitable for a wide range of applications. The product includes key parameters and data quality flags that provide important information on the reliability and accuracy of the data, and the product is generated offline with a delay of a few days after the acquisition of the Level-0 data.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543\n\n\n\n\nS2\n\n\nVegetation monitoring\n\n\n500\n\n\n0.6595\n\n\n\n\nS3\n\n\nNDVI, cloud flagging\n\n\n500\n\n\n0.8680\n\n\n\n\nS4\n\n\nCirrus detection over land\n\n\n500\n\n\n1.3748\n\n\n\n\nS5\n\n\nCloud clearing\n\n\n500\n\n\n1.6134\n\n\n\n\nS6\n\n\nVegetation state and cloud clearing\n\n\n500\n\n\n2.2557\n\n\n\n\nS7\n\n\nSST, LST, Active fire\n\n\n500\n\n\n3.7420\n\n\n\n\nS8\n\n\nSST, LST, Active fire\n\n\n500\n\n\n10.8540\n\n\n\n\nS9\n\n\nSST, LST\n\n\n1000\n\n\n12.0225\n\n\n\n\nF1\n\n\nActive fire\n\n\n500\n\n\n3.7420\n\n\n\n\nF2\n\n\nActive fire\n\n\n1000\n\n\n3.9400\n\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-slstr-level-2",
    "href": "Data/Sentinel3.html#sentinel-3-slstr-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SLSTR Level 2",
    "text": "Sentinel-3 SLSTR Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level-2 product provides higher-level geophysical parameters, but with a longer processing time and coarser spatial resolution compared to the Level-1 product. The product also includes additional data quality flags to provide more information on the reliability and accuracy of the data.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-slstr-level-0",
    "href": "Data/Sentinel3.html#sentinel-3-slstr-level-0",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SLSTR Level 0",
    "text": "Sentinel-3 SLSTR Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level 0 product is the raw unprocessed data acquired by the SLSTR instrument on board the Sentinel-3 satellite. It consists of the uncalibrated digital counts received by the SLSTR detectors for each pixel in the image. It provides a valuable source of unprocessed data for researchers and advanced users who require access to the raw data for their applications.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Feb 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543\n\n\n\n\nS2\n\n\nVegetation monitoring\n\n\n500\n\n\n0.6595\n\n\n\n\nS3\n\n\nNDVI, cloud flagging\n\n\n500\n\n\n0.8680\n\n\n\n\nS4\n\n\nCirrus detection over land\n\n\n500\n\n\n1.3748\n\n\n\n\nS5\n\n\nCloud clearing\n\n\n500\n\n\n1.6134\n\n\n\n\nS6\n\n\nVegetation state and cloud clearing\n\n\n500\n\n\n2.2557\n\n\n\n\nS7\n\n\nSST, LST, Active fire\n\n\n500\n\n\n3.7420\n\n\n\n\nS8\n\n\nSST, LST, Active fire\n\n\n500\n\n\n10.8540\n\n\n\n\nS9\n\n\nSST, LST\n\n\n1000\n\n\n12.0225\n\n\n\n\nF1\n\n\nActive fire\n\n\n500\n\n\n3.7420\n\n\n\n\nF2\n\n\nActive fire\n\n\n1000\n\n\n3.9400"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-syn-level-2",
    "href": "Data/Sentinel3.html#sentinel-3-syn-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SYN Level 2",
    "text": "Sentinel-3 SYN Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SYN Level 2 product is a higher-level processed product that contains information about the Earth’s atmosphere and its constituents. It is derived from the Level-1 and Level-2 products of the OLCI and SLSTR instruments on board the Sentinel-3 satellite.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-sral-level-1",
    "href": "Data/Sentinel3.html#sentinel-3-sral-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SRAL Level 1",
    "text": "Sentinel-3 SRAL Level 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SRAL Level-1 product provides corrected and validated geophysical parameters derived from the raw SRAL Level-0 data, along with metadata and data quality flags that enable the user to assess the reliability and suitability of the data for specific applications.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-sral-level-2",
    "href": "Data/Sentinel3.html#sentinel-3-sral-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SRAL Level 2",
    "text": "Sentinel-3 SRAL Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SRAL Level-2 product is a higher-level processed product that contains more detailed and refined geophysical parameters suitable for scientific and research applications. It contains advanced geophysical parameters such as sea surface height, significant wave height, and wind speed, that are derived from the SRAL Level-1 products using advanced processing algorithms and quality control procedures.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Mar 2016 - Present’]"
  },
  {
    "objectID": "Data/Sentinel3.html#sentinel-3-sral-level-0",
    "href": "Data/Sentinel3.html#sentinel-3-sral-level-0",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SRAL Level 0",
    "text": "Sentinel-3 SRAL Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 Synthetic Aperture Radar Altimeter (SRAL) Level-0 product contains raw data acquired by the SRAL instrument onboard the Sentinel-3 satellite. The data contains raw, time-tagged radar echoes and instrument housekeeping data, along with metadata describing the acquisition parameters and instrument characteristics.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nFeb 2016 - Present\n\n\nJul 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Feb 2016 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html",
    "href": "Data/Sentinel5P.html",
    "title": "Sentinel-5P",
    "section": "",
    "text": "The Copernicus Sentinel-5 Precursor mission is the first Copernicus mission dedicated to monitoring our atmosphere.\nThe main objective of the Copernicus Sentinel-5P mission is to perform atmospheric measurements with high spatio-temporal resolution, to be used for air quality, ozone & UV radiation, and climate monitoring & forecasting.\nThere are different data products associated with the three levels of TROPOMI processing: Level-0, Level-1B and Level-2.\nSentinel-5P Level 2 Aerosol Index\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 Aerosol Index (AER_AI) dataset provides high-resolution imagery of the UV Aerosol Index (UVAI), also called the Absorbing Aerosol Index (AAI). The AAI is based on wavelength-dependent changes in Rayleigh scattering in the UV spectral range for a pair of wavelengths. The difference between observed and modelled reflectance results in the AAI. When the AAI is positive, it indicates the presence of UV-absorbing aerosols like dust and smoke. It is useful for tracking the evolution of episodic aerosol plumes from dust outbreaks, volcanic ash, and biomass burning.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Jul 2018 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P Level 2 Carbon Monoxide\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 CO data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission, specifically focusing on measuring and analyzing the concentration of carbon monoxide in the Earth’s atmosphere. It includes data on the total column carbon monoxide content, as well as vertical profiles that describe how the concentration changes with altitude.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P Level 2 Cloud\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 Cloud dataset provides high-resolution imagery of cloud parameters. The TROPOMI/S5P cloud properties retrieval is based on the OCRA and ROCINN algorithms currently being used in the operational GOME and GOME-2 products. OCRA retrieves the cloud fraction using measurements in the UV/VIS spectral regions and ROCINN retrieves the cloud height (pressure) and optical thickness (albedo) using measurements in and around the oxygen A-band at 760 nm. Additionally, the cloud parameters are also provided for a cloud model which assumes the cloud to be a Lambertian reflecting boundary.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P Level 2 Formaldehyde\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 HCHO data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focus on measuring and analyzing the concentration of formaldehyde in the Earth’s atmosphere. The Level 2 Formaldehyde data also incorporates auxiliary information, such as geolocation, cloud properties, and surface reflectance, which are crucial for contextualizing and interpreting the measurements.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P Level 2 Methane\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 CH4 data from the Copernicus Sentinel-5P satellite shows the methane concentrations globally. This product provides processed and derived measurements of methane concentrations in the Earth’s atmosphere. It is a valuable resource for studying climate change, understanding methane emissions, and informing environmental policies and mitigation efforts.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P Level 2 Nitrogen Dioxide\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 NO2 data comes from the Copernicus Sentinel-5P satellite and shows the nitrogen dioxide concentrations across the globe. Concentrations of short-lived pollutants, such as nitrogen dioxide, are indicators of changes in economic slowdowns and are comparable to changes in emissions.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P Level 2 Ozone\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 O3 data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focuses on measuring and analyzing the concentration and distribution of ozone in the Earth’s atmosphere. Researchers and scientists utilize this data for various purposes, that includes monitoring and assessing ozone depletion, particularly in regions like the polar areas, where the ozone layer is crucial. Additionally, the data aids in air quality monitoring, enabling the evaluation of ozone pollution control measures and understanding of pollution sources.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P Level 2 Sulfur Dioxide\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 SO2 data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focuses on measuring and analyzing the concentration and distribution of sulfur dioxide in the Earth’s atmosphere. It provides comprehensive information on atmospheric sulfur dioxide’s vertical distribution and spatial variations. It includes data on the total column sulfur dioxide content and vertical profiles that describe how the concentration changes with altitude. This data also incorporates auxiliary information, such as geolocation, cloud properties, and surface reflectance, which are crucial for contextualising and interpreting the measurements. It is a valuable resource for studying air quality, volcanic activity, atmospheric chemistry, and assessing the impacts of sulfur dioxide on human health and the environment.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P Level 1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 1B data refers to a processed and calibrated dataset derived from the raw measurements acquired by the Sentinel-5P satellite. This level of data undergoes initial processing steps to correct for instrument effects, atmospheric disturbances, and other artifacts.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\n\n\n\n\nSentinel-5P Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 0 data refers to the raw data acquired by the Sentinel-5P satellite during its mission. These instruments include the Tropospheric Monitoring Instrument (TROPOMI), which is capable of measuring a wide range of atmospheric pollutants such as nitrogen dioxide, ozone, formaldehyde, and aerosols, among others.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-aerosol-index",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-aerosol-index",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Aerosol Index",
    "text": "Sentinel-5P Level 2 Aerosol Index\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 Aerosol Index (AER_AI) dataset provides high-resolution imagery of the UV Aerosol Index (UVAI), also called the Absorbing Aerosol Index (AAI). The AAI is based on wavelength-dependent changes in Rayleigh scattering in the UV spectral range for a pair of wavelengths. The difference between observed and modelled reflectance results in the AAI. When the AAI is positive, it indicates the presence of UV-absorbing aerosols like dust and smoke. It is useful for tracking the evolution of episodic aerosol plumes from dust outbreaks, volcanic ash, and biomass burning.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Jul 2018 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-carbon-monoxide",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-carbon-monoxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Carbon Monoxide",
    "text": "Sentinel-5P Level 2 Carbon Monoxide\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 CO data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission, specifically focusing on measuring and analyzing the concentration of carbon monoxide in the Earth’s atmosphere. It includes data on the total column carbon monoxide content, as well as vertical profiles that describe how the concentration changes with altitude.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-cloud",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-cloud",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Cloud",
    "text": "Sentinel-5P Level 2 Cloud\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 Cloud dataset provides high-resolution imagery of cloud parameters. The TROPOMI/S5P cloud properties retrieval is based on the OCRA and ROCINN algorithms currently being used in the operational GOME and GOME-2 products. OCRA retrieves the cloud fraction using measurements in the UV/VIS spectral regions and ROCINN retrieves the cloud height (pressure) and optical thickness (albedo) using measurements in and around the oxygen A-band at 760 nm. Additionally, the cloud parameters are also provided for a cloud model which assumes the cloud to be a Lambertian reflecting boundary.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-formaldehyde",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-formaldehyde",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Formaldehyde",
    "text": "Sentinel-5P Level 2 Formaldehyde\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 HCHO data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focus on measuring and analyzing the concentration of formaldehyde in the Earth’s atmosphere. The Level 2 Formaldehyde data also incorporates auxiliary information, such as geolocation, cloud properties, and surface reflectance, which are crucial for contextualizing and interpreting the measurements.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-methane",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-methane",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Methane",
    "text": "Sentinel-5P Level 2 Methane\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 CH4 data from the Copernicus Sentinel-5P satellite shows the methane concentrations globally. This product provides processed and derived measurements of methane concentrations in the Earth’s atmosphere. It is a valuable resource for studying climate change, understanding methane emissions, and informing environmental policies and mitigation efforts.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-nitrogen-dioxide",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-nitrogen-dioxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Nitrogen Dioxide",
    "text": "Sentinel-5P Level 2 Nitrogen Dioxide\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 NO2 data comes from the Copernicus Sentinel-5P satellite and shows the nitrogen dioxide concentrations across the globe. Concentrations of short-lived pollutants, such as nitrogen dioxide, are indicators of changes in economic slowdowns and are comparable to changes in emissions.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-ozone",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-ozone",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Ozone",
    "text": "Sentinel-5P Level 2 Ozone\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 O3 data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focuses on measuring and analyzing the concentration and distribution of ozone in the Earth’s atmosphere. Researchers and scientists utilize this data for various purposes, that includes monitoring and assessing ozone depletion, particularly in regions like the polar areas, where the ozone layer is crucial. Additionally, the data aids in air quality monitoring, enabling the evaluation of ozone pollution control measures and understanding of pollution sources.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-2-sulfur-dioxide",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-2-sulfur-dioxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Sulfur Dioxide",
    "text": "Sentinel-5P Level 2 Sulfur Dioxide\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 SO2 data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focuses on measuring and analyzing the concentration and distribution of sulfur dioxide in the Earth’s atmosphere. It provides comprehensive information on atmospheric sulfur dioxide’s vertical distribution and spatial variations. It includes data on the total column sulfur dioxide content and vertical profiles that describe how the concentration changes with altitude. This data also incorporates auxiliary information, such as geolocation, cloud properties, and surface reflectance, which are crucial for contextualising and interpreting the measurements. It is a valuable resource for studying air quality, volcanic activity, atmospheric chemistry, and assessing the impacts of sulfur dioxide on human health and the environment.\n\nOffered Data\n\n\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Apr 2018 - Present’]"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-1b",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-1b",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 1B",
    "text": "Sentinel-5P Level 1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 1B data refers to a processed and calibrated dataset derived from the raw measurements acquired by the Sentinel-5P satellite. This level of data undergoes initial processing steps to correct for instrument effects, atmospheric disturbances, and other artifacts.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023"
  },
  {
    "objectID": "Data/Sentinel5P.html#sentinel-5p-level-0",
    "href": "Data/Sentinel5P.html#sentinel-5p-level-0",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 0",
    "text": "Sentinel-5P Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 0 data refers to the raw data acquired by the Sentinel-5P satellite during its mission. These instruments include the Tropospheric Monitoring Instrument (TROPOMI), which is capable of measuring a wide range of atmospheric pollutants such as nitrogen dioxide, ozone, formaldehyde, and aerosols, among others.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "Data/Dashboard.html",
    "href": "Data/Dashboard.html",
    "title": "Copernicus Operations Dashboard",
    "section": "",
    "text": "This dashboard keeps users and stakeholders up to date with the latest information about available satellite data.\nAccess Link : https://operations.dashboard.copernicus.eu/index\nIt aims at providing details on the status of the Copernicus operations, covering Sentinel-1, 2, 3 (Land) and Sentinel-5P.\nThe Homepage includes a high-level overview of the Copernicus Sentinel missions over the past 24 h, including the number of missions, time spent gathering data, data volumes, and the number of products delivered.\nThe Events tab provides details of events over the past three months that have impact on the completeness of the data production, such as planned calibration activities, manoeuvrers, or anomalies. The information of which data is affected is included.\n\n\n\n\n\n\n\n\n\n\nThe Data Takes tab hosts a real-time list of available collections delivered by the missions, enabling users to scan through these products to find data that meet their research and development requirements, and to assess their availability.\n\n\n\n\n\nThe Publication Statistics tab provides detailed information on Copernicus Sentinel data – such as number of products delivered – covering anywhere between the past 24h and the past three months. These insights are represented visually, with one graphical representation per mission that is subdivided by sensor.\n\n\n\n\n\nIn the coming year the Dashboard is planned to improve the emerging requirements.\nFor any inquiries on the Copernicus Sentinel Operations Dashboard contact us."
  },
  {
    "objectID": "Data/Sentinel1.html",
    "href": "Data/Sentinel1.html",
    "title": "Sentinel-1",
    "section": "",
    "text": "The Sentinel-1 radar imaging mission is composed of a constellation of two polar-orbiting satellites providing continous all-weather, day and night imagery for Land and Maritime Monitoring. C-band synthentic aperture radar imaging has the advantage of operating at wavelenghts that are not obstructed by clouds or lack of illumination and therefore can acquire data during day or night under all weather conditions.\nThe end of mission of the Sentinel-1B satellite has been declared in July 2022 On 23 December 2021, Copernicus Sentinel-1B experienced an anomaly related to the instrument electronics power supply provided by the satellite platform, leaving it unable to deliver radar data. Despite all investigations and recovery attempts, ESA and the European Commission had to announce that it is the end of the mission for Sentinel-1B. Copernicus Sentinel-1A remains fully operational. More information about the end of the mission for the Sentinel-1B satellite can be found on the webpage Mission ends for Copernicus Sentinel-1B satellite. In response to the loss of Sentinel-1B, the mission observation scenario of Sentinel-1A was adjusted, affecting the nominal global coverage frequency. An up-to-date overview of the observation scenario in place can be consulted on the webpage Sentinel-1 Observation Scenario. Some regions are currently not observed by Sentinel-1. Nevertheless, the regions that are still observed, now have a repeat cycle of 12 days under a one-satellite constellation scenario, which affects possible interferometric analyses.\nSentinel data products are made available systematically and free of charge to all data users including the general public, scientific and commercial users. These data products are available in single polarisation for Wave mode and dual polarisation or single polarisation for SM, IW and EW modes.\nSentinel-1 Level 1 Ground Range Detected (GRD)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel 1 Level 1 GRD products in this Collection consist of focused SAR data that has been detected, multi-looked and projected to ground range using the Earth ellipsoid model WGS84. The ellipsoid projection of the GRD products is corrected using the terrain height specified in the product general annotation. The terrain height used varies in azimuth but is constant in range (but can be different for each IW/EW sub-swath). Ground range coordinates are the slant range coordinates projected onto the ellipsoid of the Earth. Pixel values represent detected amplitude. Phase information is lost. The resulting product has approximately square resolution pixels and square pixel spacing with reduced speckle at a cost of reduced spatial resolution.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*)(**) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJan 2023\n\n\n\n\n(***) Packed or Unpacked, SAFE with Cloud optimized GeoTIFF\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\n(****) Packed, original SAFE\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJul 2023\n\n\n\n\nPacked, original SAFE\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nOct 2014 - Present (1 year)\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023.  (**) packed means data are available in the original bundling (e.g. compressed zipping) (***) Conversion of Sentinel-1 GRD products to the SAFE with Cloud Optimized GeoTIFF (COG_SAFE) format began in May 2023. The newest products are converted and available first, and older products will be added gradually until the entire archive is converted. More details about how the original Sentinel-1-GRD products were converted to COG_SAFE format are here. (****) Original Sentinel-1 GRD products older than one year will be accessible with deferred availability (DAD), while the entire archive of COG_SAFE products will be available immediately (IAD). In case original Sentinel-1 GRD products would be needed with immediate access, users can convert COG_SAFE products to the original SAFE products using COG2GRD tool.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Oct 2014 - Present’]\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json\n\n\n\n\n\n\n\n\nSentinel-1 Level 1 Single Look Complex (SLC)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel 1 Level 1 SLC products are images in the slant range by azimuth imaging plane, in the image plane of satellite data acquisition. Each image pixel is represented by a complex (I and Q) magnitude value and therefore contains both amplitude and phase information. Each I and Q value is 16 bits per pixel. The processing for all SLC products results in a single look in each dimension using the full available signal bandwidth. The imagery is geo-referenced using orbit and attitude data from the satellite.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nOct 2014 - Present\n\n\nJan 2023\n\n\n\n\n(*) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nExcept Europe (RoW)\n\n\nFeb 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023.\n\nFurther details about the data collection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v2.2.0/schema.json\n\n\n\n\n\n\n\n\nSentinel-1 Level 2 Ocean (OCN)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-1 Level 2 OCN (Ocean) products are specifically processed radar data products for oceanographic applications. These products are derived from Sentinel-1 SAR data. They are tailored to meet the needs of oceanographic studies, such as monitoring sea surface conditions, detecting oil spills, tracking marine vessels, and studying ocean currents. The OCN products typically involve specialized processing techniques to extract relevant oceanographic information from the radar data. This can include surface wave analysis, wind speed and direction estimation, ocean surface current mapping, and identifying features such as oil slicks or marine traffic.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nDec 2014 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nDec 2014 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Oct 2014 - Present’]\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-1 Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-1 Level 0 products are unprocessed radar measurements obtained by the satellite’s SAR system, containing amplitude and phase information. They serve as the initial input for generating higher-level radar products with calibrated and corrected data.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nOct 2014 - Present (1 year)\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nExcept Europe (RoW)\n\n\nLast one year\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023."
  },
  {
    "objectID": "Data/Sentinel1.html#sentinel-1-level-1-ground-range-detected-grd",
    "href": "Data/Sentinel1.html#sentinel-1-level-1-ground-range-detected-grd",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 1 Ground Range Detected (GRD)",
    "text": "Sentinel-1 Level 1 Ground Range Detected (GRD)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel 1 Level 1 GRD products in this Collection consist of focused SAR data that has been detected, multi-looked and projected to ground range using the Earth ellipsoid model WGS84. The ellipsoid projection of the GRD products is corrected using the terrain height specified in the product general annotation. The terrain height used varies in azimuth but is constant in range (but can be different for each IW/EW sub-swath). Ground range coordinates are the slant range coordinates projected onto the ellipsoid of the Earth. Pixel values represent detected amplitude. Phase information is lost. The resulting product has approximately square resolution pixels and square pixel spacing with reduced speckle at a cost of reduced spatial resolution.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*)(**) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJan 2023\n\n\n\n\n(***) Packed or Unpacked, SAFE with Cloud optimized GeoTIFF\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\n(****) Packed, original SAFE\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJul 2023\n\n\n\n\nPacked, original SAFE\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nOct 2014 - Present (1 year)\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023.  (**) packed means data are available in the original bundling (e.g. compressed zipping) (***) Conversion of Sentinel-1 GRD products to the SAFE with Cloud Optimized GeoTIFF (COG_SAFE) format began in May 2023. The newest products are converted and available first, and older products will be added gradually until the entire archive is converted. More details about how the original Sentinel-1-GRD products were converted to COG_SAFE format are here. (****) Original Sentinel-1 GRD products older than one year will be accessible with deferred availability (DAD), while the entire archive of COG_SAFE products will be available immediately (IAD). In case original Sentinel-1 GRD products would be needed with immediate access, users can convert COG_SAFE products to the original SAFE products using COG2GRD tool.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Oct 2014 - Present’]\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json"
  },
  {
    "objectID": "Data/Sentinel1.html#sentinel-1-level-1-single-look-complex-slc",
    "href": "Data/Sentinel1.html#sentinel-1-level-1-single-look-complex-slc",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 1 Single Look Complex (SLC)",
    "text": "Sentinel-1 Level 1 Single Look Complex (SLC)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel 1 Level 1 SLC products are images in the slant range by azimuth imaging plane, in the image plane of satellite data acquisition. Each image pixel is represented by a complex (I and Q) magnitude value and therefore contains both amplitude and phase information. Each I and Q value is 16 bits per pixel. The processing for all SLC products results in a single look in each dimension using the full available signal bandwidth. The imagery is geo-referenced using orbit and attitude data from the satellite.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nOct 2014 - Present\n\n\nJan 2023\n\n\n\n\n(*) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nExcept Europe (RoW)\n\n\nFeb 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023.\n\nFurther details about the data collection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v2.2.0/schema.json"
  },
  {
    "objectID": "Data/Sentinel1.html#sentinel-1-level-2-ocean-ocn",
    "href": "Data/Sentinel1.html#sentinel-1-level-2-ocean-ocn",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 2 Ocean (OCN)",
    "text": "Sentinel-1 Level 2 Ocean (OCN)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-1 Level 2 OCN (Ocean) products are specifically processed radar data products for oceanographic applications. These products are derived from Sentinel-1 SAR data. They are tailored to meet the needs of oceanographic studies, such as monitoring sea surface conditions, detecting oil spills, tracking marine vessels, and studying ocean currents. The OCN products typically involve specialized processing techniques to extract relevant oceanographic information from the radar data. This can include surface wave analysis, wind speed and direction estimation, ocean surface current mapping, and identifying features such as oil slicks or marine traffic.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nDec 2014 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nDec 2014 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘Oct 2014 - Present’]"
  },
  {
    "objectID": "Data/Sentinel1.html#sentinel-1-level-0",
    "href": "Data/Sentinel1.html#sentinel-1-level-0",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 0",
    "text": "Sentinel-1 Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-1 Level 0 products are unprocessed radar measurements obtained by the satellite’s SAR system, containing amplitude and phase information. They serve as the initial input for generating higher-level radar products with calibrated and corrected data.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nOct 2014 - Present (1 year)\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nExcept Europe (RoW)\n\n\nLast one year\n\n\nJul 2023\n\n\n\n\n\n(*) temporary offer available until the target service offer becomes available in July 2023."
  },
  {
    "objectID": "Data/Sentinel1_COG.html",
    "href": "Data/Sentinel1_COG.html",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "",
    "text": "The Sentinel-1 GRD COG_SAFE products can be filtered by the Odata API query using three methods:\n\nFiltering ‘COG.SAFE’ substring in the product name:\nExample of query:\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T00:00:00.000Z\nUsing proper data type with “-COG” suffix. One of: S1_GRDF_1S-COG,S2_GRDF_1S-COG,S3_GRDF_1S-COG,S4_GRDF_1S-COG,S5_GRDF_1S-COG,S6_GRDF_1S-COG,S1_GRDH_1S-COG,S2_GRDH_1S-COG,S3_GRDH_1S-COG,S4_GRDH_1S-COG,S5_GRDH_1S-COG,S6_GRDH_1S-COG,S1_GRDM_1S-COG,S2_GRDM_1S-COG,S3_GRDM_1S-COG,S4_GRDM_1S-COG,S5_GRDM_1S-COG,S6_GRDM_1S-COG,IW_GRDH_1S-COG,IW_GRDM_1S-COG,EW_GRDH_1S-COG,EW_GRDM_1S-COG,WV_GRDM_1S-COG\nExample of query:\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27productType%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27IW_GRDH_1S-COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T04:00:00.000Z&$top=10\nFiltering ‘GRD’ substring in product name and ’’origin” attribute equal “CLOUDFERRO”.\nExample of query:\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27GRD%27)%20and%20Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27origin%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27CLOUDFERRO%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T04:00:00.000Z&$top=10"
  },
  {
    "objectID": "Data/Sentinel1_COG.html#how-to-search-for-cog_safe-products-with-odata-api",
    "href": "Data/Sentinel1_COG.html#how-to-search-for-cog_safe-products-with-odata-api",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "",
    "text": "The Sentinel-1 GRD COG_SAFE products can be filtered by the Odata API query using three methods:\n\nFiltering ‘COG.SAFE’ substring in the product name:\nExample of query:\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T00:00:00.000Z\nUsing proper data type with “-COG” suffix. One of: S1_GRDF_1S-COG,S2_GRDF_1S-COG,S3_GRDF_1S-COG,S4_GRDF_1S-COG,S5_GRDF_1S-COG,S6_GRDF_1S-COG,S1_GRDH_1S-COG,S2_GRDH_1S-COG,S3_GRDH_1S-COG,S4_GRDH_1S-COG,S5_GRDH_1S-COG,S6_GRDH_1S-COG,S1_GRDM_1S-COG,S2_GRDM_1S-COG,S3_GRDM_1S-COG,S4_GRDM_1S-COG,S5_GRDM_1S-COG,S6_GRDM_1S-COG,IW_GRDH_1S-COG,IW_GRDM_1S-COG,EW_GRDH_1S-COG,EW_GRDM_1S-COG,WV_GRDM_1S-COG\nExample of query:\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27productType%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27IW_GRDH_1S-COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T04:00:00.000Z&$top=10\nFiltering ‘GRD’ substring in product name and ’’origin” attribute equal “CLOUDFERRO”.\nExample of query:\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27GRD%27)%20and%20Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27origin%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27CLOUDFERRO%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T04:00:00.000Z&$top=10"
  },
  {
    "objectID": "Data/Sentinel1_COG.html#how-to-search-for-cog_safe-products-in-the-browser",
    "href": "Data/Sentinel1_COG.html#how-to-search-for-cog_safe-products-in-the-browser",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "How to search for COG_SAFE products in the Browser?",
    "text": "How to search for COG_SAFE products in the Browser?\nThere are two separate options available for Sentinel-1 GRD products. Selecting the “Level-1 GRD COG” option under Sentinel-1 will return COG_SAFE products while option “Level-1 GRD” will return original GRD products. If you would like to search for both type of products, select both options."
  },
  {
    "objectID": "Data/Sentinel1_COG.html#how-were-original-sentinel-1-grd-products-converted-to-cog_safe-products",
    "href": "Data/Sentinel1_COG.html#how-were-original-sentinel-1-grd-products-converted-to-cog_safe-products",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "How were original Sentinel-1 GRD products converted to COG_SAFE products?",
    "text": "How were original Sentinel-1 GRD products converted to COG_SAFE products?\nThe following changes were made during the conversion of original Sentinel-1 GRD products to COG_SAFE products:\n\nAll GeoTiff files available in the measurements folder were converted to cloud optimized GeoTIFF format with the gdal command:\ngdal_translate -of COG -a_nodata 0 -co OVERVIEW_COUNT=6 -co BLOCKSIZE=1024 -co BIGTIFF=NO -co OVERVIEW_RESAMPLING=RMS -co COMPRESS=ZSTD -co NUM_THREADS=ALL_CPUS -mo GRD_ORIGINAL_HEADER_SIZE=&lt;original_header_size&gt; -mo GRD_ORIGINAL_FOOTER_SIZE=&lt;original_footer_size&gt; &lt;input_tiff&gt;.tiff &lt;input_tiff&gt;-cog.tiff \nMore information about what these options mean can be found in the GDAL official documentation. Note that the output filename has a suffix “-cog”, which indicates that the files were converted to COGs.\nA suffix “_COG” was added to the name of the product and a new CRC code was calculated. For example, the original product\nS1A_IW_GRDH_1SDV_20230206T165050_20230206T165115_047118_05A716_53C5.safe became\nS1A_IW_GRDH_1SDV_20230206T165050_20230206T165115_047118_05A716_74F9_COG.safe.\nManifest file was adjusted so that it reflects these changes:\n\nsafe:processing element with a name=“COG Conversion” was added. It contains metadata about the conversion and includes the name of the original product under safe:resource child element.\ndataObject elements, which describe the measurements files, have updated values for “size”, “href”, “checksum”."
  },
  {
    "objectID": "Data/Sentinel2.html",
    "href": "Data/Sentinel2.html",
    "title": "Sentinel-2",
    "section": "",
    "text": "The Copernicus Sentinel-2 mission comprises a land monitoring constellation of two polar-orbiting satellites placed in the same sun-synchronous orbit, phased at 180° to each other. It aims at monitoring variability in land surface conditions, and its wide swath width (290 km) and high revisit time (10 days at the equator with one satellite, and 5 days with 2 satellites which results in 2-3 days at mid-latitudes) will support monitoring of Earth’s surface changes.\nEach Sentinel-2 products is composed of approximately 110x110 km tiles in cartographic geometry (UTM/WGS84 projection). Earth is subdivided on a predefined set of tiles, defined in UTM/WGS84 projection and using a 100 km step. However, each tile has a surface of 110x110 km² in order to provide large overlap with the neighbouring.\nSentinel-2 Level 2A Top of Canopy (TOC)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nSentinel-2 Level 2A Level 2A product provides atmospherically corrected Surface Reflectance (SR) images, derived from the associated Level-1C products. The atmospheric correction of Sentinel-2 images includes the correction of the scattering of air molecules (Rayleigh scattering), of the absorbing and scattering effects of atmospheric gases, in particular ozone, oxygen and water vapour and the correction of absorption and scattering due to aerosol particles. Level 2A product are considered an ARD product.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked (original ESA product)\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nMarch 2017 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked (original ESA product)\n\n\nImmediately available data(IAD)\n\n\nExcept Europe (RoW)\n\n\nDec 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked (original ESA product)\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJul 2023\n\n\n\n\nPacked (original ESA product)\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) For period 01/2020 - 11/2021 the data repository holds original ESA products and products generated using Sentinel-2 Toolbox (sen2cor). See note above.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘July 2015 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nB01\n\n\nCoastal aerosol\n\n\n60\n\n\n0.443\n\n\n\n\nB02\n\n\nBlue\n\n\n10\n\n\n0.49\n\n\n\n\nB03\n\n\nGreen\n\n\n10\n\n\n0.56\n\n\n\n\nB04\n\n\nRed\n\n\n10\n\n\n0.665\n\n\n\n\nB05\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.705\n\n\n\n\nB06\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.74\n\n\n\n\nB07\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.783\n\n\n\n\nB08\n\n\nNIR\n\n\n10\n\n\n0.842\n\n\n\n\nB8A\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.865\n\n\n\n\nB09\n\n\nWater vapour\n\n\n60\n\n\n0.945\n\n\n\n\nB10\n\n\nSWIR - Cirrus\n\n\n60\n\n\n1.375\n\n\n\n\nB11\n\n\nSWIR\n\n\n20\n\n\n1.61\n\n\n\n\nB12\n\n\nSWIR\n\n\n20\n\n\n2.19\n\n\n\n\nSCL\n\n\nScene Classification\n\n\n20\n\n\n\n\n\n\nSNW\n\n\nSnow probability\n\n\n20\n\n\n\n\n\n\nCLD\n\n\nCloud probability\n\n\n20\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nWMTS: https://services.sentinel-hub.com/ogc/wmts/7d34803f-511c-4caf-9438-6d72f32c8174\n\n\n\n\n\n\nSentinel-2 Level 1C Top of Atmosphere (TOA)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nSentinel-2 Level 1C products are available globally from 2015 onwards. These products are resampled with a constant Ground Sampling Distance (GSD) of 10, 20 and 60 m, depending on the native resolution of the different spectral bands. Pixel coordinates refer to the upper left corner of the pixel.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘July 2015 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nB01\n\n\nCoastal aerosol\n\n\n60\n\n\n0.443\n\n\n\n\nB02\n\n\nBlue\n\n\n10\n\n\n0.49\n\n\n\n\nB03\n\n\nGreen\n\n\n10\n\n\n0.56\n\n\n\n\nB04\n\n\nRed\n\n\n10\n\n\n0.665\n\n\n\n\nB05\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.705\n\n\n\n\nB06\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.74\n\n\n\n\nB07\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.783\n\n\n\n\nB08\n\n\nNIR\n\n\n10\n\n\n0.842\n\n\n\n\nB8A\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.865\n\n\n\n\nB09\n\n\nWater vapour\n\n\n60\n\n\n0.945\n\n\n\n\nB10\n\n\nSWIR - Cirrus\n\n\n60\n\n\n1.375\n\n\n\n\nB11\n\n\nSWIR\n\n\n20\n\n\n1.61\n\n\n\n\nB12\n\n\nSWIR\n\n\n20\n\n\n2.19\n\n\n\n\nSCL\n\n\nScene Classification\n\n\n20\n\n\n\n\n\n\nSNW\n\n\nSnow probability\n\n\n20\n\n\n\n\n\n\nCLD\n\n\nCloud probability\n\n\n20\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v2.2.0/schema.json\n\n\nWMTS: https://services.sentinel-hub.com/ogc/wmts/ef291c3e-77fd-43f2-a885-dced9ac1e6a7\n\n\n\n\n\n\nSentinel-2 Level 1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-2 Level 1B product provides radiometrically corrected imagery in Top-Of-Atmosphere (TOA) radiance values and in sensor geometry. Additionally, this product includes the refined geometric model which is used to generate the Level 1C product.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) EUP\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast two weeks\n\n\nOct 2023\n\n\n\n\n(*) EUP\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nFull Archive\n\n\nOct 2023\n\n\n\n\n\n(*) Access restrictions may apply.\n\n\n\nSentinel-2 Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nSentinel-2 Level-0 data is the raw data acquired by the Sentinel-2 satellite before any processing or calibration is applied. The purpose of Sentinel-2 Level-0 data is to provide a baseline for further processing and analysis of the images. Before the data can be used for scientific or operational applications, it must be preprocessed to correct for geometric distortions, radiometric calibration, atmospheric corrections, and other factors that can affect the accuracy and quality of the data.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "Data/Sentinel2.html#sentinel-2-level-2a-top-of-canopy-toc",
    "href": "Data/Sentinel2.html#sentinel-2-level-2a-top-of-canopy-toc",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 2A Top of Canopy (TOC)",
    "text": "Sentinel-2 Level 2A Top of Canopy (TOC)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nSentinel-2 Level 2A Level 2A product provides atmospherically corrected Surface Reflectance (SR) images, derived from the associated Level-1C products. The atmospheric correction of Sentinel-2 images includes the correction of the scattering of air molecules (Rayleigh scattering), of the absorbing and scattering effects of atmospheric gases, in particular ozone, oxygen and water vapour and the correction of absorption and scattering due to aerosol particles. Level 2A product are considered an ARD product.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked (original ESA product)\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nMarch 2017 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked (original ESA product)\n\n\nImmediately available data(IAD)\n\n\nExcept Europe (RoW)\n\n\nDec 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked (original ESA product)\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJul 2023\n\n\n\n\nPacked (original ESA product)\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) For period 01/2020 - 11/2021 the data repository holds original ESA products and products generated using Sentinel-2 Toolbox (sen2cor). See note above.\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘July 2015 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nB01\n\n\nCoastal aerosol\n\n\n60\n\n\n0.443\n\n\n\n\nB02\n\n\nBlue\n\n\n10\n\n\n0.49\n\n\n\n\nB03\n\n\nGreen\n\n\n10\n\n\n0.56\n\n\n\n\nB04\n\n\nRed\n\n\n10\n\n\n0.665\n\n\n\n\nB05\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.705\n\n\n\n\nB06\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.74\n\n\n\n\nB07\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.783\n\n\n\n\nB08\n\n\nNIR\n\n\n10\n\n\n0.842\n\n\n\n\nB8A\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.865\n\n\n\n\nB09\n\n\nWater vapour\n\n\n60\n\n\n0.945\n\n\n\n\nB10\n\n\nSWIR - Cirrus\n\n\n60\n\n\n1.375\n\n\n\n\nB11\n\n\nSWIR\n\n\n20\n\n\n1.61\n\n\n\n\nB12\n\n\nSWIR\n\n\n20\n\n\n2.19\n\n\n\n\nSCL\n\n\nScene Classification\n\n\n20\n\n\n\n\n\n\nSNW\n\n\nSnow probability\n\n\n20\n\n\n\n\n\n\nCLD\n\n\nCloud probability\n\n\n20\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nWMTS: https://services.sentinel-hub.com/ogc/wmts/7d34803f-511c-4caf-9438-6d72f32c8174"
  },
  {
    "objectID": "Data/Sentinel2.html#sentinel-2-level-1c-top-of-atmosphere-toa",
    "href": "Data/Sentinel2.html#sentinel-2-level-1c-top-of-atmosphere-toa",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 1C Top of Atmosphere (TOA)",
    "text": "Sentinel-2 Level 1C Top of Atmosphere (TOA)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nSentinel-2 Level 1C products are available globally from 2015 onwards. These products are resampled with a constant Ground Sampling Distance (GSD) of 10, 20 and 60 m, depending on the native resolution of the different spectral bands. Pixel coordinates refer to the upper left corner of the pixel.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘July 2015 - Present’]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nB01\n\n\nCoastal aerosol\n\n\n60\n\n\n0.443\n\n\n\n\nB02\n\n\nBlue\n\n\n10\n\n\n0.49\n\n\n\n\nB03\n\n\nGreen\n\n\n10\n\n\n0.56\n\n\n\n\nB04\n\n\nRed\n\n\n10\n\n\n0.665\n\n\n\n\nB05\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.705\n\n\n\n\nB06\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.74\n\n\n\n\nB07\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.783\n\n\n\n\nB08\n\n\nNIR\n\n\n10\n\n\n0.842\n\n\n\n\nB8A\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.865\n\n\n\n\nB09\n\n\nWater vapour\n\n\n60\n\n\n0.945\n\n\n\n\nB10\n\n\nSWIR - Cirrus\n\n\n60\n\n\n1.375\n\n\n\n\nB11\n\n\nSWIR\n\n\n20\n\n\n1.61\n\n\n\n\nB12\n\n\nSWIR\n\n\n20\n\n\n2.19\n\n\n\n\nSCL\n\n\nScene Classification\n\n\n20\n\n\n\n\n\n\nSNW\n\n\nSnow probability\n\n\n20\n\n\n\n\n\n\nCLD\n\n\nCloud probability\n\n\n20\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\nSTAC: https://stac-extensions.github.io/datacube/v2.2.0/schema.json\n\n\nWMTS: https://services.sentinel-hub.com/ogc/wmts/ef291c3e-77fd-43f2-a885-dced9ac1e6a7"
  },
  {
    "objectID": "Data/Sentinel2.html#sentinel-2-level-1b",
    "href": "Data/Sentinel2.html#sentinel-2-level-1b",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 1B",
    "text": "Sentinel-2 Level 1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-2 Level 1B product provides radiometrically corrected imagery in Top-Of-Atmosphere (TOA) radiance values and in sensor geometry. Additionally, this product includes the refined geometric model which is used to generate the Level 1C product.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) EUP\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast two weeks\n\n\nOct 2023\n\n\n\n\n(*) EUP\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nFull Archive\n\n\nOct 2023\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "Data/Sentinel2.html#sentinel-2-level-0",
    "href": "Data/Sentinel2.html#sentinel-2-level-0",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 0",
    "text": "Sentinel-2 Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nSentinel-2 Level-0 data is the raw data acquired by the Sentinel-2 satellite before any processing or calibration is applied. The purpose of Sentinel-2 Level-0 data is to provide a baseline for further processing and analysis of the images. Before the data can be used for scientific or operational applications, it must be preprocessed to correct for geometric distortions, radiometric calibration, atmospheric corrections, and other factors that can affect the accuracy and quality of the data.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed\n\n\nDeferred available data (DAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJul 2023\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "APIs.html",
    "href": "APIs.html",
    "title": "APIs",
    "section": "",
    "text": "This section gives an overview on the APIs provided by Copernicus Data Space Ecosystem."
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html",
    "href": "notebook-samples/sentinelhub/process_request.html",
    "title": "Sentinel Hub Process API",
    "section": "",
    "text": "In this example notebook we show how to use Sentinel Hub Process API to download satellite imagery. We describe how to use various parameters and configurations to obtain either processed products or raw band data. For more information about the service please check the official service documentation."
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#prerequisites",
    "href": "notebook-samples/sentinelhub/process_request.html#prerequisites",
    "title": "Sentinel Hub Process API",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nCredentials\nProcess API requires Sentinel Hub account. Please check configuration instructions about how to set up your Sentinel Hub credentials.\n\nfrom sentinelhub import SHConfig\n\nconfig = SHConfig(sh_base_url='https://sh.dataspace.copernicus.eu')\n\nif not config.sh_client_id or not config.sh_client_secret:\n    print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")\n\n\n\nImports\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n\nimport datetime\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sentinelhub import (\n    CRS,\n    BBox,\n    DataCollection,\n    DownloadRequest,\n    MimeType,\n    MosaickingOrder,\n    SentinelHubDownloadClient,\n    SentinelHubRequest,\n    bbox_to_dimensions,\n)\n\n# The following is not a package. It is a file utils.py which should be in the same folder as this notebook.\nfrom utils import plot_image\n\n\n\nSetting area of interest\nWe will download Sentinel-2 imagery of Betsiboka Estuary such as the one shown below (taken by Sentinel-2 on 2017-12-15):\n\n\n\ntitle\n\n\nThe bounding box in WGS84 coordinate system is [46.16, -16.15, 46.51, -15.58] (longitude and latitude coordinates of lower left and upper right corners). You can get the bbox for a different area at the bboxfinder website.\nAll requests require bounding box to be given as an instance of sentinelhub.geometry.BBox with corresponding Coordinate Reference System (sentinelhub.constants.CRS). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from sentinelhub.constants.CRS.\n\nbetsiboka_coords_wgs84 = (46.16, -16.15, 46.51, -15.58)\n\nWhen the bounding box bounds have been defined, you can initialize the BBox of the area of interest. Using the bbox_to_dimensions utility function, you can provide the desired resolution parameter of the image in meters and obtain the output image shape.\n\nresolution = 60\nbetsiboka_bbox = BBox(bbox=betsiboka_coords_wgs84, crs=CRS.WGS84)\nbetsiboka_size = bbox_to_dimensions(betsiboka_bbox, resolution=resolution)\n\nprint(f\"Image shape at {resolution} m resolution: {betsiboka_size} pixels\")"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-1-true-color-png-on-a-specific-date",
    "href": "notebook-samples/sentinelhub/process_request.html#example-1-true-color-png-on-a-specific-date",
    "title": "Sentinel Hub Process API",
    "section": "Example 1: True color (PNG) on a specific date",
    "text": "Example 1: True color (PNG) on a specific date\nWe build the request according to the API Reference, using the SentinelHubRequest class. Each Process API request also needs an evalscript.\nThe information that we specify in the SentinelHubRequest object is:\n\nan evalscript,\na list of input data collections with time interval,\na format of the response,\na bounding box and it’s size (size or resolution).\n\nThe evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L1C bands.\nThe image from Jun 12th 2020 is downloaded. Without any additional parameters in the evalscript, the downloaded data will correspond to reflectance values in UINT8 format (values in 0-255 range).\n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\ntrue_color_imgs = request_true_color.get_data()\n\nThe method get_data() will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays.\n\nprint(f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\")\nprint(f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\")\n\n\nimage = true_color_imgs[0]\nprint(f\"Image type: {image.dtype}\")\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\nplot_image(image, factor=3.5 / 255, clip_range=(0, 1))\n\n\nExample 1.1 Adding cloud mask data\nIt is also possible to obtain cloud masks when requesting Sentinel-2 data by using the cloud mask band (CLM) or the cloud probabilities band (CLP). More info here.\nThe factor for increasing the image brightness can already be provided in the evalscript.\n\nevalscript_clm = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"CLM\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.CLM == 1) {\n    return [0.75 + sample.B04, sample.B03, sample.B02]\n  }\n  return [3.5*sample.B04, 3.5*sample.B03, 3.5*sample.B02];\n}\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_clm,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\ndata_with_cloud_mask = request_true_color.get_data()\n\n\nplot_image(data_with_cloud_mask[0], factor=1 / 255)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-2-true-color-mosaic-of-least-cloudy-acquisitions",
    "href": "notebook-samples/sentinelhub/process_request.html#example-2-true-color-mosaic-of-least-cloudy-acquisitions",
    "title": "Sentinel Hub Process API",
    "section": "Example 2: True color mosaic of least cloudy acquisitions",
    "text": "Example 2: True color mosaic of least cloudy acquisitions\nThe SentinelHubRequest automatically creates a mosaic from all available images in the given time interval. By default, the mostRecent mosaicking order is used. More information available here.\nIn this example we will provide a month long interval, order the images w.r.t. the cloud coverage on the tile level (leastCC parameter), and mosaic them in the specified order.\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\nplot_image(request_true_color.get_data()[0], factor=3.5 / 255, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-3-all-sentinel-2s-raw-band-values",
    "href": "notebook-samples/sentinelhub/process_request.html#example-3-all-sentinel-2s-raw-band-values",
    "title": "Sentinel Hub Process API",
    "section": "Example 3: All Sentinel-2’s raw band values",
    "text": "Example 3: All Sentinel-2’s raw band values\nNow let’s define an evalscript which will return all Sentinel-2 spectral bands with raw values.\nIn this example we are downloading already quite a big chunk of data, so optimization of the request is not out of the question. Downloading raw digital numbers in the INT16 format instead of reflectances in the FLOAT32 format means that much less data is downloaded, which results in a faster download and a smaller usage of SH processing units.\nIn order to achieve this, we have to set the input units in the evalscript to DN (digital numbers) and the output sampleType argument to INT16. Additionally, we can’t pack all Sentinel-2’s 13 bands into a PNG image, so we have to set the output image type to the TIFF format via MimeType.TIFF in the request.\nThe digital numbers are in the range from 0-10000, so we have to scale the downloaded data appropriately.\n\nevalscript_all_bands = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"],\n                units: \"DN\"\n            }],\n            output: {\n                bands: 13,\n                sampleType: \"INT16\"\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B01,\n                sample.B02,\n                sample.B03,\n                sample.B04,\n                sample.B05,\n                sample.B06,\n                sample.B07,\n                sample.B08,\n                sample.B8A,\n                sample.B09,\n                sample.B10,\n                sample.B11,\n                sample.B12];\n    }\n\"\"\"\n\nrequest_all_bands = SentinelHubRequest(\n    evalscript=evalscript_all_bands,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\nall_bands_response = request_all_bands.get_data()\n\n\n# Image showing the SWIR band B12\n# Factor 1/1e4 due to the DN band values in the range 0-10000\n# Factor 3.5 to increase the brightness\nplot_image(all_bands_response[0][:, :, 12], factor=3.5 / 1e4, vmax=1)\n\n\n# From raw bands we can also construct a False-Color image\n# False color image is (B03, B04, B08)\nplot_image(all_bands_response[0][:, :, [2, 3, 7]], factor=3.5 / 1e4, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-4-save-downloaded-data-to-disk-and-read-it-from-disk",
    "href": "notebook-samples/sentinelhub/process_request.html#example-4-save-downloaded-data-to-disk-and-read-it-from-disk",
    "title": "Sentinel Hub Process API",
    "section": "Example 4: Save downloaded data to disk and read it from disk",
    "text": "Example 4: Save downloaded data to disk and read it from disk\nAll downloaded data can be saved to disk and later read from it. Simply specify the location on disk where data should be saved (or loaded from) via the data_folder argument of the request’s constructor. When executing the request’s get_data method, set the argument save_data to True.\nThis also means that in all the future requests for data, the request will first check the provided location if the data is already there, unless you explicitly demand to redownload the data.\n\nrequest_all_bands = SentinelHubRequest(\n    data_folder=\"test_dir\",\n    evalscript=evalscript_all_bands,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\n%%time\nall_bands_img = request_all_bands.get_data(save_data=True)\n\n\nprint(\n    \"The output directory has been created and a tiff file with all 13 bands was saved into the following structure:\\n\"\n)\n\nfor folder, _, filenames in os.walk(request_all_bands.data_folder):\n    for filename in filenames:\n        print(os.path.join(folder, filename))\n\n\n%%time\n# try to re-download the data\nall_bands_img_from_disk = request_all_bands.get_data()\n\n\n%%time\n# force the redownload\nall_bands_img_redownload = request_all_bands.get_data(redownload=True)\n\n\nExample 4.1: Save downloaded data directly to disk\nThe get_data method returns a list of numpy arrays and can save the downloaded data to disk, as we have seen in the previous example. Sometimes it is convenient to just save the data directly to disk. You can do that by using save_data method instead.\n\n%%time\nrequest_all_bands.save_data()\n\n\nprint(\n    \"The output directory has been created and a tiff file with all 13 bands was saved into the following structure:\\n\"\n)\n\nfor folder, _, filenames in os.walk(request_all_bands.data_folder):\n    for filename in filenames:\n        print(os.path.join(folder, filename))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-5-other-data-collections",
    "href": "notebook-samples/sentinelhub/process_request.html#example-5-other-data-collections",
    "title": "Sentinel Hub Process API",
    "section": "Example 5: Other Data Collections",
    "text": "Example 5: Other Data Collections\nThe sentinelhub-py package supports various data collections. The example below is shown for one of them, but the process is the same for all of them.\n\nNote:\nFor more examples and information check the tutorial about data collections and Sentinel Hub documentation about data collections.\n\n\nprint(\"Supported DataCollections:\\n\")\nfor collection in DataCollection.get_available_collections():\n    print(collection)\n\nFor this example let’s download the digital elevation model data (DEM). The process is similar as before, we just provide the evalscript and create the request. More data on the DEM data collection is available here. DEM values are in meters and can be negative for areas which lie below sea level, so it is recommended to set the output format in your evalscript to FLOAT32.\n\nevalscript_dem = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output:{\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32\n    }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM]\n}\n\"\"\"\n\n\ndem_request = SentinelHubRequest(\n    evalscript=evalscript_dem,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.DEM,\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\ndem_data = dem_request.get_data()\n\n\n# Plot DEM map\n# vmin = 0; cutoff at sea level (0 m)\n# vmax = 120; cutoff at high values (120 m)\nplot_image(dem_data[0], factor=1.0, cmap=plt.cm.Greys_r, vmin=0, vmax=120)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-6-multi-response-request-type",
    "href": "notebook-samples/sentinelhub/process_request.html#example-6-multi-response-request-type",
    "title": "Sentinel Hub Process API",
    "section": "Example 6 : Multi-response request type",
    "text": "Example 6 : Multi-response request type\nProcess API enables downloading multiple files in one response, packed together in a TAR archive.\nWe will get the same image as before, download in the form of digital numbers (DN) as a UINT16 TIFF file. Along with the image we will download the inputMetadata which contains the normalization factor value in a JSON format.\nAfter the download we will be able to convert the INT16 digital numbers to get the FLOAT32 reflectances.\n\nevalscript = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"],\n                units: \"DN\"\n            }],\n            output: {\n                bands: 3,\n                sampleType: \"INT16\"\n            }\n        };\n    }\n\n    function updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n        outputMetadata.userData = { \"norm_factor\":  inputMetadata.normalizationFactor }\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_multitype = SentinelHubRequest(\n    evalscript=evalscript,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response(\"default\", MimeType.TIFF),\n        SentinelHubRequest.output_response(\"userdata\", MimeType.JSON),\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\n# print out information\nmulti_data = request_multitype.get_data()[0]\nmulti_data.keys()\n\n\n# normalize image\nimg = multi_data[\"default.tif\"]\nnorm_factor = multi_data[\"userdata.json\"][\"norm_factor\"]\n\nimg_float32 = img * norm_factor\n\n\nplot_image(img_float32, factor=3.5, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-7-raw-dictionary-request",
    "href": "notebook-samples/sentinelhub/process_request.html#example-7-raw-dictionary-request",
    "title": "Sentinel Hub Process API",
    "section": "Example 7 : Raw dictionary request",
    "text": "Example 7 : Raw dictionary request\nAll requests so far were built with some helper functions. We can also construct a raw dictionary as defined in the API Reference, without these helper functions, so we have full control over building the request body.\n\nrequest_raw_dict = {\n    \"input\": {\n        \"bounds\": {\"properties\": {\"crs\": betsiboka_bbox.crs.opengis_string}, \"bbox\": list(betsiboka_bbox)},\n        \"data\": [\n            {\n                \"type\": \"S2L1C\",\n                \"dataFilter\": {\n                    \"timeRange\": {\"from\": \"2020-06-01T00:00:00Z\", \"to\": \"2020-06-30T00:00:00Z\"},\n                    \"mosaickingOrder\": \"leastCC\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": betsiboka_size[0],\n        \"height\": betsiboka_size[1],\n        \"responses\": [{\"identifier\": \"default\", \"format\": {\"type\": MimeType.TIFF.get_string()}}],\n    },\n    \"evalscript\": evalscript_true_color,\n}\n\n\n# create request\ndownload_request = DownloadRequest(\n    request_type=\"POST\",\n    url=\"https://services.sentinel-hub.com/api/v1/process\",\n    post_values=request_raw_dict,\n    data_type=MimeType.TIFF,\n    headers={\"content-type\": \"application/json\"},\n    use_session=True,\n)\n\n# execute request\nclient = SentinelHubDownloadClient(config=config)\nimg = client.download(download_request)\n\n\nplot_image(img, factor=3.5 / 255, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/process_request.html#example-8-multiple-timestamps-data",
    "href": "notebook-samples/sentinelhub/process_request.html#example-8-multiple-timestamps-data",
    "title": "Sentinel Hub Process API",
    "section": "Example 8 : Multiple timestamps data",
    "text": "Example 8 : Multiple timestamps data\nIt is possible to construct some logic in order to return data for multiple timestamps. By defining the time_interval parameter and some logic of splitting it, it is possible to create an SH reques per each “time slot” and then download the data from all the requests with the SentinelHubDownloadClient in sentinelhub-py. In this example we will create least cloudy monthly images for the year 2019.\nHowever, this is already a functionality built on top of this SH API package. We have extended the support for such usage in our package eo-learn. We recommend to use eo-learn for more complex cases where you need multiple timestamps or high-resolution data for larger areas.\n\nstart = datetime.datetime(2019, 1, 1)\nend = datetime.datetime(2019, 12, 31)\nn_chunks = 13\ntdelta = (end - start) / n_chunks\nedges = [(start + i * tdelta).date().isoformat() for i in range(n_chunks)]\nslots = [(edges[i], edges[i + 1]) for i in range(len(edges) - 1)]\n\nprint(\"Monthly time windows:\\n\")\nfor slot in slots:\n    print(slot)\n\n\ndef get_true_color_request(time_interval):\n    return SentinelHubRequest(\n        evalscript=evalscript_true_color,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.SENTINEL2_L1C,\n                time_interval=time_interval,\n                mosaicking_order=MosaickingOrder.LEAST_CC,\n            )\n        ],\n        responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n        bbox=betsiboka_bbox,\n        size=betsiboka_size,\n        config=config,\n    )\n\n\n# create a list of requests\nlist_of_requests = [get_true_color_request(slot) for slot in slots]\nlist_of_requests = [request.download_list[0] for request in list_of_requests]\n\n# download data with multiple threads\ndata = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=5)\n\n\n# some stuff for pretty plots\nncols = 4\nnrows = 3\naspect_ratio = betsiboka_size[0] / betsiboka_size[1]\nsubplot_kw = {\"xticks\": [], \"yticks\": [], \"frame_on\": False}\n\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows), subplot_kw=subplot_kw)\n\nfor idx, image in enumerate(data):\n    ax = axs[idx // ncols][idx % ncols]\n    ax.imshow(np.clip(image * 2.5 / 255, 0, 1))\n    ax.set_title(f\"{slots[idx][0]}  -  {slots[idx][1]}\", fontsize=10)\n\nplt.tight_layout()"
  },
  {
    "objectID": "notebook-samples/openeo/UDF.html",
    "href": "notebook-samples/openeo/UDF.html",
    "title": "User-Defined Functions (UDF)",
    "section": "",
    "text": "While openEO supports a wide range of pre-defined processes and allows to build more complex user-defined processes from them, you sometimes need operations or algorithms that are not (yet) available or standardized as openEO process. User-Defined Functions (UDF) is an openEO feature (through the run_udf process) that aims to fill that gap by allowing a user to express (a part of) an algorithm as a Python/R/… script to be run back-end side.\nThough several types of algorithms can be used as UDF applications, in this notebook, we showcase a simple example of how to work with UDF using the openEO Python Client library.\n\n# estabish connection to the backend and authenticate it\nimport openeo\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n\n# load collection\n\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\",\n                bands=[\"B04\", \"B03\", \"B02\"],\n                temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n                spatial_extent={\n                    \"west\": 5.05,\n                    \"south\": 51.21,\n                    \"east\": 5.1,\n                    \"north\": 51.23,\n                    \"crs\": \"EPSG:4326\",\n                },\n                max_cloud_cover=50,\n)\n\ncube = cube.reduce_dimension(dimension=\"t\", reducer=\"max\")\ncube\n\n\n    \n    \n        \n    \n    \n\n\nHere the UDF code shown in the following cell does the actual value rescaling.\n\n# Build a UDF object from an inline string with Python source code.\nudf = openeo.UDF(\n    \"\"\"\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    array.values = 0.0001 * array.values\n    return cube\n\"\"\"\n)\n\nUser can also load their UDF from a seperate file using openeo.UDF.from_file('my_udf.py') and apply it.\n\n# Apply the UDF to a cube.\nrescaled_cube = cube.apply(process=udf)\n\n\nrescaled_cube.download(\"output/rescale_s2.tiff\")\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"output/rescale_s2.tiff\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\nfig, ax = plt.subplots(figsize=(6, 2), dpi=150)\nax.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\n\nax.set_title(\"Rescaled Image\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "notebook-samples/openeo/UDP.html",
    "href": "notebook-samples/openeo/UDP.html",
    "title": "User-Defined Processes (UDP)",
    "section": "",
    "text": "openEO API allows processes to be chained together in a process graph to build a particular algorithm. Often, users have specific (sub)chains that reoccur in the same process graph or even in different process graphs or algorithms. Here user can store such (sub)chains on the back-end as a so-called user-defined process. This allows you to build your library of reusable building blocks. Ultimately, the openEO API allows you to publicly expose your user-defined process, so that other users can invoke it as a service.\nThis notebook provides a step-by-step guide on how to create your User-Defined Process (UDP) for Normalized Difference Water Index (NDWI) analysis. The guide covers the fundamental steps that need to be followed to create the UDP.\n\n# import necessary packages\n\nfrom openeo.processes import array_create\nfrom openeo.api.process import Parameter\nimport openeo\nimport json\n\n\n# establish a connection to the backend and authenticate\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nThe openEO Python client lets you define parameters as Parameter instances. In general you have to specify at least the parameter name, a description and a schema.\n\n# define input parameters\ntime_param = Parameter(\n    name=\"date\",\n    description=\"A date within wich you wish to load the Terrasope NDVI product.\",\n    schema={\"type\": \"string\"},\n)\nspatial_param = Parameter(\n    name=\"aoi\",\n    description=\"Spatial extent for area of interst to calculate ndvi\",\n    schema={\"type\": \"object\", \"subtype\": \"geojson\"},\n)\n\n\n# specify the collection with input as parameter variables that will be used in the process\n\nband = [\"B03\", \"B08\"]\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\",\n                temporal_extent=time_param,\n                spatial_extent=spatial_param,\n                bands=band,\n)\n\ncube = cube.max_time()\n\nThe NDWI is a vegetation index sensitive to the water content of vegetation and is complementary to the NDVI. High NDWI values show a high water content of the vegetation. \\[ \\mathrm{NDWI} = \\frac{\\mathrm{Green} - \\mathrm{NIR}}{\\mathrm{Green} + \\mathrm{NIR}} \\]\n\ngreen = cube.band(\"B03\")\nnir = cube.band(\"B08\")\n\nndwi = (green - nir) / (green + nir)\nndwi\n\n\n    \n    \n        \n    \n    \n\n\nWe can now store this as a user-defined process called NDWI on the back-end and pass Parameter objects\n\n# publishing the service\nprocess_name = \"NDWI\"\nconnection.save_user_defined_process(\n    user_defined_process_id=process_name,\n    process_graph=ndwi,\n    parameters=[time_param, spatial_param],\n    public=True,\n)\n\n\n    \n    \n        \n    \n    \n\n\nNow, let’s evaluate the user-defined processes we defined.\nTo use our custom NDWI process, we only have to specify a temporal and spatial extent, and let the predefined and default values do their work. We will use datacube_from_process() to construct a DataCube object which we can process further and download.\n\nbbox = {\"west\": 5.09, \"south\": 51.18, \"east\": 5.15, \"north\": 51.21, \"crs\": 4326}\ncreated_process = connection.datacube_from_process(\n    process_id=\"NDWI\", date=[\"2022-06-01\", \"2022-10-01\"], aoi=bbox\n)\n\n\ncreated_process.download(\"output/ndwi.tiff\")\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"output/ndwi.tiff\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\nfig, ax = plt.subplots(figsize=(6, 2), dpi=150)\nax.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\n\nax.set_title(\"NDWI\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "notebook-samples/openeo/basics.html",
    "href": "notebook-samples/openeo/basics.html",
    "title": "How to get started with openEO Platform: Basics",
    "section": "",
    "text": "Connect to openEO Platform and print list of available collections\n\nimport openeo\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n\n\nprint(connection.list_collection_ids())\n\n['EEA_VEGETATION_INDICES', 'SEASONAL_TRAJECTORIES', 'VEGETATION_PHENOLOGY_AND_PRODUCTIVITY_PARAMETERS_SEASON_1', 'ESA_WORLDCOVER_10M_2020_V1', 'ESA_WORLDCOVER_10M_2021_V2', 'SENTINEL3_OLCI_L1B', 'SENTINEL3_SLSTR', 'SENTINEL2_L1C', 'SENTINEL2_L2A', 'SENTINEL1_GRD', 'COPERNICUS_30']\n\n\nGet detailed information about a collection\n\nconnection.describe_collection(\"SENTINEL2_L2A\")\n\n\n    \n    \n        \n    \n    \n\n\nList processes that can be applied on the (EO) data\n\nprocesses_list = (connection.list_processes())\nprint(processes_list[:3])\n\n[{'categories': ['arrays'], 'description': 'Applies a process to each individual value in the array. This is basically what other languages call either a `for each` loop or a `map` function.', 'id': 'array_apply', 'links': [{'href': 'https://processes.openeo.org/1.2.0/examples/array_find_nodata.json', 'rel': 'example', 'title': 'Find no-data values in arrays', 'type': 'application/json'}, {'href': 'https://processes.openeo.org/1.2.0/examples/array_contains_nodata.json', 'rel': 'example', 'title': 'Check for no-data values in arrays', 'type': 'application/json'}], 'parameters': [{'description': 'An array.', 'name': 'data', 'schema': {'items': {'description': 'Any data type is allowed.'}, 'type': 'array'}}, {'description': 'A process that accepts and returns a single value and is applied on each individual value in the array. The process may consist of multiple sub-processes and could, for example, consist of processes such as ``abs()`` or ``linear_scale_range()``.', 'name': 'process', 'schema': {'parameters': [{'description': 'The value of the current element being processed.', 'name': 'x', 'schema': {'description': 'Any data type.'}}, {'description': 'The zero-based index of the current element being processed.', 'name': 'index', 'schema': {'minimum': 0, 'type': 'integer'}}, {'default': None, 'description': 'The label of the current element being processed. Only populated for labeled arrays.', 'name': 'label', 'optional': True, 'schema': [{'type': 'number'}, {'type': 'string'}, {'type': 'null'}]}, {'default': None, 'description': 'Additional data passed by the user.', 'name': 'context', 'optional': True, 'schema': {'description': 'Any data type.'}}], 'returns': {'description': 'The value to be set in the new array.', 'schema': {'description': 'Any data type.'}}, 'subtype': 'process-graph', 'type': 'object'}}, {'default': None, 'description': 'Additional data to be passed to the process.', 'name': 'context', 'optional': True, 'schema': {'description': 'Any data type.'}}], 'returns': {'description': 'An array with the newly computed values. The number of elements are the same as for the original array.', 'schema': {'items': {'description': 'Any data type is allowed.'}, 'type': 'array'}}, 'summary': 'Apply a process to each array element'}, {'categories': ['math &gt; trigonometric'], 'description': 'Computes the arc cosine of `x`. The arc cosine is the inverse function of the cosine so that *`arccos(cos(x)) = x`*.\\n\\nWorks on radians only.\\nThe no-data value `null` is passed through and therefore gets propagated.', 'examples': [{'arguments': {'x': 1}, 'returns': 0}], 'id': 'arccos', 'links': [{'href': 'http://mathworld.wolfram.com/InverseCosine.html', 'rel': 'about', 'title': 'Inverse cosine explained by Wolfram MathWorld'}], 'parameters': [{'description': 'A number.', 'name': 'x', 'schema': {'type': ['number', 'null']}}], 'returns': {'description': 'The computed angle in radians.', 'schema': {'type': ['number', 'null']}}, 'summary': 'Inverse cosine'}, {'categories': ['math &gt; trigonometric'], 'description': 'Computes the inverse hyperbolic cosine of `x`. It is the inverse function of the hyperbolic cosine so that *`arcosh(cosh(x)) = x`*.\\n\\nWorks on radians only.\\nThe no-data value `null` is passed through and therefore gets propagated.', 'examples': [{'arguments': {'x': 1}, 'returns': 0}], 'id': 'arcosh', 'links': [{'href': 'http://mathworld.wolfram.com/InverseHyperbolicCosine.html', 'rel': 'about', 'title': 'Inverse hyperbolic cosine explained by Wolfram MathWorld'}], 'parameters': [{'description': 'A number.', 'name': 'x', 'schema': {'type': ['number', 'null']}}], 'returns': {'description': 'The computed angle in radians.', 'schema': {'type': ['number', 'null']}}, 'summary': 'Inverse hyperbolic cosine'}]\n\n\nInspect one process closer\n\nconnection.describe_process(\"add\")"
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html",
    "href": "notebook-samples/openeo/Batch_job.html",
    "title": "How to execute large jobs?: Using Batch Job",
    "section": "",
    "text": "Most of the simple, basic openEO usage examples show synchronous downloading of results: you submit a process graph with a (HTTP POST) request and receive the result as direct response of that same request. This only works properly if the processing doesn’t take too long (order of seconds, or a couple of minutes at most).\nFor the heavier work (larger regions of interest, larger time series, more intensive processing, …) you have to use batch jobs.\nThis notebook shows how to programmatically create and interact with batch job using the openEO Python client library.\n\nimport openeo\n\n# connect to the backend and authenticate\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;\n\n\n\n# load your data collection\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\",\n                bands=[\"B04\", \"B03\", \"B02\"],\n                temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n                spatial_extent={\n                    \"west\": 3.202609,\n                    \"south\": 51.189474,\n                    \"east\": 3.254708,\n                    \"north\": 51.204641,\n                    \"crs\": \"EPSG:4326\",\n    },\n    max_cloud_cover=50,\n)\n\ncube = cube.max_time()\n\n\n# Store raster data as GeoTIFF files\ncube = cube.save_result(format=\"GTiff\")\n\nWhile not necessary, it is also recommended to give your batch job a descriptive title so it’s easier to identify in your job listing.\n\njob = cube.execute_batch()\n\n0:00:00 Job 'j-e6e8567c637443298bca57e2cfda0e3f': send 'start'\n0:00:11 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:16 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:23 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:31 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:41 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:00:53 Job 'j-e6e8567c637443298bca57e2cfda0e3f': queued (progress N/A)\n0:01:08 Job 'j-e6e8567c637443298bca57e2cfda0e3f': finished (progress N/A)\n\n\nAn additional but longer way of executing the job is following a couple of steps starting with creating it using create_job() then starting it with either start_job() or using start_and_wait().\nA batch job on a back-end is fully identified by its job_id.\n\njob.job_id\n\n'j-e6e8567c637443298bca57e2cfda0e3f'\n\n\nDepending on your situation or use case: make sure to properly take note of the batch job id. It allows you to “reconnect” to your job on the back-end, even if it was created at another time, by another script/notebook or even with another openEO client. Then you can later use use Connection.job(\"your job id\") to create a BatchJob object for an existing batch job.\nA batch job typically takes some time to finish, and you can check its status with the status() method.\n\njob.status()\n\n'finished'\n\n\nBatch job logs can be fetched with job.logs(). If you prefer a graphical, web-based interactive environment to manage and monitor your batch jobs, feel free to switch to an openEO web editor like openeo.dataspace.copernicus.eu at any time.\n\njob.logs()\n\n\n    \n    \n        \n    \n    \n\n\nOnce a batch job is finished you can get a handle to the results (which can be a single file or multiple files) with get_results().\n\nresults = job.get_results()\n\n\nresults\n\n\n    \n    \n        \n    \n    \n\n\nIn the general case, when you have one or more result files (also called “assets”), the easiest option to download them is using download_files() (plural) where you just specify a download folder (otherwise the current working directory will be used by default).\n\nresults.download_files(\"output/out\")\n\n[WindowsPath('output/out/openEO.tif'),\n WindowsPath('output/out/job-results.json')]\n\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"output/out/openEO.tif\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\nfig, ax = plt.subplots(figsize=(6, 2), dpi=150)\nax.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\n\nax.set_title(\"RGB Image\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "notebook-samples/openeo/NDVI_Timeseries.html",
    "href": "notebook-samples/openeo/NDVI_Timeseries.html",
    "title": "NDVI Timeseries",
    "section": "",
    "text": "This notebook presents an application case, that demonstrates how to display the NDVI (Normalized Difference Vegetation Index) timeseries for specific fields. The case study showcases the process of selecting the fields and generating average NDVI timeseries data for analysis and visualization.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shapely.geometry\nimport json\nimport scipy.signal\nimport numpy as np\n\nimport openeo\nfrom openeo.rest.conversions import timeseries_json_to_pandas\n\n\n# defining the plotting function\n\nDEFAULT_FIGSIZE = (5, 4)\n\n\ndef plot_timeseries(filename):\n    \"\"\"Helper to plot the timeseries directly from JSON file\"\"\"\n    with open(filename) as f:\n        ts = timeseries_json_to_pandas(json.load(f)).dropna()\n    ts.index = pd.to_datetime(ts.index)\n    fig, ax = plt.subplots(figsize=DEFAULT_FIGSIZE)\n    ts.plot(marker=\"o\", ax=ax)\n    ax.set_title(\"Average NDVI\")\n    ax.set_ylabel(\"NDVI\")\n    ax.set_ylim(0, 1)\n    ax.legend(title=\"parcel id\", loc=\"lower left\", ncol=2)\n\n\n# connect to the backend and authenticate\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nlet’s calculate a time series of the average NDVI in a couple of fields in this area.\nFirst, load the fields as shapely geometries:\n\nfields_geojson = '{\"type\": \"GeometryCollection\", \"geometries\": [{\"type\": \"Polygon\", \"coordinates\": [[[5.055945487931457, 51.222709834076504], [5.064972484168688, 51.221122565090525], [5.064972484168688, 51.221122565090525], [5.067474954083448, 51.218249806779134], [5.064827929485983, 51.21689628072789], [5.05917785594747, 51.217191909908095], [5.053553857094518, 51.21807492332223], [5.055945487931457, 51.222709834076504]]]}, {\"type\": \"Polygon\", \"coordinates\": [[[5.063345886679116, 51.23087606640057], [5.06604742694687, 51.22886710731809], [5.070627820472246, 51.22874440121892], [5.068403609708207, 51.22657208381529], [5.064823257492447, 51.22676051738515], [5.064892324615199, 51.2283032878514], [5.063641745941974, 51.2285757299238], [5.062340811262595, 51.227722351687945], [5.06076005158084, 51.228042312276536], [5.063345886679116, 51.23087606640057]]]}, {\"type\": \"Polygon\", \"coordinates\": [[[5.07163184674986, 51.23481147556147], [5.076706025697324, 51.23317590781036], [5.077828303041866, 51.233226237184724], [5.078024733866917, 51.23263978271262], [5.080771081607657, 51.23259097170763], [5.083734842574312, 51.23530464074437], [5.080957826735458, 51.23646091560258], [5.079752631651647, 51.23519531038643], [5.077238400183506, 51.23490534677628], [5.072856439300575, 51.23593546777778], [5.07163184674986, 51.23481147556147]]]}, {\"type\": \"Polygon\", \"coordinates\": [[[5.083897244679042, 51.23510639883143], [5.081302408741335, 51.232922477780846], [5.082963802194108, 51.233146058575876], [5.084497702305552, 51.232672717580655], [5.085732850338428, 51.2340852086282], [5.083897244679042, 51.23510639883143]]]}]}'\nfields = shapely.geometry.shape(json.loads(fields_geojson))\nfields\n\n\n\n\nWe want to calculate the NDVI for a larger time window covering of a couple of months.\nAlso note that we don’t have to specify a bounding box explicitly when loading the cube, because we will pass the desired fields in a next step, and the backend will limit the data loading to those areas appropriately.\n\ndates = (\"2020-06-01\", \"2020-10-01\")\n\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\", temporal_extent=dates, bands=[\"B04\", \"B08\", \"SCL\"]\n)\n\nred = cube.band(\"B04\")\nnir = cube.band(\"B08\")\nndvi = (nir - red) / (nir + red)\n\nWith the DataCube.aggregate_spatial() method , we can calculate the mean NDVI for each of the fields.\n\ntimeseries = ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\")\n\nWe trigger execution by downloading the result. Because DataCube.aggregate_spatial() returns a timeseries (instead of raster data), we download it in JSON format.\n\ntimeseries.download(\"output/timeseries.json\")\n\n\nplot_timeseries( \"output/timeseries.json\")\n\n\n\n\nThe result above is a good start, but needs some work: there are quite some outliers and zero’s that don’t look right.\nTo filter out the cloudy pixels: we create a cloud mask based on the scene classification band on which gaussian filter is applied.\nBy convolving the mask with the kernel, the values of neighboring pixels are taken into account when determining whether a pixel should be classified as cloud or non-cloud. This improves the accuracy of the cloud mask by considering the spatial context of each pixel in relation to its surroundings.\nTherefore, we need a simple gaussian kernel:\n\ng = scipy.signal.windows.gaussian(11, std=1.6)\nkernel = np.outer(g, g)\nkernel = kernel / kernel.sum()\nim = plt.imshow(kernel)\nplt.colorbar(im)\n\n&lt;matplotlib.colorbar.Colorbar at 0x7f413782b190&gt;\n\n\n\n\n\n\nclassification = cube.band(\"SCL\")\nmask = ~((classification == 4) | (classification == 5))\nmask = mask.apply_kernel(kernel)\nmask = mask &gt; 0.1\n\nmasked_ndvi = ndvi.mask(mask)\n\n\nmasked_timeseries = masked_ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\")\nmasked_timeseries.download(\"output/timeseries-masked.json\")\n\n\nplot_timeseries( \"output/timeseries-masked.json\")\n\n\n\n\n\nTimeseries Smoothing\nFurthermore with an aim to improve the plot’s smoothness by using a kernel, in this notebook we define a kernel as an smoothening UDF. The kernel will help to reduce noise and fluctuations in the data, resulting in a smoother and more accurate representation of the NDVI timeseries.\nHere We define an UDF (user-defined function) to interpolate the missing values and to apply a Savitzky-Golay filter for smoothing of the timeseries, using scipy.signal.savgol_filter.\n\nudf = openeo.UDF(\n    \"\"\"\nfrom scipy.signal import savgol_filter\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    filled = array.interpolate_na(dim='t')\n    smoothed_array = savgol_filter(filled.values, 5, 2, axis=0)\n    return DataCube(xarray.DataArray(smoothed_array, dims=array. dims,coords=array.coords))\n\"\"\"\n)\n\nsmoothed_ndvi = masked_ndvi.apply_dimension(code=udf, dimension=\"t\")\n\nNow, aggregate this again per field and get the time series.\n\nsmoothed_timeseries = smoothed_ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\")\n\n\nsmoothed_timeseries.download(\"output/timeseries-smoothed.json\")\n\n\nplot_timeseries(\"output/timeseries-smoothed.json\")"
  },
  {
    "objectID": "notebook-samples/openeo/Load_Collection.html",
    "href": "notebook-samples/openeo/Load_Collection.html",
    "title": "How to load a data collection?",
    "section": "",
    "text": "This notebook provides a detailed guide on how to load a data collection, including all the necessary steps involved. Additionally, it will explain how to authenticate your account to ensure secure access to the data.\n\n# import necessary packages\n\nimport openeo\n\n# connect to the backend\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n\nTo verify whether the users is authenticated, they can check if connection to the backend is authenticated.\n\n# check your connection details\nconnection\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with NullAuth&gt;\n\n\nIf the user’s connection to the backend returns a NullAuth status, it means that they are not authenticated. In this case, they can authenticate themselves by using the authenticate_oidc() method.\n\n# authenticate and recheck for your connection\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;\n\n\nAfter authentication to load the data collection, the next step is to filter it based on the specific requirements or criteria of the user. This involves narrowing down the dataset to a particular period or geographic location.\n\n# load collection\n\ncube = connection.load_collection(\n                \"SENTINEL2_L2A\",\n                bands=[\"B04\", \"B03\", \"B02\", \"SCL\"],\n                temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n                spatial_extent={\n                    \"west\": 3.202609,\n                    \"south\": 51.189474,\n                    \"east\": 3.254708,\n                    \"north\": 51.204641,\n                    \"crs\": \"EPSG:4326\",\n                },\n                max_cloud_cover=50,\n)\n\nIn this step we will apply cloud masking to filter out cloud pixels to make the result more usable. It is very common for earth observation data to have separate masking layers that for instance indicate whether a pixel is covered by a (type of) cloud or not. For Sentinel-2, one such layer is the “scene classification” layer generated by the Sen2Cor algorithm. In the following cells, we will use this layer to mask out unwanted data.\n\n# Select the \"SCL\" band from the data cube\nscl_cube = cube.band(\"SCL\")\n\n# Build mask to mask out everything but cloud\nmask = (scl_cube == 7) | (scl_cube == 8)\n\nBefore we can apply this mask to the cube we have to resample it, as the “SCL” layer has a “ground sample distance” of 20 meter, while it is 10 meter for the “B02”, “B03” and “B04” bands. We can easily do the resampling by referring directly to the cube.\n\nmask_resampled = mask.resample_cube_spatial(cube)\n\n# Apply the mask to the `evi_cube`\ncube_masked = cube.mask(mask_resampled)\n\n\n# Because GeoTIFF does not support a temporal dimension, we first eliminate it by taking the temporal maximum value for each pixel\n\nfinal_image = cube_masked.max_time()\nimage = cube.max_time()\n\nTo complete the data analysis process, the final step involves downloading the filtered data. This can be done in two ways: synchronously or through the batch job-based method. Synchronous downloading allows the user to download the data immediately, whereas batch job-based downloading enables the user to download the data in batches or at a scheduled time. The choice of method depends on the user’s preference and the size of the dataset. In this example we follow the first method, i.e., Synchronous download.\n\n# # download the RGB image\n# final_image.download(\"output/RGB_masked.tiff\")\n# image.download(\"output/RGB_withoutmask.tiff\")\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"output/RGB_withoutmask.tiff\").read()\nmasked_img = rasterio.open(\"output/RGB_masked.tiff\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\n# Assuming you have two images img1 and img2\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2), dpi=150)\n\n# Plotting the first image on the left subplot\nax1.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\nax1.set_title(\"RGB Image\")\n\n# Plotting the second image on the right subplot\nax2.imshow(normalizeimg(np.moveaxis(masked_img, 0, -1)))\nax2.set_title(\"Masked RGB Image\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "logos.html",
    "href": "logos.html",
    "title": "Documentation",
    "section": "",
    "text": "```{=html}\n&lt;div class=\"logos\"&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/EU.svg\"&gt;\n    &lt;/a&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/copernicus-white-BL.svg\"&gt;\n    &lt;/a&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/ESA_White.svg\"&gt;\n    &lt;/a&gt;\n    \n    ```"
  },
  {
    "objectID": "Registration.html",
    "href": "Registration.html",
    "title": "User registration and authentication",
    "section": "",
    "text": "This section provides information on how to register and authenticate on the Copernicus Data Space Ecosystem.\n\n\nGo to website and click “login” in the top right corner.\n\n\nYou will now get the Copernicus Data Space Ecosystems login form. Click “here” in the bottom.\n\n\nYou will now get the Copernicus Data Space Ecosystems registration form. Fill in all required fields (all except Thematic activity and Purpose of use), you can fill in optional fields, next you have to accept terms and conditions and you can accept other consents (they are optional) and then click “Register”.\n\n\n\n\n\nWhen you register, you will be asked to verify your email address. You should receive a verification email.\n\n\nWhen you open an email you need to click “Verify email address”.\n\n\n\nEmail\n\n\nNow you can log in with your credentials (providing Email and Password).\nIf you have an issue with registering or you want to deregister, please contact us directly."
  },
  {
    "objectID": "Registration.html#step-1-registration",
    "href": "Registration.html#step-1-registration",
    "title": "User registration and authentication",
    "section": "",
    "text": "Go to website and click “login” in the top right corner.\n\n\nYou will now get the Copernicus Data Space Ecosystems login form. Click “here” in the bottom.\n\n\nYou will now get the Copernicus Data Space Ecosystems registration form. Fill in all required fields (all except Thematic activity and Purpose of use), you can fill in optional fields, next you have to accept terms and conditions and you can accept other consents (they are optional) and then click “Register”."
  },
  {
    "objectID": "Registration.html#step-2-e-mail-verification",
    "href": "Registration.html#step-2-e-mail-verification",
    "title": "User registration and authentication",
    "section": "",
    "text": "When you register, you will be asked to verify your email address. You should receive a verification email.\n\n\nWhen you open an email you need to click “Verify email address”.\n\n\n\nEmail\n\n\nNow you can log in with your credentials (providing Email and Password).\nIf you have an issue with registering or you want to deregister, please contact us directly."
  },
  {
    "objectID": "cdse_doc.html",
    "href": "cdse_doc.html",
    "title": "Welcome to the Copernicus Data Space Ecosystem documentation portal",
    "section": "",
    "text": "Welcome to the Copernicus Data Space Ecosystem documentation portal\n Here you can explore our detailed documentation and learn more about the available data, APIs and applications.\nThe ecosystem will be continuously upgraded over the upcoming months, see the timelines in the evolution roadmap. Our documentation will be updated accordingly.\n\nIn this documentation, you can find more information on:\n\nData providing you with details about the available Earth Observation data and products.\nAPIs helping you to find the right interfaces to access catalogs, list collections and process data.\nApplications reducing your efforts to search, visualize, modify and download images in an easy and user-friendly way. \n\nQuick answers can be found in our FAQ.\nIf you have questions that are not answered on this portal, please contact our Support."
  },
  {
    "objectID": "Home.html",
    "href": "Home.html",
    "title": "Welcome to the Copernicus Data Space Ecosystem documentation portal",
    "section": "",
    "text": "Welcome to the Copernicus Data Space Ecosystem documentation portal\n Here you can explore our detailed documentation and learn more about the available data, APIs and applications.\nThe ecosystem will be continuously upgraded over the upcoming months, see the timelines in the evolution roadmap. Our documentation will be updated accordingly.\n\nIn this documentation, you can find more information on:\n\nData providing you with details about the available Earth Observation data and products.\nAPIs helping you to find the right interfaces to access catalogs, list collections and process data.\nApplications reducing your efforts to search, visualize, modify and download images in an easy and user-friendly way. \n\nQuick answers can be found in our FAQ.\nIf you have questions that are not answered on this portal, please contact our Support."
  },
  {
    "objectID": "Data.html",
    "href": "Data.html",
    "title": "Data",
    "section": "",
    "text": "This section provides an overview of the EO data available from Copernicus Data Space Ecosystem.\nThe data offer will gradually extend starting from January 2023\nFor the latest information about available satellite data, users and stakeholders can follow them in Copernicus Sentinel Operations Dashboard."
  },
  {
    "objectID": "FAQ.html",
    "href": "FAQ.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "What is the phase-out timing for the current Copernicus Data Hub distribution services?\n\n\nThe legacy Copernicus Data Hub distribution service will remain in operations until end of June 2023 to allow a smooth migration to the new Copernicus Data Access service by all user communities. The Copernicus Data Hub distribution service will continue offering access to Sentinel data with a gradual ramp-down of the operations capacity and data offering until end of September 2023.\n\n\n\n\nComparing with existing legacy Copernicus Data Hub, what will be the other free services other than stac/cog?\n\n\nCompared to existing Copernicus Data Hub, there will indeed be additional APIs - OGC interfaces (WMS, WMTS, WCS), OpenEO, Sentinel Hub API, S3, and others. Please refer to the Roadmap for more info on the timing of these interfaces.\n\n\n\n\nIs there an end user document available online that describes the specific data products available and specific services?\n\n\nThe user level details for every service and dataset will be provided in this documentation. With every service and dataset embedded into the ecosystem, this documentation will be updated accordingly.\n\n\n\n\nHow long is the project timescale in total ?\n\n\nThe time scale of the project is 6 years (i.e., to the end of 2028) with an optional extension up to 10 years (i.e., 2032).\n\n\n\n\nCan anyone outside from Europe have free access to any data?\n\n\nYes, data and services will be available to users worldwide.\n\n\n\n\n\n\n\nWhat data will be offered online and what is the timeline for the following months?\n\n\nFor the details on the data offer and timing, we would like to refer to the Roadmap\n\n\n\n\nIs there a page that indicates anomalies with the datasets?\n\n\nThe Copernicus Operations Dashboard provides details of events over the past three months that have impact on the completeness of the data production, such as planned calibration activities, manoeuvrers, or anomalies. The information of which data is affected is included.\n\n\n\n\nWith regard to cloud native formats/interfaces, will the data also be available in the original data formats (e.g. for data downloading)?\n\n\nYes, data will also be available in original data formats (i.e. .SAFE).\n\n\n\n\nAt the moment some of the data are delivered in Jpeg2000, is there any plan to abandon that format for the COG?\n\n\nThere is currently no plan to convert Sentinel-2 in COGs. However, there is a parallel activity happening within ESA to define format evolution for all Sentinels which will be followed, once decisions are taken. But this is not something that is happening on the short term.\n\n\n\n\nWill data, such as Sentinel-2, be processed to a consistent version?\n\n\nThe Sentinel-2 data will be available at the latest processing baseline. And with the reprocessing of Sentinel-2 happening in parallel (out of scope of this project), these will become available on this service as well.\n\n\n\n\nIs it possible to download a subset of data corresponding to an AOI, instead of the whole image?\n\n\nYes, you will be able to download a subset of data, either using S3 interface, or dedicated APIs, i.e. Sentinel Hub, OpenEO when they become available. See Roadmap section of the documentation.\n\n\n\n\nAre the data offered via Cloud Optimized Geotiffs (also Level 1)?\n\n\nSentinel-1 GRD data will be available in COG format. Sentinel-2 will stay in JP2 for the moment, as it is a similarly performant cloud optimised format.\n\n\n\n\nWhen “on-line data” is mentioned, does that mean the data are not on tape?\n\n\nThe “on-line data” or IAD we are referring to, are indeed not on the tapes. Tapes will still be there for redundancy reasons.\n\n\n\n\nCan we download the data acquired by all Sentinel missions (1, 2, 3, 5P, 6) and the other satellites (e.g. Meteosat) via the new interface? Some missions are not managed by ESA, but by EUMETSAT for example.\n\n\nInitialy Sentinel 1, Sentinel 2, Sentinel 3 and Sentinel 5P data up to L2 products will be available. Sentinel 6 data and data from Meteosat are currently not in the roadmap of the project. However access to Copernicus Contributing Missions CORE Datasets, Digital Elevation Models, data from Copernicus Services and additional data sets such as Landsat and ENVISAT and Belgian Collaborative Ground Segment hosted data are planned in the future. The Data Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data will become available.\n\n\n\n\nWill it still be the case that data is labelled as “on/offline” on the current legacy portal?\n\n\nThe vast majority of the data will be on-line : all Sentinel-2 L1C/L2A, Sentinel-1 SLC/GRD and just about all other relevant data collections.\n\n\n\n\nWill the new interface offer EO ready-to-use products or just L0 and L1 data?\n\n\nUp to L2 products will be available. The Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data become available.\n\n\n\n\nWhat is the highest resolution SAR data available in Copernicus Data Space Ecosystem?\n\n\nThe Sentinel-1 SAR achieves a spatial resolution of approximately 5 by 20 m. More info can be found here: https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions\n\n\n\n\n\n\n\nWill there be an integrated free and commercial offering to support/encourage the transfer of the users from “try basics for free towards paid subscriptions”?\n\n\nYes, there will be a common user identity, which will allow registered users to seamlessly transfer between systems. This will also extend to other systems that will be added to the free tier to the commerical tier ecosystem in the future, assuming they will integrate it.\n\n\n\n\nWhen we develop an EO ready-to-use product, could we integrate it into the interface and ask the payment from clients?\n\n\nYes, commercial services can be built on top, similar to Copernicus open license.\n\n\n\n\nCan the user come with wish-list to services data products?\n\n\nUser can come with suggestions to improve or expand the service portfolio. A user forum will be set up and released by July to accommodate this.\n\n\n\n\nAre you going to develop new services on DAS after July 2023?\n\n\nYes, a marketplace will be available where new Third party services will be able to onboard from July onwards to expand the ecosystem.\n\n\n\n\nIs there any limitation on the max number of downloads at one time?\n\n\nYes, there will be quotas and constraints for different services.\n\n\n\n\nIs it possible to download Sentinel-2 data for a large area at a high resolution in Copernicus Data Space Browser?\n\n\nDepending on your use, we suggest to use the high-res print (via the high-res print tab) where you will get large areas in a high resolution (the data is though not georeferenced) or if you need georeferenced data, split your area in several smaller images that you download or choose a bit lower resolution to stay within the limits of 2500px.\n\n\n\n\nCan you provide detailed information regarding the quotas and limits for accessing data and using the services through your platform?\n\n\nWe understand the importance of knowing the limitations and restrictions imposed on the usage of our services. For detailed information about the quotas, we recommend referring to the Service Description and Evolution document available on our documentation portal. You can find the document at https://documentation.dataspace.copernicus.eu/Roadmap.html . The quotas information can be found in Annex B.\n\n\n\n\n\n\n\nWill there be an integrated free and commercial offering to support/encourage the transfer of the users from “try basics for free towards paid subscriptions”?\n\n\nYes, there will be a common user identity, which will allow registered users to seamlessly transfer between systems. This will also extend to other systems that will be added to the free tier to the commerical tier ecosystem in the future, assuming they will integrate it.\n\n\n\n\nIf I’m having troubles with registering, what can I do?\n\n\nPlease e-mail the help-login@dataspace.copernicus.eu address for direct support on this matter.\n\n\n\n\n\n\n\nSNAP/gpt processing codes can be used in these on-line and cloud processing services?\n\n\nSNAP is integrated in cloud environment, and there will even be some dedicated on-demand services based on SNAP (i.e. S1 processing to coherence, etc).\n\n\n\n\nIs a STAC catalog planned ? Will the data be accessible on cloud object storage (S3)?\n\n\nSTAC Catalog API is indeed planned. Note that the phase-in will take from end of January to July 2023. So services will be added during this timeline, not everything will be available at the beginning. All the data will be available over S3 as well.\n\n\n\n\nWill LTA process be discontinued when all archived data become online?\n\n\nThere will still be services available for so called “deferred data access” : data collections that are not commonly used. That said, all most relevant collections will be available on-line. The Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data become available.\n\n\n\n\nWill the platform use STAC standards?\n\n\nYes, there will be STAC compliant Catalog API, as well as STAC items for inpidual products.\n\n\n\n\nAny plan to offer the Pangeo platform for a “pythonist”?\n\n\nThis is currently not in the offer or roadmap.\n\n\n\n\nHow do I generate S3 access and secret keys?\n\n\nYou can request such credentials as the guided in  https://documentation.dataspace.copernicus.eu/APIs/S3.html\n\n\n\n\nWhich one amongst the 4 catalog APIs (OData, STAC, OpenSearch, Sentinel Hub catalogue ) is updated first when new products are published?\n\n\nOpenSearch, OData and STAC catalog APIs all use the same backend database. Sentinel Hub catalog API contains a subset of the collections, hence it works only for the ones that have been imported to Sentinel Hub, Therefore there is no first updated one.\n\n\n\n\nWhat is the limitation of the number of requests that I can do at the time?\n\n\nFor detailed information about the limits, we recommend referring to the Service Description and Evolution document available on our documentation portal. You can find the document at https://documentation.dataspace.copernicus.eu/Roadmap.html. The quotas information can be found in Annex B.\n\n\n\n\nCan I connect directly to the S3 bucket using AWS S3 commands with the S3 keys provided or do I have to use “s3cmd” to download images?\n\n\nYes, you can connect to S3 bucket using AWS S3 connection. However some functionality may not be supported. It is recommended to use the ‘s3cmd’ command to download products.\n\n\n\n\nDo you have to authenticate for requesting through OpenSearch API?\n\n\nThere’s no need to use any user or authentication when you want to search. User authentication is required for downloading products.\n\n\n\n\nCan we use the Sentinel Hub bucket and fetch the products based on the id we fetched from OpenSearch API?\n\n\nYou can use Sentinel Hub bucket in addition to some programming tools by providing product ID obtained using OpenSearch API or OData of the Copernicus Dataspace Ecosystem.\n\n\n\n\nWhat is the benefit of fetching imagery from Copernicus Dataspace S3 bucket?\n\n\nDownloading products via S3 is faster as it delivers products as an .zip archive, skipping the need of zipper.\n\n\n\n\nOn which region resides the Copernicus Dataspace S3 bucket?\n\n\nRepo is located in Warsaw/Poland.\n\n\n\n\nHow can we search for the product in S3 bucket?\n\n\nSearching via ID or product name in the OpenSearch or OData will give the S3 path to the product in response.\n\n\n\n\n\n\n\nIs there any difference between EU users and non-EU users?\n\n\nThere is no difference between EU users and non-EU users. That said, there will be a continuity of the accounts with higher throughput, managed by ESA (i.e. Copernicus Services, International Hub, etc.).\n\n\n\n\nWhich distribution channels will be available for high-throughput data access? I assume the public side (dataspase.copernicus.eu) has a bandwidth limitation. Or does the public side have user tiers, or is high-throughput data transfer (such as https://creodias.eu/remote-transfer-for-eodata ) only a paid service?\n\n\nAll distribution options (i.e. OData, S3, Sentinel Hub,..) will be constrained with user quotas, which includes both bandwidth limitation, as well as monthly limits.\n\n\n\n\nCan you give indictions about the cost of the “extra” services?\n\n\nPricing will be published soon.\n\n\n\n\n This December advertisement of DAS says that “For those interested in processing, there will be scalable cloud resources available, optimized for EO tasks”. Does this refer to the current CreoDIAS resources, or something completely new that hasn’t been addressed yet? \n\n\nScalable cloud resources will be part of the commercial offering and can be obtained at CREODIAS in first instance. ICT-wise, there will be two options, including Open Telekom Cloud.\n\n\n\n\nAre there tutorials (online & physical meetings) to use the new interface?\n\n\nTutorials will be added to the documentation in due time explaining the usage of the different interfaces. We will also be present on different conferences explaining the service & ecosystem."
  },
  {
    "objectID": "FAQ.html#general",
    "href": "FAQ.html#general",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "What is the phase-out timing for the current Copernicus Data Hub distribution services?\n\n\nThe legacy Copernicus Data Hub distribution service will remain in operations until end of June 2023 to allow a smooth migration to the new Copernicus Data Access service by all user communities. The Copernicus Data Hub distribution service will continue offering access to Sentinel data with a gradual ramp-down of the operations capacity and data offering until end of September 2023.\n\n\n\n\nComparing with existing legacy Copernicus Data Hub, what will be the other free services other than stac/cog?\n\n\nCompared to existing Copernicus Data Hub, there will indeed be additional APIs - OGC interfaces (WMS, WMTS, WCS), OpenEO, Sentinel Hub API, S3, and others. Please refer to the Roadmap for more info on the timing of these interfaces.\n\n\n\n\nIs there an end user document available online that describes the specific data products available and specific services?\n\n\nThe user level details for every service and dataset will be provided in this documentation. With every service and dataset embedded into the ecosystem, this documentation will be updated accordingly.\n\n\n\n\nHow long is the project timescale in total ?\n\n\nThe time scale of the project is 6 years (i.e., to the end of 2028) with an optional extension up to 10 years (i.e., 2032).\n\n\n\n\nCan anyone outside from Europe have free access to any data?\n\n\nYes, data and services will be available to users worldwide."
  },
  {
    "objectID": "FAQ.html#data",
    "href": "FAQ.html#data",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "What data will be offered online and what is the timeline for the following months?\n\n\nFor the details on the data offer and timing, we would like to refer to the Roadmap\n\n\n\n\nIs there a page that indicates anomalies with the datasets?\n\n\nThe Copernicus Operations Dashboard provides details of events over the past three months that have impact on the completeness of the data production, such as planned calibration activities, manoeuvrers, or anomalies. The information of which data is affected is included.\n\n\n\n\nWith regard to cloud native formats/interfaces, will the data also be available in the original data formats (e.g. for data downloading)?\n\n\nYes, data will also be available in original data formats (i.e. .SAFE).\n\n\n\n\nAt the moment some of the data are delivered in Jpeg2000, is there any plan to abandon that format for the COG?\n\n\nThere is currently no plan to convert Sentinel-2 in COGs. However, there is a parallel activity happening within ESA to define format evolution for all Sentinels which will be followed, once decisions are taken. But this is not something that is happening on the short term.\n\n\n\n\nWill data, such as Sentinel-2, be processed to a consistent version?\n\n\nThe Sentinel-2 data will be available at the latest processing baseline. And with the reprocessing of Sentinel-2 happening in parallel (out of scope of this project), these will become available on this service as well.\n\n\n\n\nIs it possible to download a subset of data corresponding to an AOI, instead of the whole image?\n\n\nYes, you will be able to download a subset of data, either using S3 interface, or dedicated APIs, i.e. Sentinel Hub, OpenEO when they become available. See Roadmap section of the documentation.\n\n\n\n\nAre the data offered via Cloud Optimized Geotiffs (also Level 1)?\n\n\nSentinel-1 GRD data will be available in COG format. Sentinel-2 will stay in JP2 for the moment, as it is a similarly performant cloud optimised format.\n\n\n\n\nWhen “on-line data” is mentioned, does that mean the data are not on tape?\n\n\nThe “on-line data” or IAD we are referring to, are indeed not on the tapes. Tapes will still be there for redundancy reasons.\n\n\n\n\nCan we download the data acquired by all Sentinel missions (1, 2, 3, 5P, 6) and the other satellites (e.g. Meteosat) via the new interface? Some missions are not managed by ESA, but by EUMETSAT for example.\n\n\nInitialy Sentinel 1, Sentinel 2, Sentinel 3 and Sentinel 5P data up to L2 products will be available. Sentinel 6 data and data from Meteosat are currently not in the roadmap of the project. However access to Copernicus Contributing Missions CORE Datasets, Digital Elevation Models, data from Copernicus Services and additional data sets such as Landsat and ENVISAT and Belgian Collaborative Ground Segment hosted data are planned in the future. The Data Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data will become available.\n\n\n\n\nWill it still be the case that data is labelled as “on/offline” on the current legacy portal?\n\n\nThe vast majority of the data will be on-line : all Sentinel-2 L1C/L2A, Sentinel-1 SLC/GRD and just about all other relevant data collections.\n\n\n\n\nWill the new interface offer EO ready-to-use products or just L0 and L1 data?\n\n\nUp to L2 products will be available. The Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data become available.\n\n\n\n\nWhat is the highest resolution SAR data available in Copernicus Data Space Ecosystem?\n\n\nThe Sentinel-1 SAR achieves a spatial resolution of approximately 5 by 20 m. More info can be found here: https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions"
  },
  {
    "objectID": "FAQ.html#services",
    "href": "FAQ.html#services",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Will there be an integrated free and commercial offering to support/encourage the transfer of the users from “try basics for free towards paid subscriptions”?\n\n\nYes, there will be a common user identity, which will allow registered users to seamlessly transfer between systems. This will also extend to other systems that will be added to the free tier to the commerical tier ecosystem in the future, assuming they will integrate it.\n\n\n\n\nWhen we develop an EO ready-to-use product, could we integrate it into the interface and ask the payment from clients?\n\n\nYes, commercial services can be built on top, similar to Copernicus open license.\n\n\n\n\nCan the user come with wish-list to services data products?\n\n\nUser can come with suggestions to improve or expand the service portfolio. A user forum will be set up and released by July to accommodate this.\n\n\n\n\nAre you going to develop new services on DAS after July 2023?\n\n\nYes, a marketplace will be available where new Third party services will be able to onboard from July onwards to expand the ecosystem.\n\n\n\n\nIs there any limitation on the max number of downloads at one time?\n\n\nYes, there will be quotas and constraints for different services.\n\n\n\n\nIs it possible to download Sentinel-2 data for a large area at a high resolution in Copernicus Data Space Browser?\n\n\nDepending on your use, we suggest to use the high-res print (via the high-res print tab) where you will get large areas in a high resolution (the data is though not georeferenced) or if you need georeferenced data, split your area in several smaller images that you download or choose a bit lower resolution to stay within the limits of 2500px.\n\n\n\n\nCan you provide detailed information regarding the quotas and limits for accessing data and using the services through your platform?\n\n\nWe understand the importance of knowing the limitations and restrictions imposed on the usage of our services. For detailed information about the quotas, we recommend referring to the Service Description and Evolution document available on our documentation portal. You can find the document at https://documentation.dataspace.copernicus.eu/Roadmap.html . The quotas information can be found in Annex B."
  },
  {
    "objectID": "FAQ.html#registration-and-authentication",
    "href": "FAQ.html#registration-and-authentication",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Will there be an integrated free and commercial offering to support/encourage the transfer of the users from “try basics for free towards paid subscriptions”?\n\n\nYes, there will be a common user identity, which will allow registered users to seamlessly transfer between systems. This will also extend to other systems that will be added to the free tier to the commerical tier ecosystem in the future, assuming they will integrate it.\n\n\n\n\nIf I’m having troubles with registering, what can I do?\n\n\nPlease e-mail the help-login@dataspace.copernicus.eu address for direct support on this matter."
  },
  {
    "objectID": "FAQ.html#apis",
    "href": "FAQ.html#apis",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "SNAP/gpt processing codes can be used in these on-line and cloud processing services?\n\n\nSNAP is integrated in cloud environment, and there will even be some dedicated on-demand services based on SNAP (i.e. S1 processing to coherence, etc).\n\n\n\n\nIs a STAC catalog planned ? Will the data be accessible on cloud object storage (S3)?\n\n\nSTAC Catalog API is indeed planned. Note that the phase-in will take from end of January to July 2023. So services will be added during this timeline, not everything will be available at the beginning. All the data will be available over S3 as well.\n\n\n\n\nWill LTA process be discontinued when all archived data become online?\n\n\nThere will still be services available for so called “deferred data access” : data collections that are not commonly used. That said, all most relevant collections will be available on-line. The Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data become available.\n\n\n\n\nWill the platform use STAC standards?\n\n\nYes, there will be STAC compliant Catalog API, as well as STAC items for inpidual products.\n\n\n\n\nAny plan to offer the Pangeo platform for a “pythonist”?\n\n\nThis is currently not in the offer or roadmap.\n\n\n\n\nHow do I generate S3 access and secret keys?\n\n\nYou can request such credentials as the guided in  https://documentation.dataspace.copernicus.eu/APIs/S3.html\n\n\n\n\nWhich one amongst the 4 catalog APIs (OData, STAC, OpenSearch, Sentinel Hub catalogue ) is updated first when new products are published?\n\n\nOpenSearch, OData and STAC catalog APIs all use the same backend database. Sentinel Hub catalog API contains a subset of the collections, hence it works only for the ones that have been imported to Sentinel Hub, Therefore there is no first updated one.\n\n\n\n\nWhat is the limitation of the number of requests that I can do at the time?\n\n\nFor detailed information about the limits, we recommend referring to the Service Description and Evolution document available on our documentation portal. You can find the document at https://documentation.dataspace.copernicus.eu/Roadmap.html. The quotas information can be found in Annex B.\n\n\n\n\nCan I connect directly to the S3 bucket using AWS S3 commands with the S3 keys provided or do I have to use “s3cmd” to download images?\n\n\nYes, you can connect to S3 bucket using AWS S3 connection. However some functionality may not be supported. It is recommended to use the ‘s3cmd’ command to download products.\n\n\n\n\nDo you have to authenticate for requesting through OpenSearch API?\n\n\nThere’s no need to use any user or authentication when you want to search. User authentication is required for downloading products.\n\n\n\n\nCan we use the Sentinel Hub bucket and fetch the products based on the id we fetched from OpenSearch API?\n\n\nYou can use Sentinel Hub bucket in addition to some programming tools by providing product ID obtained using OpenSearch API or OData of the Copernicus Dataspace Ecosystem.\n\n\n\n\nWhat is the benefit of fetching imagery from Copernicus Dataspace S3 bucket?\n\n\nDownloading products via S3 is faster as it delivers products as an .zip archive, skipping the need of zipper.\n\n\n\n\nOn which region resides the Copernicus Dataspace S3 bucket?\n\n\nRepo is located in Warsaw/Poland.\n\n\n\n\nHow can we search for the product in S3 bucket?\n\n\nSearching via ID or product name in the OpenSearch or OData will give the S3 path to the product in response."
  },
  {
    "objectID": "FAQ.html#documentation",
    "href": "FAQ.html#documentation",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Is there any difference between EU users and non-EU users?\n\n\nThere is no difference between EU users and non-EU users. That said, there will be a continuity of the accounts with higher throughput, managed by ESA (i.e. Copernicus Services, International Hub, etc.).\n\n\n\n\nWhich distribution channels will be available for high-throughput data access? I assume the public side (dataspase.copernicus.eu) has a bandwidth limitation. Or does the public side have user tiers, or is high-throughput data transfer (such as https://creodias.eu/remote-transfer-for-eodata ) only a paid service?\n\n\nAll distribution options (i.e. OData, S3, Sentinel Hub,..) will be constrained with user quotas, which includes both bandwidth limitation, as well as monthly limits.\n\n\n\n\nCan you give indictions about the cost of the “extra” services?\n\n\nPricing will be published soon.\n\n\n\n\n This December advertisement of DAS says that “For those interested in processing, there will be scalable cloud resources available, optimized for EO tasks”. Does this refer to the current CreoDIAS resources, or something completely new that hasn’t been addressed yet? \n\n\nScalable cloud resources will be part of the commercial offering and can be obtained at CREODIAS in first instance. ICT-wise, there will be two options, including Open Telekom Cloud.\n\n\n\n\nAre there tutorials (online & physical meetings) to use the new interface?\n\n\nTutorials will be added to the documentation in due time explaining the usage of the different interfaces. We will also be present on different conferences explaining the service & ecosystem."
  },
  {
    "objectID": "Applications.html",
    "href": "Applications.html",
    "title": "Applications",
    "section": "",
    "text": "This section provides an overview of the EO Applications available from Copernicus Data Space Ecosystem.\n\n\nThe Copernicus Data Space Ecosystem Browser serves as a central hub for accessing, exploring and utilizing the wealth of Earth observation and environmental data provided by the Copernicus Sentinel constellations, contributing missions, Auxiliary engineering data, on-demand data and more (Check out the documentation on Data for more details) . Based on Sentinel Hub’s EO Browser, users can visualise, compare and analyse and download all this data for a variety of applications, from environmental monitoring and disaster management to urban planning and agriculture. Check out the user guide to know more about the features of the Browser and how to use it.\n\n\n\nThe openEO algorithm plaza host many algorithms that are built on top of the openEO API. These algorithms also termed as Earth Observation services can be addressed via openEO Web Editor or via API to embed into new services or platforms. Users are granted with credits to explore the available algorithms and check if they are fit for purpose for their needs. The plaza not only allows to explore the services but also enables third party services provider to onboard their algorithms semi-automatically for further exposure.\n\n\n\nThe openEO Web Editor is a web app that allows users to interact with an openEO back-end and perform various tasks related to Earth observation data processing. This application can be of great use for users who are not familiar with a programming language. The openEO Web Editor can act as a simple interface for:\n\nData Discovery: User can explore and discover available Earth observation datasets.\nWorkflow Creation: User can create an openEO processing workflow from basic building blocks in a drag-and-drop interface.\nWorkflow Execution: Once User have defined their processing workflow and configured the parameters, User can execute the workflow using the Web Editor.\nResult Visualization: User can explore the output data on interactive maps, generate charts and graphs\nJob Management: The Web Editor allows you to monitor your processing jobs, view job histories, and access the generated results."
  },
  {
    "objectID": "Applications.html#browser",
    "href": "Applications.html#browser",
    "title": "Applications",
    "section": "",
    "text": "The Copernicus Data Space Ecosystem Browser serves as a central hub for accessing, exploring and utilizing the wealth of Earth observation and environmental data provided by the Copernicus Sentinel constellations, contributing missions, Auxiliary engineering data, on-demand data and more (Check out the documentation on Data for more details) . Based on Sentinel Hub’s EO Browser, users can visualise, compare and analyse and download all this data for a variety of applications, from environmental monitoring and disaster management to urban planning and agriculture. Check out the user guide to know more about the features of the Browser and how to use it."
  },
  {
    "objectID": "Applications.html#openeo-algorithm-plaza",
    "href": "Applications.html#openeo-algorithm-plaza",
    "title": "Applications",
    "section": "",
    "text": "The openEO algorithm plaza host many algorithms that are built on top of the openEO API. These algorithms also termed as Earth Observation services can be addressed via openEO Web Editor or via API to embed into new services or platforms. Users are granted with credits to explore the available algorithms and check if they are fit for purpose for their needs. The plaza not only allows to explore the services but also enables third party services provider to onboard their algorithms semi-automatically for further exposure."
  },
  {
    "objectID": "Applications.html#openeo-web-editor",
    "href": "Applications.html#openeo-web-editor",
    "title": "Applications",
    "section": "",
    "text": "The openEO Web Editor is a web app that allows users to interact with an openEO back-end and perform various tasks related to Earth observation data processing. This application can be of great use for users who are not familiar with a programming language. The openEO Web Editor can act as a simple interface for:\n\nData Discovery: User can explore and discover available Earth observation datasets.\nWorkflow Creation: User can create an openEO processing workflow from basic building blocks in a drag-and-drop interface.\nWorkflow Execution: Once User have defined their processing workflow and configured the parameters, User can execute the workflow using the Web Editor.\nResult Visualization: User can explore the output data on interactive maps, generate charts and graphs\nJob Management: The Web Editor allows you to monitor your processing jobs, view job histories, and access the generated results."
  },
  {
    "objectID": "Roadmap.html",
    "href": "Roadmap.html",
    "title": "Service description and evolution roadmap",
    "section": "",
    "text": "The Service description and evolution document provides a comprehensive view of all data products and services available in the frame of the Copernicus Data Space Ecosystem, both the “Copernicus Free Services” as well as the services operated by third parties.\n\n\n\n\n\n\nRoadmap Summary\n\n\n\n\n\nMore detailed information on the timelines for Copernicus Data Space Ecosystem data, APIs and Application updates can be found here:\n\nData timeline overview\nAPIs timeline overview\nApplications timeline overview"
  },
  {
    "objectID": "Roadmap.html#roadmap",
    "href": "Roadmap.html#roadmap",
    "title": "Service description and evolution roadmap",
    "section": "",
    "text": "Roadmap Summary"
  },
  {
    "objectID": "Roadmap.html#details",
    "href": "Roadmap.html#details",
    "title": "Service description and evolution roadmap",
    "section": "",
    "text": "More detailed information on the timelines for Copernicus Data Space Ecosystem data, APIs and Application updates can be found here:\n\nData timeline overview\nAPIs timeline overview\nApplications timeline overview"
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html",
    "href": "Applications/AlgorithmPlaza.html",
    "title": "openEO algorithm plaza",
    "section": "",
    "text": "This section of the document provides a comprehensive overview of essential links related to the openEO algorithm plaza. These links serve as valuable resources for individuals seeking to gain further knowledge about the platform. Included are references to a guide tailored for general users, a guide designed specifically for developers and service providers, as well as additional links pertaining to various services offered by openEO."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#getting-started",
    "href": "Applications/AlgorithmPlaza.html#getting-started",
    "title": "openEO algorithm plaza",
    "section": "Getting Started",
    "text": "Getting Started\nAre you new to the openEO algorithm plaza? Get started by exploring the following guides:\n\nopenEO algorithm plaza Introduction\nGuide for openEO algorithm plaza users\nGuide for third party service providers"
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#popular-links",
    "href": "Applications/AlgorithmPlaza.html#popular-links",
    "title": "openEO algorithm plaza",
    "section": "Popular links",
    "text": "Popular links\n\nopenEO algorithm plaza overview\nSigning in\nManage your services\nManage your billing information\nExecute a service"
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#support",
    "href": "Applications/AlgorithmPlaza.html#support",
    "title": "openEO algorithm plaza",
    "section": "Support",
    "text": "Support\n\nExecuting services\nIf you are experiencing issues with executing your service, feel free to contact our support team by creating a ticket.\n\n\nPublishing services\nAre you having trouble publishing your service onto the openEO algorithm plaza? Our support team is ready to assist! Feel free to create a ticket."
  },
  {
    "objectID": "Applications/WebEditor.html",
    "href": "Applications/WebEditor.html",
    "title": "openEO Web Editor",
    "section": "",
    "text": "The openEO Web Editor is a web-based graphical user interface (GUI) that allows users to interact with the openEO API and perform various tasks related to Earth observation data processing. It provides a user-friendly interface for users who are not familiar with a programming language to carry out several Earth Observation data processing tasks, such as querying available data, defining processing workflows, executing processes, and visualising the results. It allows users to build complex processing chains by connecting different processing steps as building blocks and provides options to specify parameters and input data for each step.\nThe openEO Web Editor can be accessed via https://openeo.dataspace.copernicus.eu/. Even without logging in, users have the ability to retrieve information on available collections, processes, User Defined Functions(UDF) Runtimes, and the options for exporting files. Additionally, users can create openEO process graphs, however, log in is necessary to execute them."
  },
  {
    "objectID": "Applications/WebEditor.html#getting-started",
    "href": "Applications/WebEditor.html#getting-started",
    "title": "openEO Web Editor",
    "section": "Getting Started",
    "text": "Getting Started\nUpon initial access to the provided link, users are presented with the following screen which is further explained below in refernce to the given numbering:\n\n\nService Offering\nThe sidebar offers users the ability to navigate through the available collections, processes, UDF Runtimes and Export file formats. At the top of the sidebar, there is a search feature that allows for direct searching.\nWithin the Collections section, users can access a comprehensive list of data collections available in the backend through openEO. Clicking on any of these collections will bring up a detailed metadata window.\nUnder the Processes section, users can find a comprehensive list of openEO processes specifically designed for Earth Observation processing. These processes operate on individual values within an array, accepting and returning a single value.\nThe UDF Runtimes section provides information on the available environments or platforms where User Defined Functions (UDFs) can be executed. Currently, the python runtime is available during this stage of development.\nIn the Export File Formats section, users are guided on the supported output formats within openEO. Clicking on each format provides a detailed summary of its associated parameters.\nHelp\nThe Help icon at the top of the screen will provide you with a short tour of the main section of the editor.\nWizard\nThe Wizard is an experimental feature that will help you to create openEO processes in a simple way for some common use cases.\nServer\nThe Server icon will pop up a window giving the user detailed information on the server used for processing the created processes.\nGuest\nThe Guest naming will be replaced with your username when logged in. The dropdown will provide with an option to Log in.\nFeatures\nThe basic functionalities that can be handy when creating the processes in openEO Web Editor is available in this row. These functionalities includes creating a new script, importing processes from external sources, exporting in another programming language, validating processes on the server side, editing process metadata, adding parameters, etc.\nProcess Editor\nThis is the editor for the processes. We recommend to work in “Visual Model” mode, where you can create processing chains simply by adding collections and processes and connecting them with each other. The “Code” mode allows to see the generated JSON process, which is usually only needed if you want to run the process using another client library such as Python or R.\nThe area on it’s right will later be used for previewing collections or inspecting the results of batch jobs, web services or other computations. It will also be used to display log messages, if available.\nLog in\nAs previously mentioned, it is necessary to log in to interact with the server. A new window will appear when attempting to log in, as demonstrated below. While other options are sometimes available, the recommended authentication choice is the “Copernicus Data Space Ecosystem”. For further information regarding various authentication methods or to seek assistance, you can always click on the “help” option at the top or contact us."
  },
  {
    "objectID": "Applications/WebEditor.html#create-a-workflow",
    "href": "Applications/WebEditor.html#create-a-workflow",
    "title": "openEO Web Editor",
    "section": "Create a workflow",
    "text": "Create a workflow\nBased on their applications user can build their model by simple drag and drop method. Some processes may necessitate input parameters, which must be carefully considered. As an illustration, we present a simple case of creating a workflow to calculate NDVI using the Sentinel 2 L2A collection. Three main steps involved in using openEO for Earth Observation data processing is shown below.\n\nLoad Collection\nIn order to load the required collection make sure it is available by searching in the sidebar. Once you find your collection you can simply drag and drop it for carrying out further actions. In the following clip, you can observe the sequential actions are taken to accomplish the following tasks: choosing a collection of interest, defining the spatial and temporal boundaries, and filtering the necessary bands for subsequent processing. Specifically, for calculating the NDVI, the Red band (B04) and Near-Infrared (NIR) band (B08) have been selected.\n\n\n\nApply Processes\nEventually, the next step involves implementing essential processes, ranging from straightforward operations like adding bands to more complex tasks such as importing or defining user-defined functions (UDFs). In the following clip, a reduce_dimension() process is employed to eliminate the temporal dimension by selecting the maximum value. The same process is utilised to reduce the band dimension after executing a series of addition, subtraction, and division operations necessary for the NDVI calculation.\n\n\n\nSelect a format\nAs a final step in the workflow creation, the following clip demonstrates selecting the output format. Since our application involves simple NDVI calculation, we want to save it as a GeoTiff."
  },
  {
    "objectID": "Applications/WebEditor.html#execute-the-workflow",
    "href": "Applications/WebEditor.html#execute-the-workflow",
    "title": "openEO Web Editor",
    "section": "Execute the workflow",
    "text": "Execute the workflow\nTo complete the data analysis process, the final step involves executing the created workflow. This can be done in two ways: synchronously or through batch job-based method. Synchronous method allows the user to download the data directly, whereas batch job-based method enables the user to execute process as a batch. The choice of method depends on the user’s preference and the size of the dataset.\n\nIn the above figure, the red box includes the two methods possible for executing the process. In this example, I used the synchronus method by directly clicking on Run now, which popped up a box in the bottom right corner.\nOnce the execution process is completed, the result is automatically saved locally. It can also be visualised in the parallel window as shown in the image below:\n\nFurthermore, if you have created Batch Job, you can monitor its action from the same window."
  },
  {
    "objectID": "Applications/Browser.html",
    "href": "Applications/Browser.html",
    "title": "Documentation",
    "section": "",
    "text": "The Browser is a web browser application that allows you to easily search, visualize, modify and download imagery from the Sentinel satellites. You can access the Browser at:\nhttps://dataspace.copernicus.eu/browser/\nCurrently you need a free account to use the Browser. To register for a free account, click here to the browser. A new window will open where you can click on New user? Click here to create an account and access the data. Once you have created the account, you will automatically be logged in to the Browser. Remember to save your login credentials for the next time you want to log in to the Browser.\n Fig 1: Browser start screen\nThe Browser window is divided into three parts:\n\nThe sidebar on the left side of the screen. Here you can set the parameters to search for, visualize and download data.\nThe map in the middle of the screen. Here you can zoom in and out and move around to find the place you are interest in. In this area you will see visualized satellite imagery or geometries of the products, that are the result of your search.\nThe toolbar on the right side of the screen. Here you find various tools (e.g., for measuring or downloading images) with which you can work with the data displayed on the map."
  },
  {
    "objectID": "Applications/Browser.html#about-the-browser",
    "href": "Applications/Browser.html#about-the-browser",
    "title": "Documentation",
    "section": "",
    "text": "The Browser is a web browser application that allows you to easily search, visualize, modify and download imagery from the Sentinel satellites. You can access the Browser at:\nhttps://dataspace.copernicus.eu/browser/\nCurrently you need a free account to use the Browser. To register for a free account, click here to the browser. A new window will open where you can click on New user? Click here to create an account and access the data. Once you have created the account, you will automatically be logged in to the Browser. Remember to save your login credentials for the next time you want to log in to the Browser.\n Fig 1: Browser start screen\nThe Browser window is divided into three parts:\n\nThe sidebar on the left side of the screen. Here you can set the parameters to search for, visualize and download data.\nThe map in the middle of the screen. Here you can zoom in and out and move around to find the place you are interest in. In this area you will see visualized satellite imagery or geometries of the products, that are the result of your search.\nThe toolbar on the right side of the screen. Here you find various tools (e.g., for measuring or downloading images) with which you can work with the data displayed on the map."
  },
  {
    "objectID": "Applications/Browser.html#visualization",
    "href": "Applications/Browser.html#visualization",
    "title": "Documentation",
    "section": "Visualization",
    "text": "Visualization\nYou can find the VISUALIZE tab in the upper left corner of the sidebar (selected by default). The VISUALIZE tab will allow you to easily visualize satellite imagery on the map. Change or modify your visualization with just a few clicks.\n\nVisualizing data\nIn order to visualize data on the map, you need to zoom in to your area of interest. You can do this either with the mouse wheel or with the location search in the upper right corner.\nLet’s try to visualize the latest Sentinel-2 L2A imagery over Italy.\n\nEither zoom to Italy with the mouse wheel or type Italy in the search box in the upper right corner.\nIn the sidebar, a maximum cloud coverage of 30% and the product type Sentinel-2 L2A are already preselected. To visualize the latest available data with cloud coverage below 30% click on the Show latest date button.\n\n\nFig 2: VISUALIZE tab with show latest date button and Sentinel-2 L2A collection highlighted\nYou can now see the latest data over Italy on the map. Depending on the latest data available you will see data from one or more orbits (stripes of images on the map).\n\nModifying and Changing a Visualization\nIf you want to improve how the data is displayed on the map, you can modify the visualization by clicking on Show effects and advanced options at the bottom of the sidebar. Change the Gain/Gamma values, the values of the R/G/B colour channels, specify which sampling method is used for the visualization (Layer default, Bilinear, Bicubic, Nearest) or click on Reset to reset all changes made. To return to the visualization layers overview, click on Show visualizations.\nTo visualize different Sentinel-2 band combinations, either use one of the prepared options from the list of layers (e.g., NDVI for the Normalized Difference Vegetation Index using the Sentinel bands B4 and B8) or click Custom at the bottom of the layers list.\n\nFig 3: Custom Layers option with Composite Index and Custom script highlighted\nHere you can create a custom R/G/B composite or Index (band ratio, normalized difference index) by dragging and dropping the Sentinel-2 bands into the appropriate circles or use the Custom script functionality to insert a piece of JavaScript code.\n\n\nChanging the Data Collection\nYou can switch visualizing between different data collections by clicking on the arrow next to the Data Collections section in the Visualization tab. Once you click on the arrow as seen in Fig. 4, you will be able to see a drop-down menu with a list of the satellite data that is available. Let us try to visualize Sentinel-3 data of the same location and date as that of the Sentinel-2 data in Visualizing data section.\n\nClick on the drop-down arrow on the right next to Pins icon.\nClick on the drop-down arrow next to Sentinel-2 and select Sentinel-3.\nYou can select the product you want to visualize. To visualize the Brightness temperature, select Sentinel-3 SLSTR L1B. You can see the predefined layers that can be visualized and click on the green button to Show latest date.\n\nAt the moment, the Data Collections available for visualization are Sentinel-2 (L1C and L2A), Sentinel-3 (OLCI Level-1 EFT, SLSTR Level-1 RBT) and Sentinel-5P.\n\nFig 4: Changing Data Collection from Visualization tab directly\n\n\nComparing Visualizations\nTo compare two (or more) visualizations you must add them to the compare panel. You can add a visualization to the compare panel by clicking on the Add to compare button in each visualization layer (see Fig. 4). When you have added all the layers you want to compare to the compare panel, you can switch to it by clicking on the compare icon (  ). In the compare panel you can choose between a Split and an Opacity mode. With the Split mode you can compare two images side by side. With the Opacity mode you can compare two (or more) visualizations on top of each other.\n\nFig 5: Add to compare and compare icon\n\n\nSaving Pins\nTo save a visualization for future viewing, you can save it as a pin by clicking on ( ) next to the Layer name and clicking on Add to Pins. You can find the saved pins by clicking on the ( ) icon. If you wish to compare saved pins, you can add them to the compare panel as explained in the previous section. If you have multiple pins saved and want to compare them altogether, you can directly go to the compare panel and add all the pins to compare by clicking on ( ). Another feature of the Browser is that you can export pins as a JSON file and import previously exported pins as well.\n\nFig 6: Add to pins and Pins icon\n\n\n\nProduct Search for Current Visualization\nWhen you are visualizing data (chapter Visualizing data), you can easily find the products associated with the data you see on the map. The product allows you to inspect the full metadata and easily download the raw data. To find connected products, just click the Find products for current view button in the sidebar (under the Show latest date button).\n\nFig 7: Find products for current view button position in the sidebar.\n\n\n3D Visualization\nWith the 3D visualization tool, users can also visualize the terrain. To obtain a 3D visualization, you need to first select a layer to view and then click on the  icon. You can move forward, backward, left, or right by right clicking on the pan console (labelled 1 in the red box in Fig. 8) and rotate around a point by right clicking on the camera console (labelled 2 in the red box in Fig. 8). The viewing angle can be adjusted by scaling vertically and panning in all directions. You can further explore the area by adjusting the sun projected shadows and the shading parameters of the scene in the settings (labelled as box 3 and 4 respectively in Fig. 8). This 3D view can also be downloaded as a PNG or JPEG file. Let us try visualizing Mont Blanc, the highest peak in the Alps.\n\nFollow the steps mentioned in Visualizing data chapter to visualize Mont Blanc and select the “True Color” visualization.\nClick on the  icon placed at the right of the screen.\nYou can navigate around the visualization either with your mouse, keyboard or directly on the map by following the instructions mentioned in the “Help” section (click on the ( ) icon).\nClick on the Settings icon ( ). Set the Vertical terrain scaling to 150% by moving the slider.\nTo adjust shadows, click on the Parameters next to Sun projected shadows toggle switch.\nTo adjust Shading parameters, click on Edit and modify the Ambient factor, Diffuse factor, Specular factor, and Specular power.\nYou can Reset values at any point to return to the default settings.\n\n Fig 8: 3D visualization in the Browser with pop-up Settings windows on the right"
  },
  {
    "objectID": "Applications/Browser.html#product-search",
    "href": "Applications/Browser.html#product-search",
    "title": "Documentation",
    "section": "Product Search",
    "text": "Product Search\nWith the product search you can find products from four Sentinel missions (Sentinel-1, Sentinel-2, Sentinel-3, Sentinel-5p) and the sensors on board these satellites (C-SAR, MSI, OLCI, SRAL, SLSTR, SYNERGY). You can explore the metadata for each of those products, download the raw data or visualize the data on the map (currently only Sentinel-2 L1C and L2A are supported, but more data sources will be supported here in the future).\nThe SEARCH tab is located in the sidebar next to the VISUALIZE tab (see Fig. 9).\n\nFig 9: SEARCH tab with different Data Sources, Time range and Search button\n\nHow to find a Product\nTo find products you can either use the keyword search (text input) or select one or more data sources using the checkboxes. To find products for a specific time range only, set the from/to date in the date input boxes. For example, let us find the latest Sentinel-2 L2A image over Italy for the beginning of 2023.\n\nZoom in on Italy on the map with the scroll wheel of your mouse.\nSelect Sentinel-2 &gt; MSI (selected by default) &gt; L2A.\nSet the Time Range to reflect two weeks (e.g., 2023-01-02, 2023-01-16)\nPress the Search button\n\n Fig 10: SEARCH tab with L2A collection selected and map centred on Rome (Italy)\nYou will now see the first 50 search results for your search settings (Sentinel L2A data over Italy for a time range of 2 weeks) in the sidebar and on the map. To load the next 50 results, click on the Load more button at the end of the list in the sidebar. You can view the metadata of a product in the sidebar or by selecting a product on the map. In both cases you can:\n\nDirectly view the basic metadata (preview image (available for most Sentinel-2 L1C, L2A, Sentinel-3 SLSTR and Sentinel-3 OLCI products), name, mission, instrument, acquisition time)\nView the full metadata by clicking on the product info button ( ) in the results (full metadata)\n\n\nAdditional Filters\nTo get more suitable results, you can also select or choose additional filters as shown in Figure 11. 1. Select the Data Source and the appropriate instrument/ processing level. 2. Click on the Filter button and set the filtering parameters. 3. Press the Search button. Here, you can choose various parameters depending on the chosen Data Source. For example, you can see the filter parameters for Sentinel-1 in Figure 11, letting you filter the results based on satellite platform, orbit direction, relative orbit number, acquisition mode, Beam ID and polarization.\n\nFig 11: Data filters and parameters\n\n\nVisualize the search result\nOnce you have found a product, you can visualize the results in two ways: either by directly selecting the viszualize button (  ) in the sidebar or by selecting the visualize button in the results panel on the map. You can open the results panel by clicking on one of the displayed tile footprints on the map.\n Fig 12: Product metadata and visualize button\n\n\n\nHow to download a Product\nWhen you have found a product (see How to find a Product) that you would like to download, you can do so by clicking click on the download icon (  ) for the desired product in the results (in the sidebar or in the results panel on the map after selecting a product). After you click the button, a progress bar will appear below the product to indicate the status of your download. If you have started a download by mistake, you can cancel it by clicking on the “x” below the download button.\nYou can continue to use the app as normal while a product is being downloaded.\n\nFig 13: Product download (in progress) with Download product and cancel button highlighted"
  },
  {
    "objectID": "Applications/Browser.html#tools",
    "href": "Applications/Browser.html#tools",
    "title": "Documentation",
    "section": "Tools",
    "text": "Tools\nThe Browser has several tools to help you better understand the data on the map and prepare it for sharing with others. These tools can be found in the upper right corner of the Browser. They can help you select the Area of Interest, measure, download the image, create a timelapse if you want to observe the area over a longer period of time, or analyse the statistics of an index (e.g., the NDVI).\n\nArea/Point of Interest\nUse the Area of Interest (AOI) tool to draw a rectangular or polygonal area of interest by clicking on the  icon in the upper right corner of the browser. You can also upload a KML/KMZ, GPX, WKT (in EPSG:4326) or GEOJSON/JSON file to create an AOI.\nUse the  icon to mark a location and re-centre to the Point of Interest(POI)\n\n\nMeasure\nYou can use the Measure tool by clicking on the  icon to get the distance and area measurements. To measure the distance between two points, simply click on the start and end points on the map, to measure the area, draw a polygon (areas can also be measured using the AOI drawing, as described in Area/Point of Interest).\n\n\nImage Download\nThere are three different download options. You can switch between the options using the tabs at the top of the pop-up window. Each option contains a preview of the data at the bottom. When you are satisfied with your download settings, you will find the  button below the preview:\n\nBasic\n\nYou can use the Show Captions toggle switch to add data source, date, zoom scale and branding information to the exported images.\nYou can also use the Add Map Overlays toggle switch to add place labels, streets and political boundaries to the image or the Show Legend toggle switch to add the legend data.\nYou can use the Crop to AOI toggle switch to crop the image to the bounds of area of interest, if drawn previously.\nIf you want to download the entire image but highlight the AOI, it can be done by enabling the Draw AOI Geometry.\nUse the textbox to add a short description to the exported image.\nChoose between two image formats (JPG, PNG).\nA preview of the image that will be downloaded is displayed under Preview. Previews are available only when you zoom in enough.\n\nAnalytical\n\nAfter preparing the data for download, click the  button to download the image in JPG, PNG, KMZ or GeoTIFF format.\nChoose between different image formats, resolutions and coordinate systems before downloading the image. You can also attach a logo.\nIn the Analytical panel, you can select multiple layers (Visualized/Raw) and download them all in a single ZIP file.\n\nHigh-res print\n\nPrepare the selected visual for high-resolution printing by manually selecting a format, size and DPI. Add captions, legends and descriptions as needed.\n\n\n\n\nTimelapse\nTimelapses are a very popular and useful tool to show how a certain location on Earth changed through time. Using the timelapse tool you can create your own visualization of changes through time and export it as .GIF or .MPEG4 to share it with others online. Let’s create a timelapse of the deforestation in the Brazil from 2018 – 2022.\n\nGo to: https://sentinelshare.page.link/osH4\nClick on the timelapse icon (  ) and click on the play button in the middle of the screen. This opens a pop-up window to create a timelapse.\nChange the settings on the left side to:\n\nDates 2018-01-01 – 2022-12-31\nSelect 1 image per: month Alternatively, you can select only certain months in a year using the filter by months option. Click on Search to see all the results.\n\nIn the Visualizations set the Min. tile coverage to 100% and the Max. cloud coverage to 2% and manually deselect the images from the 2022-05-30 (slightly cloudy) and the 2022-09-07 (blurry).\nOnce you have the list of images you want to display in the timelapse, select the speed, and transition to prepare your timelapse.\nClick on the play button to check the result and download the animation as a GIF-file using the Download button for further use online/offline.\n\n Fig 14: Browser timelapse tool with settings highlighted\n\nHistogram\nWith the Histogram tool you can display statistical data (the distribution of values) for specific layers by clicking on the  icon. The histogram is calculated for the data within your AOI, if defined or otherwise for the whole screen. This tool currently only works for index layers (e.g., the NDVI).\n\nFig. 15: Example of a distribution plot of NDVI values"
  },
  {
    "objectID": "Applications/PlazaDetails/UserGuide.html",
    "href": "Applications/PlazaDetails/UserGuide.html",
    "title": "Guide for openEO plaza algorithm users",
    "section": "",
    "text": "Below you can find more information on the following topics:\n\nOverview\nCreate your account\nSigning in\nManage your Profile\nManage your billing information\nExecute a service\nService Report"
  },
  {
    "objectID": "Applications/PlazaDetails/SignIn.html",
    "href": "Applications/PlazaDetails/SignIn.html",
    "title": "Signing In",
    "section": "",
    "text": "You arrive at this page by being unauthenticated and clicking on the Sign In navigation option. Through this flow, any user can login into their registered account after they have successfully validated their email address through the link sent to their email."
  },
  {
    "objectID": "Applications/PlazaDetails/Introduction.html",
    "href": "Applications/PlazaDetails/Introduction.html",
    "title": "About openEO Algorithm plaza",
    "section": "",
    "text": "The openEO algorithm plaza allows you to share an algorithm or workflow that you developed with our user community. It takes away the IT aspects of publishing a service, so that you can entirely focus on the algorithm’s development. Publishing your algorithm as a service will give it greater visibility and expose it to a larger audience that can give feedback.\nThe openEO algorithm plaza relies on standardized web interfaces, so our users can access your service in an easy manner. A visual description of your service is published, to give an attractive overview of the capabilities.\n\n\n\n\nWithin the context of Earth Observation, a service can do anything, from computing a simple Normalized Difference Vegetation Index (NDVI) for a bounding box, to exposing a complex peer-reviewed algorithm with numerous parameters. Of course, you want to keep your target audience in mind, so you may want to hold back on hard to interpret options when you are trying to reach a non-scientific audience.\nOnce your algorithm is exposed as a service, users will be able to ‘invoke’ it with a given set of parameters. Within EO, an area of interest and/or time period are very common parameter sets to filter on.\n\n\n\nEach of the advertised services in the openEO algorithm plaza will be assigned a maturity level. This level indicates what end users can expect from the services with regards to:\n\nValidation of the results\nStability\nScalability\nDocumentation\n\nThe table below provides an overview of the different maturity levels that are applied within the openEO algorithm plaza.\n\n\n\n\n\n\n\nLevel\nDescription\n\n\n\n\nPrototype\nService is provided ‘as-is’, with a short description and possibly a reference to what it tries to implement.\n\n\nIncubating\nQuality of the service is documented with example requests (sets of parameters) and the corresponding output, as well as the resources required to generate that output. Allowing interested users to self-assess whether this service is suitable for usage.\n\n\nVerified\nThe service is labelled verified based on its software readiness and irrelevance to the scientific validation report.\n\n\nValidated\nThe service is validated, and validation reports are available in addition to being verified.\n\n\nOperational\nThe service has been shown to be fit for larger scale production and integration in operational systems. Rules for estimating resource usage are available, or a unit cost is established. (€ per hectare, € per request, etc.)\n\n\n\n\nDetailed descriptions of the criteria for each maturity level are explained here.\n\n\n\n\n\n\nGuide for openEO algorithm plaza users\nGuide for third party service providers\n\n\n\n\n\nopenEO algorithm plaza overview\nSigning in\nManage your services\nManage your billing information\nExecute a service"
  },
  {
    "objectID": "Applications/PlazaDetails/Introduction.html#concepts",
    "href": "Applications/PlazaDetails/Introduction.html#concepts",
    "title": "About openEO Algorithm plaza",
    "section": "",
    "text": "Within the context of Earth Observation, a service can do anything, from computing a simple Normalized Difference Vegetation Index (NDVI) for a bounding box, to exposing a complex peer-reviewed algorithm with numerous parameters. Of course, you want to keep your target audience in mind, so you may want to hold back on hard to interpret options when you are trying to reach a non-scientific audience.\nOnce your algorithm is exposed as a service, users will be able to ‘invoke’ it with a given set of parameters. Within EO, an area of interest and/or time period are very common parameter sets to filter on.\n\n\n\nEach of the advertised services in the openEO algorithm plaza will be assigned a maturity level. This level indicates what end users can expect from the services with regards to:\n\nValidation of the results\nStability\nScalability\nDocumentation\n\nThe table below provides an overview of the different maturity levels that are applied within the openEO algorithm plaza.\n\n\n\n\n\n\n\nLevel\nDescription\n\n\n\n\nPrototype\nService is provided ‘as-is’, with a short description and possibly a reference to what it tries to implement.\n\n\nIncubating\nQuality of the service is documented with example requests (sets of parameters) and the corresponding output, as well as the resources required to generate that output. Allowing interested users to self-assess whether this service is suitable for usage.\n\n\nVerified\nThe service is labelled verified based on its software readiness and irrelevance to the scientific validation report.\n\n\nValidated\nThe service is validated, and validation reports are available in addition to being verified.\n\n\nOperational\nThe service has been shown to be fit for larger scale production and integration in operational systems. Rules for estimating resource usage are available, or a unit cost is established. (€ per hectare, € per request, etc.)\n\n\n\n\nDetailed descriptions of the criteria for each maturity level are explained here."
  },
  {
    "objectID": "Applications/PlazaDetails/Introduction.html#guides",
    "href": "Applications/PlazaDetails/Introduction.html#guides",
    "title": "About openEO Algorithm plaza",
    "section": "",
    "text": "Guide for openEO algorithm plaza users\nGuide for third party service providers"
  },
  {
    "objectID": "Applications/PlazaDetails/Introduction.html#quicklinks",
    "href": "Applications/PlazaDetails/Introduction.html#quicklinks",
    "title": "About openEO Algorithm plaza",
    "section": "",
    "text": "openEO algorithm plaza overview\nSigning in\nManage your services\nManage your billing information\nExecute a service"
  },
  {
    "objectID": "Applications/PlazaDetails/Reporting.html",
    "href": "Applications/PlazaDetails/Reporting.html",
    "title": "Reporting",
    "section": "",
    "text": "This documentation section demonstrates how to use the reporting function within the openEO algorithm plaza. Individuals using the platform can track the services they have used and see how credits have been deducted for each service. The purpose of this guide is to help users efficiently track and document their service consumption while also keeping an eye on their credit balance.\nPlease check that you are logged in to your account for accessing the reporting functionality. Once logged in, select the “Reporting” option from the navbar, that will take you to the screen shown in the figure below:\n\nIf you haven’t executed any services yet, there may not be much information displayed on the screen. However, as you start utilizing services, the screen will populate with relevant data that can be visualized in the following manner:\n\nFiltering Reports: You will have the option to filter the reports based on a specific time interval. This allows you to view the service usage and credit deductions within a desired timeframe, providing a more targeted analysis.\nCredit Usage Display: A section will be available to display the credits used, showcasing both the synchronous and batch job execution methods. This information helps you understand how your credits are being utilized for different types of job executions. Hovering over the credit usage details will provide additional information on the specific service used.\nJobs List: The screen will include a list of the jobs that have been executed. This list provides a comprehensive overview of the services that have been utilized. Each job entry will typically include details such as job ID, execution time, and any relevant metadata associated with the job.\n\n\n\nOn the top right corner of the screen, you will notice an “Export” button. By clicking on this button, you will have the option to download the report in either PDF or CSV file format. This feature enables you to save and archive the report for future reference or share it with others as needed.\n\nNext to the “Personal” section, you will find the “Service” tab, specifically designed for service providers to monitor and track reports on the services published by their organisation. If you haven’t provided service, this tab will appear empty, as mentioned earlier. However, if you have published services, the page will populate with a similar layout with an addition to “Service Execution” section as shown below:\n\nHere, apart from monitoring credit usage and jobs, an additional section “Service execution” is introduced. Furthermore, users have the option to apply a filter to the report, enabling them to focus specifically on a particular service."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html",
    "href": "Applications/PlazaDetails/ServiceMaturity.html",
    "title": "Service Maturity",
    "section": "",
    "text": "All the services on the openEO algorithm plaza are assigned a maturity level that indicates what users can expect from the service in regard to its performance and metadata. Currently, we have five different maturity levels for each service, namely Prototype being the primary and default level, followed by Incubating, Verified, Validated and Operational as advanced services. These levels are determined solely based on software readiness and user documentation criteria. These criteria are generally designed to ensure that the service meets specific standards and provides customers with a certain level of quality."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-1-prototype",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-1-prototype",
    "title": "Service Maturity",
    "section": "Level 1: Prototype",
    "text": "Level 1: Prototype\nBy default, every published service will have a prototype level. It is expected that service providers consider the following points when publishing a service:\n\nThe service is executable, and basic logging information is supported.\nA possible reference or a general overview of what it tries to implement is provided as service metadata.\n\n\nIf your service satisfies the criteria for a higher level, you can request an upgrade anytime once your service is published. Nevertheless, please note that every criterion must be satisfied for an upgrade."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-2-incubating",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-2-incubating",
    "title": "Service Maturity",
    "section": "Level 2: Incubating",
    "text": "Level 2: Incubating\nIn addition to the criteria for prototype level, a few additional criteria, as mentioned below, need to be satisfied to be upgraded to incubating service.\n\nService metadata should also include an example of executing the service along with the expected output format.\nAn approximate assumption on how much user credit is required to execute a service should be provided.\n\n\nNote that no added value will be associated with services with a prototype or incubating levels. In other words, approximate credit will include added value cost only on services that are either verified, validated or operational."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-3-verified-or-validated",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-3-verified-or-validated",
    "title": "Service Maturity",
    "section": "Level 3: Verified or Validated",
    "text": "Level 3: Verified or Validated\nWhen a service is labelled as either verified or validated, they mark the same level of maturity. Users can expect the same level of performance from them, but the naming difference is due to its irrelevance/relevance to software validation reports as a part of user documentation.\n\nLevel 3a: Verified\n\nA comprehensive functional and integration test should be possible.\nThere should be advanced logging that could help while debugging.\nService metadata should include information on detailed descriptions of the services, their parameters and a link to a publication that supports the methodology adopted. An example of executing service expected outcome should be provided in a similar manner to that of incubating service.\nApproximate cost estimation on a larger scale should be presented.\n\n\nPlease mention or provide a report to the support team if there exist any constraints/limitations with the services that should be considered.\n\n\n\nLevel 3b: Validated\n\nAll the criteria mentioned for the verified level are applicable to this level, along with the additional criteria that the validation report should be provided either as a separate document to the support team or a non-expiring link.\n\n\nAlthough services can be either of verified or validated type, i.e. if a service satisfies all the criteria mentioned under verified but does not provide a validation report despite being relevant to them will be labelled as incubating."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-4-operational",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-4-operational",
    "title": "Service Maturity",
    "section": "Level 4: Operational",
    "text": "Level 4: Operational\nA highly improved service can only be marked with the highest level of maturity i.e. operational, when it fully satisfies the following criteria:\n\nAll the conditions to be either verified or validated should be satisfied.\nThe service has been shown to fit large-scale production and integration in an operating system.\nRules and constraints for estimating resource usage should be provided as a document to the support team.\nService lifecycle management policy should be available for the end users.\nAn article summarising the process used for the service should be available on a peer-reviewed website or journal or a conference article (There is no limitation to a specific journal, but proof that the article was peer-reviewed should be provided to the openEO algorithm plaza support service)."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#requesting-a-change-of-the-maturity-level",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#requesting-a-change-of-the-maturity-level",
    "title": "Service Maturity",
    "section": "Requesting a change of the maturity level",
    "text": "Requesting a change of the maturity level\nBased on the fulfilment of the above criteria, service providers can request an upgrade of the service by submitting a ticket at our help center."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html",
    "href": "Applications/PlazaDetails/ManageOrg.html",
    "title": "Manage your organization",
    "section": "",
    "text": "Organisations are core elements of the openEO algorithm plaza Portal, as they are the entities that relate users, accesses, services, data, etc. One can think of an organisation as a company in most cases, although users can be a one-man organisation. By default, when a registration is made through the Portal, an organisation is always created with the user that made the registration as the sole user, even if unnamed and with no data. In a user’s Profile page, they can click on the Organisation option in sub-navigation and arrive at the Organisation page, where they can view and edit the organisation’s details, such as:\n\nOrganisation name (mandatory)\nOrganisation Identity registration (optional)\nOrganisation Avatar / logo URL (optional)\nOrganisation description (optional)\nOrganisation website (optional)\nTerms of use URL (optional) and other “useful links” e.g., Terms of Service, Privacy, YouTube, and Support URLs\nUpdate button, disabled by default\n\n\n\n\nYou have arrived here after triggering the Invite User flow through the team screen. You can see a content block to add a new user that contains:\n\nEmail address (Mandatory)\nName (Optional)\nRole dropdown (Admin, Developer, etc.), defaulting as Developer\nSubmit button\n\nYou can fill out the fields accordingly and submit the form to invite the new User to your Team and expect a success / error feedback message upon sending it. The form should also disappear after successful submission. You can see the newly invited user in the user list, however, without a Role dropdown and clearly flagged with an “Invitation Pending” message."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html#provide-your-organisation-details",
    "href": "Applications/PlazaDetails/ManageOrg.html#provide-your-organisation-details",
    "title": "Manage your organization",
    "section": "",
    "text": "Organisations are core elements of the openEO algorithm plaza Portal, as they are the entities that relate users, accesses, services, data, etc. One can think of an organisation as a company in most cases, although users can be a one-man organisation. By default, when a registration is made through the Portal, an organisation is always created with the user that made the registration as the sole user, even if unnamed and with no data. In a user’s Profile page, they can click on the Organisation option in sub-navigation and arrive at the Organisation page, where they can view and edit the organisation’s details, such as:\n\nOrganisation name (mandatory)\nOrganisation Identity registration (optional)\nOrganisation Avatar / logo URL (optional)\nOrganisation description (optional)\nOrganisation website (optional)\nTerms of use URL (optional) and other “useful links” e.g., Terms of Service, Privacy, YouTube, and Support URLs\nUpdate button, disabled by default"
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html#invite-team-members",
    "href": "Applications/PlazaDetails/ManageOrg.html#invite-team-members",
    "title": "Manage your organization",
    "section": "",
    "text": "You have arrived here after triggering the Invite User flow through the team screen. You can see a content block to add a new user that contains:\n\nEmail address (Mandatory)\nName (Optional)\nRole dropdown (Admin, Developer, etc.), defaulting as Developer\nSubmit button\n\nYou can fill out the fields accordingly and submit the form to invite the new User to your Team and expect a success / error feedback message upon sending it. The form should also disappear after successful submission. You can see the newly invited user in the user list, however, without a Role dropdown and clearly flagged with an “Invitation Pending” message."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html",
    "href": "Applications/PlazaDetails/ManageService.html",
    "title": "Manage your services",
    "section": "",
    "text": "You arrive here by clicking on Services on the sub-navigation options of the portal. In addition to the main navigation for the portal, and the sub-navigation for the portal, you can see a Call to Action (CTA) button for Register your first service in the main body of the page. On first use, you won’t have created any services, so you will be presented with the first use screen. You can click on the CTA button to load the Add service page or click on the Learn how link to load the documentation page. If you have already created at least 1 service previously, you will see the screen below.\n\nThe services are shared within your oganization. If you are a member of multiple organizations, navigate to the profile page to change your Linked Organization.\n\n\nIn the Services area, you can see cards for the services you have created, together with a card area with a Register service CTA button. On already created services, you can see an avatar (at this stage, just a colour and initials from the service name), the service name and a service status indication. As a user, you can click on the avatar or the service’s name to load its detail page. In addition, you can click on the Register service CTA button to load the add service page to create a new service.\n\n\n\nA good integration in openEO algorithm plaza already starts when programming your algorithm.\nIn openEO, a ‘datacube’ view is used, which hides a lot of the complexity when working with huge EO data archives. It provides full archive access to the most popular datasets. You will have to get familiar with the Application Programming Interface (API), which provides a lot of predefined processes. To integrate existing code, you will have to use the concept of ‘User Defined Functions’ (UDFs). Parallelization and scalability are taken care of.\n\n\nA basic introduction on using openEO can be found here. To deploy your openEO algorithm as a service, we rely on the ‘user defined process’ functionality.\n\n\n\nA good description of your service is key to attract users. Try to give a concise overview of the use cases your service was built for. Higher level services (Level-3 and -4) should also, when available, reference scientific literature and/or validation reports.\nExamples of invocations and images of resulting output are a good way to help people getting started. Finally, a user may want to have an idea of the resource consumption and time required to run your service for a given input.\n\n\n\n\nThe final step as an algorithm/service developer is to publish the service on openEO algorithm plaza. This will make the service visible to other openEO algorithm plaza users, allowing them to incorporate and use the new service in their own workflows. The following sections will guide you through the publishing process.\n\n\nThe next step is to create a new entry on openEO algorithm plaza. This can be done in the Dashboard by selecting Services. The page provides an overview of all the services that are created within your organisation.\n\nTo register your service, click the Register your first service button. You will now be presented with a wizard to enter the necessary information regarding your service.\nThe first step requires you to select the type of service that you want to publish. Currently, the following types are supported:\n\nopenEO - A service that is integrated through the openEO orchestrator\n\n\nIn the next step you can register the basic information for the service. The table below provides an overview of the different required fields:\n\n\n\n\n\n\n\n\nField\nRequired\nDescription\n\n\n\n\nService name\nYes\nTitle of your service, as it will be displayed in the openEO algorithm plaza.\n\n\nSummary\nNo\nShort description of your service. The summary will be visible in the openEO algorithm plaza overview.\n\n\nDescription\nNo\nFull description of your service. The description supports full Markdown syntax.\n\n\nAvatar\nNo\nURL to an image that can be used an avatar of your service. The avatar will be visible in the openEO algorithm plaza overview.\n\n\n\nClick Register Service to finish the basic registration. Finishing the basic registration allows you to provide more details on the service by either clicking the Next button or using one of the shortcuts on the navigation menu.\nIn the Media Files and Links section you can upload image that will be shown when a user views your service on the catalogue. You can add images by dragging and dropping files into the designated area or click the plus icon. Next to images, you can also specify the different multiple URLs that will be shown in the detailed information of the service.\nThe openEO Settings can be used to specify the openEO namespace and service ID of your service. Entering this information will enable the Access Service button, allowing visitors of openEO algorithm plaza to execute your service through the openEO Web Editor. The required information is represented in the following table:\n\n\n\nField\nRequired\nDescription\n\n\n\n\nNamespace\nYes\nNamespace of openEO service. When the service was created through a User Defined Process (UDP), the namespace is formatted as u:&lt;publisher username/id&gt;. This information can be extracted from the public URL when creating and sharing the UDP through openEO.\n\n\nService name\nYes\nName of the service as shared within openEO. For a User Defined Process (UDP), the service name corresponds with the ID of the service.\n\n\n\n\n\n\n\nIn order to upgrade the level of service, service providers should improve their services and documentation in such a way that it meets the criteria (here) for the desired levels. Then a request can be made at our help center for upgrading the service.\n\n\n\nBoth the openEO algorithm plaza and orchestrators provide several procedures to operate your service. The following sections describe the different actions that can be taken to hide, suspend, and delete a service from openEO algorithm plaza.\n\n\nChanging the visibility of a service to private ensures that the service is not visible on openEO algorithm plaza. This can be useful to do some bug fixing, developments, and testing before publishing it to openEO algorithm plaza.\nChanging a service’s visibility can be done by navigating to openEO algorithm plaza’s Dashboard. Select the Services submenu to get a list of all services that your organisation manages on openEO algorithm plaza. Next, select the service for which you want to change the visibility by clicking the corresponding entry in the list. This will open the service details. Scroll down to the Publishing settings where you can set the service’s visibility to private.\n\nIt is important to note that setting the visibility to private only hides the service in openEO algorithm plaza. Users are still able to view and execute the service through the orchestrators. The following sections provide additional information on how to remove your service from the openEO algorithm plaza and orchestrators.\n\n\n\nSimilar to making a service private, a TPS can remove a service from openEO algorithm plaza. This will remove it from the openEO algorithm plaza service catalogue and delete all of its related data.\nRemoving a service is done by navigating to the service list on the Dashboard. Click the Services submenu to open a list of all services managed by your organisation. Next, select the service you would like to remove by clicking on its corresponding tile in the list. This will show the window to edit the service. At the bottom of the page, click the Remove button. A popup window will request your confirmation of deleting the service. Clicking Yes will remove the service from the openEO algorithm plaza and your organisation.\n\nIt is important to note that removing the service from the openEO algorithm plaza does not remove it from the orchestrators. Users are still able to execute the service through the orchestrators. The next section provides additional information on how to remove your service from the orchestrators.\n\n\n\nRemoving a service from the orchestrators will disable its execution by any of the orchestrator’s users. The process of removing a service is depending on the orchestrator that was used to onboard the service.\n\n\nopenEO provides two ways to remove a service (also known as a user-defined process in openEO):\n\nUsing the OpenEO APIThe process_graphs endpoint allows users to remove a service based on its ID. More information is available in the official API documentation.\nUsing the openEO Python ClientThe openEO Python Client supplies a delete function that can be executed for any user defined process that is managed by the authenticated user. More information is available in the official Python Client documentation."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#services-overview",
    "href": "Applications/PlazaDetails/ManageService.html#services-overview",
    "title": "Manage your services",
    "section": "",
    "text": "You arrive here by clicking on Services on the sub-navigation options of the portal. In addition to the main navigation for the portal, and the sub-navigation for the portal, you can see a Call to Action (CTA) button for Register your first service in the main body of the page. On first use, you won’t have created any services, so you will be presented with the first use screen. You can click on the CTA button to load the Add service page or click on the Learn how link to load the documentation page. If you have already created at least 1 service previously, you will see the screen below.\n\nThe services are shared within your oganization. If you are a member of multiple organizations, navigate to the profile page to change your Linked Organization.\n\n\nIn the Services area, you can see cards for the services you have created, together with a card area with a Register service CTA button. On already created services, you can see an avatar (at this stage, just a colour and initials from the service name), the service name and a service status indication. As a user, you can click on the avatar or the service’s name to load its detail page. In addition, you can click on the Register service CTA button to load the add service page to create a new service."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#develop-your-service",
    "href": "Applications/PlazaDetails/ManageService.html#develop-your-service",
    "title": "Manage your services",
    "section": "",
    "text": "A good integration in openEO algorithm plaza already starts when programming your algorithm.\nIn openEO, a ‘datacube’ view is used, which hides a lot of the complexity when working with huge EO data archives. It provides full archive access to the most popular datasets. You will have to get familiar with the Application Programming Interface (API), which provides a lot of predefined processes. To integrate existing code, you will have to use the concept of ‘User Defined Functions’ (UDFs). Parallelization and scalability are taken care of.\n\n\nA basic introduction on using openEO can be found here. To deploy your openEO algorithm as a service, we rely on the ‘user defined process’ functionality.\n\n\n\nA good description of your service is key to attract users. Try to give a concise overview of the use cases your service was built for. Higher level services (Level-3 and -4) should also, when available, reference scientific literature and/or validation reports.\nExamples of invocations and images of resulting output are a good way to help people getting started. Finally, a user may want to have an idea of the resource consumption and time required to run your service for a given input."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#register-and-publish-your-service",
    "href": "Applications/PlazaDetails/ManageService.html#register-and-publish-your-service",
    "title": "Manage your services",
    "section": "",
    "text": "The final step as an algorithm/service developer is to publish the service on openEO algorithm plaza. This will make the service visible to other openEO algorithm plaza users, allowing them to incorporate and use the new service in their own workflows. The following sections will guide you through the publishing process.\n\n\nThe next step is to create a new entry on openEO algorithm plaza. This can be done in the Dashboard by selecting Services. The page provides an overview of all the services that are created within your organisation.\n\nTo register your service, click the Register your first service button. You will now be presented with a wizard to enter the necessary information regarding your service.\nThe first step requires you to select the type of service that you want to publish. Currently, the following types are supported:\n\nopenEO - A service that is integrated through the openEO orchestrator\n\n\nIn the next step you can register the basic information for the service. The table below provides an overview of the different required fields:\n\n\n\n\n\n\n\n\nField\nRequired\nDescription\n\n\n\n\nService name\nYes\nTitle of your service, as it will be displayed in the openEO algorithm plaza.\n\n\nSummary\nNo\nShort description of your service. The summary will be visible in the openEO algorithm plaza overview.\n\n\nDescription\nNo\nFull description of your service. The description supports full Markdown syntax.\n\n\nAvatar\nNo\nURL to an image that can be used an avatar of your service. The avatar will be visible in the openEO algorithm plaza overview.\n\n\n\nClick Register Service to finish the basic registration. Finishing the basic registration allows you to provide more details on the service by either clicking the Next button or using one of the shortcuts on the navigation menu.\nIn the Media Files and Links section you can upload image that will be shown when a user views your service on the catalogue. You can add images by dragging and dropping files into the designated area or click the plus icon. Next to images, you can also specify the different multiple URLs that will be shown in the detailed information of the service.\nThe openEO Settings can be used to specify the openEO namespace and service ID of your service. Entering this information will enable the Access Service button, allowing visitors of openEO algorithm plaza to execute your service through the openEO Web Editor. The required information is represented in the following table:\n\n\n\nField\nRequired\nDescription\n\n\n\n\nNamespace\nYes\nNamespace of openEO service. When the service was created through a User Defined Process (UDP), the namespace is formatted as u:&lt;publisher username/id&gt;. This information can be extracted from the public URL when creating and sharing the UDP through openEO.\n\n\nService name\nYes\nName of the service as shared within openEO. For a User Defined Process (UDP), the service name corresponds with the ID of the service."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#upgrade-your-service",
    "href": "Applications/PlazaDetails/ManageService.html#upgrade-your-service",
    "title": "Manage your services",
    "section": "",
    "text": "In order to upgrade the level of service, service providers should improve their services and documentation in such a way that it meets the criteria (here) for the desired levels. Then a request can be made at our help center for upgrading the service."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#operate-your-services",
    "href": "Applications/PlazaDetails/ManageService.html#operate-your-services",
    "title": "Manage your services",
    "section": "",
    "text": "Both the openEO algorithm plaza and orchestrators provide several procedures to operate your service. The following sections describe the different actions that can be taken to hide, suspend, and delete a service from openEO algorithm plaza.\n\n\nChanging the visibility of a service to private ensures that the service is not visible on openEO algorithm plaza. This can be useful to do some bug fixing, developments, and testing before publishing it to openEO algorithm plaza.\nChanging a service’s visibility can be done by navigating to openEO algorithm plaza’s Dashboard. Select the Services submenu to get a list of all services that your organisation manages on openEO algorithm plaza. Next, select the service for which you want to change the visibility by clicking the corresponding entry in the list. This will open the service details. Scroll down to the Publishing settings where you can set the service’s visibility to private.\n\nIt is important to note that setting the visibility to private only hides the service in openEO algorithm plaza. Users are still able to view and execute the service through the orchestrators. The following sections provide additional information on how to remove your service from the openEO algorithm plaza and orchestrators.\n\n\n\nSimilar to making a service private, a TPS can remove a service from openEO algorithm plaza. This will remove it from the openEO algorithm plaza service catalogue and delete all of its related data.\nRemoving a service is done by navigating to the service list on the Dashboard. Click the Services submenu to open a list of all services managed by your organisation. Next, select the service you would like to remove by clicking on its corresponding tile in the list. This will show the window to edit the service. At the bottom of the page, click the Remove button. A popup window will request your confirmation of deleting the service. Clicking Yes will remove the service from the openEO algorithm plaza and your organisation.\n\nIt is important to note that removing the service from the openEO algorithm plaza does not remove it from the orchestrators. Users are still able to execute the service through the orchestrators. The next section provides additional information on how to remove your service from the orchestrators.\n\n\n\nRemoving a service from the orchestrators will disable its execution by any of the orchestrator’s users. The process of removing a service is depending on the orchestrator that was used to onboard the service.\n\n\nopenEO provides two ways to remove a service (also known as a user-defined process in openEO):\n\nUsing the OpenEO APIThe process_graphs endpoint allows users to remove a service based on its ID. More information is available in the official API documentation.\nUsing the openEO Python ClientThe openEO Python Client supplies a delete function that can be executed for any user defined process that is managed by the authenticated user. More information is available in the official Python Client documentation."
  },
  {
    "objectID": "Applications/PlazaDetails/Strength.html",
    "href": "Applications/PlazaDetails/Strength.html",
    "title": "Credit Strength",
    "section": "",
    "text": "The following mentioned are among the popular services available in openEO algorithm plaza. Here we have presented an average credit strength for these services. Please note that depending on the time interval and area of interest, the credits can slightly vary.\nThe purpose of this document is to solely provide users with an assumption on how these credits work and their strength for varying services.\n\nNDVI\nFor the calculation of Normalized Difference Vegetation Index (NDVI), you can acquire ~250 NDVI images, each with an area of 1 hectare, i.e. 1 NDVI image patch of 1 hectare cost 3-5 credits.\nNDII\nComputation of the Normalized Difference Infrared Index (NDII) provides the user with an indication of the water content in the plant canopies. A straightforward calculation of the NDII can be achieved from openEO algorithm plaza NDII service with the use of 4-8 credits per hectare area, i.e. you can use your 1000 credits for computing NDII in a given area of ~117 hectares.\nBiomass\nThe Biomass service provided by openEO algorithm plaza can be a critical component in tracking and quantifying carbon capture in agriculture and natural vegetation. Users can use this service with approximately 20-40 credits per hectare, i.e. ~33-hectare area with a total of 1000 credits.\nCropSAR\nThe operational agricultural monitoring can be a key use case for this service as it uses Sentinel-1 radar observations to augment those of Sentinel-2. By doing so, more continuous vegetation properties monitoring can be performed, including vegetation information for situations where these properties cannot be retrieved from Sentinel-2 observations due to cloud occurrence. Users can use this service with approximately 40-60 credits per hectare, i.e. ~20-hectare area with a total of 1000 credits.\n\n\nThough the required credit for direct download of the output data is two credits for all the services, it has a time limitation of 10 seconds to run the entire process. Otherwise, the download process will fail."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceProviderGuide.html",
    "href": "Applications/PlazaDetails/ServiceProviderGuide.html",
    "title": "Guide for Third Party Service Providers (TPS)",
    "section": "",
    "text": "Below you can find more information on the following topics.\n\nCreate your account\nSigning in\nManage your organisation\nManage your services\nManage your profile\nManage your billing information\nService Report"
  },
  {
    "objectID": "Applications/PlazaDetails/Overview.html",
    "href": "Applications/PlazaDetails/Overview.html",
    "title": "Overview",
    "section": "",
    "text": "Being an online Application Programming Interface (API) and integrations, openEO algorithm plaza provides a self-service portal through which customers, internal staff, and external providers can interact, publish, and use integrations easily in one place. In general, because EO user and service provider platforms aggregate services and integrations from a range of providers, the selection is usually wider, and availability is higher than in vendor-specific online portals. As an authenticated user using the openEO algorithm plaza, you should be able to view the advertised services.\n\nYou will see:\n\nA main list of all the services, ordered by popularity, paginated.\nA text filter bar to filter through the existing services.\nAttribute filtering (publisher, category, type).\n\nEach service will be visually represented on a card by:\n\nA logo\nThe service’s title\nThe service’s short description\nThe service’s maturity level\n\nYou can click on each service and be redirected to the service’s detail page.\n\n\n\n\nYou arrive at the services overview after having logged in. Alternatively, you can access this overview by clicking ‘Dashboard’ –&gt; ‘Catalogue’ Per service, some brief information about its organisation and a list of other services that this organisation has published to the openEO algorithm plaza is available. You can click on any of the services listed as part of this organisation and be redirected to the service detail."
  },
  {
    "objectID": "Applications/PlazaDetails/Overview.html#service-publishers",
    "href": "Applications/PlazaDetails/Overview.html#service-publishers",
    "title": "Overview",
    "section": "",
    "text": "You arrive at the services overview after having logged in. Alternatively, you can access this overview by clicking ‘Dashboard’ –&gt; ‘Catalogue’ Per service, some brief information about its organisation and a list of other services that this organisation has published to the openEO algorithm plaza is available. You can click on any of the services listed as part of this organisation and be redirected to the service detail."
  },
  {
    "objectID": "Applications/PlazaDetails/Overview.html#service-details-view",
    "href": "Applications/PlazaDetails/Overview.html#service-details-view",
    "title": "Overview",
    "section": "Service details view",
    "text": "Service details view\n\nAs a user, you want to know about a specific service. You arrive at this page by clicking on a service from the openEO algorithm plaza’s main page.\n\nAs an authenticated user that is visualizing the details of a specific service, you can see:\n\nA logo\nA list of features\nA description\nThe owner (organisation)\nA list of other services from the organisation\n\nYou can click on the organisation’s page (“publisher page”) and be redirected to the organisation’s page, listing all the available openEO algorithm plaza services from this organisation."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html",
    "href": "Applications/PlazaDetails/ManageBilling.html",
    "title": "Manage your billing information",
    "section": "",
    "text": "During the execution of our openEO algorithm plaza services, credits will be deducted for each execution. You can manage your credits directly on the openEO algorithm plaza by clicking the Billing menu item. This redirects to the billing page where you can see:\n\nAn overview of your current credit score\nA Call to Action (CTA) button to top up your credits\nA selection menu to select a subscription plan\nAn overview of your financial transactions\n\n\n\nTo visualize available credits in your account, first, you must sign in. If you don’t have login credentials, please Register.\nOnce logged in, click on the Billing tab that leads to a page showing your available credits, followed by additional information on subscription.\n\nThe credits that are shown are shared amongst your organization. If you are a member of multiple organizations, navigate to the profile page to change your Billing Organization.\n\n\n\n\n\nCredits are deducted based on the chosen services and spatial extent. The amount will vary depending on the processing complexity and time required for each type of service. Detailed examples of some well-known services and how they fit into the 1000 free credits can further be found here.\nMoreover, every user is provided with 1000 credits each month, with which they can execute multiple services.\n\n\n\nBased on the required credits for executing a service, if you think your available credits are insufficient, there are two ways you can replenish the credits available in your account. You can purchase them as a one-time purchase or buy a subscription.\n\nPurchase Credits\nYou can add/purchase a limited credit amount through a one-time payment by clicking on Add credits button next to the credit score. After choosing among the different credit packs, you are redirected to a payment service to continue payment.\n\nCredits packs will be made available soon.\n\nOnce we receive the payment, your credits will be updated.\nCredit Subscription\nThe other way is by selecting one of the available subscription plans. Once you click on the “Start subscription” button, you will be redirected to the payment page for your selected subscription plan, where you can provide the payment details for recurring payments.\n\nSubscriptions will be made available soon.\n\nAt any time, you can change or cancel an active subscription. The current credits will be kept, and you will receive a new amount after the successful payment of the new subscription plan.\n\n\n\n\nIf you want to request a statement regarding your credit expenditure, you can create a ticket with your username, email, and the time interval for the requested information."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html#monitor-available-credits",
    "href": "Applications/PlazaDetails/ManageBilling.html#monitor-available-credits",
    "title": "Manage your billing information",
    "section": "",
    "text": "To visualize available credits in your account, first, you must sign in. If you don’t have login credentials, please Register.\nOnce logged in, click on the Billing tab that leads to a page showing your available credits, followed by additional information on subscription.\n\nThe credits that are shown are shared amongst your organization. If you are a member of multiple organizations, navigate to the profile page to change your Billing Organization."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html#credits-strength",
    "href": "Applications/PlazaDetails/ManageBilling.html#credits-strength",
    "title": "Manage your billing information",
    "section": "",
    "text": "Credits are deducted based on the chosen services and spatial extent. The amount will vary depending on the processing complexity and time required for each type of service. Detailed examples of some well-known services and how they fit into the 1000 free credits can further be found here.\nMoreover, every user is provided with 1000 credits each month, with which they can execute multiple services."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html#adding-credits",
    "href": "Applications/PlazaDetails/ManageBilling.html#adding-credits",
    "title": "Manage your billing information",
    "section": "",
    "text": "Based on the required credits for executing a service, if you think your available credits are insufficient, there are two ways you can replenish the credits available in your account. You can purchase them as a one-time purchase or buy a subscription.\n\nPurchase Credits\nYou can add/purchase a limited credit amount through a one-time payment by clicking on Add credits button next to the credit score. After choosing among the different credit packs, you are redirected to a payment service to continue payment.\n\nCredits packs will be made available soon.\n\nOnce we receive the payment, your credits will be updated.\nCredit Subscription\nThe other way is by selecting one of the available subscription plans. Once you click on the “Start subscription” button, you will be redirected to the payment page for your selected subscription plan, where you can provide the payment details for recurring payments.\n\nSubscriptions will be made available soon.\n\nAt any time, you can change or cancel an active subscription. The current credits will be kept, and you will receive a new amount after the successful payment of the new subscription plan."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageBilling.html#request-for-statement",
    "href": "Applications/PlazaDetails/ManageBilling.html#request-for-statement",
    "title": "Manage your billing information",
    "section": "",
    "text": "If you want to request a statement regarding your credit expenditure, you can create a ticket with your username, email, and the time interval for the requested information."
  },
  {
    "objectID": "Applications/PlazaDetails/CreateAccount.html",
    "href": "Applications/PlazaDetails/CreateAccount.html",
    "title": "Create an account",
    "section": "",
    "text": "If you haven’t previously registered and created an account, you need to click on the Register navigation option on the main openEO algorithm plaza portal landing page and this will launch the registration flow."
  },
  {
    "objectID": "Applications/PlazaDetails/CreateAccount.html#sign-up",
    "href": "Applications/PlazaDetails/CreateAccount.html#sign-up",
    "title": "Create an account",
    "section": "",
    "text": "If you haven’t previously registered and created an account, you need to click on the Register navigation option on the main openEO algorithm plaza portal landing page and this will launch the registration flow."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageProfile.html",
    "href": "Applications/PlazaDetails/ManageProfile.html",
    "title": "Manage your profile",
    "section": "",
    "text": "As a user, you want to be able to view and update your profile settings, including the security aspects (Passphrase).\n\nYou arrive at this page by clicking on the user’s avatar (top right-hand corner of the openEO algorithm plaza portal screen). You will be able to see a sub-navigation menu with options (Overview, Security, Team, Organization) and a logout icon."
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html",
    "href": "Applications/PlazaDetails/ExecuteService.html",
    "title": "Execute a service",
    "section": "",
    "text": "Services can be executed through the tools that are provided by the different orchestrators. The table below shows a short summary of the different tools that are available for each orchestrator.\n\n\n\n\n\n\nopenEO\n\n\n\n\nOnline user interface - web editor  Client Libraries (JavaScript, Python, R) API\n\n\n\nThere are several ways to discover how a service can be executed. When publishing a service on the openEO algorithm plaza, a service provider can choose to provide the following information in the service details:\n\nAn executable link which redirects the user to the online orchestrator’s user interface. If this is the case, an Access service button will appear when opening an openEO algorithm plaza service.\nSample code in the service description on how to execute a service.\n\n\n\nBoth orchestrators provide an online user interface where users can execute services directly in a web browser. Through these graphical user interfaces, users can execute, link, and configure different services. More information on the usage of the online applications is presented in the table below.\n\n\n\nopenEO\n\n\n\n\nAccess\n\n\nDocumentation\n\n\n\n\n\n\nopenEO provides client libraries to support the creation and execution of JavaScript, Python and R services. The full client libraries documentation is available on the official openEO support pages:\n\nJavaScript\nPython\nR\n\nThe following example shows a code sample on how to execute a service through the openEO Python Client.\nimport openeo\n\n# Setup parameters\naoi = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [\n                5.179324150085449,\n                51.2498689148547\n            ],\n            [\n                5.178744792938232,\n                51.24672597710759\n            ],\n            [\n                5.185289382934569,\n                51.24504696935156\n            ],\n            [\n                5.18676996231079,\n                51.245342479161295\n            ],\n            [\n                5.187370777130127,\n                51.24918393390799\n            ],\n            [\n                5.179324150085449,\n                51.2498689148547\n            ]\n        ]\n    ]\n}\ndate = '2020-06-01'\n\n# Setup connection with OpenEO\neoconn = openeo.connect(\"https://openeo.vito.be\").authenticate_oidc(\"egi\")\n\n# Create a processing graph from the BIOMASS process using an active openEO connection\ntaskmap = eoconn.datacube_from_process(\"taskmap_generate\", namespace=\"https://openeo.vito.be/openeo/1.0/processes/u:EOplaza_tps/taskmap_generate\", aoi=aoi,\n                                       date=date)\n\n# Execute the openEO request as a batch job\ntaskmap_job = taskmap.save_result(format='gtiff').send_job()\ntaskmap_job.start_and_wait().get_results()\nTo execute a service from the openEO algorithm plaza through one of the OpenEO client libraries, it is important to use the datacube_from_process function. This accepts the ID and namespace of the service. Both are made available in the service description on the openEO algorithm plaza. The full documentation on using the function is available on the official openEO documentation.\nMore examples are available in the openEO GitHub repository.\n\n\n\nBoth openEO provide a fully documented API as a more advanced way to integrate features of both orchestrators in any existing application or workflow. These APIs can also be used to execute openEO algorithm plaza services. The documentation of these services is available at:\n\n\n\nopenEO\n\n\n\n\nDocumentation"
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html#online-user-interface",
    "href": "Applications/PlazaDetails/ExecuteService.html#online-user-interface",
    "title": "Execute a service",
    "section": "",
    "text": "Both orchestrators provide an online user interface where users can execute services directly in a web browser. Through these graphical user interfaces, users can execute, link, and configure different services. More information on the usage of the online applications is presented in the table below.\n\n\n\nopenEO\n\n\n\n\nAccess\n\n\nDocumentation"
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html#client-libraries",
    "href": "Applications/PlazaDetails/ExecuteService.html#client-libraries",
    "title": "Execute a service",
    "section": "",
    "text": "openEO provides client libraries to support the creation and execution of JavaScript, Python and R services. The full client libraries documentation is available on the official openEO support pages:\n\nJavaScript\nPython\nR\n\nThe following example shows a code sample on how to execute a service through the openEO Python Client.\nimport openeo\n\n# Setup parameters\naoi = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [\n                5.179324150085449,\n                51.2498689148547\n            ],\n            [\n                5.178744792938232,\n                51.24672597710759\n            ],\n            [\n                5.185289382934569,\n                51.24504696935156\n            ],\n            [\n                5.18676996231079,\n                51.245342479161295\n            ],\n            [\n                5.187370777130127,\n                51.24918393390799\n            ],\n            [\n                5.179324150085449,\n                51.2498689148547\n            ]\n        ]\n    ]\n}\ndate = '2020-06-01'\n\n# Setup connection with OpenEO\neoconn = openeo.connect(\"https://openeo.vito.be\").authenticate_oidc(\"egi\")\n\n# Create a processing graph from the BIOMASS process using an active openEO connection\ntaskmap = eoconn.datacube_from_process(\"taskmap_generate\", namespace=\"https://openeo.vito.be/openeo/1.0/processes/u:EOplaza_tps/taskmap_generate\", aoi=aoi,\n                                       date=date)\n\n# Execute the openEO request as a batch job\ntaskmap_job = taskmap.save_result(format='gtiff').send_job()\ntaskmap_job.start_and_wait().get_results()\nTo execute a service from the openEO algorithm plaza through one of the OpenEO client libraries, it is important to use the datacube_from_process function. This accepts the ID and namespace of the service. Both are made available in the service description on the openEO algorithm plaza. The full documentation on using the function is available on the official openEO documentation.\nMore examples are available in the openEO GitHub repository."
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html#api",
    "href": "Applications/PlazaDetails/ExecuteService.html#api",
    "title": "Execute a service",
    "section": "",
    "text": "Both openEO provide a fully documented API as a more advanced way to integrate features of both orchestrators in any existing application or workflow. These APIs can also be used to execute openEO algorithm plaza services. The documentation of these services is available at:\n\n\n\nopenEO\n\n\n\n\nDocumentation"
  },
  {
    "objectID": "404-not-found.html",
    "href": "404-not-found.html",
    "title": "Page not found",
    "section": "",
    "text": "Page not found"
  }
]