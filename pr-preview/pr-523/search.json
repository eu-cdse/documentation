[
  {
    "objectID": "Registration.html",
    "href": "Registration.html",
    "title": "User registration and authentication",
    "section": "",
    "text": "This section provides information on how to register and authenticate on the Copernicus Data Space Ecosystem."
  },
  {
    "objectID": "Registration.html#step-1-registration",
    "href": "Registration.html#step-1-registration",
    "title": "User registration and authentication",
    "section": "Step 1: Registration",
    "text": "Step 1: Registration\nGo to website where you can simply click on “login” with the button located in the top right corner.\n\n\n\n\n\nOn the landing page, locate the “REGISTER” button on the screen’s right side. Clicking on it will lead you to the Copernicus Data Space Ecosystems registration form. Please ensure to complete all mandatory fields (excluding Thematic activity and Purpose of Use), and you have the option to fill in any optional fields. Once you have provided the necessary information, accept the terms and conditions. Additionally, you can accept any other optional consents if applicable. Finally, click the “REGISTER” button to complete the process."
  },
  {
    "objectID": "Registration.html#step-2-e-mail-verification",
    "href": "Registration.html#step-2-e-mail-verification",
    "title": "User registration and authentication",
    "section": "Step 2: E-mail verification",
    "text": "Step 2: E-mail verification\nUpon registration, you will be prompted to verify your email address by receiving a verification email. To complete the process, simply click on the “Verify email address” link when you open the email.\n\nAfter successfully verifying your email, your registration process is complete. You can now log in using your credentials (providing Email and Password).\nIf you have an issue with registering or you want to deregister, please contact us."
  },
  {
    "objectID": "APIs/Subscriptions.html",
    "href": "APIs/Subscriptions.html",
    "title": "Subscriptions",
    "section": "",
    "text": "This section provides the detailed description of PUSH and PULL subscriptions within the Copernicus Data Space Ecosystem Catalogue, its workflows and exemplary requests.\nSubscription services allow users to receive notifications in an automated way about the Event that has taken place in the Copernicus Data Space Ecosystem Catalogue. Currently, they inform users about newly added products to the Data Space Catalogue according to the set of filter parameters supplied within the subscription request.\nThere two types of Subscriptions available for users:\nUsers are encouraged to explore examples of processing scripts for Subscriptions which can be found at the following links:"
  },
  {
    "objectID": "APIs/Subscriptions.html#pull-subscriptions",
    "href": "APIs/Subscriptions.html#pull-subscriptions",
    "title": "Subscriptions",
    "section": "PULL Subscriptions",
    "text": "PULL Subscriptions\nFor PULL notifications, the nominal scenario can be described as follows:\n\nCreation of the subscription\n\nThe client submits a subscription create request to Subscription Service. With the creation request, users can specify the filtering parameters for the products within the subscription, status of the subscription, stage order, priority and subscription event to be monitored. All of the parameters are optional. If not provided by the client, the default values will be assigned. The request is then processed by the Subscription Service, and a response is returned which includes a unique identifier assigned to the subscription (subscription’s Id), subscription status (initially set to running), subscription request submission date, filtering parameters, stage order, priority of the subscription and subscription event to be monitored.\n\nProduct Notification\n\nAfter a new product is added to the Data Space Catalogue, the Subscription Service sends the notification to the client’s queue. Therefore users should read and acknowledge the notifications on the queue regularly. In case the maximum size of the queue is exceeded, the oldest products notifications will be automatically removed with no possibility to be retrieved. If the subscription is paused, the new products’ availability notifications will not be sent to the queue.\n\nPULL Subscription Entity Description\nBelow please find the description of the PULL Subscription Entity.\n\n\n\n    \n\n\n\n\n\n\n\n\n\nSubscription Properties\nType\nDescription\nExample\n\n\n\n\nId\nGuid\nIt is a universally unique identifier (UUID). The Id is a local identifier for the Subscription instance within the Catalogue, assigned upon Subscription creation.\n991c4730-cf6f-432a-9f6c-47be0230ff45\n\n\nStatus\nSubscription Status enumeration\nThe allowed values of the subscription status are:\nrunning\npaused\ncancelled\n\nThe default value set to 'Status', if not provided by user, is 'running'.\nrunning\n\n\nSubscriptionEvent\nSubscription Event enumeration\nThe subscription event to be monitored and for which notification is provided:\ncreated\nThe default value set to \"SubscriptionEvent\", if not provided by user, is \"created\".\n\nFor \"SubscriptionEvent\" = \"created\" the notifications about newly added products to the Data Space Catalogue will be sent to the user's endpoint.\ncreated\n\n\nFilterParam\nString\nThe filter parameters of the Subscription (refers to the $filter= parameter of any Products? query). The same filtering parameters as described for [OData Data Sapce Catalogue](https://documentation.dataspace.copernicus.eu/APIs/OData.html#filter-option) are available.\nCollection/Name eq 'SENTINEL-1' and Attributes/OData.CSC.StringAttribute/any (att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'IW_SLC__1S')\n\n\nSubmissionDate\nDateTimeOffset\nDate and time at which the Subscription was received by the Catalogue. Time is in UTC in the format YYYY-MMDDThh:mm:ss.sssZ\n2024-01-17T09:13:04.654Z\n\n\nLastNotificationDate\nDateTimeOffset\nDate and time corresponding to the last time the Subscription Ack endpoint was queried by the client. Time is in UTC in the format YYYY-MMDDThh:mm:ss.sssZ\n2024-01-17T09:50:10.654Z\n\n\nStageOrder\nBoolean\nAutomatically orders the staging of products fulfilling the subscription.\n\nOnly used if SubscriptionEvent = created \n\nCurrently, the order of staging products is not feasible as all new products in Data Space Catalogue have status set to 'Online' and can be accessed immediately without setting an order.\ntrue\n\n\nPriority\nInt64\nPriority of the created orders resulting from the subscription. Currently automatically fixed to '1' without the possibility to change the value. Within further development of the Subscription Service it is possible to enable Priority function which will determine the priority of the user's orders.\n1\n\n\nAckId\nString\nAcknowledge Id assigned to each product notification. Required for acknowledging the notification messages from the client's queue.\nMTcxMDc1NjcwNjUzMi0wOjk5MWM0NzMwLWNmNmYtNDMyYS05ZjZjLTQ3YmUwMjMwZmY0NQ==\n\n\nAckMessagesNum\nInt64\nThe number of the notifications that were acknowledged.\n20\n\n\nCurrentQueueLength\nInt64\nCurrent length of the individual user's queue.\n2115\n\n\nMaxQueueLength\nInt64\nThe maximum number of notifications on the individual user's queue.\n100000\n\n\n\n\n\n\n\n\nCreate Subscription\nTo create PULL Subscription users need to submit a subscription create request to the Subscription endpoint.\nWhile creating a subscription, users can specify the Event they would like to be notified. For now, the following Event can be chosen:\n\nCreated\n\nWithin the Subscription create request, users can also provide the filtering parameters (e.g. productType, collection, geofootprint). The Subscription Service will then provide the notifications about newly added products to the Copernicus Data Space Ecosystem Catalogue according to the set of filter parameters supplied within the subscription request. If FilterParam is not provided within the subscription request body, it will be automatically set to empty and then the notifications about all newly added products will be generated.\nSubscriptions enables the same filtering parameters as described for OData Data Sapce Catalogue. All filters should be provided in FilterParam field.\nTo create PULL Subscription a request to the Data Space service should be submitted:\n\nHTTP requestResponse example\n\n\nPOST \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions\n \n{\n    \"StageOrder\": true,\n    \"FilterParam\": \"Collection/Name eq 'SENTINEL-1' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'IW_SLC__1S')\",\n    \"Priority\": 1,\n    \"Status\": \"running\",\n    \"SubscriptionEvent\": [\n        \"created\"\n    ]\n}\n\n\n201 Created\n \n{\n    \"Id\": \"991c4730-cf6f-432a-9f6c-47be0230ff45\",\n    \"FilterParam\": \"Collection/Name eq 'SENTINEL-1' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'IW_SLC__1S')\",\n    \"StageOrder\": true,\n    \"Priority\": 1,\n    \"Status\": \"running\",\n    \"SubscriptionEvent\": [\n        \"created\"\n    ],\n    \"SubmissionDate\": \"2024-03-13T09:39:49.404Z\",\n    \"@odata.context\": \"$metadata#Subscriptions/$entity\"\n}\n\n\n\n\n\nRead Subscription\nTo read the subscription notifications from the client’s queue, the request to subscription Read endpoint should be submitted:\n\nHTTP request\n\n\nGET \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(subscription_id)/Read\n\n\n\nWhile requesting subscription Read endpoint, by default top one notifications will be read. Users can specify to read maxiumum 20 top notifications by adding $top parameter to their request.\n\nExample request\n\n\nGET \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(991c4730-cf6f-432a-9f6c-47be0230ff45)/Read?$top=2\n\n\n\nResponse example\n\nIf Subscription is Active or Paused\n\nThe whole response from the Subscripton Read endpoint is kept on the indivdual user’s queue for three days. After three days, only the endpoint response without value and ProductName is available (as provided below).\n\nResponse exampleResponse example after 3 days\n\n\n200 OK\n \n[\n    {\n        \"@odata.context\": \"$metadata#Notification/$entity\",\n        \"SubscriptionEvent\": \"created\",\n        \"ProductId\": \"d2ff986b-9454-43d6-95e0-1a0ae27019d7\",\n        \"ProductName\": \"S1A_IW_SLC__1SDV_20240313T054626_20240313T054653_052959_066921_3759.SAFE\",\n        \"SubscriptionId\": \"991c4730-cf6f-432a-9f6c-47be0230ff45\",\n        \"NotificationDate\": \"2024-03-13T13:39:59.000Z\",\n        \"AckId\": \"MTcxMDc1NjcwNjUzMi0wOjk5MWM0NzMwLWNmNmYtNDMyYS05ZjZjLTQ3YmUwMjMwZmY0NQ==\",\n        \"value\": {\n            \"@odata.context\": \"$metadata#Products(Assets())(Attributes())(Locations())/$entity\",\n            \"@odata.mediaContentType\": \"application/octet-stream\",\n            \"Id\": \"d2ff986b-9454-43d6-95e0-1a0ae27019d7\",\n            \"Name\": \"S1A_IW_SLC__1SDV_20240313T054626_20240313T054653_052959_066921_3759.SAFE\",\n            \"ContentType\": \"application/octet-stream\",\n            \"ContentLength\": 8217756705,\n            \"OriginDate\": \"2024-03-13T06:47:17.308Z\",\n            \"PublicationDate\": \"2024-03-13T06:56:59.293Z\",\n            \"ModificationDate\": \"2024-03-13T10:47:57.429Z\",\n            \"Online\": true,\n            \"EvictionDate\": \"\",\n            \"S3Path\": \"/eodata/Sentinel-1/SAR/IW_SLC__1S/2024/03/13/S1A_IW_SLC__1SDV_20240313T054626_20240313T054653_052959_066921_3759.SAFE\",\n            \"Checksum\": [\n                {\n                    \"Value\": \"a7443f2e7186a5c114c951c9a24979ea\",\n                    \"Algorithm\": \"MD5\",\n                    \"ChecksumDate\": \"2024-03-13T10:47:45.298465Z\"\n                },\n                {\n                    \"Value\": \"62768a5a51dd61ad4f3f92d3c9926b66fafb1ee945f0e30b0e6ecd0c1590822d\",\n                    \"Algorithm\": \"BLAKE3\",\n                    \"ChecksumDate\": \"2024-03-13T10:47:57.259964Z\"\n                }\n            ],\n            \"ContentDate\": {\n                \"Start\": \"2024-03-13T05:46:26.715Z\",\n                \"End\": \"2024-03-13T05:46:53.707Z\"\n            },\n            \"Footprint\": \"geography'SRID=4326;POLYGON ((13.873887 65.505287, 14.91091 67.090202, 8.940076 67.587387, 8.268893 65.983887, 13.873887 65.505287))'\",\n            \"GeoFootprint\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [...\n                ]\n            },\n            \"Attributes\": [...\n            ],\n            \"Assets\": [\n                {\n                    \"Type\": \"QUICKLOOK\",\n                    \"Id\": \"b43f60cb-3869-4c1d-b1e5-336e0d057f43\",\n                    \"DownloadLink\": \"https://catalogue.dataspace.copernicus.eu/odata/v1/Assets(b43f60cb-3869-4c1d-b1e5-336e0d057f43)/$value\",\n                    \"S3Path\": \"/eodata/Sentinel-1/SAR/IW_SLC__1S/2024/03/13/S1A_IW_SLC__1SDV_20240313T054626_20240313T054653_052959_066921_3759.SAFE\"\n                }\n            ],\n            \"Locations\": [...\n            ]\n        }\n    },\n    {\n        \"@odata.context\": \"$metadata#Notification/$entity\",\n        \"SubscriptionEvent\": \"created\",\n        \"ProductId\": \"33ad5694-9208-4001-ae4f-6d7cd0579ce0\",\n        \"ProductName\": \"S1A_IW_SLC__1SDV_20240313T092716_20240313T092732_052961_066935_89F2.SAFEE\",\n        \"SubscriptionId\": \"991c4730-cf6f-432a-9f6c-47be0230ff45\",\n        \"NotificationDate\": \"2024-03-13T13:39:59.000Z\",\n        \"AckId\": \"MTcxMDc1NjcwNjY2NC0wOjk5MWM0NzMwLWNmNmYtNDMyYS05ZjZjLTQ3YmUwMjMwZmY0NQ==\",\n        \"value\": {\n            \"@odata.context\": \"$metadata#Products(Assets())(Attributes())(Locations())/$entity\"\",\n            \"@odata.mediaContentType\": \"application/octet-stream\",\n            \"Id\": \"33ad5694-9208-4001-ae4f-6d7cd0579ce0\",\n            \"Name\": \"S1A_IW_SLC__1SDV_20240313T092716_20240313T092732_052961_066935_89F2.SAFE\",\n            \"ContentType\": \"application/octet-stream\",\n            \"ContentLength\": 4355824564,\n            \"OriginDate\": \"2024-03-13T11:15:44.930Z\",\n            \"PublicationDate\": \"2024-03-13T11:23:27.577Z\",\n            \"ModificationDate\": \"2024-03-13T11:24:14.138Z\",\n            \"Online\": true,\n            \"EvictionDate\": \"\",\n            \"S3Path\": \"/eodata/Sentinel-1/SAR/IW_SLC__1S/2024/03/13/S1A_IW_SLC__1SDV_20240313T092716_20240313T092732_052961_066935_89F2.SAFE\",\n            \"Checksum\": [\n                {\n                    \"Value\": \"2aa3dd4d604166d9937d1e2ea33d1a84\",\n                    \"Algorithm\": \"MD5\",\n                    \"ChecksumDate\": \"2024-03-13T11:24:04.717777Z\"\n                },\n                {\n                    \"Value\": \"b60f11d44ee700736ceb16bdacf25af89c878b6d2b370ca6e801743fb127e1dc\",\n                    \"Algorithm\": \"BLAKE3\",\n                    \"ChecksumDate\": \"2024-03-13T11:24:13.985182Z\"\n                }\n            ],\n            \"ContentDate\": {\n                \"Start\": \"2024-03-13T09:27:16.441Z\",\n                \"End\": \"2024-03-13T09:27:32.471Z\"\n            },\n            \"Footprint\": \"geography'SRID=4326;POLYGON ((-57.645779 -18.073198, -57.413177 -17.107573, -59.767452 -16.559637, -60.01339 -17.520658, -57.645779 -18.073198))'\",\n            \"GeoFootprint\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [...\n                ]\n            },\n            \"Attributes\": [...\n            ],\n            \"Assets\": [\n                {\n                    \"Type\": \"QUICKLOOK\",\n                    \"Id\": \"f4cfe4c9-5b56-47c2-87ce-05b090c7a4ba\",\n                    \"DownloadLink\": \"https://catalogue.dataspace.copernicus.eu/odata/v1/Assets(f4cfe4c9-5b56-47c2-87ce-05b090c7a4ba)/$value\",\n                    \"S3Path\": \"/eodata/Sentinel-1/SAR/IW_SLC__1S/2024/03/13/S1A_IW_SLC__1SDV_20240313T092716_20240313T092732_052961_066935_89F2.SAFE\"\n                }\n            ],\n            \"Locations\": [...\n            ]\n        }\n    }\n]\n\n\n200 OK\n \n[\n    {\n        \"@odata.context\": \"$metadata#Notification/$entity\",\n        \"SubscriptionEvent\": \"created\",\n        \"ProductId\": \"d2ff986b-9454-43d6-95e0-1a0ae27019d7\",\n        \"SubscriptionId\": \"991c4730-cf6f-432a-9f6c-47be0230ff45\",\n        \"NotificationDate\": \"2024-03-13T13:39:59.000Z\",\n        \"AckId\": \"MTcxMDc1NjcwNjUzMi0wOjk5MWM0NzMwLWNmNmYtNDMyYS05ZjZjLTQ3YmUwMjMwZmY0NQ==\"\n    },\n    {\n        \"@odata.context\": \"$metadata#Notification/$entity\",\n        \"SubscriptionEvent\": \"created\",\n        \"ProductId\": \"33ad5694-9208-4001-ae4f-6d7cd0579ce0\",\n        \"SubscriptionId\": \"991c4730-cf6f-432a-9f6c-47be0230ff45\",\n        \"NotificationDate\": \"2024-03-13T13:39:59.000Z\",\n        \"AckId\": \"MTcxMDc1NjcwNjY2NC0wOjk5MWM0NzMwLWNmNmYtNDMyYS05ZjZjLTQ3YmUwMjMwZmY0NQ==\"\n    }\n]\n\n\n\n\nIf Subscription is Cancelled\n\n\nResponse example\n\n\n404 Not Found\n \n{\n    \"detail\": {\n        \"message\": \"Subscription with id 991c4730-cf6f-432a-9f6c-47be0230ff45 not found.\",\n        \"request_id\": \"aed89ead-b495-4f76-b6e9-51870973a44e\"\n    }\n}\n\n\n\n\n\nAck Subscription\nAll notifications, after reading by the client, should be acknowledged to not exceed the limit of the queue. For acknowledging the notifications, the assigned parametr is added to the notification - ‘AckId’. Each product notification has its own AckId token, which should be used to acknowledge the notifications messages on the client’s queue. Using the ‘AckId’ token for a specific notification means acknowledging receipt of the notification for which the ‘AckId’ was assigned, along with all preceding messages. For example if user use READ endpoint with top parameter set to 10 and then use the AckID of 10th message in Ack endpoint then all 10 messages will be acknowledged and removed from subscription queue.\nTo ack the notifications on the queue:\n\nHTTP Request\n\n\nPOST \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(991c4730-cf6f-432a-9f6c-47be0230ff45)/Ack?$ackid=token\n\n\n\n\nRequest example\n\n\nPOST \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(991c4730-cf6f-432a-9f6c-47be0230ff45)/Ack?$ackid=MTcxMDc1NjcwNjY2NC0wOjk5MWM0NzMwLWNmNmYtNDMyYS05ZjZjLTQ3YmUwMjMwZmY0NQ==\n\n\n\nResponse example\n\nIf Subscription is Active or Paused\n\n\nResponse example\n\n\n200 OK\n \n{\n    \"@odata.context\": \"$metadata#Notification/$entity\",\n    \"AckMessagesNum\": 2,\n    \"CurrentQueueLength\": 2115,\n    \"MaxQueueLength\": 100000\n}\n\n\n\n\nIf Subscription is Cancelled\n\n\nResponse example\n\n\n404 Not Found\n \n{\n    \"detail\": {\n        \"message\": \"Subscription with id 991c4730-cf6f-432a-9f6c-47be0230ff4 not found.\",\n        \"request_id\": \"ae19864a-5bda-4893-9f02-a62eba95fd7a\"\n    }\n}"
  },
  {
    "objectID": "APIs/Subscriptions.html#push-subscriptions",
    "href": "APIs/Subscriptions.html#push-subscriptions",
    "title": "Subscriptions",
    "section": "PUSH Subscriptions",
    "text": "PUSH Subscriptions\nFor PUSH notifications, the nominal scenario can be described as follows:\n\nCreation of the subscription\n\nThe client submits a subscription create request to Subscription Service. The user’s request needs to contain an endpoint URL to which the notifications will be sent and endpoint’s credentials (if client’s endpoint requires authentication). The user’s endpoint credentials are stored safely in the dedicated vault. The request is processed by the Subscription Service, and a response is returned which includes a unique identifier assigned to the subscription (subscription’s Id), subscription status (initially set to running), subscription request submission date, filtering parameters, stage order, priority of the subscription, subscription event to be monitored and client’s endpoint URL. If client’ notification endpoint is not submitted, then PULL subscription will be created.\n\nProduct Notification\n\nAfter a new product is added to the Copernicus Data Space Ecosystem Catalogue, the Subscription Service sends the notification to the client’s endpoint. In case of user’s endpoint unavailability, the PUSH notification is retried three times and then it fails. The notifications are sent to user’s endpoint until the subscription is paused or deleted.\n\nPUSH Subscription Entity Description\nBelow please find the description of the Subscription Entity.\n\n\n\n    \n\n\n\n\n\n\n\n\n\nSubscription Properties\nType\nDescription\nExample\n\n\n\n\nId\nGuid\nIt is a universally unique identifier (UUID). The Id is a local identifier for the Subscription instance within the Catalogue, assigned upon Subscription creation.\n9249dde5-4838-4a34-8925-bac8c1d53f09\n\n\nStatus\nSubscription Status enumeration\nThe allowed values of the subscription status are:\nrunning\npaused\ncancelled\n\nThe default value set to 'Status', if not provided by user, is 'running'.\nrunning\n\n\nSubscriptionEvent\nSubscription Event enumeration\nThe subscription event to be monitored and for which notification is provided:\ncreated\nThe default value set to \"SubscriptionEvent\", if not provided by user, is \"created\".\n\nFor \"SubscriptionEvent\" = \"created\" the notifications about newly added products to the Data Space Catalogue will be sent to the user's endpoint.\ncreated\n\n\nFilterParam\nString\nThe filter parameters of the Subscription (refers to the $filter= parameter of any Products? query). The same filtering parameters as described for [OData Data Sapce Catalogue](https://documentation.dataspace.copernicus.eu/APIs/OData.html#filter-option) are available.\nCollection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A')\n\n\nSubmissionDate\nDateTimeOffset\nDate and time at which the Subscription was received by the Catalogue. Time is in UTC in the format YYYY-MMDDThh:mm:ss.sssZ\n2024-01-17T09:13:04.654Z\n\n\nLastNotificationDate\nDateTimeOffset\nDate and time corresponding to the last time the Subscription Service sent a Notification to the user's endpoint. Time is in UTC in the format YYYY-MMDDThh:mm:ss.sssZ\n2024-01-17T09:50:10.654Z\n\n\nStageOrder\nBoolean\nAutomatically orders the staging of products fulfilling the subscription.\n\nOnly used if SubscriptionEvent = created \n\nCurrently, the order of staging products is not feasible as all new products in Data Space Catalogue have status set to 'Online' and can be accessed immediately without setting an order.\ntrue\n\n\nPriority\nInt64\nPriority of the created orders resulting from the subscription. Currently automatically fixed to '1' without the possibility to change the value. Within further development of the Subscription Service it is possible to enable Priority function which will determine the priority of the user's orders.\n1\n\n\nNotificationEndpoint\nString\nUser's Endpoint URI used by the Data Space Catalogue for subscription notifications.\nAny URI, e.g. https://userservice/notification\n\n\nNotificationEpUsername\nString\nThe username associated with the Endpoint URI. It is mandatory if NotificationEndpoint requires authentication.\nserviceusername\n\n\nNotificationEpPassword\nString\nThe password associated with the Endpoint URI. It is mandatory if NotificationEndpoint requires authentication.\n***********\n\n\n\n\n\n\n\n\nCreate Subscription\nTo create PUSH Subscription users should specify the notification endpoint to which PUSH notifications from the Subscription Service will be sent.\nWhile creating a subscription, users can specify the Event they would like to be notified. For now, the following Event can be chosen:\n\nCreated\n\nWithin the Subscription create request, users can also provide the filtering parameters (e.g. productType, collection, geofootprint). The Subscription Service will then send the notification to the user about newly added products to the Copernicus Data Space Ecosystem Catalogue according to the set of filter parameters supplied within the subscription request. If FilterParam is not provided within the subscription request body, it will be automatically set to empty and then the notifications about all newly added products will be sent to user’s endpoint.\nSubscriptions enables the same filtering parameters as described for OData Data Sapce Catalogue. All filters should be provided in FilterParam field.\nTo create a PUSH Subscription a request to the Subscription Service service should be submitted:\n\nHTTP requestResponse example\n\n\nPOST \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions\n \n{\n  \"StageOrder\": true,\n  \"FilterParam\": \"Collection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A')\",\n  \"Priority\": 1,\n  \"NotificationEndpoint\": \"https://userservice/notification\",\n  \"NotificationEpUsername\": \"serviceusername\",\n  \"NotificationEpPassword\": \"********\",\n  \"Status\": \"running\",\n  \"SubscriptionEvent\": [\n    \"created\"\n  ]\n}\n\n\n201 Created\n \n{\n    \"Id\": \"7ca682c3-7b21-4e9b-952e-874798101340\",\n    \"FilterParam\": \"Collection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A')\",\n    \"StageOrder\": true,\n    \"Priority\": 1,\n    \"Status\": \"running\",\n    \"NotificationEndpoint\": \"https://userservice/notification\",\n    \"SubscriptionEvent\": [\n        \"created\"\n    ],\n    \"SubmissionDate\": \"2024-01-18T09:47:34.2672\",\n    \"@odata.context\": \"$metadata#Subscriptions/$entity\"\n}\n\n\n\n\n\nNotification sender\nAfter creating the subscription, the notifications about new products entering the Data Space Catalogue according to the set of subscription’s filter parameters should be automatically sent to user’s endpoint:\n\nNotification example\n\n\n{\n    \"@odata.context\": \"$metadata#Notification/$entity\",\n    \"SubscriptionEvent\": \"created\",\n    \"ProductId\": \"8d654e59-d7b6-4a53-b086-c9de764e506b\",\n    \"ProductName\": \"S2A_MSIL2A_20240129T062121_N0510_R034_T44VMN_20240129T093752.SAFE\",\n    \"SubscriptionId\": \"c06f2e68-fb9e-4e22-ac57-49566e8621fb\",\n    \"NotificationDate\": \"2024-01-29T10:59:08.698Z\",\n    \"value\": {\n        \"@odata.context\": \"$metadata#Products(Assets())(Attributes())(Locations())/$entity\",\n        \"@odata.mediaContentType\": \"application/octet-stream\",\n        \"Id\": \"8d654e59-d7b6-4a53-b086-c9de764e506b\",\n        \"Name\": \"S2A_MSIL2A_20240129T062121_N0510_R034_T44VMN_20240129T093752.SAFE\",\n        \"ContentType\": \"application/octet-stream\",\n        \"ContentLength\": 769373106,\n        \"OriginDate\": \"2024-01-29T10:42:05.000Z\",\n        \"Checksum\": [\n            {\n                \"Value\": \"902d7e7e85b7392618a957f3e9f94168\",\n                \"Algorithm\": \"MD5\",\n                \"ChecksumDate\": \"2024-01-29T10:59:06.907635Z\"\n            },\n            {\n                \"Value\": \"949f14ebf523a07e722cc50047df89d2f60c2a5bc581d7dbc0c0458d4ae32133\",\n                \"Algorithm\": \"BLAKE3\",\n                \"ChecksumDate\": \"2024-01-29T10:59:08.095992Z\"\n            }\n        ],\n        \"ContentDate\": {\n            \"Start\": \"2024-01-29T06:21:21.024Z\",\n            \"End\": \"2024-01-29T06:21:21.024Z\"\n        },\n        \"Footprint\": \"geography'SRID=4326;POLYGON ((80.89747740096813 61.3325521177604, 79.13124823455819 61.3215912623266, 79.1878753803679 60.33630031682041, 80.0736808744782 60.34174571197013, 80.08271516161926 60.35300228895745, 80.19618187051994 60.4932042236609, 80.31061087184456 60.63330859780532, 80.4259343524467 60.7733392028608, 80.54233622006822 60.91328820862503, 80.65958672113561 61.05317537011384, 80.77810533703949 61.19290341271132, 80.89747740096813 61.3325521177604))'\",\n        \"GeoFootprint\": {\n            \"type\": \"Polygon\",\n            \"coordinates\": [\n                [...\n                ]\n            ]\n        },\n        \"Attributes\": [...\n        ],\n        \"ModificationDate\": \"2024-01-29T10:59:08.201Z\",\n        \"PublicationDate\": \"2024-01-29T10:58:20.247Z\",\n        \"Online\": true,\n        \"EvictionDate\": \"\",\n        \"S3Path\": \"/eodata/Sentinel-2/MSI/L2A/2024/01/29/S2A_MSIL2A_20240129T062121_N0510_R034_T44VMN_20240129T093752.SAFE\",\n        \"Assets\": [\n            {\n                \"Type\": \"QUICKLOOK\",\n                \"Id\": \"31cef3a2-65e2-4f94-bd0f-138a2897e5cd\",\n                \"DownloadLink\": \"https://catalogue.dataspace.copernicus.eu/odata/v1/Assets(31cef3a2-65e2-4f94-bd0f-138a2897e5cd)/$value\",\n                \"S3Path\": \"/eodata/Sentinel-2/MSI/L2A/2024/01/29/S2A_MSIL2A_20240129T062121_N0510_R034_T44VMN_20240129T093752.SAFE\"\n            }\n        ],\n        \"Locations\": [...\n        ]\n    }\n}"
  },
  {
    "objectID": "APIs/Subscriptions.html#pull-and-push-subscriptions-operations",
    "href": "APIs/Subscriptions.html#pull-and-push-subscriptions-operations",
    "title": "Subscriptions",
    "section": "PULL and PUSH Subscriptions Operations",
    "text": "PULL and PUSH Subscriptions Operations\n\nGet Subscriptions\n\nUser’s subscriptions Info\nUsers are able to check their existing subscriptions.\nTo get information about the user’s Subscriptions (PUSH and PULL) the following endpoint should be used:\n\nHTTP requestResponse example\n\n\nGET \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions/Info\n\n\n200 OK\n\n[\n    {\n        \"Id\": \"7ca682c3-7b21-4e9b-952e-874798101340\",\n        \"FilterParam\": \"Collection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A')\",\n        \"StageOrder\": true,\n        \"Priority\": 1,\n        \"Status\": \"running\",\n        \"NotificationEndpoint\": \"https://userservice/notification\",\n        \"LastNotificationDate\": \"2024-01-18T09:47:45.540Z\",\n        \"SubscriptionEvent\": [\n            \"created\"\n        ],\n        \"SubmissionDate\": \"2024-01-18T09:47:34.267Z\",\n        \"@odata.context\": \"$metadata#Subscriptions/$entity\"\n    },\n    {\n        \"Id\": \"991c4730-cf6f-432a-9f6c-47be0230ff45\",\n        \"FilterParam\": \"Collection/Name eq 'SENTINEL-1' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'IW_SLC__1S')\",\n        \"StageOrder\": true,\n        \"Priority\": 1,\n        \"Status\": \"paused\",\n        \"LastNotificationDate\": \"2024-03-20T09:49:29.918Z\",\n        \"SubscriptionEvent\": [\n            \"created\"\n        ],\n        \"SubmissionDate\": \"2024-03-13T09:33:51.371Z\",\n        \"@odata.context\": \"$metadata#Subscriptions/$entity\"\n    }\n]\n\n\n\n\n\nSubscription Info\nUsers are also able to get information about the specified subscription by its Id.\nTo get information about the specified subscription:\n\nHTTP request\n\n\nGET \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(subscription_id)\n\n\n\n\nRequest exampleResponse example\n\n\nGET \\  \nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(7ca682c3-7b21-4e9b-95 2e-874798101340)\n\n\n200 OK\n\n{\n    \"Id\": \"7ca682c3-7b21-4e9b-952e-874798101340\",\n    \"FilterParam\": \"Collection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A')\",\n    \"StageOrder\": true,\n    \"Priority\": 1,\n    \"Status\": \"running\",\n    \"NotificationEndpoint\": \"https://userservice/notification\",\n    \"LastNotificationDate\": \"2024-01-18T09:47:45.540Z\",\n    \"SubscriptionEvent\": [\n        \"created\"\n    ],\n    \"SubmissionDate\": \"2024-01-18T09:47:34.267Z\",\n    \"@odata.context\": \"$metadata#Subscriptions/$entity\"\n}\n\n\n\n\n\nUpdate Subscription\nWithin the PUSH Subscription update, the following parameters can be modified:\n\nStatus\nNotificationEndpoint\nNotificationEpUsername\nNotificationEpPassword\n\nWithin the PULL Subscription update, the following parameter can be modified:\n\nStatus\n\nThe Subscription status can be changed to:\n\nrunning (subscription will be working, for PUSH subscriptions notifications will be sent to user’s endpoint and for PULL subscriptions notifications will be saved to subscription queue),\npaused (subscription will be stopped and push notifications will not be sent, notifications sent before the change of the status to paused will still be available),\ncancelled (subscription will be deleted).\n\nTo update an existing subscription:\n\nHTTP request\n\n\nPATCH \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(subscription_id)\n\n\n\nTo change the status of the subscription (running→paused or paused→running):\n\nRequest exampleResponse example\n\n\nPATCH \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(7ca682c3-7b21-4e9b-952e-874798181340)\n{\n  \"Status\": \"paused\"\n}\n\n\n200 OK\n \n{\n    \"Id\": \"7ca682c3-7b21-4e9b-952e-874798181340\",\n    \"FilterParam\": \"Collection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A')\",\n    \"StageOrder\": true,\n    \"Priority\": 1,\n    \"Status\": \"paused\",\n    \"NotificationEndpoint\": \"https://userservice/notification\",\n    \"LastNotificationDate\": \"2024-01-18T09:49:29.918Z\",\n    \"SubscriptionEvent\": [\n        \"created\"\n    ],\n    \"SubmissionDate\": \"2024-01-18T09:47:34.267Z\",\n    \"@odata.context\": \"$metadata#Subscriptions/Sentity\"\n}\n\n\n\nTo change the subscription’s status from running/paused to cancelled (Deletion of the Subscription):\n\nRequest example\n\n\nPATCH \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(7ca682c3-7b21-4e9b-952e-874798181340)\n{\n  \"Status\": \"cancelled\"\n}\n\n\n\n\n\nDelete Subscription\nIn case of the Subscription deletion (PUSH or PULL), it is requested to provide subscription Id.\nTo delete an existing subscription:\n\nHTTP request\n\n\nDELETE \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(subscription_id)\n\n\n\n\nRequest exampleResponse example\n\n\nDELETE \\\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Subscriptions(7ca682c3-7b21-4e9b-952e-874798181340)\n\n\n204 No Content"
  },
  {
    "objectID": "APIs/OData.html",
    "href": "APIs/OData.html",
    "title": "OData",
    "section": "",
    "text": "OData is an SO/IEC approved, OASIS standard , which is based on https RESTful Application Programming Interfaces. It enables resources, which are identified by URLs and defined in a data model, to be created and edited using simple HTTPS messages. OData makes it possible to build REST-based data services that let Web clients publish and edit resources that are recognized by Uniform Resource Locators (URLs) and described in a data model using straightforward HTTPS messages."
  },
  {
    "objectID": "APIs/OData.html#odata-products-endpoint",
    "href": "APIs/OData.html#odata-products-endpoint",
    "title": "OData",
    "section": "OData Products endpoint",
    "text": "OData Products endpoint\n\n\n\n\n\n\nTip\n\n\n\nCrucial for the search performance is specifying the collection name. Example: Collection/Name eq ‘SENTINEL-3’\nThe additional efficient way to accelerate the query performance is limiting the query by acquisition dates, e.g.: ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\n\n\n\nQuery structure\nAs a general note, the OData query consists of elements which in this documentation are called “options”. The interface supports the following search options:\n\nfilter\norderby\ntop\nskip\ncount\nexpand\n\nSearch options should always be preceded with $ and consecutive options should be separated with &.\nConsecutive filters within filter option should be separated with and or or. Not operator can also be used e.g.:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=not (Collection/Name eq 'SENTINEL-2') and not contains(Name,'OPER_AUX') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:10:00.000Z&$orderby=ContentDate/Start&$top=100\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=not (Collection/Name eq 'SENTINEL-2') and not contains(Name,'OPER_AUX') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:10:00.000Z&$orderby=ContentDate/Start&$top=100\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n4a4ef482-84a2-551d-8086-e3de6d39c488\nS3B_SL_1_RBT____20220503T000015_20220503T00031...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2022/05/03/S...\n{'type': 'Polygon', 'coordinates': [[[-29.448,...\n\n\n1\n711d4854-6419-5513-9e19-25b166cdbcd5\nS3B_SL_1_RBT____20220503T000015_20220503T00031...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2022/05/03/S...\n{'type': 'Polygon', 'coordinates': [[[-29.4495...\n\n\n2\nc6d30f04-e179-582e-82bb-bf8057a8247a\nS3B_SL_2_WST____20220503T000015_20220503T00031...\n/eodata/Sentinel-3/SLSTR/SL_2_WST/2022/05/03/S...\n{'type': 'Polygon', 'coordinates': [[[-29.4495..."
  },
  {
    "objectID": "APIs/OData.html#filter-option",
    "href": "APIs/OData.html#filter-option",
    "title": "OData",
    "section": "Filter option",
    "text": "Filter option\n\nQuery by name\nTo search for a specific product by its exact name:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Name eq 'S1A_IW_GRDH_1SDV_20141031T161924_20141031T161949_003076_003856_634E.SAFE'\n\n\n\nTo search for Sentinel-1 products containing “COG” in their names:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and contains(Name,'COG') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and contains(Name,'COG') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n4bc2660f-19cd-59d0-83f9-529ea7f35adf\nS1A_IW_GRDH_1SDV_20220510T162138_20220510T1622...\n/eodata/Sentinel-1/SAR/CARD-BS/2022/05/10/S1A_...\n{'type': 'Polygon', 'coordinates': [[[16.90387...\n\n\n1\n412cd51e-0019-531a-8b80-08e5732c1334\nS1A_IW_GRDH_1SDV_20220510T050358_20220510T0504...\n/eodata/Sentinel-1/SAR/CARD-BS/2022/05/10/S1A_...\n{'type': 'Polygon', 'coordinates': [[[27.27137...\n\n\n2\n56aeff94-3a60-5b2d-a94d-32ff855b1ef9\nS1A_IW_GRDH_1SDV_20220509T154157_20220509T1542...\n/eodata/Sentinel-1/SAR/CARD-BS/2022/05/09/S1A_...\n{'type': 'Polygon', 'coordinates': [[[24.55337...\n\n\n\n\n\n\n\n\n\n\nTo search for Copernicus Contributing Mission (CCM) data:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Name eq 'SP07_NAO_MS4_2A_20210729T064948_20210729T064958_TOU_1234_90f0.DIMA'&$expand=Attributes\n\n\n\nAlternatively contains, endswith and startswith can be used to search for products ending or starting with provided string. You should use Collection/Name filter even if it overlaps with startswith or contains clause.\n\n\nQuery by list\nIn case a user desires to search for multiple products by name in one query, the POST method can be used:\nPOST\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products/OData.CSC.FilterList\nRequest body:\n{\n  \"FilterProducts\":\n    [\n     {\"Name\": \"S1A_IW_GRDH_1SDV_20141031T161924_20141031T161949_003076_003856_634E.SAFE\"},\n     {\"Name\": \"S3B_SL_1_RBT____20190116T050535_20190116T050835_20190117T125958_0179_021_048_0000_LN2_O_NT_003.SEN3\"},\n     {\"Name\": \"xxxxxxxx.06.tar\"}\n    ]\n }\nTwo results are returned, as there is no product named xxxxxxxx.06.tar.\n\n\nQuery Collection of Products\nTo search for products within a specific collection:\nFor Sentinel-2:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:11:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:11:00.000Z\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\nb2ac733d-efa4-49e9-9edc-fb37e2a7f938\nS2B_OPER_AUX_GNSSRD_POD__20220510T031816_V2022...\n/eodata/Sentinel-2/AUX/AUX_GNSSRD/2022/05/03/S...\nNone\n\n\n1\na449f701-d29a-4ce9-b838-33061ee1d573\nS2A_OPER_AUX_GNSSRD_POD__20220510T030151_V2022...\n/eodata/Sentinel-2/AUX/AUX_GNSSRD/2022/05/03/S...\nNone\n\n\n2\n7e0f9557-d537-56bb-90a1-9b4a746f0f55\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XMQ_2...\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n{'type': 'Polygon', 'coordinates': [[[-138.241...\n\n\n\n\n\n\n\n\n\n\nFor Copernicus Contributing Missions (CCM):\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'CCM'\n\n\n\nThe following collections are currently available:\n\nCopernicus Sentinel Mission\n\nSENTINEL-1\nSENTINEL-2\nSENTINEL-3\nSENTINEL-5P\nSENTINEL-6\nSENTINEL-1-RTC (Sentinel-1 Radiometric Terrain Corrected)\n\nComplementary data\n\nGLOBAL-MOSAICS (Sentinel-1 and Sentinel-2 Global Mosaics)\nSMOS (Soil Moisture and Ocean Salinity)\nENVISAT (ENVISAT- Medium Resolution Imaging Spectrometer - MERIS)\nLANDSAT-5\nLANDSAT-7\nLANDSAT-8\nCOP-DEM (Copernicus DEM)\nTERRAAQUA (Terra MODIS and Aqua MODIS)\nS2GLC (S2GLC 2017)\n\nCopernicus Contributing Missions (CCM)\n\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27CCM%27%20and%20ContentDate/Start%20gt%202005-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T00:11:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27CCM%27%20and%20ContentDate/Start%20gt%202005-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T00:11:00.000Z\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\nb0e48a00-0ae2-435c-8a88-6e49be378d27\nEW02_WV1_PM8_SO_20110526T100509_20110526T10051...\n/eodata/CCM/VHR1-2_Urban_Atlas_2012/WV1_PM8_SO...\n{'type': 'Polygon', 'coordinates': [[[2.011538...\n\n\n1\n64343709-6d61-4ae0-99f6-660624787634\nDEM1_SAR_DGE_30_20130522T041103_20140523T03195...\n/eodata/CCM/COP-DEM_GLO-30-DGED/SAR_DGE_30_A4A...\n{'type': 'Polygon', 'coordinates': [[[-134.0, ...\n\n\n2\n7b2dcb4a-b3d5-426c-ae60-8960f13112b6\nDEM1_SAR_DGE_30_20110617T173652_20140204T17305...\n/eodata/CCM/COP-DEM_GLO-30-DGED/SAR_DGE_30_A4A...\n{'type': 'Polygon', 'coordinates': [[[4.0, 33....\n\n\n\n\n\n\n\n\n\n\n\n\nQuery by Publication Date\nTo search for products published between two dates:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate gt 2019-05-15T00:00:00.000Z and PublicationDate lt 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate gt 2019-05-15T00:00:00.000Z and PublicationDate lt 2019-05-16T00:00:00.000Z\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n2997cd87-a273-5bbc-998a-1c72fe152b06\nS3A_SL_1_RBT____20160904T192151_20160904T19245...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/09/04/S...\n{'type': 'Polygon', 'coordinates': [[[42.9227,...\n\n\n1\n05d3b080-14b1-5e93-b72b-3743f8d8a37c\nS3A_SL_1_RBT____20160904T191051_20160904T19125...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/09/04/S...\n{'type': 'Polygon', 'coordinates': [[[50.5057,...\n\n\n2\nd204583c-2328-57c0-9534-f52121048cf1\nS3A_SL_1_RBT____20160904T192451_20160904T19275...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/09/04/S...\n{'type': 'Polygon', 'coordinates': [[[41.386, ...\n\n\n\n\n\n\n\n\n\n\nTo define inclusive interval ge and le parameters can be used:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate ge 2019-05-15T00:00:00.000Z and PublicationDate le 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=PublicationDate ge 2019-05-15T00:00:00.000Z and PublicationDate le 2019-05-16T00:00:00.000Z\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n2997cd87-a273-5bbc-998a-1c72fe152b06\nS3A_SL_1_RBT____20160904T192151_20160904T19245...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/09/04/S...\n{'type': 'Polygon', 'coordinates': [[[42.9227,...\n\n\n1\n05d3b080-14b1-5e93-b72b-3743f8d8a37c\nS3A_SL_1_RBT____20160904T191051_20160904T19125...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/09/04/S...\n{'type': 'Polygon', 'coordinates': [[[50.5057,...\n\n\n2\nd204583c-2328-57c0-9534-f52121048cf1\nS3A_SL_1_RBT____20160904T192451_20160904T19275...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2016/09/04/S...\n{'type': 'Polygon', 'coordinates': [[[41.386, ...\n\n\n\n\n\n\n\n\n\n\n\n\nQuery by Sensing Date\nTo search for products acquired between two dates:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/Start lt 2019-05-16T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/Start lt 2019-05-16T00:00:00.000Z\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n4725d436-3e90-5480-bee1-0f13a7fc14fd\nS3B_SL_1_RBT____20190515T000040_20190515T00034...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2019/05/15/S...\n{'type': 'Polygon', 'coordinates': [[[-8.40421...\n\n\n1\n169fda08-9928-576e-a556-97a6d3b9bacf\nS3B_SL_1_RBT____20190515T000040_20190515T00034...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2019/05/15/S...\n{'type': 'Polygon', 'coordinates': [[[-8.40421...\n\n\n2\n07c0c999-5f9d-553f-9b3d-f2b8ab013856\nS3B_SL_2_LST____20190515T000040_20190515T00034...\n/eodata/Sentinel-3/SLSTR/SL_2_LST/2019/05/15/S...\n{'type': 'Polygon', 'coordinates': [[[-8.40421...\n\n\n\n\n\n\n\n\n\n\nAs an example, for the Copernicus Contributions Mission Data (CCM):\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'CCM' and OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((12.655118166047592 47.44667197521409,21.39065656328509 48.347694733853245,28.334291357162826 41.877123516783655,17.47086198383573 40.35854475076158,12.655118166047592 47.44667197521409))') and ContentDate/Start gt 2021-05-20T00:00:00.000Z and ContentDate/Start lt 2021-07-21T00:00:00.000Z\n\n\n\nUsually, there are two parameters describing the ContentDate (Acquisition Dates) for a product - Start and End. Depending on what the user is looking for, these parameters can be mixed, e.g.:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/End lt 2019-05-15T00:05:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=ContentDate/Start gt 2019-05-15T00:00:00.000Z and ContentDate/End lt 2019-05-15T00:05:00.000Z\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n4725d436-3e90-5480-bee1-0f13a7fc14fd\nS3B_SL_1_RBT____20190515T000040_20190515T00034...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2019/05/15/S...\n{'type': 'Polygon', 'coordinates': [[[-8.40421...\n\n\n1\n169fda08-9928-576e-a556-97a6d3b9bacf\nS3B_SL_1_RBT____20190515T000040_20190515T00034...\n/eodata/Sentinel-3/SLSTR/SL_1_RBT/2019/05/15/S...\n{'type': 'Polygon', 'coordinates': [[[-8.40421...\n\n\n2\n07c0c999-5f9d-553f-9b3d-f2b8ab013856\nS3B_SL_2_LST____20190515T000040_20190515T00034...\n/eodata/Sentinel-3/SLSTR/SL_2_LST/2019/05/15/S...\n{'type': 'Polygon', 'coordinates': [[[-8.40421...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFiltering by ContentDate/Start is much faster than by ContentDate/End for big collections. Narrowing ContentDate/Start gives the best performance boost for SENTINEL-2 collection.\n\n\n\n\nQuery by Geographic Criteria\nTo search for products intersecting the specified polygon:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((12.655118166047592 47.44667197521409,21.39065656328509 48.347694733853245,28.334291357162826 41.877123516783655,17.47086198383573 40.35854475076158,12.655118166047592 47.44667197521409))') and ContentDate/Start gt 2022-05-20T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((12.655118166047592 47.44667197521409,21.39065656328509 48.347694733853245,28.334291357162826 41.877123516783655,17.47086198383573 40.35854475076158,12.655118166047592 47.44667197521409))') and ContentDate/Start gt 2022-05-20T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n0d3b8cf1-01fb-5f7e-820a-1d5442875575\nLC08_L1TP_180031_20220520_20220520_02_RT\n/eodata/Landsat-8/OLI_TIRS/L1TP/2022/05/20/LC0...\n{'type': 'Polygon', 'coordinates': [[[27.73522...\n\n\n1\nd3b5fbd9-9ffd-579b-b327-4de3e8502591\nLC08_L2SP_180031_20220520_20220525_02_T1\n/eodata/Landsat-8/OLI_TIRS/L2SP/2022/05/20/LC0...\n{'type': 'Polygon', 'coordinates': [[[27.73522...\n\n\n2\n0bfcd52a-1c10-5870-820a-7282032fe8e4\nLC08_L1TP_180031_20220520_20220525_02_T1\n/eodata/Landsat-8/OLI_TIRS/L1TP/2022/05/20/LC0...\n{'type': 'Polygon', 'coordinates': [[[27.73522...\n\n\n\n\n\n\n\n\n\n\nSimilarly, for the Copernicus Contributing Missions (CCM) data:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'CCM' and OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((12.655118166047592 47.44667197521409,21.39065656328509 48.347694733853245,28.334291357162826 41.877123516783655,17.47086198383573 40.35854475076158,12.655118166047592 47.44667197521409))')&$top=20\n\n\n\nTo search for products intersecting the specified point:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography%27SRID=4326;POINT(-0.5319577002158441%2028.65487836189358)%27)\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=OData.CSC.Intersects(area=geography%27SRID=4326;POINT(-0.5319577002158441%2028.65487836189358)%27)\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n9f9a63cd-98bd-520a-ab31-098b1f2a1e44\nS2A_MSIL2A_20151021T104102_N0204_R008_T30RYS_2...\n/eodata/Sentinel-2/MSI/L2A/2015/10/21/S2A_MSIL...\n{'type': 'Polygon', 'coordinates': [[[-0.94897...\n\n\n1\n6d7d8ec3-f032-50c3-a051-533e3c41869d\nS2A_MSIL1C_20151021T104102_N0204_R008_T30RYS_2...\n/eodata/Sentinel-2/MSI/L1C/2015/10/21/S2A_MSIL...\n{'type': 'Polygon', 'coordinates': [[[-0.94897...\n\n\n2\n726d7033-f0f3-50fd-a7a2-d9023c383616\nS2A_MSIL2A_20151130T104412_N0204_R008_T30RYS_2...\n/eodata/Sentinel-2/MSI/L2A/2015/11/30/S2A_MSIL...\n{'type': 'Polygon', 'coordinates': [[[-0.94897...\n\n\n\n\n\n\n\n\n\n\nDisclaimers:\n\nMULTIPOLYGON is currently not supported.\nPolygon must start and end with the same point.\nCoordinates must be given in EPSG 4326\n\n\n\nQuery by attributes\nTo search for products by attributes, it is necessary to build a filter with the following structure:\nAttributes/OData.CSC.ValueTypeAttribute/any(att:att/Name eq ‘[Attribute.Name]’ and att/OData.CSC.ValueTypeAttribute/Value eq ‘[Attribute.Value]’)\nwhere\n\nValueTypeAttribute can take the following values:\n\nStringAttribute\nDoubleAttribute\nIntegerAttribute\nDateTimeOffsetAttribute\n\n[Attribute.Name] is the attribute name which can take multiple values, depending on collection (Attachment 1 - Coming soon)\neq before [Attribute.Value] can be substituted with le, lt, ge, gt in case of Integer, Double or DateTimeOffset Attributes\n[Attribute.Value] is the specific value that the user is searching for\n\nTo get Sentinel-2 products with CloudCover&lt;40% between two dates:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 40.00) and ContentDate/Start gt 2022-01-01T00:00:00.000Z and ContentDate/Start lt 2022-01-03T00:00:00.000Z&$top=10\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-2%27%20and%20Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 40.00) and ContentDate/Start gt 2022-01-01T00:00:00.000Z and ContentDate/Start lt 2022-01-03T00:00:00.000Z&$top=10\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n6fc4fa05-a2ff-55d8-8e35-80cfea40803f\nS2B_MSIL1C_20220101T000459_N0301_R130_T52DEJ_2...\n/eodata/Sentinel-2/MSI/L1C/2022/01/01/S2B_MSIL...\n{'type': 'Polygon', 'coordinates': [[[128.9995...\n\n\n1\n3d0f3447-4b75-5115-8132-7047eab6ca22\nS2B_MSIL1C_20220101T000459_N0301_R130_T48CWU_2...\n/eodata/Sentinel-2/MSI/L1C/2022/01/01/S2B_MSIL...\n{'type': 'Polygon', 'coordinates': [[[109.6598...\n\n\n2\n13bf9e1e-e9e2-52fb-9274-5430131d3099\nS2B_MSIL1C_20220101T000459_N0301_R130_T52DDF_2...\n/eodata/Sentinel-2/MSI/L1C/2022/01/01/S2B_MSIL...\n{'type': 'Polygon', 'coordinates': [[[126.2203...\n\n\n\n\n\n\n\n\n\n\nTo get products with cloudCover&lt; 10% and productType=S2MSI2A and ASCENDING orbitDirection between two dates:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value lt 10.00) and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'orbitDirection' and att/OData.CSC.StringAttribute/Value eq 'ASCENDING') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T04:00:00.000Z&$top=10\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value lt 10.00) and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'orbitDirection' and att/OData.CSC.StringAttribute/Value eq 'ASCENDING') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T04:00:00.000Z&$top=10\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n7e0f9557-d537-56bb-90a1-9b4a746f0f55\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XMQ_2...\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n{'type': 'Polygon', 'coordinates': [[[-138.241...\n\n\n1\na3041799-63e6-5b61-a16a-cb5bfabce2aa\nS2B_MSIL2A_20220503T000139_N0400_R016_T09XVJ_2...\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n{'type': 'Polygon', 'coordinates': [[[-128.506...\n\n\n2\n716d55e7-ee2a-5985-afed-4ca073864ca9\nS2B_MSIL2A_20220503T000139_N0400_R016_T08XNQ_2...\n/eodata/Sentinel-2/MSI/L2A/2022/05/03/S2B_MSIL...\n{'type': 'Polygon', 'coordinates': [[[-135.001...\n\n\n\n\n\n\n\n\n\n\nTo query a subset of CCM data for a specific area of interest and time period, selecting a specific mission, e.g. only Worldview-3:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'CCM' and OData.CSC.Intersects(area=geography'SRID=4326;POLYGON ((6.535492 50.600673, 6.535492 50.937662, 7.271576 50.937662, 7.271576 50.600673, 6.535492 50.600673))') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'platformName' and att/OData.CSC.StringAttribute/Value eq 'WorldView-3') and ContentDate/Start gt 2022-05-20T00:00:00.000Z and ContentDate/Start lt 2022-07-21T00:00:00.000Z\n\n\n\nTo search all products of a specific dataset under CCM (for example for the products belonging to VHR_IMAGE_2018):\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'datasetFull' and att/OData.CSC.StringAttribute/Value eq 'VHR_IMAGE_2018')"
  },
  {
    "objectID": "APIs/OData.html#orderby-option",
    "href": "APIs/OData.html#orderby-option",
    "title": "OData",
    "section": "Orderby option",
    "text": "Orderby option\nOrderby option can be used to order the products in an ascending (asc) or descending (desc) direction. If asc or desc is not specified, then the resources will be ordered in ascending order.\n\n\n\n\n\n\nTip\n\n\n\nUsing the orderby option will exclude potential duplicates from the search results.\n\n\nTo order products by ContentDate/Start in a descending direction:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and contains(Name,'S1A_EW_GRD') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T03:00:00.000Z&$orderby=ContentDate/Start desc\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and contains(Name,'S1A_EW_GRD') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T03:00:00.000Z&$orderby=ContentDate/Start desc\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n6928b379-4f9a-5473-a12a-7e7e4b83f776\nS1A_EW_GRDM_1SSH_20220503T024410_20220503T0244...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[-105.464...\n\n\n1\n9b4e3124-fa8e-4ea7-b43e-d5f08297ea8c\nS1A_EW_GRDM_1SSH_20220503T024410_20220503T0244...\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n{'type': 'MultiPolygon', 'coordinates': [[[[-1...\n\n\n2\n2abd9bf9-7a35-4916-8bf5-34727d71da1b\nS1A_EW_GRDM_1SSH_20220503T024310_20220503T0244...\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n{'type': 'MultiPolygon', 'coordinates': [[[[-9...\n\n\n\n\n\n\n\n\n\n\nBy default, if the orderby option is not used, the results are not ordered. If orderby option is used, additional orderby by id is also used, so that the results are fully ordered, and no products are lost while paginating through the results.\nThe acceptable arguments for this option: ContentDate/Start, ContentDate/End, PublicationDate, ModificationDate, in directions: asc, desc."
  },
  {
    "objectID": "APIs/OData.html#top-option",
    "href": "APIs/OData.html#top-option",
    "title": "OData",
    "section": "Top option",
    "text": "Top option\nTop option specifies the maximum number of items returned from a query.\nTo limit the number of results:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and startswith(Name,'S1A_EW_GRD') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T12:00:00.000Z&$top=100\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-1%27%20and%20startswith(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$top=100\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n\n\n1\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n\n\n2\nc8532dc6-3967-52b8-8ee4-ea63eb1a8ba2\nS1A_EW_GRDM_1SSH_20220503T090752_20220503T0908...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[-71.2011...\n\n\n\n\n\n\n\n\n\n\nThe default value is set to 20.\nThe acceptable arguments for this option: Integer &lt;0,1000&gt;"
  },
  {
    "objectID": "APIs/OData.html#skip-option",
    "href": "APIs/OData.html#skip-option",
    "title": "OData",
    "section": "Skip option",
    "text": "Skip option\nThe skip option can be used to skip a specific number of results. Exemplary application of this option would be paginating through the results, however, for performance reasons, we recommend limiting queries with small time intervals as a substitute for skipping in a more generic query.\nTo skip a specific number of results:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and startswith(Name,'S1A_EW_GRD') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T12:00:00.000Z&$skip=23\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-1%27%20and%20startswith(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$skip=23\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n7f916b48-5b57-473c-af82-8a225521b28f\nS1A_EW_GRDM_1SSH_20220503T073204_20220503T0732...\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n{'type': 'MultiPolygon', 'coordinates': [[[[-7...\n\n\n1\ne3898003-7a7d-44df-a2c2-cbf0805ec028\nS1A_EW_GRDM_1SSH_20220503T090752_20220503T0908...\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n{'type': 'MultiPolygon', 'coordinates': [[[[-7...\n\n\n2\n478efa12-e574-493a-88b5-7ea20a705971\nS1A_EW_GRDM_1SDH_20220503T083125_20220503T0831...\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n{'type': 'MultiPolygon', 'coordinates': [[[[-2...\n\n\n\n\n\n\n\n\n\n\nThe default value is set to 0.\nWhenever a query results in more products than 20 (default top value), the API provides a nextLink at the bottom of the page:\n\"@OData.nextLink\":\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and startswith(Name,'S1A_EW_GRD')+and+ContentDate/Start+gt+2022-05-03T00:00:00.000Z+and+ContentDate/Start+lt+2022-05-03T12:00:00.000Z&$skip=20\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-1%27%20and%20startswith(Name,'S1A_EW_GRD')+and+ContentDate/Start+gt+2022-05-03T00:00:00.000Z+and+ContentDate/Start+lt+2022-05-03T12:00:00.000Z&$skip=20\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n01f4c791-29d8-528b-8d91-3de9b76c2f28\nS1A_EW_GRDM_1SDH_20220503T091826_20220503T0919...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[156.8000...\n\n\n1\nb816ddc3-3f29-5efa-af97-9b5156dbb7b1\nS1A_EW_GRDM_1SDH_20220503T082925_20220503T0830...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[-21.9873...\n\n\n2\n1cb829b0-b919-40fd-8388-8c82048a7465\nS1A_EW_GRDM_1SDH_20220503T083025_20220503T0831...\n/eodata/Sentinel-1/SAR/EW_GRDM_1S-COG/2022/05/...\n{'type': 'MultiPolygon', 'coordinates': [[[[-2...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: Integer &lt;0,10000&gt;"
  },
  {
    "objectID": "APIs/OData.html#count-option",
    "href": "APIs/OData.html#count-option",
    "title": "OData",
    "section": "Count option",
    "text": "Count option\nThe count option lets users get the exact number of products matching the query. This option is disabled by default to accelerate the query performance.\n\n\n\n\n\n\nTip\n\n\n\nDon’t use count option if not necessary, it slows down the execution of the request.\n\n\nTo get the exact number of products for a given query:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and  contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$count=True\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-1%27%20and%20contains(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$count=True\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n\n\n1\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n\n\n2\nc8532dc6-3967-52b8-8ee4-ea63eb1a8ba2\nS1A_EW_GRDM_1SSH_20220503T090752_20220503T0908...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[-71.2011...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: True, true, 1, False, false, 0."
  },
  {
    "objectID": "APIs/OData.html#expand-option",
    "href": "APIs/OData.html#expand-option",
    "title": "OData",
    "section": "Expand option",
    "text": "Expand option\nThe expand option enables users to see the full metadata of each returned result.\nTo see the metadata of the results:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-1%27%20and%20startswith(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$expand=Attributes\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-1%27%20and%20startswith(Name,%27S1A_EW_GRD%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T12:00:00.000Z&$expand=Attributes\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n3b46f46b-4862-5587-89cb-9c52a9cc106a\nS1A_EW_GRDM_1SDH_20220503T051020_20220503T0511...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[34.92659...\n\n\n1\nd1402094-d440-570c-9f55-07ffdd2fae19\nS1A_EW_GRDM_1SDH_20220503T064800_20220503T0649...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[15.66478...\n\n\n2\nc8532dc6-3967-52b8-8ee4-ea63eb1a8ba2\nS1A_EW_GRDM_1SSH_20220503T090752_20220503T0908...\n/eodata/Sentinel-1/SAR/GRD/2022/05/03/S1A_EW_G...\n{'type': 'Polygon', 'coordinates': [[[-71.2011...\n\n\n\n\n\n\n\n\n\n\nThe acceptable arguments for this option: Attributes, Assets and Locations.\n\nExpand Assets\nExpand assets allows to list additional assets of products, including quicklooks:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-3%27%20and%20contains(Name,%20%27SL_2_FRP___%27)&$expand=Assets\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-3%27%20and%20contains(Name,%20%27SL_2_FRP___%27)&$expand=Assets\").json()\ndf = pd.DataFrame.from_dict(json['value'])\n\n# Print only specific columns\ncolumns_to_print = ['Id', 'Name','S3Path','GeoFootprint']  \ndf[columns_to_print].head(3)\n\n\n\n\n\n\n\n\n\nId\nName\nS3Path\nGeoFootprint\n\n\n\n\n0\n8b5bd188-ad26-4f80-a023-6fbef6fd9b00\nS3A_SL_2_FRP____20201127T201256_20201127T20155...\n/eodata/Sentinel-3/SLSTR/SL_2_FRP___/2020/11/2...\n{'type': 'Polygon', 'coordinates': [[[28.8194,...\n\n\n1\n6330eadf-1323-4318-9e4a-56b9f0612f45\nS3B_SL_2_FRP____20201231T213317_20201231T21361...\n/eodata/Sentinel-3/SLSTR/SL_2_FRP___/2020/12/3...\n{'type': 'Polygon', 'coordinates': [[[-20.0396...\n\n\n2\na0dcd562-1331-425d-a08b-829837a0da8c\nS3B_SL_2_FRP____20201231T213017_20201231T21331...\n/eodata/Sentinel-3/SLSTR/SL_2_FRP___/2020/12/3...\n{'type': 'Polygon', 'coordinates': [[[-11.667,...\n\n\n\n\n\n\n\n\n\n\n\n\nExpand Locations\nExpand Locations allows users to see full list of available products’ forms and locations from which the products can be downloaded:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20%27SENTINEL-1%27%20and%20contains(Name,%27RAW%27)&$orderby=ContentDate/Start%20desc&$top=10&$expand=Locations\n\n\n\nThe information about data storage locations and storage forms (compressed/uncompressed) are specified under expand=Locations.\n\n\nQuicklook\nFor example, a quicklook for product S3A_SL_2_FRP____20200821T042815_20200821T043115_20200822T092750_0179_062_033_2340_LN2_O_NT_004.SEN3 with ID of a quicklook f4a87522-dd81-4c40-856e-41d40510e3b6, can be downloaded with the request:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Assets(f4a87522-dd81-4c40-856e-41d40510e3b6)/$value\n\n\n\nDownload link is also available under DownloadLink parameter in Assets."
  },
  {
    "objectID": "APIs/OData.html#listing-product-nodes",
    "href": "APIs/OData.html#listing-product-nodes",
    "title": "OData",
    "section": "Listing product nodes",
    "text": "Listing product nodes\nProduct content can be listed by accessing the following URL patterns using Nodes:\nhttps://download.dataspace.copernicus.eu/odata/v1/Products(&lt;PRODUCT_UUID&gt;)/Nodes\nhttps://download.dataspace.copernicus.eu/odata/v1/Products(&lt;PRODUCT_UUID&gt;)/Nodes(&lt;NODE_NAME&gt;)/Nodes\nhttps://download.dataspace.copernicus.eu/odata/v1/Products(&lt;PRODUCT_UUID&gt;)/Nodes(&lt;NODE_NAME&gt;)/Nodes(&lt;NODE_NAME&gt;)/Nodes\nwhere:\n - is ID of the product obtained by search query,\n - is name of element inside product returned from previous listing response.\nOnly nodes that are folders can have their contents listed. Attempting to list Nodes for file results returning an empty list. The listing Nodes feature is available for both authorized and unauthorized users.\n\nExample nodes listing\nExample URL:\nhttps://download.dataspace.copernicus.eu/odata/v1/Products(db0c8ef3-8ec0-5185-a537-812dad3c58f8)/Nodes\nResponse:\n{\n   \"result\":[\n      {\n         \"Id\":\"S2A_MSIL1C_20180927T051221_N0206_R033_T42FXL_20180927T073143.SAFE\",\n         \"Name\":\"S2A_MSIL1C_20180927T051221_N0206_R033_T42FXL_20180927T073143.SAFE\",\n         \"ContentLength\":0,\n         \"ChildrenNumber\":9,\n         \"Nodes\":{\n            \"uri\":\"https://download.dataspace.copernicus.eu/odata/v1/Products(db0c8ef3-8ec0-5185-a537-812dad3c58f8)/Nodes(S2A_MSIL1C_20180927T051221_N0206_R033_T42FXL_20180927T073143.SAFE)/Nodes\"\n         }\n      }\n   ]\n}\nEvery Listed Node has “uri” field, which lists its children."
  },
  {
    "objectID": "APIs/OData.html#engineering-level-product-search",
    "href": "APIs/OData.html#engineering-level-product-search",
    "title": "OData",
    "section": "Engineering level product search",
    "text": "Engineering level product search\nIn order to search for engineering level products, you must perform authorization by providing access token to the query.\n\ncURL\n\n\ncurl --location \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?%24filter=contains(Name%2C%27L1B_CA_SIR%27)\" --header \"Authorization: Bearer $ACCESS_TOKEN\""
  },
  {
    "objectID": "APIs/OData.html#product-download",
    "href": "APIs/OData.html#product-download",
    "title": "OData",
    "section": "Product Download",
    "text": "Product Download\nFor downloading products you need an authorization token as only authorized users are allowed to download data products.\nTo get the token you can use the following scripts:\n\ncURL\n\n\ncurl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n  --header 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'grant_type=password' \\\n  --data-urlencode 'username=&lt;LOGIN&gt;' \\\n  --data-urlencode 'password=&lt;PASSWORD&gt;' \\\n  --data-urlencode 'client_id=cdse-public'\n\n\n\nor \n\ncURL\n\n\ncurl -d 'client_id=cdse-public' -d 'username=&lt;LOGIN&gt;' -d 'password=&lt;PASSWORD&gt;' -d 'grant_type=password' 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | python3 -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}'\n\n\n\nAlong with the Access Token, you will be returned a Refresh Token, the latter is used to generate a new Access Token without the need to specify a Username or Password; this helps to make requests less vulnerable to your credentials being exposed.\nTo re-generate the Access Token from the Refresh Token, it can be done with the following request:\n\ncURL\n\n\ncurl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n  --header 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'grant_type=refresh_token' \\\n  --data-urlencode 'refresh_token=&lt;REFRESH_TOKEN&gt;' \\\n  --data-urlencode 'client_id=cdse-public'\n\n\n\n\n\nOnce you have your token, you require a product Id which can be found in the response of the products search: https://catalogue.dataspace.copernicus.eu/odata/v1/Products\nFinally, you can download the product using this script:\n\ncURL\n\n\ncurl -H \"Authorization: Bearer $ACCESS_TOKEN\" 'https://catalogue.dataspace.copernicus.eu/odata/v1/Products(060882f4-0a34-5f14-8e25-6876e4470b0d)/$value' --location-trusted --output /tmp/product.zip\n\n\n\nor\n\nWget\n\n\nwget  --header \"Authorization: Bearer $ACCESS_TOKEN\" 'https://catalogue.dataspace.copernicus.eu/odata/v1/Products(db0c8ef3-8ec0-5185-a537-812dad3c58f8)/$value' -O example_odata.zip\n\n\n\n\nPython\n\n\nimport requests\n\nurl = f\"https://download.dataspace.copernicus.eu/odata/v1/Products(a5ab498a-7b2f-4043-ae2a-f95f457e7b3b)/$value\"\n\nheaders = {\"Authorization\": f\"Bearer {access_token}\"}\n\nsession = requests.Session()\nsession.headers.update(headers)\nresponse = session.get(url, headers=headers, stream=True)\n\nwith open(\"product.zip\", \"wb\") as file:\n    for chunk in response.iter_content(chunk_size=8192):\n        if chunk:\n            file.write(chunk)\n\n\n\n\nCompressed Product Download\nFor downloading products in their native format (as zipped files) you need to proceed with the standard authorization as for Product Download.\nThe access to compressed products (stored in native format):\n\ncURL\n\n\ncurl -H \"Authorization: Bearer $ACCESS_TOKEN\" 'https://catalogue.dataspace.copernicus.eu/odata/v1/Products(060882f4-0a34-5f14-8e25-6876e4470b0d)/$zip' --location-trusted --output /tmp/product.zip\n\n\n\nor\n\nWget\n\n\nwget  --header \"Authorization: Bearer $ACCESS_TOKEN\" 'https://catalogue.dataspace.copernicus.eu/odata/v1/Products(db0c8ef3-8ec0-5185-a537-812dad3c58f8)/$zip' -O example_odata.zip\n\n\n\n\nPython\n\n\nimport requests\n\nurl = f\"https://download.dataspace.copernicus.eu/odata/v1/Products(a5ab498a-7b2f-4043-ae2a-f95f457e7b3b)/$zip\"\n\nheaders = {\"Authorization\": f\"Bearer {access_token}\"}\n\nsession = requests.Session()\nsession.headers.update(headers)\nresponse = session.get(url, headers=headers, stream=True)\n\nwith open(\"product.zip\", \"wb\") as file:\n    for chunk in response.iter_content(chunk_size=8192):\n        if chunk:\n            file.write(chunk)"
  },
  {
    "objectID": "APIs/OData.html#odata-deletedproducts-endpoint",
    "href": "APIs/OData.html#odata-deletedproducts-endpoint",
    "title": "OData",
    "section": "OData DeletedProducts endpoint",
    "text": "OData DeletedProducts endpoint\nThe DeletedProducts OData endpoint allows users to access information about the deleted products in the Copernicus Data Space Ecosystem Catalog. This endpoint provides a convenient way to retrieve details about the products that have been deleted from the CDSE Catalog. By utilizing the supported operations and filtering options, users can efficiently access the required deleted products’ details. For the DeletedProducts OData endpoint, requests should be built the same way as for the OData Products endpoint OData Query structure with the change in the endpoint URL ‘Products’ to ‘DeletedProducts’.\n\nEndpoint URL\nThe DeletedProducts OData endpoint can be accessed using the following URL:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts\n\n\n\n\n\nQuery structure\nThe DeletedProducts OData endpoint supports the same searching options as a standard OData Products endpoint. For more information, please go to OData Query structure\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=not contains(Name,'S1') and DeletionDate gt 2023-04-01T00:00:00.000Z and DeletionDate lt 2023-05-30T23:59:59.999Z&$orderby=DeletionDate&$top=20\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo accelerate the query performance, it is recommended to limit the query by specified dates, e.g.:\nDeletionDate gt 2022-05-03T00:00:00.000Z and DeletionDate lt 2023-05-03T00:00:00.000Z\n\n\n\n\nFilter option\nTo search for products by properties, a filter should be built as explained Filter option\nThe acceptable products’ properties for OData DeletedProducts endpoint are:\n\nName - search for a specific product by its exact name\nId - search for a specific product by its id\nDeletionDate - search by deletion date\nDeletionCause - search by deletion cause\nCollection/Name - search within a specific collection\nOriginDate - search by origin date\nContentDate/Start and ContentDate/End - search by sensing date\nFootprint - search by geographic criteria\nAttributes - search by product’s attributes\n\n\nQuery by name\nTo search for a deleted product by its exact name:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=Name eq 'S2A_MSIL1C_20210404T112111_N0500_R037_T31VEG_20230209T101305.SAFE'\n\n\n\n\n\nQuery by Id\nTo search for a deleted product by its Id:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts(29008eb1-1a51-48a8-9aec-288b00f7debe)\n\n\n\n\n\nQuery by Deletion Date\nTo search for products deleted between two inclusive interval dates:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=DeletionDate ge 2023-04-26T00:00:00.000Z and DeletionDate le 2023-04-27T23:59:59.999Z\n\n\n\n\n\nQuery by Deletion Cause\nTo search for products deleted from specific reason:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=DeletionCause eq 'Duplicated product' or DeletionCause eq 'Corrupted product'\n\n\n\nAllowed values of the DelationCause parameter are:\n\nDuplicated product\nMissing checksum\nCorrupted product\nObsolete product or Other\n\n\n\nQuery by Collection of Products\nTo search for deleted products within a specific collection:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=Collection/Name eq 'SENTINEL-2' and DeletionDate gt 2023-04-01T00:00:00.000Z and DeletionDate lt 2023-09-30T23:59:59.999Z\n\n\n\nFor available collections, please refer to Query Collection of Products. Also, please note that it is possible that none of the products have been deleted from the available collections.\n\n\nQuery by Sensing Date\nTo search for deleted products acquired between two dates:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=ContentDate/Start gt 2021-09-01T00:00:00.000Z and ContentDate/End lt 2021-09-01T00:05:00.000Z\n\n\n\n\n\nQuery by Geographic Criteria\nTo search for deleted products intersecting the specified polygon:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=OData.CSC.Intersects(area=geography'SRID=4326;POLYGON ((-75.000244 -42.4521508418609, -75.000244 -43.4409190460844, -73.643585 -43.432873907284, -73.66513 -42.4443775132447, -75.000244 -42.4521508418609))') and ContentDate/Start gt 2021-01-01T00:00:00.000Z and ContentDate/End lt 2021-04-01T23:59:59.999Z\n\n\n\n\n\nQuery by attributes\nTo search for products by attributes, it is necessary to build a filter with the specified structure as defined Query Collection of Products.\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=Attributes/OData.CSC.IntegerAttribute/any(att:att/Name eq 'orbitNumber' and att/OData.CSC.IntegerAttribute/Value eq 10844) and attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'orbitDirection' and att/OData.CSC.StringAttribute/Value eq 'ASCENDING')\n\n\n\n\n\n\nOrderby option\nOrderby option works the same way as explained Orderby option.\n\n\n\n\n\n\nTip\n\n\n\nUsing the orderby option will exclude potential duplicates from the search results.\n\n\nFor OData DeletedProducts endpoint, acceptable arguments for this option are:\n\nContentDate/Start\nContentDate/End\nDeletionDate\n\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=contains(Name,'S1A_EW_GRD') and DeletionDate gt 2023-04-01T00:00:00.000Z and DeletionDate lt 2023-05-30T23:59:59.999Z&$orderby=DeletionDate desc\n\n\n\n\n\nExpand option\nThe expand option enables users to see the full metadata of each returned result.\nThe acceptable argument for this option is:\n\nAttributes\n\nTo see the metadata of the results:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=contains(Name,'S2A') and DeletionDate gt 2023-04-01T00:00:00.000Z and DeletionDate lt 2023-05-30T23:59:59.999Z&$expand=Attributes\n\n\n\n\n\nSkip option\nSkip option can be used as defined Skip option.\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=contains(Name,'S2A') and ContentDate/Start ge 2021-04-01T00:00:00.000Z and ContentDate/Start le 2021-04-30T23:59:59.999Z&$skip=30\n\n\n\n\n\nTop option\nTop option can be used as defined Top option.\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=contains(Name,'S1A_EW_GRD') and ContentDate/Start ge 2021-09-01T00:00:00.000Z and ContentDate/Start le 2021-09-30T23:59:59.999Z&$top=40\n\n\n\n\n\nCount option\nCount option can be used as defined Count option\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/DeletedProducts?$filter=contains(Name,'S1A_EW_GRD') and DeletionDate gt 2023-04-01T00:00:00.000Z and DeletionDate lt 2023-05-30T23:59:59.999Z&$orderby=DeletionDate desc&$count=True"
  },
  {
    "objectID": "APIs/openEO/large_scale_processing.html",
    "href": "APIs/openEO/large_scale_processing.html",
    "title": "Large scale processing",
    "section": "",
    "text": "Processing of larger areas extending to a global scale is one of the more challenging tasks in earth observation, but certainly one that this platform aims to tackle. In this page we describe one of the best practice based on the example of processing a croptype map for all 27 countries in the European Union. We do recommend you to reaching out on the forum or helpdesk regarding your particular case, as workflows can vary, and adequate processing resources may require some advanced planning.\nThe approach described here is based on local files to track the production. This is a low-cost approach that does not require special IT knowledge but comes with some risks, such as losing your local files. A more robust approach for production-grade projects would typically rely on some sort of database or STAC catalogue service to monitor processing. Such a setup is, however quite similar in many aspects.\nThe basic strategy for processing large areas is to split them up into smaller areas, usually according to a regular tile grid. Splitting reduces the size of the area that needs to be processed by one batch job and avoids running into all kinds of limitations. For instance, when processing a specific projection, you anyway have to stay within the bounds of that projection. Also, the output file size of a job often becomes impractical when working over huge areas. Or you will hit bottlenecks in the backend implementation that does not occur for normally sized jobs. Also, when a smaller job fails or requires reprocessing, the cost will be smaller."
  },
  {
    "objectID": "APIs/openEO/large_scale_processing.html#relevant-openeo-features",
    "href": "APIs/openEO/large_scale_processing.html#relevant-openeo-features",
    "title": "Large scale processing",
    "section": "Relevant openEO features",
    "text": "Relevant openEO features\nWe want to highlight a few key elements that made us choose openEO for large-scale processing:\n\nPerformance & scalability\nSTAC metadata is automatically generated for you, ensuring that your output is ready for dissemination without requiring you to become a metadata expert.\nWhere relevant FAIR principles are taken into account automatically, such as providing provenance information.\nCloud-optimized file formats are generated by default.\nProcessing can be distributed over multiple backends."
  },
  {
    "objectID": "APIs/openEO/large_scale_processing.html#preparation",
    "href": "APIs/openEO/large_scale_processing.html#preparation",
    "title": "Large scale processing",
    "section": "Preparation",
    "text": "Preparation\nThe concept involves initially generating and persistently storing a list of tiles to be produced, including all the necessary attributes for each specific tile. This approach provides a comprehensive visual overview of the processing that will take place.\nHaving job parameters in a file is also useful for debugging afterwards. Determining parameters at runtime means you don’t have absolute certainty over the value of a specific argument, as there may be bugs in your code."
  },
  {
    "objectID": "APIs/openEO/large_scale_processing.html#prepare-tiling-grid",
    "href": "APIs/openEO/large_scale_processing.html#prepare-tiling-grid",
    "title": "Large scale processing",
    "section": "Prepare tiling grid",
    "text": "Prepare tiling grid\nThe tiling grid choice depends on your preferred projection system, which, in turn, is determined by your area of interest. For Europe, you can use the EPSG:3035 projection, while for global processing, considering different projections in accordance with UTM zones may be preferable.\nThe size of tiles in your grid is also important and often ranges from 20km to 100km. For relatively light workflows, a 100km grid can work well, while for more demanding cases, a 20km grid is better. In our example, we chose to work with 20km tiles because the workflow was quite demanding. A smaller tile size can also result in less unneeded processing when your target area has an irregular shape, like most countries and continents.\nA couple of basic grids can be found here: https://artifactory.vgt.vito.be/ui/repos/tree/General/auxdata-public/grids\nThe images below illustrate the overlap in the UTM grids versus a regular LAEA grid.\n\n\n\nUTM 100km\nLAEA 100km\n\n\n\n\n\n\n\n\n\nA grid can be masked based on the countries we want to load, the following script shows an example:\nimport geopandas as gpd\neurope = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\neurope = europe[europe.continent==\"Europe\"]\ndf = gpd.read_file(\"https://artifactory.vgt.vito.be/auxdata-public/grids/LAEA-20km.gpkg\",mask=europe)"
  },
  {
    "objectID": "APIs/openEO/large_scale_processing.html#prepare-job-attributes",
    "href": "APIs/openEO/large_scale_processing.html#prepare-job-attributes",
    "title": "Large scale processing",
    "section": "Prepare job attributes",
    "text": "Prepare job attributes\nIn addition to the tiling grid, we recommend determining other necessary properties for your processing jobs in advance. This enables a thorough review of these properties before initiating the processing. Examples includes basic elements such as job titles or tile-specific processing parameters, as well as attributes to determine the processing order.\nIn this step, you may also want to make sure to determine the correct tile extent in the coordinate system of your tile grid. Providing exact coordinates in the right projection is necessary to ensure pixel-perfect alignment of your tiles."
  },
  {
    "objectID": "APIs/openEO/large_scale_processing.html#tuning-your-processing-job",
    "href": "APIs/openEO/large_scale_processing.html#tuning-your-processing-job",
    "title": "Large scale processing",
    "section": "Tuning your processing job",
    "text": "Tuning your processing job\nBefore kicking off large processing, you want to be very sure that the correct output is generated and that you have sufficient credits and resources available to finish your job in time. This can be done by simply running various jobs and using the statistics reported in the metadata to determine average parameters. (The map production section below shows a way to collect these parameters in a CSV.)\nFor instance, for the case of processing the EU27 croptype map, consisting of ~11000 20km tiles, we made the following calculations up front:\n\nThe average runtime was 30 minutes, which means that it would take ~15 days of continuous processing with 15 parallel jobs.\nThe average cost was below 100 credits, so we would be able to process with a budget of 1100000 credits.\n\nTo achieve these numbers, we did have to optimize batch job settings and the overall workflow to reduce resource usage.\nA common bottleneck to parallelization is memory consumption, and it can be useful to know the maximum memory allocation on a single machine in your backend of choice. For instance, in a cloud environment with 16GB per machine and 4 CPUs, using slightly less than 4GB per worker is efficient as you can fit 4 parallel workers on a single VM while requiring 6GB would fit only 2 workers and leave about 4GB unused.\nIn our example, we used the openEO backend running on the Copernicus dataspace, which is based on Geotrellis, the execution options are documented here."
  },
  {
    "objectID": "APIs/openEO/large_scale_processing.html#starting-map-production",
    "href": "APIs/openEO/large_scale_processing.html#starting-map-production",
    "title": "Large scale processing",
    "section": "Starting map production",
    "text": "Starting map production\nThe openEO Python client provides a useful tool to run multiple processing jobs in multiple backends.\nIt takes a GeoJSON corresponding to your tile grid and job properties per tile and triggers a function provided by you whenever a new job needs to be created. You can configure multiple backends and set the number of parallel jobs per backend.\nSimilarly, it also takes care of error handling and can be considered more resilient compared to writing a simple loop yourself.\nThis script uses a CSV file to track your jobs, and whenever it is interrupted, it can simply resume from that CSV file, making it tolerant to failure.\n\n\n\nTracking jobs by CSV"
  },
  {
    "objectID": "APIs/openEO/large_scale_processing.html#errors-during-production",
    "href": "APIs/openEO/large_scale_processing.html#errors-during-production",
    "title": "Large scale processing",
    "section": "Errors during production",
    "text": "Errors during production\nIt’s common for some tasks to run into issues during production, which is okay if it doesn’t happen too frequently. If a task fails, take a quick look at the error logs. If there’s no obvious reason, a simple retry might do the trick. Sometimes, you might need to allocate more memory.\nWe also see a limited number of cases where issues in the underlying product archive cause failures or artifacts. These are harder to resolve and may require interaction with the backend."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html",
    "href": "APIs/openEO/Python_Client/Python.html",
    "title": "Getting started with the openEO Python client",
    "section": "",
    "text": "This Getting Started guide will just give a small taste of using the openEO Python client library in the context of the Copernicus Data Space Ecosystem. Consult the official openEO Python client library documentation for more in-depth information and a broader coverage of its functionality."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#installation",
    "href": "APIs/openEO/Python_Client/Python.html#installation",
    "title": "Getting started with the openEO Python client",
    "section": "Installation",
    "text": "Installation\n\n\n\n\n\n\nTip\n\n\n\n\n\nAs with any Python project, it is recommended to work in some kind of virtual environment (venv, virtualenv, conda, docker, …) to avoid interference with other projects or applications.\n\n\n\nThe openEO Python client library is available on PyPI and can easily be installed with a tool like pip, for example:\npip install openeo\nThe client library is also available on Conda Forge and can be easily installed in a conda environment, for example:\nconda install -c conda-forge openeo\n\n\n\n\n\n\nTip\n\n\n\n\n\nSee the official openeo installation docs for more details, alternative installation procedures or troubleshooting tips."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#exploring-a-back-end",
    "href": "APIs/openEO/Python_Client/Python.html#exploring-a-back-end",
    "title": "Getting started with the openEO Python client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO back-end of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu. We establish a connection to this back-end as follows:\nimport openeo\n\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\")\nThe Connection object we created here is the central gateway to interact with the back-end:\n\nlist data collections, available processes, file formats and other capabilities of the back-end\nstart building your openEO algorithm from the desired data on the back-end\nexecute and monitor (batch) jobs on the back-end\netc.\n\n\nEO Collections\nEO data in openEO is organized in so-called collections, which are used as the input data for your openEO jobs (see the glossary for more info). Collections can be listed and inspected programmatically:\n# List collections available on the openEO back-end\nconnection.list_collection_ids()\n\n# Get detailed metadata of a certain collection\nconnection.describe_collection(\"SENTINEL2_L2A\")\nHowever, it is often easier to browse collections through the openEO collection listing page or the collection listing sidebar of the openEO Web Editor.\n\n\nopenEO Processes\nProcesses in openEO are operations that can be applied on (EO) data (see the the openEO glossary for more info). For example: calculate the mean of an array, mask out pixels outside a given polygon or calculate spatial aggregations. The output of one process can be used as the input of another process, and by doing so, multiple processes can be connected that way in a larger “process graph”, as illustrated in this conceptual diagram:\n\n\n\n\nflowchart TD\n  load_collection --&gt; NDVI[calculate NDVI]\n  load_collection --&gt; cm[build cloud mask]\n  NDVI --&gt; mask[apply mask]\n  cm --&gt; mask\n  mask --&gt; aggregate_spatial\n  load_geojson[load geometries] --&gt; aggregate_spatial\n  aggregate_spatial --&gt; save_result\n\n\n\n\n\nWhile it is possible to programmatically list and inspect the available processes (e.g. connection.list_processes() with the openEO python client), it is recommended to just consult the process listing page, the process listing sidebar of the openEO Web Editor, or the official openeo.org processes listing."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#authentication",
    "href": "APIs/openEO/Python_Client/Python.html#authentication",
    "title": "Getting started with the openEO Python client",
    "section": "Authentication",
    "text": "Authentication\nBasic metadata about collection and processes, as discussed above is publicly available and does not require being logged in. However, for downloading EO data or running processing workflows, it is necessary to authenticate so that permissions, resource usage, etc. can be managed properly.\n\n\n\n\n\n\nImportant\n\n\n\nMake sure to complete your Copernicus Data Space Ecosystem registration before attempting to do the authentication explained below.\n\n\nOnce properly registered, you will be able to authenticate your connection handle in your Python code with Connection.authenticate_oidc(), just like this:\nconnection.authenticate_oidc()\n\nBy default, the first time you call this authenticate_oidc() method, a URL will be printed. Something like for example:\nVisit https://auth.example.com/device?user_code=EAXD-RQXV to authenticate.\nVisit this URL (click it or copy-paste it into your web browser) and follow the login flow using your Copernicus Data Space Ecosystem credentials.\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can visit this URL with any browser you prefer to complete the login procedure (e.g. on your laptop or smartphone). It does not have to be a browser running on the same machine/network as your Python script/application.\n\n\n\nOnce the authentication is completed, your Python script will receive the necessary authentication tokens and print\nAuthorized successfully.\nOther times, when you still have valid (refresh) tokens on your system, it will not be necessary to go through the Copernicus Data Space Ecosystem login steps and you will immediately see\nAuthenticated using refresh token.\n\nIn any case, your connection is now authenticated and capable to make download/processing requests.\nA more in-depth discussion of various authentication concepts is available in the openEO Python client documentation."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#working-with-datacube",
    "href": "APIs/openEO/Python_Client/Python.html#working-with-datacube",
    "title": "Getting started with the openEO Python client",
    "section": "Working with Datacube",
    "text": "Working with Datacube\nNow that we know how to discover the capabilities of the back-end and how to authenticate, let’s do some real work and process some EO data in a batch job. We’ll build the desired algorithm by working on so-called “Datacubes”, which is the central concept in openEO to represent EO data.\n\nCreating a Datacube\nThe first step is loading the desired slice of a data collection with Connection.load_collection:\ndatacube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    spatial_extent={\"west\": 5.14, \"south\": 51.17, \"east\": 5.17, \"north\": 51.19},\n    temporal_extent = [\"2021-02-01\", \"2021-04-30\"],\n    bands=[\"B02\", \"B04\", \"B08\"],\n    max_cloud_cover=85,\n)\nThis results in a Datacube object containing the “SENTINEL2_L2A” data restricted to the given spatial extent, the given temporal extend and the given bands .\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can also filter the datacube step by step or at a later stage by using the following filter methods:\ndatacube = datacube.filter_bbox(west=5.14, south=51.17, east=5.17, north=51.19)\ndatacube = datacube.filter_temporal(start_date=\"2021-02-01\", end_date=\"2021-04-30\")\ndatacube = datacube.filter_bands([\"B02\", \"B04\", \"B08\"])\nStill, it is recommended to always use the filters directly in load_collection to avoid loading too much data upfront.\n\n\n\n\n\nApplying processes\nBy applying an openEO process on a datacube, we create a new datacube object that represents the manipulated data. The standard way to do this with the Python client is to call the appropriate Datacube object method. The most common or popular openEO processes have a dedicated Datacube method (e.g. mask, aggregate_spatial, filter_bbox, …). Other processes without a dedicated method can still be applied in a generic way. An on top of that, there are also some convenience methods that implement openEO processes is a compact, Pythonic interface.\nFor example, the min_time method implements a reduce_dimension process along the temporal dimension, using the max process as reducer function:\ndatacube = datacube.max_time()\nThis creates a new datacube (we overwrite the existing variable), where the time dimension is eliminated and for each pixel we just have the minimum value of the corresponding timeseries in the original datacube.\nSee the Python client Datacube API for a more complete listing of methods that implement openEO processes.\n\n\n\n\n\n\nNote\n\n\n\nStill unsure on how to make use of processes with the Python client? Visit the official documentation on working with processes."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#execution",
    "href": "APIs/openEO/Python_Client/Python.html#execution",
    "title": "Getting started with the openEO Python client",
    "section": "Execution",
    "text": "Execution\nIt’s important to note that all the datacube processes we applied up to this point are not actually executed yet, neither locally nor remotely on the back-end. We just built an abstract representation of the algorithm (input data and processing chain), encapsulated in a local Datacube object (e.g. the result variable above). To trigger an actual execution (on the back-end) we have to explicitly send this representation to the back-end.\n\nBatch job execution\nMost of the simple, basic openEO usage examples show synchronous downloading of results. This only works properly if the processing doesn’t take too long and is focused on a smaller area of interest. However, you have to use batch jobs for the heavier work (larger regions of interest, larger time series, more intensive processing).\n# While not necessary, it is also recommended to give your batch job a descriptive title so it’s easier to identify in your job listing.\njob = cube.execute_batch()\n\nThis documentation mainly discusses how to programmatically create and interact with batch job using the openEO Python client library. The openEO API however does not enforce usage of the same tool for each step in the batch job life cycle.\nFor example: if you prefer a graphical, web-based interactive environment to manage and monitor your batch jobs, feel free to switch to an openEO web editor like openeo.dataspace.copernicus.eu/ at any time. After logging in with the same account you use in your Python scripts, you should see your batch jobs listed under the “Data Processing” tab. More information on using openEO web editor is discussed here.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe official openEO Python Client documentation has more information on batch job basics {target=“_blank”} or more detailed batch job (result) management"
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#full-example",
    "href": "APIs/openEO/Python_Client/Python.html#full-example",
    "title": "Getting started with the openEO Python client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the Python client.\nA common task in earth observation is to apply a formula to a number of spectral bands in order to compute an ‘index’, such as NDVI, NDWI, EVI, … In this tutorial we’ll go through a couple of steps to extract EVI (enhanced vegetation index) values and timeseries\nimport openeo\n\n# First, we connect to the back-end and authenticate. \ncon = openeo.connect(\"openeo.dataspace.copernicus.eu\")\ncon.authenticate_oidc()\n\n# Now that we are connected, we can initialize our datacube object with the area of interest \n# and the time range of interest using Sentinel 1 data.\ndatacube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    spatial_extent={\"west\": 5.14, \"south\": 51.17, \"east\": 5.17, \"north\": 51.19},\n    temporal_extent = [\"2021-02-01\", \"2021-04-30\"],\n    bands=[\"B02\", \"B04\", \"B08\"],\n    max_cloud_cover=85,\n)\n\n# By filtering as early as possible (directly in load_collection() in this case), \n# we make sure the back-end only loads the data we are interested in and avoid incurring unneeded costs.\n\n\n#From this data cube, we can now select the individual bands with the DataCube.band() method and rescale the digital number values to physical reflectances:\nblue = sentinel2_cube.band(\"B02\") * 0.0001\nred = sentinel2_cube.band(\"B04\") * 0.0001\nnir = sentinel2_cube.band(\"B08\") * 0.0001\n\n\n# We now want to compute the enhanced vegetation index and can do that directly with these band variables:\nevi_cube = 2.5 * (nir - red) / (nir + 6.0 * red - 7.5 * blue + 1.0)\n\n# Now we can use the compact “band math” feature again to build a binary mask with a simple comparison operation:\n# Select the \"SCL\" band from the data cube\nscl_band = s2_scl.band(\"SCL\")\n# Build mask to mask out everything but class 4 (vegetation)\nmask = (scl_band != 4)\n\n# Before we can apply this mask to the EVI cube we have to resample it, as the “SCL” layer has a “ground sample distance” of 20 meter, while it is 10 meter for the “B02”, “B04” and “B08” bands. We can easily do the resampling by referring directly to the EVI cube.\nmask_resampled = mask.resample_cube_spatial(evi_cube)\n\n# Apply the mask to the `evi_cube`\nevi_cube_masked = evi_cube.mask(mask_resampled)\n\n# Because GeoTIFF does not support a temporal dimension, we first eliminate it by taking the temporal maximum value for each pixel:\nevi_composite = evi_cube.max_time()\n\n# Now we can download this to a local file:\nevi_composite.download(\"evi-composite.tiff\")\nNow, you can inspect the result for the EVI map."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#user-defined-functions",
    "href": "APIs/openEO/Python_Client/Python.html#user-defined-functions",
    "title": "Getting started with the openEO Python client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function. Therefore, you can create a Python function that will be executed at the back-end and functions as a process in your process graph.\nDetailed information about Python UDFs can be found in the official documentation as well as examples in the Python client repository."
  },
  {
    "objectID": "APIs/openEO/Python_Client/Python.html#useful-links",
    "href": "APIs/openEO/Python_Client/Python.html#useful-links",
    "title": "Getting started with the openEO Python client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO Python Client Library:\n\nExample scripts\nExample Jupyter Notebooks\nOfficial openEO Python Client Library Documentation\nRepository on GitHub"
  },
  {
    "objectID": "APIs/openEO/openEO.html",
    "href": "APIs/openEO/openEO.html",
    "title": "openEO",
    "section": "",
    "text": "openEO represents an innovative community standard that revolutionizes geospatial data processing and analysis. This groundbreaking framework provides a novel approach to accessing, processing, and analyzing diverse Earth observation data. By adopting openEO, developers, researchers, and data scientists gain access to a unified and interoperable platform, empowering them to harness distributed computing environments and leverage cloud-based resources for addressing complex geospatial challenges.\n\n\n\nWith openEO’s collaborative nature, users can seamlessly share code, workflows, and data processing methods across platforms and tools, fostering collaboration and advancing the accessibility, scalability, and reproducibility of Earth observation data. Additionally, openEO provides intuitive programming libraries that enable easy analysis of diverse Earth observation datasets. These libraries facilitate efficient access and processing of large-scale data across multiple infrastructures, supporting various applications, including exploratory research, detailed mapping, and information extraction from Earth observation. Moreover, this streamlined approach enhances the development process, enabling the utilization of Earth observation data for a wide range of applications and services.\nThe endpoint for the public service is 100% open source and compatible with Pangeo technology. Read more about it here.\nEndpoint: https://openeo.dataspace.copernicus.eu/\nConcrete examples of what you can do with openEO can be found in the notebooks section of this documentation."
  },
  {
    "objectID": "APIs/openEO/openEO.html#overview",
    "href": "APIs/openEO/openEO.html#overview",
    "title": "openEO",
    "section": "",
    "text": "openEO represents an innovative community standard that revolutionizes geospatial data processing and analysis. This groundbreaking framework provides a novel approach to accessing, processing, and analyzing diverse Earth observation data. By adopting openEO, developers, researchers, and data scientists gain access to a unified and interoperable platform, empowering them to harness distributed computing environments and leverage cloud-based resources for addressing complex geospatial challenges.\n\n\n\nWith openEO’s collaborative nature, users can seamlessly share code, workflows, and data processing methods across platforms and tools, fostering collaboration and advancing the accessibility, scalability, and reproducibility of Earth observation data. Additionally, openEO provides intuitive programming libraries that enable easy analysis of diverse Earth observation datasets. These libraries facilitate efficient access and processing of large-scale data across multiple infrastructures, supporting various applications, including exploratory research, detailed mapping, and information extraction from Earth observation. Moreover, this streamlined approach enhances the development process, enabling the utilization of Earth observation data for a wide range of applications and services.\nThe endpoint for the public service is 100% open source and compatible with Pangeo technology. Read more about it here.\nEndpoint: https://openeo.dataspace.copernicus.eu/\nConcrete examples of what you can do with openEO can be found in the notebooks section of this documentation."
  },
  {
    "objectID": "APIs/openEO/openEO.html#added-value-of-openeo-api",
    "href": "APIs/openEO/openEO.html#added-value-of-openeo-api",
    "title": "openEO",
    "section": "Added value of openEO API",
    "text": "Added value of openEO API\nThe key benefits of using openEO API can be summarized as follows:\n\nUnified and straightforward access to multiple Earth observation datasets.\nScalable and efficient processing capabilities.\nA standardized system that works across different platforms.\nIndependence from underlying technologies and software libraries.\nReproducibility through transparent workflows, supporting principles of FAIR (Findable, Accessible, Interoperable, and Reusable) and Open Science.\n\nWhen using the openEO API, users can choose JavaScript, Python, or R as their client library. This allows them to work with any backend and compare them based on capacity, cost, and result quality.\nNevertheless, if you are unfamiliar with programming, you could start using the web-based editor for openEO. It supports visual modelling of your algorithms and simplified JavaScript-based access to the openEO workflows and providers. An overview of the openEO web-editor is available in the Applications section of this documentation."
  },
  {
    "objectID": "APIs/openEO/openEO.html#datacubes",
    "href": "APIs/openEO/openEO.html#datacubes",
    "title": "openEO",
    "section": "Datacubes",
    "text": "Datacubes\nIn openEO, a datacube is a fundamental concept and a key component of the platform. Data is represented as datacubes in openEO, which are multi-dimensional arrays with additional information about their dimensionality. Datacubes can provide a nice and tidy interface for spatiotemporal data as well as for the operations you may want to execute on them. An in-depth introduction to datacubes and processing them with openEO can be found here."
  },
  {
    "objectID": "APIs/openEO/openEO.html#collections",
    "href": "APIs/openEO/openEO.html#collections",
    "title": "openEO",
    "section": "Collections",
    "text": "Collections\nIn openEO, a backend offers set of collections to be processed. A user can access and process from this comprehensive list of data collections available in the Copernicus Data Space Ecosystem backend through openEO. They can load (a subset of) a collection using the load_collection process, which returns a raster datacube."
  },
  {
    "objectID": "APIs/openEO/openEO.html#file-formats",
    "href": "APIs/openEO/openEO.html#file-formats",
    "title": "openEO",
    "section": "File formats",
    "text": "File formats\nDepending on the data cube that your process graph creates and on your later use case, some file formats are more suitable to export your data (save_result) than others. A user can choose among possible output formats within openEO."
  },
  {
    "objectID": "APIs/openEO/openEO.html#processes",
    "href": "APIs/openEO/openEO.html#processes",
    "title": "openEO",
    "section": "Processes",
    "text": "Processes\nIn openEO, a user can find several processes to perform operations on Earth Observation data. These can range from simple add() to complex predict_probabilities(). Furthermore, a user can create complex workflows by chaining multiple processes together."
  },
  {
    "objectID": "APIs/openEO/openEO.html#support",
    "href": "APIs/openEO/openEO.html#support",
    "title": "openEO",
    "section": "Support",
    "text": "Support\nNeed help locating your preferred programming language? Or you need help finding functionalities that you want to use. Then you have the option to report issues via Submit a request or actively proposing API changes through Pull Request to our GitHub repo."
  },
  {
    "objectID": "APIs/openEO/openEO.html#general-limitations",
    "href": "APIs/openEO/openEO.html#general-limitations",
    "title": "openEO",
    "section": "General limitations",
    "text": "General limitations\n\nSize of retrieved data\nAs a rule of thumb, openEO is tested up to areas of 100x100km at 10m resolution. Larger extents may work, but we recommend always starting first with smaller areas. Also, consider that large area jobs may result in outputs of multiple gigabytes that become inconveniently large to download or handle on your local machine.\nAlso, the temporal extent can have a significant impact, so here, we recommend starting with a small extent. Note that it is possible to increase job resources.\n\n\nFree tier limitations\nThe following limitations need to be taken into account:\n\nSynchronous requests are limited to 2 concurrent requests\nBatch jobs are limited to 2 concurrent jobs\n\nThese limits are in place to prevent individual users from overloading the service. However, if these limits cause issues with your use case, then Submit a request and our support team will do their best to help you."
  },
  {
    "objectID": "APIs/openEO/openeo_processing.html",
    "href": "APIs/openEO/openeo_processing.html",
    "title": "openEO process implementation details",
    "section": "",
    "text": "This page details several relevant aspects of the implementation of specific openEO processes that are relevant for reproducibility.\nThe openEO deployment of CDSE public service is 100% open source and has a specific goal of supporting open science.\n\n\nThe sar_backscatter process allows on-the-fly computation of Sentinel-1 sigma0 backscatter. It is based on the open-source Orfeo Toolbox and sufficiently fast to provide a cost-effective option for large-scale processing.\n\n\nWhen thermal noise is removed, values are set to 0, but Orfeo also uses 0 for nodata.\n\n\n\n\nThe load_collection implementation is quite advanced and tries to optimise data loading from the data space archive.\nWhen no resampling options are specified in the process graph, we try to respect the original pixel grid of the data. This is done to allow processing that is equally exact as file-based processing.\n\n\nProperty filtering depends on the data space catalogue, which currently has limited STAC capabilities. This sometimes prevents the usage of standardised STAC property names, which affects the portability of other process graphs."
  },
  {
    "objectID": "APIs/openEO/openeo_processing.html#sar-backscatter",
    "href": "APIs/openEO/openeo_processing.html#sar-backscatter",
    "title": "openEO process implementation details",
    "section": "",
    "text": "The sar_backscatter process allows on-the-fly computation of Sentinel-1 sigma0 backscatter. It is based on the open-source Orfeo Toolbox and sufficiently fast to provide a cost-effective option for large-scale processing.\n\n\nWhen thermal noise is removed, values are set to 0, but Orfeo also uses 0 for nodata."
  },
  {
    "objectID": "APIs/openEO/openeo_processing.html#load_collection",
    "href": "APIs/openEO/openeo_processing.html#load_collection",
    "title": "openEO process implementation details",
    "section": "",
    "text": "The load_collection implementation is quite advanced and tries to optimise data loading from the data space archive.\nWhen no resampling options are specified in the process graph, we try to respect the original pixel grid of the data. This is done to allow processing that is equally exact as file-based processing.\n\n\nProperty filtering depends on the data space catalogue, which currently has limited STAC capabilities. This sometimes prevents the usage of standardised STAC property names, which affects the portability of other process graphs."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/LandslideNDVI/LandslidesNDVI.html",
    "href": "APIs/openEO/openeo-community-examples/python/LandslideNDVI/LandslidesNDVI.html",
    "title": "NDVI-based approach to study Landslide areas",
    "section": "",
    "text": "Research indicates that NDVI can play a crucial role in identifying landslide zones. While an advanced workflow is possible, this notebook opts for a simple approach using the difference of NDVI and applying a threshold to the result to detect landslide occurred areas. Our analysis relies on the Sentinel-2 Level 2A collection fetched from the Copernicus Data Space Ecosystem using openEO.\n\nimport openeo\nimport rasterio\nfrom rasterio.plot import show\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport matplotlib.patches as mpatches\n\n\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nHere, we do the test for Ischia in Italy for the fall of 2022, where several landsides were registered.\n\nspatial_extent = {\n    \"west\": 13.882567409197492,\n    \"south\": 40.7150627793427,\n    \"east\": 13.928593792166282,\n    \"north\": 40.747050251559216,\n}\n\nLet us load pre Sentinel2 collection\n\ns2pre = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2022-08-25\", \"2022-11-25\"],\n    spatial_extent=spatial_extent,\n    bands=[\"B04\", \"B08\"],\n)\n\nNow, let’s calculate pre-NDVI and take a mean over the temporal extent.\n\nprendvi = s2pre.ndvi().mean_time()\n\nFor the post datacube, let’s load the Sentinel2 collection with the temporal extent starting from the end of the pre-event temporal extent.\n\ns2post = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2022-11-26\", \"2022-12-25\"],\n    spatial_extent=spatial_extent,\n    bands=[\"B04\", \"B08\"],\n)\n\n\n# calculate post NDVI and take a mean over temporal extent\npostndvi = s2post.ndvi().mean_time()\n\n\n# calculate difference in NDVI\ndiff = postndvi - prendvi\n\n\n# lets execute the process\ndiff.download(\"NDVIDiff.tiff\")\n\n\nPlot the result\n\n# load the calculated data\nimg = rasterio.open(\"NDVIDiff.tiff\")\n\nTo better visualise the output, we apply a threshold to define landslide areas.\n\nvalue = img.read(1)\ncmap = matplotlib.colors.ListedColormap([\"black\", \"red\"])\nfig, ax = plt.subplots(figsize=(8, 6), dpi=80)\nim = show(\n    ((value &lt; -0.48) & (value &gt; -1)),\n    vmin=0,\n    vmax=1,\n    cmap=cmap,\n    transform=img.transform,\n    ax=ax,\n)\nvalues = [\"Absence\", \"Presence\"]\ncolors = [\"black\", \"red\"]\nax.set_title(\"Detected Landslide Area\")\nax.set_xlabel(\"X Coordinates\")\nax.set_ylabel(\"Y Coordinates\")\npatches = [\n    mpatches.Patch(color=colors[i], label=\"Landslide {l}\".format(l=values[i]))\n    for i in range(len(values))\n]\nfig.legend(handles=patches, bbox_to_anchor=(0.83, 1.03), loc=1)\n\n&lt;matplotlib.legend.Legend at 0x7f72025a6390&gt;\n\n\n\n\n\nA general observation drawn from the aforementioned result is that the red regions indicate potential landslide activity or vegetation loss.\nThe red region corresponds to an area where notably large landslides were recorded. However, some false positives can also be noticed in the northwest—an urban area, though not many landslides were reported in those regions. Hence, it is conceivable that there is a change in NDVI, but it might be due to many factors, such as cloud cover, harvesting, vegetation loss, etc. This shows that the difference in the NDVI approach is suitable for rapid mapping but can also contain a lot of misclassified pixels and needs further validation.\n\nWhen comparing the result with the ground truth, it resembles a few landslides that were reported and as shown in this Wikipedia resource.\n\n\n\nimage.png"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html",
    "title": "Parcel delineation using Sentinel-2",
    "section": "",
    "text": "Authors:\nTuning:"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#introduction",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#introduction",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Introduction",
    "text": "Introduction\nIn this notebook we will be performing parcel delineation using Sentinel-2 data retrieved from- and processed on openEO. The models are generated using a U-Net and are pretrained. So in this notebook, we are dealing with the inference part of training a model. We will however also show how you can retrieve features from openEO, so that you know how the entire workflow looks like.\n\nfrom pathlib import Path\nimport json\nimport openeo\nfrom openeo import processes as eop\nfrom shapely.geometry import shape, box\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport xarray as xr\nfrom numpy import datetime_as_string\n\n\nopeneo.client_version()\n\n'0.27.0'\n\n\n\n## Output folder\nbase_path = Path(\"results\")"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#authentication",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#authentication",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Authentication",
    "text": "Authentication\nWe first need to connect to an openEO provider. Most providers require you to register an account, and provide you with a basic amount of processing credits. In this notebook we will use the Copernicus Data Scpace Ecosystem as openEO provider.\nAll the known openEO providers and their services: https://hub.openeo.org/\nMore info on authentication: https://open-eo.github.io/openeo-python-client/auth.html\nRun the authenticate_oidc() method again in case you can no longer connect. The token expires after a certain time.\n\nbackend_url = \"openeo.dataspace.copernicus.eu/\"\n\neoconn = openeo.connect(backend_url)\neoconn.authenticate_oidc()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#load-collection",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#load-collection",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Load collection",
    "text": "Load collection\nWe start off by loading in a collection. In this case, we are loading in Sentinel-2 L2A. More information on the collections available can be displayed with eoconn.list_collections(). Use eoconn.describe_collection(\"SENTINEL2_L2A\") for example to get the description of a specific collection.\nMore information on finding and loading data: https://open-eo.github.io/openeo-python-client/data_access.html\n\nbbox = [5.0, 51.2, 5.1, 51.3]\nyear = 2021\n\nstartdate = f\"{year}-01-01\"\nenddate = f\"{year}-09-30\"\n\n\ns2_bands = eoconn.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[startdate, enddate],\n    spatial_extent=dict(zip([\"west\", \"south\", \"east\", \"north\"], bbox)),\n    bands=[\"B04\", \"B08\", \"SCL\"],\n    max_cloud_cover=20,\n)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#select-usable-observations",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#select-usable-observations",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Select usable observations",
    "text": "Select usable observations\nThis pipeline will use 12 NDVI tiles in total. Depending on the time range selected, it is likely that your temporal dimension contains a lot more than 12 NDVI tiles. Therefore, we apply a selection procedure that selects the tiles with the highest number of clear pixels.\n\nnb_of_timesteps = 12\n\n\n## We use the SCL band to create a mask where clouded pixels are set to 1\n## and other pixels are set to 0\nscl_band = s2_bands.band(\"SCL\")\ns2_cloudmask = ( (scl_band == 8) | (scl_band == 9) | (scl_band == 3) ) * 1.0\n\n## Reduce the spacial dimension using the reducer \"mean\" to calculate the average cloud coverage\n#TODO: replace aggregate_spacial with reduce_spacial in a future openeo client version\nbbox_poly = box(*bbox)\navg_cloudmask = s2_cloudmask\\\n    .aggregate_spatial(geometries=bbox_poly, reducer=\"mean\") \n\n## Download the result for local sorting\navg_cloudmask.download(base_path / \"avg_cloudmask.nc\", format=\"NetCDF\")\n\n\n## Open the calculated cloudmask aggregation\navg_array = xr.open_dataset(base_path / \"avg_cloudmask.nc\")\n\n## Sort the timesteps by their cloud coverage and select the best ones\nbest_timesteps_dt64 = avg_array.squeeze(\"feature\")\\\n    .sortby(\"band_0\",ascending=True)\\\n    .coords[\"t\"].values[:nb_of_timesteps]\n\n## Close the dataset\navg_array.close()\n\n## Convert the timestep labels to iso format\nbest_timesteps = [datetime_as_string(t, unit=\"s\", timezone=\"UTC\") for t in best_timesteps_dt64]\n\n\n## Create a condition that checks if a date is one of the best timesteps\ncondition = lambda x : eop.any(\n    [\n        eop.date_between(\n            x = x,\n            min = timestep,\n            max = eop.date_shift(date=timestep, value=1, unit='day')) \n        for timestep in best_timesteps\n    ]\n)\n## Filter the bands using the condition\ns2_bands_reduced = s2_bands.filter_labels(\n    condition = condition,\n    dimension = \"t\"\n)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#calculate-ndvi",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#calculate-ndvi",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Calculate NDVI",
    "text": "Calculate NDVI\nThe delineation will be estimated based on the NDVI. The ndvi process can be used for these calculations.\n\nndviband = s2_bands_reduced.ndvi(red=\"B04\", nir=\"B08\")\n\nNote that the openEO Python clients generates an openEO process graph, which is then sent to one of the backends selected by the platform based on the operations that you are using. This process graph is then executed on selected platform. However, if you want to inspect intermediate results, you can, for example using ndviband.download(...) like below. Executing this line will allow you to inspect the NDVI images.\n\nndviband.download(base_path / \"ndvi.nc\")\n\nThe intermediate result (here only 3 of them are ploted) of the NDVI looks as shown below:\n\n## Load your dataset\nndvi_data = xr.open_dataset(base_path / \"ndvi.nc\")\n\n## Access the \"var\" variable\nvar = ndvi_data[\"var\"]\n\n## Select the top 3 time steps\nthree_steps = var[\"t\"][-3:]\n\n## Create a 1x3 horizontal plot for the top 3 time steps\nplt.figure(figsize=(16, 10))  # Adjust the figure size as needed\nfor i, t in enumerate(three_steps):\n    plt.subplot(1, 3, i + 1)\n    data_slice = var.sel(t=t)\n    dt = t.values.astype(\"M8[D]\").astype(\"O\")  # Convert to Python datetime object\n    formatted_date = dt.strftime(\"%Y-%m-%d\")  # Format the date\n    plt.imshow(data_slice, cmap=\"viridis\", origin=\"lower\", vmin=0, vmax=1)\n    plt.title(f\"Date: {formatted_date}\")\n    # Hide both horizontal and vertical ticks and labels\n    plt.xticks([])\n    plt.yticks([])\nplt.tight_layout()  # Ensures proper spacing between subplots\nplt.show()\n\n## Close the dataset\nndvi_data.close()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#apply-a-neural-network",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#apply-a-neural-network",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Apply a neural network",
    "text": "Apply a neural network\nWe now apply a neural network, that requires 128x128 pixel ‘chunks’ input. To avoid discontinuities between neighboring chunks, we work with an overlap of 32 pixels in all directions. The U-Net itself is trained on an input size of (x,y,1), that is, just one grayscale channel as an input, which is just one NDVI tile. However, we are using 12 NDVI images as an input (the 12 images selected in the previous step). That is because we are doing inference using 3 different models, 4 times per model. The final prediction is then the median of all predictions per pixel.\nAs you may know, a U-Net just like any other CNN applies a filter over an image. This can be done using apply_neighborhood, an openEO process defined here: https://openeo.org/documentation/1.0/processes.html#apply_neighborhood .\nFurther preprocessing of the data and the inference logic of the models is coded in an UDF. UDF’s are used to implement any custom code. It can therefore be used to quickly transfer code that you already wrote outside of openEO, or it can be used to implement features that are not present in openEO yet. It does however come at a cost of being slower than using openEO functionalities, due to optimization reasons. UDF’s are explained here: https://open-eo.github.io/openeo-python-client/udf.html\nThe pretrained models are converted to onnx models to allow for interoperability between different AI tools. More information on onnx and how to conveert your models from a specific framework can be found on their website. The onnxruntime package and other dependencies, used in udf_segmentation.py, have to be passed to the backend. This is done by passing a dependency archive as a job option, alongside the models.\n\ndependencies_url = \"https://artifactory.vgt.vito.be:443/auxdata-public/openeo/onnx_dependencies.zip\"\nmodels_url = \"https://artifactory.vgt.vito.be:443/artifactory/auxdata-public/openeo/parcelDelination/BelgiumCropMap_unet_3BandsGenerator_Models.zip\"\njob_options = {\n    \"udf-dependency-archives\": [\n        f\"{dependencies_url}#onnx_deps\",\n        f\"{models_url}#onnx_models\",\n    ]\n}\n\n\n## Apply the segmentation UDF using `apply_neighborhood`\n## An overlap of 32px is used, resulting in a 128x128 pixel input\nsegmentationband = ndviband.apply_neighborhood(\n    process=openeo.UDF.from_file(\"udf_segmentation.py\"),\n    size=[\n        {\"dimension\": \"x\", \"value\": 64, \"unit\": \"px\"},\n        {\"dimension\": \"y\", \"value\": 64, \"unit\": \"px\"},\n    ],\n    overlap=[\n        {\"dimension\": \"x\", \"value\": 32, \"unit\": \"px\"},\n        {\"dimension\": \"y\", \"value\": 32, \"unit\": \"px\"},\n    ],\n)\n\n\nsegmentation_job = segmentationband.create_job(\n    title=\"segmentation_onnx_job\", \n    out_format=\"NetCDF\", \n    job_options=job_options\n)\nsegmentation_job.start_and_wait()\nsegmentation_job.download_result(base_path / \"delineation.nc\")\n\n0:00:00 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': send 'start'\n0:00:24 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:00:29 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:00:39 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:00:47 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:00:57 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:01:10 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:01:26 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:01:46 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:02:12 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': queued (progress N/A)\n0:02:42 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:03:22 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:04:10 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:05:09 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:06:10 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:07:10 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:08:11 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:09:12 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:10:13 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': running (progress N/A)\n0:11:15 Job 'vito-j-24011501398f497fbf13cf76a0a1bbfb': finished (progress N/A)\n\n\nWindowsPath('results/parcels/delineation.nc')\n\n\nThe result of the U-Net is a map with more clearly defined boundaries, however the result is not optimal. We will therefore post-process our U-Net result by applying non-ML filters.\n\n## Load your dataset\nds = xr.open_dataset(base_path / \"delineation.nc\")\n\n## Access the \"var\" variable\nvar = ds[\"var\"]\n\n## Plot the data\nvar.plot(figsize=(10, 14), cmap=\"gray\")  # Use a colormap that suits your data\nplt.title(\"Parcel Delineation\")\nplt.show()\n\n## Close the dataset\nds.close()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#segmentation-postprocessing",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#segmentation-postprocessing",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Segmentation postprocessing",
    "text": "Segmentation postprocessing\nWe postprocess the output from the neural network using a sobel filter and Felzenszwalb’s algorithm, which are then merged. This time, we work on larger chunks, to reduce the need for stitching the vector output.\n\n## Apply the sobel felzenszwalb UDF using `apply_neighborhood`\nsobel_felzenszwalb = segmentationband.apply_neighborhood(\n    process=openeo.UDF.from_file(\"udf_sobel_felzenszwalb.py\"),\n    size=[\n        {\"dimension\": \"x\", \"value\": 256, \"unit\": \"px\"},\n        {\"dimension\": \"y\", \"value\": 256, \"unit\": \"px\"},\n    ],\n    overlap=[\n        {\"dimension\": \"x\", \"value\": 0, \"unit\": \"px\"},\n        {\"dimension\": \"y\", \"value\": 0, \"unit\": \"px\"},\n    ],\n)\n\n\nsobel_felzenszwalb_job = sobel_felzenszwalb.create_job(\n    title=\"sobel_felzenszwalb\",\n    out_format=\"NetCDF\",\n    job_options=job_options\n)\nsobel_felzenszwalb_job.start_and_wait()\nsobel_felzenszwalb_job.download_result(base_path / \"delineation_filtered.nc\")\n\n0:00:00 Job 'j-240206f8717f419b96cb35e01323ff77': send 'start'\n0:00:15 Job 'j-240206f8717f419b96cb35e01323ff77': created (progress N/A)\n0:00:21 Job 'j-240206f8717f419b96cb35e01323ff77': created (progress N/A)\n0:00:27 Job 'j-240206f8717f419b96cb35e01323ff77': created (progress N/A)\n0:00:36 Job 'j-240206f8717f419b96cb35e01323ff77': created (progress N/A)\n0:00:46 Job 'j-240206f8717f419b96cb35e01323ff77': created (progress N/A)\n0:00:58 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:01:14 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:01:33 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:01:57 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:02:28 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:03:05 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:03:57 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:04:56 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:05:57 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:06:57 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:07:57 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:08:58 Job 'j-240206f8717f419b96cb35e01323ff77': running (progress N/A)\n0:09:59 Job 'j-240206f8717f419b96cb35e01323ff77': finished (progress N/A)\n\n\nWindowsPath('results/delineation_filtered.nc')\n\n\n\n## Load your dataset\nds = xr.open_dataset(base_path / \"delineation_filtered.nc\")\n\n## Access the \"var\" variable\nvar = ds[\"var\"]\n\n## Plot the data\nvar.plot(figsize=(10, 14), cmap=\"gray\")  # Use a colormap that suits your data\nplt.title(\"Parcel Delineation - filtered\")\nplt.show()\n\n## Close the dataset\nds.close()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#convert-to-vector",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#convert-to-vector",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Convert to vector",
    "text": "Convert to vector\nWe are now ready to convert the raster image to vector. In openEO, we have an integrated process to do so, called raster_to_vector. You can read more about this method, or about other methods of interest, in our documentation: https://docs.openeo.cloud/processes/#raster_to_vector Note: This process is still in development, so results may not be perfect.\n\n## Convert the raster to a vector\nvectorization = sobel_felzenszwalb.raster_to_vector()\n\n\nvectorization_job = vectorization.create_job(\n    title=\"vectorization\",\n    out_format=\"json\",\n    job_options=job_options\n)\nvectorization_job.start_and_wait()\nvectorization_job.download_result(base_path / \"parcels.json\")\n\n0:00:00 Job 'j-240206b71829447fb44fe4b18bfce0eb': send 'start'\n0:00:16 Job 'j-240206b71829447fb44fe4b18bfce0eb': created (progress N/A)\n0:00:21 Job 'j-240206b71829447fb44fe4b18bfce0eb': created (progress N/A)\n0:00:29 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:00:37 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:00:47 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:00:59 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:01:15 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:01:34 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:01:59 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:02:29 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:03:07 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:03:54 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:04:53 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:05:54 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:06:54 Job 'j-240206b71829447fb44fe4b18bfce0eb': queued (progress N/A)\n0:07:55 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:08:55 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:09:56 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:10:56 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:11:57 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:13:17 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:14:17 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:15:18 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:16:18 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:17:18 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:18:19 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:19:20 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:20:20 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:21:21 Job 'j-240206b71829447fb44fe4b18bfce0eb': running (progress N/A)\n0:22:25 Job 'j-240206b71829447fb44fe4b18bfce0eb': finished (progress N/A)\n\n\nWindowsPath('results/parcels.json')\n\n\n\n## Load the vector data as a GeoDataFrame\nwith open(base_path / \"parcels.json\") as f:\n    polygons = json.load(f)\ngeom = [shape(p) for p in polygons]\nparcels_gdf = gpd.GeoDataFrame(geometry=geom, crs=\"EPSG:32631\")\n\n## Save the GeoDataFrame to a file\nparcels_gdf.to_file(str(base_path / \"parcels.gpkg\"), layer=\"parcels\", driver=\"GPKG\")\n\n## Plot the data\nparcels_gdf.plot(cmap=\"OrRd\", figsize=(10, 16), edgecolor=\"black\")\nplt.title(\"Vector Parcels\")\nplt.show()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#sampling",
    "href": "APIs/openEO/openeo-community-examples/python/ParcelDelineation/Parcel delineation.html#sampling",
    "title": "Parcel delineation using Sentinel-2",
    "section": "Sampling",
    "text": "Sampling\nIf you are training your own network, openEO can be used to get training data. In general, a workflow that is often used by researchers using our platform is: * data access, data preparation, feature engineering and sampling: openEO * model training: outside of openEO (e.g. on GPU’s) * model inference: in openEO using UDF’s\nIn this notebook we are only doing inference. But to show you how to sample data, this is a small section on how that would work. When you are training a CNN, you will likely already have a set of images (e.g. for this use case, a number of delineated fields at a certain date, with a certain spatial extent). Sampling would therefore consist of: * Loading in a collection, like we did before * Calculating whatever index, raw band, custom calculation, or collection of one of the aforementioned you need for your use case * Applying openEO processes filter_spatial and filter_temporal on your image corresponding to the labeled images you already have * Downloading the results using execute_batch() (batch processing), or download() (synchronous processing, if your images are fairly small)\nIf you are using a recurrent net or another ML model where your input is flat (for example, a random forest, a booster, an SVM, …) and you are sampling points rather than entire images, you can use filter_spatial to filter your feature cube to the points for which you actually have sampling data, and the option sample_by_feature=True to store them as a separate record. You can do the same thing with aggregate_spatial. You can find more information here as well as a notebook where it is applied, here.\n\n## We can reuse the `ndviband` from the previous steps to create training data\ntraining_data = ndviband.filter_spatial(\n    json.load(open(\"resources/soy_2019.geojson\"))\n)\n\n\ntraining_data_job = training_data.create_job(\n    title=\"training_data\",\n    out_format=\"NetCDF\",\n    sample_by_feature=True,\n)\ntraining_data_job.start_and_wait()\ntraining_data_job.get_results(base_path / \"training_data.nc\")"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/rank_composites.html",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/rank_composites.html",
    "title": "Rank composites",
    "section": "",
    "text": "Optical satellite imagery contains gaps due to clouds, and the observation scenario. Many methods rely on having gap-free data available at regular time intervals. The most common technique to achieve this is to combine pixels from different observations, which is also referred to as compositing.\nVarious compositing approaches exist, in this notebook, we demonstrate ‘rank composites’ or more specifically the ‘max NDVI’ composite. A rank composite uses a single ‘rank band’ to decide if pixels of other bands are included in the composite. The advantage of rank composites over compositing per band is that the spectral signal represented by the different bands has been observed in reality in a single observation, and is not a combination of spectral values that occurred at different points in time.\nThis method is used in various peer reviewed publications, and some of its properties have been validated based on specific sensors: https://www.tandfonline.com/doi/abs/10.1080/01431168608948945\nIn this case the ‘rank band’ is a simple NDVI, which we ‘score’ based on the maximum value. The rank band can also be a combination of values leading to a more complex score, such as distance to cloud and observation angles. This variant is called a ‘best available pixel’ composite. (https://doi.org/10.1080/07038992.2014.945827)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/rank_composites.html#openeo-implementation",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/rank_composites.html#openeo-implementation",
    "title": "Rank composites",
    "section": "openEO implementation",
    "text": "openEO implementation\nThe steps to implement this method in openEO are relatively simple, but may be different from the steps in a ‘traditional’ programming language:\n\nWe load and compute the rank band separately\nThe rank band is converted into a mask, retaining only pixels that we want to select\nA datacube with raw bands is loaded, and the rank band mask is applied to it\naggregate_temporal(_period) is used to create a composite at regular intervals if needed\n\nMost methods require composites for multiple time periods as input. For instance, one composite per month, or every 10 days. We can compute these in one process graph, using apply_neighborhood, so that the result is also an immediate input for further processing.\n\nspatial_extent = {'west': 4.45, 'east': 4.50, 'south': 51.16, 'north': 51.17, 'crs': 'epsg:4326'}\n\n\nimport openeo\nimport xarray\nimport numpy as np\nimport io\nimport requests\n\nimport panel as pn\n\nimport pyproj\nimport matplotlib.pyplot as plt\nimport matplotlib\n\n%matplotlib inline\n\n\nc=openeo.connect(\"openeo.dataspace.copernicus.eu\")\nc.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeocloud.vito.be/openeo/1.0.0/' with OidcBearerAuth&gt;\n\n\nWe first create a binary cloud mask, as we don’t want to consider clouded pixels. This is also a good way to avoid loading too much data, which is costly.\n\nscl = c.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent = [\"2022-06-04\", \"2022-08-01\"],\n    bands = [\"SCL\"],\n    max_cloud_cover=95\n)\n\ncloud_mask = scl.process(\n    \"to_scl_dilation_mask\",\n    data=scl,\n    kernel1_size=17, kernel2_size=77,\n    mask1_values=[2, 4, 5, 6, 7],\n    mask2_values=[3, 8, 9, 10, 11],\n    erosion_kernel_size=3)\n\n\n/home/driesj/python/openeo-python-client/openeo/rest/connection.py:1133: UserWarning: SENTINEL2_L2A property filtering with properties that are undefined in the collection metadata (summaries): eo:cloud_cover.\n  return DataCube.load_collection(\n\n\nNow we load the bands required to compute NDVI, apply the cloud mask, and compute NDVI. The NDVI will be our ‘rank band’ in this example.\n\nndvi_bands = c.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent = [\"2022-06-04\", \"2022-08-01\"],\n    bands = [\"B04\", \"B08\", \"SCL\"],\n    max_cloud_cover=95\n)\n\nndvi_bands = ndvi_bands.mask(cloud_mask)\n\nndvi = ndvi_bands.ndvi(nir=\"B08\",red=\"B04\")\n\nThe next step is the most difficult one, and constructs the final mask that will be used to load the full datacube, but with only the observations where the NDVI is equal to the maximum.\nWe first create a function that computes the maximum NDVI from a series of values, and then loops again over those values to set values to 1 if they are equal to the maximum, and zero otherwise.\nThe apply_neighborhood process is used here to define the groups of NDVI values on which we want to run this function. We want to create multiple monthly max-NDVI composites, so we specify that the size of groups along the time dimension should correspond to 1 month. Apply_neighborhood is one of the more complex processes, but once you understand it, you’ll notice it’s quite versatile and useful.\n\ndef max_ndvi_selection(ndvi):\n    max_ndvi = ndvi.max()\n    return ndvi.array_apply(lambda x:x!=max_ndvi)\n\nrank_mask = ndvi.apply_neighborhood(\n        max_ndvi_selection,\n        size=[{'dimension': 'x', 'unit': 'px', 'value': 1}, {'dimension': 'y', 'unit': 'px', 'value': 1},\n              {'dimension': 't', 'value': \"month\"}],\n        overlap=[]\n    )\n\nAt this point, we download our mask for inspection. This is just an intermediate result, and is not needed in a real use case.\n\nrank_mask.filter_bbox(spatial_extent).execute_batch(\"the_mask.nc\")\n\n0:00:00 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': send 'start'\n0:00:20 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:00:28 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:00:35 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:00:43 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:00:53 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:01:06 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:01:22 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:01:41 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:02:06 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': queued (progress N/A)\n0:02:36 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': running (progress N/A)\n0:03:14 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': running (progress N/A)\n0:04:01 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': running (progress N/A)\n0:05:00 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': running (progress N/A)\n0:06:01 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': running (progress N/A)\n0:07:02 Job 'vito-j-ca99a93e1d7641d1b4e7a4714d7cfe90': finished (progress N/A)\n\n\n\n    \n    \n        \n    \n    \n\n\n\nmask_ds = xarray.open_dataset('the_mask.nc')\nmask_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (t: 12, x: 352, y: 119)\nCoordinates:\n  * t        (t) datetime64[ns] 2022-06-04 2022-06-11 ... 2022-07-24 2022-07-29\n  * x        (x) float64 6.014e+05 6.014e+05 6.014e+05 ... 6.049e+05 6.049e+05\n  * y        (y) float64 5.67e+06 5.67e+06 5.67e+06 ... 5.669e+06 5.669e+06\nData variables:\n    crs      |S1 ...\n    var      (t, y, x) uint8 ...\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platform - Geotrellis backend: 0.16.2a1\n    description:  \n    title:        xarray.DatasetDimensions:t: 12x: 352y: 119Coordinates: (3)t(t)datetime64[ns]2022-06-04 ... 2022-07-29standard_name :tlong_name :taxis :Tarray(['2022-06-04T00:00:00.000000000', '2022-06-11T00:00:00.000000000',\n       '2022-06-14T00:00:00.000000000', '2022-06-16T00:00:00.000000000',\n       '2022-06-29T00:00:00.000000000', '2022-07-01T00:00:00.000000000',\n       '2022-07-04T00:00:00.000000000', '2022-07-11T00:00:00.000000000',\n       '2022-07-16T00:00:00.000000000', '2022-07-19T00:00:00.000000000',\n       '2022-07-24T00:00:00.000000000', '2022-07-29T00:00:00.000000000'],\n      dtype='datetime64[ns]')x(x)float646.014e+05 6.014e+05 ... 6.049e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([601375., 601385., 601395., ..., 604865., 604875., 604885.])y(y)float645.67e+06 5.67e+06 ... 5.669e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5669795., 5669785., 5669775., 5669765., 5669755., 5669745., 5669735.,\n       5669725., 5669715., 5669705., 5669695., 5669685., 5669675., 5669665.,\n       5669655., 5669645., 5669635., 5669625., 5669615., 5669605., 5669595.,\n       5669585., 5669575., 5669565., 5669555., 5669545., 5669535., 5669525.,\n       5669515., 5669505., 5669495., 5669485., 5669475., 5669465., 5669455.,\n       5669445., 5669435., 5669425., 5669415., 5669405., 5669395., 5669385.,\n       5669375., 5669365., 5669355., 5669345., 5669335., 5669325., 5669315.,\n       5669305., 5669295., 5669285., 5669275., 5669265., 5669255., 5669245.,\n       5669235., 5669225., 5669215., 5669205., 5669195., 5669185., 5669175.,\n       5669165., 5669155., 5669145., 5669135., 5669125., 5669115., 5669105.,\n       5669095., 5669085., 5669075., 5669065., 5669055., 5669045., 5669035.,\n       5669025., 5669015., 5669005., 5668995., 5668985., 5668975., 5668965.,\n       5668955., 5668945., 5668935., 5668925., 5668915., 5668905., 5668895.,\n       5668885., 5668875., 5668865., 5668855., 5668845., 5668835., 5668825.,\n       5668815., 5668805., 5668795., 5668785., 5668775., 5668765., 5668755.,\n       5668745., 5668735., 5668725., 5668715., 5668705., 5668695., 5668685.,\n       5668675., 5668665., 5668655., 5668645., 5668635., 5668625., 5668615.])Data variables: (2)crs()|S1...crs_wkt :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]]spatial_ref :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]][1 values with dtype=|S1]var(t, y, x)uint8...long_name :varunits :grid_mapping :crs[502656 values with dtype=uint8]Indexes: (3)tPandasIndexPandasIndex(DatetimeIndex(['2022-06-04', '2022-06-11', '2022-06-14', '2022-06-16',\n               '2022-06-29', '2022-07-01', '2022-07-04', '2022-07-11',\n               '2022-07-16', '2022-07-19', '2022-07-24', '2022-07-29'],\n              dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Float64Index([601375.0, 601385.0, 601395.0, 601405.0, 601415.0, 601425.0,\n              601435.0, 601445.0, 601455.0, 601465.0,\n              ...\n              604795.0, 604805.0, 604815.0, 604825.0, 604835.0, 604845.0,\n              604855.0, 604865.0, 604875.0, 604885.0],\n             dtype='float64', name='x', length=352))yPandasIndexPandasIndex(Float64Index([5669795.0, 5669785.0, 5669775.0, 5669765.0, 5669755.0, 5669745.0,\n              5669735.0, 5669725.0, 5669715.0, 5669705.0,\n              ...\n              5668705.0, 5668695.0, 5668685.0, 5668675.0, 5668665.0, 5668655.0,\n              5668645.0, 5668635.0, 5668625.0, 5668615.0],\n             dtype='float64', name='y', length=119))Attributes: (4)Conventions :CF-1.9institution :openEO platform - Geotrellis backend: 0.16.2a1description :title :\n\n\nWe inspect the mask by filtering out nodata and plotting.\n\nmask_ds['var'] = mask_ds['var'].where(mask_ds['var']!=129)\nmask_ds['var'].plot(vmin=0,vmax=1,col=\"t\",col_wrap=4)\n\n&lt;xarray.plot.facetgrid.FacetGrid at 0x7f72f4674ed0&gt;"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/rank_composites.html#creating-and-downloading-your-composite",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/rank_composites.html#creating-and-downloading-your-composite",
    "title": "Rank composites",
    "section": "Creating and downloading your composite",
    "text": "Creating and downloading your composite\nNow it’s time to create and load the actual composite, which is very simply once a compositing mask has been created. It’s very important in this step to use the exact same ‘load_collection’ paratemers as were used to create the mask(s), to have a correct output. Note that we still use aggregate_temporal_period, which has 2 effects: - after masking, observations will still have their original dates, this process will generate equitemporal intervals. - In the case where multiple observations have the same NDVI value, the first observation will be retained.\n\nrgb_bands = c.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent = [\"2022-06-04\", \"2022-08-01\"],\n    bands = [\"B02\", \"B03\",\"B04\"],\n    max_cloud_cover=95\n)\n\ncomposite = rgb_bands.mask(rank_mask).aggregate_temporal_period(\"month\",\"first\")\n\ncomposite.filter_bbox(spatial_extent).execute_batch(\"composite.nc\")\n\n\ncomposite = xarray.open_dataset('composite.nc')\ncomposite\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (t: 2, x: 352, y: 119)\nCoordinates:\n  * t        (t) datetime64[ns] 2022-06-01 2022-07-01\n  * x        (x) float64 6.014e+05 6.014e+05 6.014e+05 ... 6.049e+05 6.049e+05\n  * y        (y) float64 5.67e+06 5.67e+06 5.67e+06 ... 5.669e+06 5.669e+06\nData variables:\n    crs      |S1 ...\n    B02      (t, y, x) float32 ...\n    B03      (t, y, x) float32 ...\n    B04      (t, y, x) float32 ...\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platform - Geotrellis backend: 0.16.2a1\n    description:  \n    title:        xarray.DatasetDimensions:t: 2x: 352y: 119Coordinates: (3)t(t)datetime64[ns]2022-06-01 2022-07-01standard_name :tlong_name :taxis :Tarray(['2022-06-01T00:00:00.000000000', '2022-07-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')x(x)float646.014e+05 6.014e+05 ... 6.049e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([601375., 601385., 601395., ..., 604865., 604875., 604885.])y(y)float645.67e+06 5.67e+06 ... 5.669e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5669795., 5669785., 5669775., 5669765., 5669755., 5669745., 5669735.,\n       5669725., 5669715., 5669705., 5669695., 5669685., 5669675., 5669665.,\n       5669655., 5669645., 5669635., 5669625., 5669615., 5669605., 5669595.,\n       5669585., 5669575., 5669565., 5669555., 5669545., 5669535., 5669525.,\n       5669515., 5669505., 5669495., 5669485., 5669475., 5669465., 5669455.,\n       5669445., 5669435., 5669425., 5669415., 5669405., 5669395., 5669385.,\n       5669375., 5669365., 5669355., 5669345., 5669335., 5669325., 5669315.,\n       5669305., 5669295., 5669285., 5669275., 5669265., 5669255., 5669245.,\n       5669235., 5669225., 5669215., 5669205., 5669195., 5669185., 5669175.,\n       5669165., 5669155., 5669145., 5669135., 5669125., 5669115., 5669105.,\n       5669095., 5669085., 5669075., 5669065., 5669055., 5669045., 5669035.,\n       5669025., 5669015., 5669005., 5668995., 5668985., 5668975., 5668965.,\n       5668955., 5668945., 5668935., 5668925., 5668915., 5668905., 5668895.,\n       5668885., 5668875., 5668865., 5668855., 5668845., 5668835., 5668825.,\n       5668815., 5668805., 5668795., 5668785., 5668775., 5668765., 5668755.,\n       5668745., 5668735., 5668725., 5668715., 5668705., 5668695., 5668685.,\n       5668675., 5668665., 5668655., 5668645., 5668635., 5668625., 5668615.])Data variables: (4)crs()|S1...crs_wkt :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]]spatial_ref :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]][1 values with dtype=|S1]B02(t, y, x)float32...long_name :B02units :grid_mapping :crs[83776 values with dtype=float32]B03(t, y, x)float32...long_name :B03units :grid_mapping :crs[83776 values with dtype=float32]B04(t, y, x)float32...long_name :B04units :grid_mapping :crs[83776 values with dtype=float32]Indexes: (3)tPandasIndexPandasIndex(DatetimeIndex(['2022-06-01', '2022-07-01'], dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Float64Index([601375.0, 601385.0, 601395.0, 601405.0, 601415.0, 601425.0,\n              601435.0, 601445.0, 601455.0, 601465.0,\n              ...\n              604795.0, 604805.0, 604815.0, 604825.0, 604835.0, 604845.0,\n              604855.0, 604865.0, 604875.0, 604885.0],\n             dtype='float64', name='x', length=352))yPandasIndexPandasIndex(Float64Index([5669795.0, 5669785.0, 5669775.0, 5669765.0, 5669755.0, 5669745.0,\n              5669735.0, 5669725.0, 5669715.0, 5669705.0,\n              ...\n              5668705.0, 5668695.0, 5668685.0, 5668675.0, 5668665.0, 5668655.0,\n              5668645.0, 5668635.0, 5668625.0, 5668615.0],\n             dtype='float64', name='y', length=119))Attributes: (4)Conventions :CF-1.9institution :openEO platform - Geotrellis backend: 0.16.2a1description :title :\n\n\n\n\nrgb_array=composite.to_array(dim=\"bands\").sel(bands=[\"B04\",\"B03\",\"B02\"]).astype(np.float32)/10000\nrgb_array\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (bands: 3, t: 2, y: 119, x: 352)&gt;\narray([[[[0.1007, 0.1026, 0.0713, ..., 0.0566, 0.0427, 0.0598],\n         [0.0868, 0.101 , 0.0811, ..., 0.083 , 0.0714, 0.104 ],\n         [0.087 , 0.0872, 0.0858, ..., 0.13  , 0.097 , 0.1382],\n         ...,\n         [0.0996, 0.096 , 0.0677, ..., 0.0165, 0.0178, 0.0228],\n         [0.0599, 0.059 , 0.0776, ..., 0.015 , 0.0168, 0.023 ],\n         [0.0532, 0.0518, 0.0499, ..., 0.0145, 0.0156, 0.0192]],\n\n        [[   nan,    nan, 0.0833, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [0.1098,    nan,    nan, ...,    nan,    nan,    nan],\n         ...,\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan]]],\n\n\n       [[[0.0966, 0.0972, 0.0716, ..., 0.0665, 0.0536, 0.0714],\n         [0.0845, 0.0871, 0.0762, ..., 0.0773, 0.072 , 0.1106],\n         [0.083 , 0.083 , 0.0882, ..., 0.1206, 0.1004, 0.1616],\n...\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan]]],\n\n\n       [[[0.0732, 0.0776, 0.0601, ..., 0.0479, 0.0394, 0.0458],\n         [0.0676, 0.078 , 0.0606, ..., 0.0708, 0.0594, 0.0787],\n         [0.0746, 0.0784, 0.0802, ..., 0.1036, 0.0727, 0.145 ],\n         ...,\n         [0.0742, 0.0708, 0.0469, ..., 0.0196, 0.018 , 0.0236],\n         [0.0438, 0.0426, 0.0546, ..., 0.0188, 0.0182, 0.0208],\n         [0.0429, 0.0431, 0.0418, ..., 0.0179, 0.0188, 0.0206]],\n\n        [[   nan,    nan, 0.093 , ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [0.1146,    nan,    nan, ...,    nan,    nan,    nan],\n         ...,\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan]]]],\n      dtype=float32)\nCoordinates:\n  * t        (t) datetime64[ns] 2022-06-01 2022-07-01\n  * x        (x) float64 6.014e+05 6.014e+05 6.014e+05 ... 6.049e+05 6.049e+05\n  * y        (y) float64 5.67e+06 5.67e+06 5.67e+06 ... 5.669e+06 5.669e+06\n  * bands    (bands) object 'B04' 'B03' 'B02'xarray.DataArraybands: 3t: 2y: 119x: 3520.1007 0.1026 0.0713 0.0976 0.1158 0.0876 ... nan nan nan nan nan nanarray([[[[0.1007, 0.1026, 0.0713, ..., 0.0566, 0.0427, 0.0598],\n         [0.0868, 0.101 , 0.0811, ..., 0.083 , 0.0714, 0.104 ],\n         [0.087 , 0.0872, 0.0858, ..., 0.13  , 0.097 , 0.1382],\n         ...,\n         [0.0996, 0.096 , 0.0677, ..., 0.0165, 0.0178, 0.0228],\n         [0.0599, 0.059 , 0.0776, ..., 0.015 , 0.0168, 0.023 ],\n         [0.0532, 0.0518, 0.0499, ..., 0.0145, 0.0156, 0.0192]],\n\n        [[   nan,    nan, 0.0833, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [0.1098,    nan,    nan, ...,    nan,    nan,    nan],\n         ...,\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan]]],\n\n\n       [[[0.0966, 0.0972, 0.0716, ..., 0.0665, 0.0536, 0.0714],\n         [0.0845, 0.0871, 0.0762, ..., 0.0773, 0.072 , 0.1106],\n         [0.083 , 0.083 , 0.0882, ..., 0.1206, 0.1004, 0.1616],\n...\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan]]],\n\n\n       [[[0.0732, 0.0776, 0.0601, ..., 0.0479, 0.0394, 0.0458],\n         [0.0676, 0.078 , 0.0606, ..., 0.0708, 0.0594, 0.0787],\n         [0.0746, 0.0784, 0.0802, ..., 0.1036, 0.0727, 0.145 ],\n         ...,\n         [0.0742, 0.0708, 0.0469, ..., 0.0196, 0.018 , 0.0236],\n         [0.0438, 0.0426, 0.0546, ..., 0.0188, 0.0182, 0.0208],\n         [0.0429, 0.0431, 0.0418, ..., 0.0179, 0.0188, 0.0206]],\n\n        [[   nan,    nan, 0.093 , ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [0.1146,    nan,    nan, ...,    nan,    nan,    nan],\n         ...,\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n         [   nan,    nan,    nan, ...,    nan,    nan,    nan]]]],\n      dtype=float32)Coordinates: (4)t(t)datetime64[ns]2022-06-01 2022-07-01standard_name :tlong_name :taxis :Tarray(['2022-06-01T00:00:00.000000000', '2022-07-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')x(x)float646.014e+05 6.014e+05 ... 6.049e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([601375., 601385., 601395., ..., 604865., 604875., 604885.])y(y)float645.67e+06 5.67e+06 ... 5.669e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5669795., 5669785., 5669775., 5669765., 5669755., 5669745., 5669735.,\n       5669725., 5669715., 5669705., 5669695., 5669685., 5669675., 5669665.,\n       5669655., 5669645., 5669635., 5669625., 5669615., 5669605., 5669595.,\n       5669585., 5669575., 5669565., 5669555., 5669545., 5669535., 5669525.,\n       5669515., 5669505., 5669495., 5669485., 5669475., 5669465., 5669455.,\n       5669445., 5669435., 5669425., 5669415., 5669405., 5669395., 5669385.,\n       5669375., 5669365., 5669355., 5669345., 5669335., 5669325., 5669315.,\n       5669305., 5669295., 5669285., 5669275., 5669265., 5669255., 5669245.,\n       5669235., 5669225., 5669215., 5669205., 5669195., 5669185., 5669175.,\n       5669165., 5669155., 5669145., 5669135., 5669125., 5669115., 5669105.,\n       5669095., 5669085., 5669075., 5669065., 5669055., 5669045., 5669035.,\n       5669025., 5669015., 5669005., 5668995., 5668985., 5668975., 5668965.,\n       5668955., 5668945., 5668935., 5668925., 5668915., 5668905., 5668895.,\n       5668885., 5668875., 5668865., 5668855., 5668845., 5668835., 5668825.,\n       5668815., 5668805., 5668795., 5668785., 5668775., 5668765., 5668755.,\n       5668745., 5668735., 5668725., 5668715., 5668705., 5668695., 5668685.,\n       5668675., 5668665., 5668655., 5668645., 5668635., 5668625., 5668615.])bands(bands)object'B04' 'B03' 'B02'array(['B04', 'B03', 'B02'], dtype=object)Indexes: (4)tPandasIndexPandasIndex(DatetimeIndex(['2022-06-01', '2022-07-01'], dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Float64Index([601375.0, 601385.0, 601395.0, 601405.0, 601415.0, 601425.0,\n              601435.0, 601445.0, 601455.0, 601465.0,\n              ...\n              604795.0, 604805.0, 604815.0, 604825.0, 604835.0, 604845.0,\n              604855.0, 604865.0, 604875.0, 604885.0],\n             dtype='float64', name='x', length=352))yPandasIndexPandasIndex(Float64Index([5669795.0, 5669785.0, 5669775.0, 5669765.0, 5669755.0, 5669745.0,\n              5669735.0, 5669725.0, 5669715.0, 5669705.0,\n              ...\n              5668705.0, 5668695.0, 5668685.0, 5668675.0, 5668665.0, 5668655.0,\n              5668645.0, 5668635.0, 5668625.0, 5668615.0],\n             dtype='float64', name='y', length=119))bandsPandasIndexPandasIndex(Index(['B04', 'B03', 'B02'], dtype='object', name='bands'))Attributes: (0)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/rank_composites.html#final-result-conclusion",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/rank_composites.html#final-result-conclusion",
    "title": "Rank composites",
    "section": "Final result & conclusion",
    "text": "Final result & conclusion\nWe finally plot composites generated for 2 months. While this notebook ends here, for most real world cases, this is the point where you can start your actual work, as you now have gap-free equitemporal composites. Note that in openEO, things happen on the fly, and this method is quite efficient, so there’s no need to actually store these intermediate composites somewhere before movin on, you can just take the composited data cube, and go from there!\n\nNote on performance\nThis approach was designed with efficiency in mind: we explicitly load a minimum amount of bands to construct the mask. As a result if observations are not used in the composite at all, they do not need to be loaded for the final result. The max-NDVI approach is however somewhat limited in this regard, because the plots of the mask show that often many chunks are needed for the final output.\nOne other remark is that it could be an option to construct the mask at lower resolution: this would further reduce data loading times, at the cost of a somewhat less accurate max-NDVI composite.\n\nxarray.plot.imshow(rgb_array.isel(t=0),vmin=0,vmax=0.18,rgb=\"bands\",col_wrap=2)\n\n&lt;matplotlib.image.AxesImage at 0x7f72af386890&gt;"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/OilSpill/OilSpillMapping.html",
    "href": "APIs/openEO/openeo-community-examples/python/OilSpill/OilSpillMapping.html",
    "title": "Oil spill mapping using Sentinel-1",
    "section": "",
    "text": "Several advanced techniques have been discussed and presented by researchers; however, in this notebook, we want to showcase a basic methodology for mapping oil spills using openEO.\nThough openEO is fully capable of executing advanced workflows, our focus here is to show a simple yet effective method. This notebook was inspired by the algorithm shown here.\nAdditionally, the following references were equally helpful when preparing this usecase:\n# Load the essentials\nimport openeo\nimport openeo.processes\nimport numpy as np\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\nFor this workflow, our area of interest is the southern coast of Kuwait near the resort community of Al Khiran, where an oil spill was reported in 2017.\nhttps://skytruth.org/2017/08/satellite-imagery-reveals-scope-of-last-weeks-massive-oil-spill-in-kuwait/\naoi = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [48.325487506118264, 28.742803969343313],\n            [48.325487506118264, 28.414218984218607],\n            [48.75387693420447, 28.414218984218607],\n            [48.75387693420447, 28.742803969343313],\n            [48.325487506118264, 28.742803969343313],\n        ]\n    ],\n}\ns1_image = connection.load_collection(\n    \"SENTINEL1_GRD\",\n    temporal_extent=[\"2017-08-09\", \"2017-08-12\"],\n    spatial_extent=aoi,\n    bands=[\"VV\"],\n)\n\ns1_image = s1_image.sar_backscatter(coefficient=\"sigma0-ellipsoid\")\nUsually the distribution of SAR backscatter values is too heavy tailed and difficult to analyse (visually and numerically). Therefore let’s normalize the backscatter values by Log with base 10. For further information See https://forum.step.esa.int/t/sigma0-vh-vs-sigma0-vhdb/2661?u=abraun\ns1_image = s1_image.apply(process=lambda data: 10 * openeo.processes.log(data, base=10))\nNow let us define the adaptive thresholding. It is a two-step process where we first identify the mean value within a window and then select anything below the mean of that threshold.\nfilter_window = np.ones([601, 601])\n# calculate factor\nfactor = 1 / np.prod(filter_window.shape)\nthresholds = s1_image.apply_kernel(kernel=filter_window, factor=factor)\nthreshold_shift = 3.5\nthresholds = thresholds - threshold_shift\nthresholds = thresholds.rename_labels(dimension=\"bands\", target=[\"threshold\"])\nIn the above cell, we selected the threshold based on the https://eo4society.esa.int/wp-content/uploads/2022/01/OCEA03_OilSpill_Kuwait.pdf and it can be changed to any value based on the requirements.\nNow we have a separate datacube with the threshold for the entire study area. Let us compare it with our Sentinel-1 datacube. But before that, to have similar properties, we are renaming the amplitude bands and applying the merge_cube process.\ns1_image = s1_image.rename_labels(dimension=\"bands\", target=[\"amplitude\"])\ns1_image = s1_image.merge_cubes(thresholds)\noil_spill = s1_image.band(\"amplitude\") &lt; s1_image.band(\"threshold\")\n# execute the workflow\noil_spill.execute_batch(title=\"Oil Spill Data\", outputfile=\"OilSpill.nc\")\n\n0:00:00 Job 'j-2402068af9e9445cba04c4dd08152f5b': send 'start'\n0:00:22 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:00:28 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:00:36 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:00:46 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:00:58 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:01:12 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:01:32 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:01:52 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:02:17 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:02:49 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:03:29 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:04:19 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:05:20 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:06:21 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:07:24 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:08:26 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:09:33 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:10:35 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:11:36 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:12:38 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:13:40 Job 'j-2402068af9e9445cba04c4dd08152f5b': running (progress N/A)\n0:14:43 Job 'j-2402068af9e9445cba04c4dd08152f5b': finished (progress N/A)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/OilSpill/OilSpillMapping.html#let-us-plot-the-result",
    "href": "APIs/openEO/openeo-community-examples/python/OilSpill/OilSpillMapping.html#let-us-plot-the-result",
    "title": "Oil spill mapping using Sentinel-1",
    "section": "Let us plot the result",
    "text": "Let us plot the result\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport xarray as xr\nimport matplotlib.patches as mpatches\nfrom rasterio.plot import show\n\n\noilspill = xr.load_dataset(\"OilSpill.nc\")\n\n\ndata = oilspill[[\"var\"]].to_array(dim=\"bands\")\n\n\ncmap = matplotlib.colors.ListedColormap([\"black\", \"#FFFFED\"])\nvalues = [\"Absence\", \"Presence\"]\ncolors = [\"black\", \"#FFFFED\"]\n\noilspill_array = data.squeeze().values[600:-600, 600:-600]\nfig, axes = plt.subplots(ncols=1, figsize=(5, 5), dpi=100)\naxes.imshow(oilspill_array, vmin=0, vmax=1, cmap=cmap)\naxes.set_title(\"Oil Spill Image\")\n\npatches = [\n    mpatches.Patch(color=colors[i], label=\"Oil {l}\".format(l=values[i]))\n    for i in range(len(values))\n]\nfig.legend(handles=patches, bbox_to_anchor=(0.9, 0.3), loc=1)\naxes.axes.get_xaxis().set_visible(False)\naxes.axes.get_yaxis().set_visible(False)\n\n\n\n\nIf we compare with the available manually mapped ground truth shown in the image below, we can conclude that our workflow effectively showed the oil spill in the selected area of interest.\n)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/BurntMapping/burntmapping_chunks.html",
    "href": "APIs/openEO/openeo-community-examples/python/BurntMapping/burntmapping_chunks.html",
    "title": "Burnt area mapping using chunk_polygon on UDF",
    "section": "",
    "text": "In this notebook classical Normalized Burnt Ratio(NBR) difference is performedon a chunk of polygons. You can find ways to develop your process and use chunk_polygon on a usecase. The method followed in this notebook to compute DNBR is inspired from UN SPIDER’s recommended preactices.\n(To be noted: chunk_polygon are experimental at the moment)\n\n# import necessary packages\nimport openeo\nfrom openeo.api.process import Parameter\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport rasterio\nimport numpy as np\n\n# connect with the backend\neoconn = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nUser can choose among different backend available here to connect to their choice of backend. Regarding the authentication process OpenID connect (oidc) is recommended, but not always straightforward to use. In cases where you are unable to connect with the backend use basic authentication method explained here.\n\n# function to load geojson file\ndef read_json(path: Path) -&gt; dict:\n    with open(path) as input:\n        field = json.load(input)\n        input.close()\n    return field\n\nTo use the data collection, a user must use the correct backend with the data collection. Then using load_collection, they can specify bands, temporal extent (i.e. interested time interval) and even spatial extent. In this example, we have loaded the entire collection so that process (including UDF) can later be applied to spatial chunks.\n\n# load datacube for beforeand after fire \nbefore_date = [\"2021-01-12\",\"2021-03-12\"]\nafter_date = [\"2021-05-18\", \"2021-07-18\"]\n\nbefore_cube = eoconn.load_collection(\n                            \"SENTINEL2_L1C_SENTINELHUB\",\n                            temporal_extent = before_date,\n                            bands = ['B08','B12']\n                            )\nafter_cube = eoconn.load_collection(\n                            \"SENTINEL2_L1C_SENTINELHUB\",\n                            temporal_extent = after_date,\n                            bands = ['B08','B12'],\n                            )\n\nHere we tried in presenting a method to create and use UDF as an openEO feature. In a similar manner user can create their own UDF as needed to apply to their data cube. More information on UDF. The reason to create UDF openEO, is similar to creating a function in general python i.e to avoid recursive script.\nOur UDF computes Normalised Burnt Ratio (NBR) from the selected band by performing simple band computation and returns a NBR datacube.\n\n# Create a UDF object from inline source code for computing nbr\nmy_code = \"\"\"\nfrom openeo.udf import XarrayDataCube\n\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    # access the underlying xarray\n    inarr = cube.get_array()\n\n    # nbr\n    nir = inarr.loc[:,'B08']\n    swir = inarr.loc[:,'B12']\n    nbr = (nir-swir)/(nir+swir)\n    \n    # extend bands dim\n    nbr=nbr.expand_dims(dim='bands', axis=-3).assign_coords(bands=['nbr'])\n    \n    # wrap back to datacube and return\n    return XarrayDataCube(nbr)\n\"\"\"\nudf_process = lambda data: data.run_udf(udf=my_code,runtime='python')\n\nWe used the chunk_polygon method to apply our UDF over a spatial chunk of the datacube. In the case of a simple process that does not require UDF, you can directly load your spatial extent in the dataset.\n\n#specify aoi chunks\nspatial_param = read_json(\"cal_aoi_v2.geojson\") \n\n# compute nbr for pre and post datacube\npre_nbr = before_cube.chunk_polygon(chunks=spatial_param,process=udf_process)\npost_nbr = after_cube.chunk_polygon(chunks=spatial_param,process=udf_process)\n\nFurthermore, since we loaded our collection for specific time intervals, it can include multiple time dimensions. Thus reduce_dimension applies a reducer to a data cube dimension by collapsing all the pixel values along the time dimension into an output value computed by the reducer.\n\n# perform time dimension reduction\npre_n = pre_nbr.reduce_dimension(dimension=\"t\", reducer=\"mean\")\npost_n = post_nbr.reduce_dimension(dimension=\"t\", reducer=\"mean\")\n\n# find the difference between pre and post image\nsub = post_n-pre_n\n\nOnce the process is completed, you can also save it as your process using save_user_defined_process that can later be used for a similar task. Otherwise, you can download the result either by direct download (in case of the small spatial extent with few processing) or perform create a batch job in case it is a heavy task over a large extent.\n\n#download your output\nsub.download(\"sub_nbr_udf.tiff\")\n\n\n#set colors for plotting and classes based on UN SPIDER recommended practices\nimport matplotlib\nimg = rasterio.open(\"sub_nbr_udf.tiff\").read()\ncmap = matplotlib.colors.ListedColormap(['green','yellow','orange','red','purple'])\nbounds = [-0.5, 0.1, 0.27, 0.440, 0.660, 1.3] \nnorm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\ncmap.set_over('purple')\ncmap.set_under('white')\nfig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'xticks': [], 'yticks': []})\ncax = ax.imshow(img[0], cmap=cmap,norm=norm)\nplt.title('Burn Severity Map')\ncbar = fig.colorbar(cax, ax=ax, fraction=0.035, pad=0.04, ticks=bounds)\ncbar.ax.set_yticklabels(['Unburned', 'Low Severity', 'Moderate-low Severity', 'Moderate-high Severity', 'High Severity'])\nplt.show()\n\n\n\n\nThe bound set for the legend are based on the description provided in the UN SPIDER guideline."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/WorldCereal/WorldCereal.html",
    "href": "APIs/openEO/openeo-community-examples/python/WorldCereal/WorldCereal.html",
    "title": "WorldCereal product download",
    "section": "",
    "text": "This example illustrates the use of openEO for combining and downloading data from the ESA WorldCereal project.\nThis project provides a global map of cereals for 2021 at 10m resolution! It can be used as an important base layer for agriculture use cases. Combined with the power of openEO, you can easily generate agricultural statistics over an area of interest, or use this data as a masking layer in an advanced workflow.\nIn this example, we’ll illustrate a fairly simple case of combining two collections into a single image file.\n\nimport openeo\n\nc = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nWe list the available collection id’s to make sure we have the right name.\n\n[col[\"id\"] for col in c.list_collections() if \"WORLDCEREAL\" in col[\"id\"]]\n\n['ESA_WORLDCEREAL_ACTIVECROPLAND',\n 'ESA_WORLDCEREAL_IRRIGATION',\n 'ESA_WORLDCEREAL_TEMPORARYCROPS',\n 'ESA_WORLDCEREAL_WINTERCEREALS',\n 'ESA_WORLDCEREAL_MAIZE',\n 'ESA_WORLDCEREAL_SPRINGCEREALS']\n\n\n\nc.describe_collection(\"ESA_WORLDCEREAL_MAIZE\")\n\n\n    \n    \n        \n    \n    \n\n\nIn the following block, we combine two WorldCereal collections into a single output. Both the maize and the wintercereal collection will have value 100 for their respective crops. This means that once the two datacubes are merged, it’s impossible to distinguish between the two. Therefore, a linear transformation is applied to the winter datacube. Furthermore, since both collections are mapped to a different point in time, the time dimension is reduced, such that the resulting map only contains one timestep with both crops shown. The formula used here is just an example, and can be made much more complex depending on your use case.\n\nextent = {'west': 3.0, 'south': 50.0, 'east': 4.0, 'north': 51.0, 'crs': 'EPSG:4326'}\n\ntemporal = ('2020-09-01T00:00:00Z', '2021-12-31T00:00:00Z')\n\nmaize = c.load_collection(\"ESA_WORLDCEREAL_MAIZE\",\n                         temporal_extent= temporal,\n                         spatial_extent=extent,\n                         bands=[\"CLASSIFICATION\"]).reduce_dimension(dimension=\"t\",reducer=\"mean\")\n\nwinter = c.load_collection(\"ESA_WORLDCEREAL_WINTERCEREALS\",\n                         temporal_extent= temporal,\n                         spatial_extent=extent,\n                         bands=[\"CLASSIFICATION\"]).apply(lambda x:100*(x+10)).reduce_dimension(dimension=\"t\",reducer=\"mean\")\n\ncombined = maize.merge_cubes(winter, overlap_resolver=\"sum\")\n\nWe now have defined what openEO calls a ‘process graph’, but still need to execute it. We will use an ‘asynchronous’ batch job that gets sent to the server, as it can take a longer time to execute.\nWhen finished, this command will automatically download the result from openEO to your local working directory. You can also follow the progress and view results in the openEO web editor.\n\njob = combined.execute_batch(\n    title = \"Worldcereal example Terrascope\",\n    out_format=\"GTiff\",\n)\n\n0:00:00 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': send 'start'\n0:00:22 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:00:28 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:00:35 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:00:43 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:01:18 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:01:31 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:01:47 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:02:06 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:02:30 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:03:00 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': queued (progress N/A)\n0:03:54 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': running (progress N/A)\n0:04:42 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': running (progress N/A)\n0:05:40 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': running (progress N/A)\n0:06:41 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': running (progress N/A)\n0:07:41 Job 'vito-j-0e6bd54acb9d4de2b6b6e03a5bb120dd': finished (progress N/A)\n\n\n\njob.get_results().download_files()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RescaleChunks/rescale_chunks.html",
    "href": "APIs/openEO/openeo-community-examples/python/RescaleChunks/rescale_chunks.html",
    "title": "Rescale RGB image for spatial chunks",
    "section": "",
    "text": "This notebook shows a simple process for rescaling Sentinel 2 RGB images within polygon chunks that also showcases how to use chunk_polygon() with a (User Defined Function) UDF. (To be noted: chunk_polygon are experimental at the moment)\n\n# import necessary packages\nimport openeo\nfrom openeo.api.process import Parameter\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport rasterio\n\n# connect with the backend\neoconn = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nUser can choose among different backend available here to connect to the backend of their choice. Regarding the authentication process OpenID connect (oidc) is recommended, but not always straightforward to use. In cases where you are unable to connect with the backend use basic authentication method explained here.\n\n# function to load geojson file\ndef read_json(path: Path) -&gt; dict:\n    with open(path) as input:\n        field = json.load(input)\n        input.close()\n    return field\n\nTo use the data collection, a user must use the correct backend with the data collection. Then using load_collection, they can specify bands, temporal extent (i.e. interested time interval) and even spatial extent. In this example, we have loaded the entire collection so that process (including UDF) can later be applied to spatial chunks.\n\n# Load your data cube based on your prefernce\n\nS2_cube = eoconn.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent = [\"2022-06-04\", \"2022-08-04\"],\n    bands = [\"B02\", \"B03\", \"B04\"]\n)\n\nHere we tried in presenting a method to create and use UDF as an openEO feature. In a similar manner user can create their own UDF as needed to apply to their data cube. More information on UDF.\n\n# Create a UDF object from inline source code.\nmy_udf = openeo.UDF(\"\"\"\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    array.values = 0.0001 * array.values\n    return cube\n\"\"\")\n\nWe used the chunk_polygon method to apply our UDF over a spatial chunk of the datacube. In the case of a simple process that does not require UDF, you can directly load your spatial extent in the dataset.\nFurthermore, since we loaded our collection for specific time intervals, it can include multiple time dimensions. Thus reduce_dimension applies a reducer to a data cube dimension by collapsing all the pixel values along the time dimension into an output value computed by the reducer.\n\n# apply rescale to chunks of polygon\naoi = read_json(\"cologne_aoi.geojson\")\nrescaled_chunks = S2_cube.chunk_polygon(chunks=aoi,process=my_udf)\n\n# perform time dimension reduction\nRrescaled_chunks = rescaled_chunks.reduce_dimension(dimension=\"t\", reducer=\"mean\")\n\nOnce the process is completed, you can also save it as your process using save_user_defined_process that can later be used for a similar task. Otherwise, you can download the result either by direct download (in case of the small spatial extent with few processing) or perform create a batch job in case it is a heavy task over a large extent.\n\n## download your result either using synchronous method or batch\n# synchronous download\n# rescaled_chunks.download(\"rescaled_test_v1.tiff\")\n# \n# Or perform batch processing if area is comparatively large\nbatch_job = Rrescaled_chunks.create_job(out_format = \"GTiff\", title=\"rescaled_chunks2\")\nbatch_job.start_and_wait()\nresults = batch_job.get_results()\nresults.download_files()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/FloodSAR/flood_sar_udf.html",
    "href": "APIs/openEO/openeo-community-examples/python/FloodSAR/flood_sar_udf.html",
    "title": "Flood extent using Sentinel 1",
    "section": "",
    "text": "Flood extent can be determined using a change detection approach on Sentinel-1 data. In this process, we have tried adopting UN SPIDER’s recommended practice for computing flood extents by implementing an openEO UDF.\n\n# import necessary packages\nimport openeo\nfrom openeo.api.process import Parameter\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport rasterio\nimport numpy as np\n\n# connect with the backend\neoconn = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nUser can choose among different backend available here to connect to the backend. Rrgarding the authentication process OpenID connect (oidc) is recommended, but not always straightforward to use. In cases where you are unable to connect with the backend use basic authentication method explained here.\n\n# function to load geojson file\ndef read_json(path: Path) -&gt; dict:\n    with open(path) as input:\n        field = json.load(input)\n        input.close()\n    return field\n\nTo use the data collection, a user must use the correct backend with the data collection. Then using load_collection, they can specify bands, temporal extent (i.e. interested time interval) and even spatial extent.\n\n# load before flash flood params\nbefore_date = [\"2021-05-12\",\"2021-05-12\"]\nafter_date = [\"2021-06-18\", \"2021-06-18\"]\nspatial_param = read_json(\"aoi/cologne_all.geojson\")\n\n\n# using S1 data from Sentinelhub (https://hub.openeo.org/) directly instead of downloading\n\nbefore_cube = eoconn.load_collection(\n                            \"SENTINEL1_GAMMA0_SENTINELHUB\",\n                            temporal_extent = before_date,\n                            spatial_extent = spatial_param,\n                            bands = ['VV'],\n                            properties={\"sat:orbit_state\": lambda v: v==\"ascending\"}\n                            )\nafter_cube = eoconn.load_collection(\n                            \"SENTINEL1_GAMMA0_SENTINELHUB\",\n                            temporal_extent = after_date,\n                            spatial_extent = spatial_param,\n                            bands = ['VV'],\n                            properties={\"sat:orbit_state\": lambda v: v==\"ascending\"}\n                            )\n\nSince now we have details on temporal dimension we can perform dimension reduction. As we loaded our collection for specific time intervals, it can include multiple time dimensions. Thus reduce_dimension applies a reducer to a data cube dimension by collapsing all the pixel values along the time dimension into an output value computed by the reducer.\n\n#'reduce_dimension' to reduce temporal dimension\nrbefore_cube = before_cube.reduce_dimension(dimension=\"t\", reducer=\"mean\")\nrafter_cube = after_cube.reduce_dimension(dimension=\"t\", reducer=\"mean\")\n\n\n# calculating the ratio of post and pre datacube as mentioned in the UNSPIDER documentation for flood extent using Sentinel 1\ndifference = rafter_cube.divide(rbefore_cube)\n\nHere we tried in presenting a method to create and use UDF as an openEO feature. In a similar manner user can create their own UDF as needed to apply to their data cube. More information on UDF.\nOur UDF is designed to perform thresholding to the final result obtained by comparing pre and post datacubes and returns a cube that assigns 1 to region with higher value than threshold otherwise 0.\n\n# define a udf that will perform thresholding of the dataset\nudf = openeo.UDF(\"\"\"\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    \n    # UN defined difference threshold\n    array.values = np.where(array &gt; 1.5, 1, 0)\n    return cube\n\"\"\")\n\n# Apply the UDF to a cube.\nthreshold_cube = difference.apply(process=udf)\n\nOnce the process is completed, you can also save it as your process using save_user_defined_process that can later be used for a similar task. Otherwise, you can download the result either by direct download (in case of the small spatial extent with few processing) or perform create a batch job in case it is a heavy task over a large extent.\n\n# download your result either syncronous or proceed as batch job\nthreshold_cube.download(\"s1_diff.tiff\")"
  },
  {
    "objectID": "APIs/openEO/openeo_deployment.html",
    "href": "APIs/openEO/openeo_deployment.html",
    "title": "openEO public service deployment",
    "section": "",
    "text": "The openEO deployment of the Copernicus Data Space Ecosystem public service has the aim to protect against lock-in in various ways: - The software is 100% open source, preventing dependency on a vendor. - openEO is an open standard with a web service API. Allowing to switch to other APIs that implement openEO immediately. - openEO workflows use standardized processes. Avoiding your workflows being strongly coupled to a specific technology.\n\n\n\n\nThe service runs on Cloudferro and T-Systems infrastructure, close to the storage systems that store the Sentinel archives. It also reads from these archives directly and processes the data on the fly. For complex products like Sentinel-1, we have the sar_backscatter process that performs on-the-fly orthorectification.\nFor products like Sentinel-2, with lots of overlap, we have custom code in place to resolve this as efficiently and correctly as possible.\nWe tune the settings of data access libraries like GDAL to the specific needs of the clouds that we work with. This is a tedious process and subject to change. When you observe suboptimal data access performance, it may be good to enquire about this.\n\n\nSome datasets are accessed via the Sentinelhub API instead of the raw files. This is done to provide a cost-effective deployment, and be able to offer a wide choice of datasets, which would otherwise be impossible.\n\n\n\n\nProcessing happens on a Kubernetes cluster with auto-scaling capabilities. In that cluster, your jobs run as Apache Spark applications. This is a very widely used and mature big data processing framework. It is comparable to Dask, which mainly focuses on being a pure Python implementation.\nWe currently do not have benchmarks that rigorously compare the performance of openEO with other processing frameworks, but we can make some relevant observations:\n\nThere’s no technical evidence that, by design, other processing approaches are somehow better or faster.\nWe have validated the backend by running large-scale processing tasks and achieved results that matched and sometimes even exceeded the expectations with respect to processing budgets.\nUsing a service such as openEO implies significant cost savings in terms of personnel costs compared to an approach based on infrastructure as a service (IAAS).\nThe main cost driver and performance bottleneck of many EO workflows is the data access performance, which is relatively independent of the software, assuming that tuning parameters are properly set.\n\nThe openEO backend will try to determine performance-sensitive parameters of your processing job automatically. This includes settings for memory, cores and data partitioning/chunking. It is, however, possible that the automatic tuning needs some fixing for your use case. A typical situation is that workflows require more memory, but sometimes, more advanced tuning, such as partitioning, needs to be applied.\n\n\n\nJust like any other backend, you can run your batch jobs using open-source software and the public docker image.\nAt openEO.org, you can find a list of open-source implementations. There’s also some guidance for getting started as a service provider.\nTo run your small-scale testing locally, we can recommend the Pangeo based ‘local processing’ feature.\n\n\n\nThe openEO Hub maintains a list of other openEO services:\nhttps://hub.openeo.org"
  },
  {
    "objectID": "APIs/openEO/openeo_deployment.html#deployment",
    "href": "APIs/openEO/openeo_deployment.html#deployment",
    "title": "openEO public service deployment",
    "section": "",
    "text": "The service runs on Cloudferro and T-Systems infrastructure, close to the storage systems that store the Sentinel archives. It also reads from these archives directly and processes the data on the fly. For complex products like Sentinel-1, we have the sar_backscatter process that performs on-the-fly orthorectification.\nFor products like Sentinel-2, with lots of overlap, we have custom code in place to resolve this as efficiently and correctly as possible.\nWe tune the settings of data access libraries like GDAL to the specific needs of the clouds that we work with. This is a tedious process and subject to change. When you observe suboptimal data access performance, it may be good to enquire about this.\n\n\nSome datasets are accessed via the Sentinelhub API instead of the raw files. This is done to provide a cost-effective deployment, and be able to offer a wide choice of datasets, which would otherwise be impossible.\n\n\n\n\nProcessing happens on a Kubernetes cluster with auto-scaling capabilities. In that cluster, your jobs run as Apache Spark applications. This is a very widely used and mature big data processing framework. It is comparable to Dask, which mainly focuses on being a pure Python implementation.\nWe currently do not have benchmarks that rigorously compare the performance of openEO with other processing frameworks, but we can make some relevant observations:\n\nThere’s no technical evidence that, by design, other processing approaches are somehow better or faster.\nWe have validated the backend by running large-scale processing tasks and achieved results that matched and sometimes even exceeded the expectations with respect to processing budgets.\nUsing a service such as openEO implies significant cost savings in terms of personnel costs compared to an approach based on infrastructure as a service (IAAS).\nThe main cost driver and performance bottleneck of many EO workflows is the data access performance, which is relatively independent of the software, assuming that tuning parameters are properly set.\n\nThe openEO backend will try to determine performance-sensitive parameters of your processing job automatically. This includes settings for memory, cores and data partitioning/chunking. It is, however, possible that the automatic tuning needs some fixing for your use case. A typical situation is that workflows require more memory, but sometimes, more advanced tuning, such as partitioning, needs to be applied.\n\n\n\nJust like any other backend, you can run your batch jobs using open-source software and the public docker image.\nAt openEO.org, you can find a list of open-source implementations. There’s also some guidance for getting started as a service provider.\nTo run your small-scale testing locally, we can recommend the Pangeo based ‘local processing’ feature.\n\n\n\nThe openEO Hub maintains a list of other openEO services:\nhttps://hub.openeo.org"
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html",
    "title": "Getting started with JavaScript client",
    "section": "",
    "text": "This Getting Started guide will give you just a simple overview of the capabilities of the openEO JavaScript client library."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#installation",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#installation",
    "title": "Getting started with JavaScript client",
    "section": "Installation",
    "text": "Installation\nThe openEO JavaScript Client can be used in all modern browsers (excludes Internet Explorer) and all maintained Node.js versions (&gt;= 10.x). It can also been used for mobile app development with the Ionic Framework, for example.\nThe easiest way to try out the client is using one of the examples. Alternatively, you can create an HTML file and include the client with the following HTML script tags:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/axios@0.21/dist/axios.min.js\"&gt;&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/@openeo/js-client@2/openeo.min.js\"&gt;&lt;/script&gt;\nThis gives you a minified version for production environments. If you’d like a better development experience, use the following code:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/axios@0.21/dist/axios.js\"&gt;&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/@openeo/js-client@2/openeo.js\"&gt;&lt;/script&gt;\nIf you are working on a Node.js application or you are using a Node.js-based build tool for web development (e.g. Webpack), you can install the client via npm by using the following command:\n\nnpm install @openeo/js-client\nAfterwards you can load the library. Depending on whether you are directly working in Node.js or are just using a Node.js build tool, the import can be different. Please inform yourself which import is suited for your project.\nThis is usually used directly in Node.js:\nconst { OpenEO } = require('@openeo/js-client');\nThis may be used in build tools such as Webpack:\nimport { OpenEO } from '@openeo/js-client';\nNow that the installation was successfully finished, we can now connect to openEO compliant back-ends. In the following chapters we quickly walk through the main features of the JavaScript client.\nIf you have trouble installing the client, feel free to create a ticket or leave an issue at the GitHub project."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#exploring-a-back-end",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#exploring-a-back-end",
    "title": "Getting started with JavaScript client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO instance of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu.\nFirst we need to establish a connection to the back-end.\nvar con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n\n\n\n\n\n\nNote\n\n\n\nThe JavaScript client uses Promises (async/await). So there are two ways to express the code above:\nPromises:\nOpenEO.connect(\"https://openeo.dataspace.copernicus.eu\").then(function(con) {\n  // Success\n}).catch(function(error) {\n  // Error\n});\nasync/await:\ntry {\n  var con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n  // Success\n} catch (error) {\n  // Error\n}\n\n\nTo simplify the code here, we use async/await in all examples and don’t catch errors. So we assume you run the code in an async function and also in a try/catch block.\nAfter establishing the connection to the back-end, it can be explored using the Connection object returned. The basic service’s metadata (capabilities) can be accessed via\nvar info = con.capabilities();\nThis allows to request a couple of different information, like API version, description, related links or the billing plans. You can print some of these information to the console as follows:\nconsole.log(\"API Version: \", info.apiVersion());\nconsole.log(\"Description: \", info.description());\n\nconsole.log(\"Billing plans:\");\ninfo.listPlans().forEach(plan =&gt; {\n  console.log(`${plan.name}: ${plan.url}`);\n});\n\nconsole.log(\"Related links:\");\ninfo.links().forEach(link =&gt; {\n  console.log(`${link.title}: ${link.href}`);\n});\n\nCollections\nCollections represent the basic data the back-end provides (e.g. Sentinel 2 collection). Collections are used as input data for job executions (more info on collections). With the following code snippet you can print all 400+ available collection names and their summary.\nconsole.log(\"Available Collections:\");\nvar response = await con.listCollections();\nresponse.collections.forEach(collection =&gt; {\n  console.log(`${collection.id}: ${collection.summary}`);\n});\nTo get detailed information about a single collection, you can pass any of the collection IDs requested earlier to describeCollection and get a full object of STAC compliant Collection metadata back. In this example we request information about the Sentinel-2 Level 1C data from Google:\nconsole.log(await con.describeCollection(\"COPERNICUS/S2\"));\nTo get the full set of metadata you should always use describeCollection.\n\n\nProcesses\nProcesses in openEO are small tasks that can be applied on (EO) data. The input of a process might be the output of another process, so that several connected processes form a new (user-defined) process itself. Therefore, a process resembles the smallest unit of task descriptions in openEO (more details on processes). With the following code snippet you can print all available process IDs and their summaries.\nconsole.log(\"Available Collections:\");\nvar response = await con.listProcesses();\nresponse.processes.forEach(process =&gt; {\n  console.log(`${process.id}: ${process.summary}`);\n});\nIn contrast to the collections, the process descriptions returned by listProcesses are complete. There’s no need to call describeProcess to get the full set of metadata. describeProcess is just a convenience function to get a single process from listProcesses. In this example we request the process specification for the apply process:\nconsole.log(await con.describeProcess(\"apply\"));\nFor a graphical overview of the openEO processes, there is an online documentation for general process descriptions and the openEO Hub for back-end specific process descriptions."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#authentication",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#authentication",
    "title": "Getting started with JavaScript client",
    "section": "Authentication",
    "text": "Authentication\nIn the code snippets above we did not need to log in since we just queried publicly available back-end information. However, to run non-trivial processing queries one has to authenticate so that permissions, resource usage, etc. can be managed properly.\nTo authenticate your account on the backend of the Copernicus Data Space Ecosystem, it is necessary for you to complete the registration process. Once registered, the OIDC (OpenID Connect)authentication method will be employed to verify your identity using an external service.\n\n\n\n\n\n\nWarning\n\n\n\nIf you have included the library using HTML script tags, then you need to include the following OIDC client before the openEO client:\n&lt;script src=\"https://cdn.jsdelivr.net/npm/oidc-client@1/lib/oidc-client.min.js\"&gt;&lt;/script&gt;\nNo further action is required, if you have installed the client via npm.\n\n\nAs OpenID Connect authentication is a bit more complex and depends on the environment your are using it in, please refer to the JavaScript client documentation for more information.\nCalling this method opens your system web browser, with which you can authenticate yourself on the back-end authentication system. After that the website will give you the instructions to go back to the JavaScript client, where your connection has logged your account in. This means that every call that comes after that via the con variable is executed by your user account."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#creating-a-user-defined-process",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#creating-a-user-defined-process",
    "title": "Getting started with JavaScript client",
    "section": "Creating a (user-defined) process",
    "text": "Creating a (user-defined) process\nNow that we know how to discover the back-end and how to authenticate, lets continue by creating a new batch job to process some data. First we need to create a user-defined process and for that a process builder is the easiest method.\n\nvar builder = await con.buildProcess();\nWith the builder, a datacube can be initialized by selecting a collection from the back-end with the process load_collection:\nvar datacube = builder.load_collection(\n        \"SENTINEL2_L2A\",\n        {west: 3.20, south: 51.19, east: 3.26, north: 51.21},\n        [\"2022-05-01\", \"2022-05-30\"],\n        [\"B04\", \"B03\", \"B02\"]\n);\nThis results in a datacube containing the “SENTINEL2_L2A” data restricted to the given spatial extent, the given temporal extend and the given bands .\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou can also filter the datacube at a later stage by using the following filter methods:\ndatacube = builder.filter_bbox(datacube, {west: 3.20, south: 51.19, east: 3.26, north: 51.21});\ndatacube = builder.filter_temporal(datacube, [\"2022-05-01\", \"2022-05-30\"]);\ndatacube = builder.filter_bands(datacube, [\"B04\", \"B03\", \"B02\"]);\nStill, it is recommended to always use the filters in load_collection to avoid loading too much data upfront.\n\n\n\nHaving the input data ready, we want to apply a process on the datacube, which returns a datacube with the process applied:\n\nvar min = function(data) { return this.min(data); };\ndatacube = builder.reduce_dimension(datacube, min, \"t\");\nThe datacube is now reduced by the time dimension named t, by taking the minimum value of the timeseries values. Now the datacube has no time dimension left.\nOther so called “reducer” processes exist, e.g. for computing maximum and mean values.\n\n\n\n\n\n\nNote\n\n\n\nEverything applied to the datacube at this point is neither executed locally on your machine nor executed on the back-end. It just defines the input data and process chain the back-end needs to apply when it sends the datacube to the back-end and executes it there. How this can be done is the topic of the next chapter.\n\n\nAfter applying all processes you want to execute, we need to tell the back-end to export the datacube, for example as GeoTiff:\n\nvar result = builder.save_result(datacube, \"GTiff\");"
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#batch-job-management",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#batch-job-management",
    "title": "Getting started with JavaScript client",
    "section": "Batch Job Management",
    "text": "Batch Job Management\nAfter you finished working on your (user-defined) process, we can now send it to the back-end and start the execution. In openEO, an execution of a (user-defined) process (here defined using the process builder) is called a (batch) job. Therefore, we need to create a job at the back-end using our datacube, giving it the title Example Title.\n\nvar job = await con.createJob(result, \"Example Title\");\nThe createJob method sends all necessary information to the back-end and creates a new job, which gets returned. After this, the job is just created, but has not started the execution at the back-end yet. It needs to be queued for processing explicitly:\n\nawait job.startJob();\nNow the execution of the job can be monitored by requesting the job status and the log files every once in a while (30 seconds in this example):\n\nlet stopFn = job.monitorJob((job, logs) =&gt; {\n  console.log(job.status);\n  logs.forEach(log =&gt; console.log(`${log.level}: ${log.message}`));\n}, 30);\nThe monitoring stops automatically once the job has finished, was canceled or errored out. But with the return value of the monitorJob function, you can also stop monitoring the job manually:\n\nstopFn();\nWhen the job is finished, calling listResults gets you the URLs to the results.\n\nvar urls = await job.listResults();\n\n\n\n\n\n\nTip\n\n\n\n\n\nThis only works if the job execution has finished. We recommend to use listResults in combination with monitorJob, for example as follows:\n\nlet stopFn = job.monitorJob(async (job, logs) =&gt; {\n  if (job.status === \"finished\") {\n    var urls = await job.listResults();\n    urls.forEach(url =&gt; console.log(`Download result from: ${url.href}`));\n  }\n});\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere’s also the method downloadResults to download the results directly. Unfortunately, you can only download files from a Node.js environment where file access to your local drive is possible. In a Browser environment, it is also an option to download the STAC Item or Collection for the results using the getResultsAsStac method and point a STAC client to it for downloading.\n\n\nNow you know the general workflow of job executions."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#full-example",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#full-example",
    "title": "Getting started with JavaScript client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the JavaScript client in a Node.js environment. Instead of batch job processing, we compute the image synchronously. Synchronous processing means the result is directly returned in the response, which usually works only for smaller amounts of data.\nHere, we want to produce a monthly RGB composite of Sentinel 1 backscatter data over the area of Vienna, Austria for three months in 2017. This can be used for classification and crop monitoring.\nIn the following code example, we use inline code comments to describe what we are doing.\n// Make the client available to the Node.js script\n// Also include the Formula library for simple math expressions\nconst { OpenEO, Formula } = require('@openeo/js-client');\n\nasync function example() {\n  // Connect to the back-end\n  var con = await OpenEO.connect(\"https://openeo.dataspace.copernicus.eu\");\n  // Authenticate \n  await con.authenticateOIDC();\n  // Create a process builder\n  var builder = await con.buildProcess();\n  // We are now loading the Sentinel-1 data over the Area of Interest\n  var datacube = builder.load_collection(\n    \"SENTINEL1_GRD\",\n    {west: 16.06, south: 48.06, east: 16.65, north: 48.35},\n    [\"2017-03-01\", \"2017-06-01\"],\n    [\"VV\"]\n  );\n\n  // Since we are creating a monthly RGB composite, we need three separated time ranges (March aas R, April as G and May as G).\n  // Therefore, we split the datacube into three datacubes using a temporal filter.\n  var march = builder.filter_temporal(datacube, [\"2017-03-01\", \"2017-04-01\"]);\n  var april = builder.filter_temporal(datacube, [\"2017-04-01\", \"2017-05-01\"]);\n  var may = builder.filter_temporal(datacube, [\"2017-05-01\", \"2017-06-01\"]);\n\n  // We aggregate the timeseries values into a single image by reducing the time dimension using a mean reducer.\n  var mean = function(data) {\n    return this.mean(data);\n  };\n  march = builder.reduce_dimension(march, mean, \"t\");\n  april = builder.reduce_dimension(april, mean, \"t\");\n  may = builder.reduce_dimension(may, mean, \"t\");\n\n  // Now the three images will be combined into the temporal composite.\n  // We rename the bands to R, G and B as otherwise the bands are overlapping and the merge process would fail.\n  march = builder.rename_labels(march, \"bands\", [\"R\"], [\"VV\"]);\n  april = builder.rename_labels(april, \"bands\", [\"G\"], [\"VV\"]);\n  may = builder.rename_labels(may, \"bands\", [\"B\"], [\"VV\"]);\n\n  datacube = builder.merge_cubes(march, april);\n  datacube = builder.merge_cubes(datacube, may);\n\n  // To make the values match the RGB values from 0 to 255 in a PNG file, we need to scale them.\n  // We can simplify expressing math formulas using the openEO Formula parser.\n  datacube = builder.apply(datacube, new Formula(\"linear_scale_range(x, -20, -5, 0, 255)\"));\n\n  // Finally, save the result as PNG file.\n  // In the options we specify which band should be used for \"red\", \"green\" and \"blue\" color.\n  datacube = builder.save_result(datacube, \"PNG\", {\n    red: \"R\",\n    green: \"G\",\n    blue: \"B\"\n  });\n\n  // Now send the processing instructions to the back-end for (synchronous) execution and save the file as result.png\n  await con.downloadResult(datacube, \"../_images/result.png\");\n}\n\n// Run the example, write errors to the console.\nexample().catch(error =&gt; console.error(error));\nNow the resulting PNG file of the RGB backscatter composite is stored as result.png in the node.JS working directory and should look as follows:"
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#user-defined-functions",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#user-defined-functions",
    "title": "Getting started with JavaScript client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function. Unfortunately, you can only create Python and R functions at the moment. Therefore, this guide doesn’t get into detail. For more information check out the Python or R tutorials on UDFs."
  },
  {
    "objectID": "APIs/openEO/JavaScript_Client/JavaScript.html#useful-links",
    "href": "APIs/openEO/JavaScript_Client/JavaScript.html#useful-links",
    "title": "Getting started with JavaScript client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO JavaScript Client Library:\n\nExamples\nDocumentation\nRepository"
  },
  {
    "objectID": "APIs/openEO/File_formats.html",
    "href": "APIs/openEO/File_formats.html",
    "title": "File Formats",
    "section": "",
    "text": "File formats and their options are often very different between processing software. To improve interoperability, the openEO API supports the following file formats currently for saving your results."
  },
  {
    "objectID": "APIs/TCP.html",
    "href": "APIs/TCP.html",
    "title": "TCP Stack Configuration",
    "section": "",
    "text": "In order to improve the download performance of EO products from the Copernicus Data Space Ecosystem platform, below is the recommended configuration of TCP stack for a machine with Linux operating system:\nsysctl -w net.core.rmem_max=\"2147483647\"\nsysctl -w net.core.wmem_max=\"2147483647\"\nsysctl -w net.ipv4.tcp_rmem=\"8192 262144 536870912\"\nsysctl -w net.ipv4.tcp_wmem=\"4096 65536 536870912\"\nsysctl -w net.core.default_qdisc=fq\nsysctl -w net.ipv4.tcp_congestion_control=bbr\nsysctl -w net.core.netdev_max_backlog=300000\nsysctl -w net.core.somaxconn=65535"
  },
  {
    "objectID": "APIs/SentinelHub/AsyncProcess.html",
    "href": "APIs/SentinelHub/AsyncProcess.html",
    "title": "Asynchronous Processing API",
    "section": "",
    "text": "Asynchronous Processing API is currently in beta release.\nAsynchronous Processing API (or shortly \"Async API\") allows you to process more data with a single request than Processing API. This is possible because the processing results are not returned immediately but are - after some time - delivered in your object storage. We recommend using Async API when you want to process bigger images, when you do not want to deal with tiled results and when it is not crucial for you to get the processing results immediately."
  },
  {
    "objectID": "APIs/SentinelHub/AsyncProcess.html#general-approach",
    "href": "APIs/SentinelHub/AsyncProcess.html#general-approach",
    "title": "Asynchronous Processing API",
    "section": "General approach",
    "text": "General approach\nThe Async API allows you to process the data in a similar way as Processing API; you define input data, area of interest and time range in the body of an Async API request and Sentinel Hub will process the data as defined in your evalscript. When using Async API keep in mind that:\n\nThe maximum output image size can not exceed 10000 pixels in any dimension.\nEvalscript can be either sent directly in the request or it can be stored in object storage and referenced in an async request ( see parameter evalscriptReference in Async API reference for more details). This allows you to use bigger evalscripts.\nThe processing is asynchronous, which means that you do not get results in a response of your request. Instead they are delivered in your object storage.\nA copy of your Async API request is also stored in your object storage. After the request is processed, the copy is updated and additional information about the cost of the request is added.\nOnly a limited number of async requests can run concurrently for each Sentinel Hub user. The exact limit depends on the account type.\nThe processing time depends on request size and on the current and past load of the service. Generally, the first request is the slowest while the subsequent requests run faster.\nThe cost is the same as with Process API, except that the minimal cost is 10 PU per request."
  },
  {
    "objectID": "APIs/SentinelHub/AsyncProcess.html#bucket-access",
    "href": "APIs/SentinelHub/AsyncProcess.html#bucket-access",
    "title": "Asynchronous Processing API",
    "section": "Bucket access",
    "text": "Bucket access\nThe Async API uses buckets to:\n\nread evalscript from a bucket (this is optional because an evalscript can also be provided directly in a request),\nwrite results of processing to a bucket.\n\nOne bucket or different buckets can be used for these purposes."
  },
  {
    "objectID": "APIs/SentinelHub/AsyncProcess.html#bucket-settings",
    "href": "APIs/SentinelHub/AsyncProcess.html#bucket-settings",
    "title": "Asynchronous Processing API",
    "section": "Bucket settings",
    "text": "Bucket settings\nIf you do not yet have a bucket at Copernicus Data Space Ecosystem, please follow these steps to get one.\nYou will have to configure your bucket to allow read access to Sentinel Hub. To do this, update your bucket policy to include the following statement (don’t forget to replace &lt;bucket_name&gt; with your actual bucket name):\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::ddf4c98b5e6647f0a246f0624c8341d9:root\"\n            },\n            \"Action\": [\n                \"s3:GetBucketLocation\",\n                \"s3:ListBucket\",\n                \"s3:GetObject\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;\",\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}\nA python script to set a bucket policy can be downloaded here."
  },
  {
    "objectID": "APIs/SentinelHub/AsyncProcess.html#checking-the-status-of-the-request",
    "href": "APIs/SentinelHub/AsyncProcess.html#checking-the-status-of-the-request",
    "title": "Asynchronous Processing API",
    "section": "Checking the status of the request",
    "text": "Checking the status of the request\nWhile the request is running, you can get its status (see this example). Once the processing is finished the request is deleted from our system. If you try to check its status after it has been deleted, you will get a '404 Not Found' response even if the request was processed successfully."
  },
  {
    "objectID": "APIs/SentinelHub/AsyncProcess.html#troubleshooting",
    "href": "APIs/SentinelHub/AsyncProcess.html#troubleshooting",
    "title": "Asynchronous Processing API",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIn case anything goes wrong when creating an Async request, we will return an error message immediately. If anything goes wrong once the Async request has been created, we will deliver an \"error.json\" file with an error message to your object storage."
  },
  {
    "objectID": "APIs/SentinelHub/AsyncProcess.html#examples",
    "href": "APIs/SentinelHub/AsyncProcess.html#examples",
    "title": "Asynchronous Processing API",
    "section": "Examples",
    "text": "Examples\nExample of a Async API request"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html",
    "href": "APIs/SentinelHub/OGC/WMS.html",
    "title": "Web Mapping Service",
    "section": "",
    "text": "The Sentinel Hub WMS service conforms to the WMS standard. It not only provides access to raw satellite data but also to processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMS, help you understand the structure, show you how to run the requests in different environments and how it can be integrated with QGIS, ArcGIS and web applications.\nIt is possible to obtain multiple separate instances (which act as separate WMS services) each with their own configuration and list of layers which will likely be useful to advanced users.\nThe base URL for the WMS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;\nFor example, a GetCapabilities request can be done by changing the &lt;INSTANCE_ID&gt; to your provided instance ID and opening the following URL:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetCapabilities\nSome of the most common provided products:\n\nTRUE_COLOR - a brightened RGB image\nFALSE_COLOR - uses near-infrared instead of the blue band\nNDVI - Normalized Difference Vegetation Index\nEVI - Enhanced Vegetation Index\n\nList of all available products.\nThe service supports standard WMS requests: GetMap, GetCapabilities, GetFeatureInfo, and also some custom requests. Supported WMS versions are 1.1.1 and 1.3.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nFor a list of supported coordinate reference systems check the GetCapabilities result."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html#wms-request",
    "href": "APIs/SentinelHub/OGC/WMS.html#wms-request",
    "title": "Web Mapping Service",
    "section": "",
    "text": "The Sentinel Hub WMS service conforms to the WMS standard. It not only provides access to raw satellite data but also to processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMS, help you understand the structure, show you how to run the requests in different environments and how it can be integrated with QGIS, ArcGIS and web applications.\nIt is possible to obtain multiple separate instances (which act as separate WMS services) each with their own configuration and list of layers which will likely be useful to advanced users.\nThe base URL for the WMS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;\nFor example, a GetCapabilities request can be done by changing the &lt;INSTANCE_ID&gt; to your provided instance ID and opening the following URL:\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetCapabilities\nSome of the most common provided products:\n\nTRUE_COLOR - a brightened RGB image\nFALSE_COLOR - uses near-infrared instead of the blue band\nNDVI - Normalized Difference Vegetation Index\nEVI - Enhanced Vegetation Index\n\nList of all available products.\nThe service supports standard WMS requests: GetMap, GetCapabilities, GetFeatureInfo, and also some custom requests. Supported WMS versions are 1.1.1 and 1.3.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nFor a list of supported coordinate reference systems check the GetCapabilities result."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMS.html#wms-url-parameters",
    "href": "APIs/SentinelHub/OGC/WMS.html#wms-url-parameters",
    "title": "Web Mapping Service",
    "section": "WMS URL Parameters",
    "text": "WMS URL Parameters\nStandard common WMS URL parameters (parameter names are case insensitive, values are case sensitive):\n\n\n\nWMS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WMS\".\n\n\nVERSION\nWMS version standard. Optional, default: \"1.3.0\". Supported values: \"1.1.1\" and \"1.3.0\".\n\n\nREQUEST\nWhat is requested, valid values: GetMap, GetFeatureInfo, GetCapabilities or a custom request's name. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WMS URL parameters, the WMS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetMap request URL parameters:\n\n\n\nWMS parameter\nInfo\n\n\n\n\nBBOX\nSpecifies the bounding box of the requested image. Coordinates must be in the specified coordinate reference system. The four coordinates representing the top-left and bottom-right of the bounding box must be separated by commas. Required. Example: BBOX=-13152499,4038942,-13115771,4020692\n\n\nCRS\n(when VERSION 1.3.0 or higher) the coordinate reference system in which the BBOX is specified and in which to return the image. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nSRS\n(when VERSION 1.1.1 or lower) the coordinate reference system in which the BBOX is specified and in which to return the image. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values.\n\n\nWIDTH\nReturned image width in pixels. Required, unless RESX is used. If WIDTH is used, HEIGHT is also required.\n\n\nHEIGHT\nReturned image height in pixels. Required, unless RESY is used. If HEIGHT is used, WIDTH is also required.\n\n\nRESX\nReturned horizontal image resolution in UTM units (if m is added, e.g. 10m, in metrical units). (optional instead of WIDTH). If used, RESY is also required.\n\n\nRESY\nReturned vertical image resolution in UTM units (if m is added, e.g. 10m, in metrical units). (optional instead of HEIGHT). If used, RESX is also required.\n\n\nLAYERS\nThe preconfigured layer (image) to be returned. You must specify exactly one layer and optionally add additional overlays. Required. Example: LAYERS=TRUE_COLOR,OUTLINE\n\n\nEXCEPTIONS\nThe exception format. Optional, default: \"XML\". Supported values: \"XML\", \"INIMAGE\", \"BLANK\" (all three for version &gt;= 1.3.0), \"application/vnd.ogc.se_xml\", \"application/vnd.ogc.se_inimage\", \"application/vnd.ogc.se_blank\" (all three for version &lt; 1.3.0).\n\n\n\nStandard GetFeatureInfo request URL parameters:\n\n\n\nWMS parameter\nInfo\n\n\n\n\nBBOX\nSpecifies the bounding box of the area which contains the queried point. Coordinates are in the specified CRS/SRS. Four coordinates representing the top-left and bottom-right of the bounding box must be separated by comma. Required. Example: BBOX=-13152499,4038942,-13115771,4020692\n\n\nCRS\n(when VERSION 1.3.0 or higher) the coordinate reference system in which the BBOX is specified. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nSRS\n(when VERSION 1.1.1 or lower) the coordinate reference system in which the BBOX is specified. Optional, default: \"EPSG:3857\". For a list of available CRSs see the GetCapabilities result.\n\n\nWIDTH\nThe image-space width containing the queried point, in pixels. Required.\n\n\nHEIGHT\nThe image-space height containing the queried point, in pixels. Required.\n\n\nINFO_FORMAT\nThe output format of the feature info content. Check GetCapabilities for a list of supported formats.\n\n\nRESY\nThe layers for which the feature info is requested.\n\n\nI and J\n(when VERSION 1.3.0 or higher) The X and Y coordinates in the output image space in pixels of the feature queried.\n\n\nX and Y\n(when VERSION 1.1.1 or lower) The X and Y coordinates in the output image space in pixels of the feature queried."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html",
    "href": "APIs/SentinelHub/OGC/WMTS.html",
    "title": "Web Mapping Tile Service",
    "section": "",
    "text": "The Sentinel Hub WMTS (Web Map Tile Service) service conforms to the WMTS standard. It provides access to Sentinel-2's 13 unprocessed bands (B01 through B12, with B8A following B08) as well as processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration. Provides access to the same bands product and additional informational layers as the WMS request except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. As with the WMS service, WMTS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMTS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WMTS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request and supports the standard WMTS requests GetTile, GetCapabilities. It supports WMTS version 1.0.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nCheck GetCapabilities for a list of supported coordinate reference systems and tile matrix sets which can be used for the TILEMATRIX and TILEMATRIXSET parameters."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html#wmts-request",
    "href": "APIs/SentinelHub/OGC/WMTS.html#wmts-request",
    "title": "Web Mapping Tile Service",
    "section": "",
    "text": "The Sentinel Hub WMTS (Web Map Tile Service) service conforms to the WMTS standard. It provides access to Sentinel-2's 13 unprocessed bands (B01 through B12, with B8A following B08) as well as processed products such as true color imagery and NDVI. Access to the service is done via a custom server instance URL which will be provided to you upon registration. Provides access to the same bands product and additional informational layers as the WMS request except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. As with the WMS service, WMTS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WMTS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WMTS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request and supports the standard WMTS requests GetTile, GetCapabilities. It supports WMTS version 1.0.0.\nIf you want to force a specific output format (e.g. float 32 or uint 16) set sampleType in your evalscript as explained here. Use dataMask band in your evalscript as explained here to make pixels transparent.\nCheck GetCapabilities for a list of supported coordinate reference systems and tile matrix sets which can be used for the TILEMATRIX and TILEMATRIXSET parameters."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WMTS.html#wmts-parameters",
    "href": "APIs/SentinelHub/OGC/WMTS.html#wmts-parameters",
    "title": "Web Mapping Tile Service",
    "section": "WMTS Parameters",
    "text": "WMTS Parameters\nStandard common WMTS URL parameters (names are case insensitive):\n\n\n\nWMTS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WMTS\".\n\n\nVERSION\nWMTS version standard. Optional, default: \"1.0.0\". Supported values: \"1.0.0\".\n\n\nREQUEST\nWhat is requested, valid values: GetTile or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WMS URL parameters, the WMS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetTile request URL parameters:\n\n\n\nWMTS parameter\nInfo\n\n\n\n\nTILEMATRIXSET\nThe matrix set to be used for the output tile. Check GetCapabilities for a list of supported matrix sets.\n\n\nTILEMATRIX\nThe matrix to be used for the output tile. Check GetCapabilities for a list of supported matrices.\n\n\nTILECOL\nThe column index of the output tile. Check GetCapabilities for a list of supported matrix widths.\n\n\nTILEROW\nThe row index of the output tile. Check GetCapabilities for a list of supported matrix heights.\n\n\nLAYER\nThe preconfigured (in the instance) layer for which to generate the output tile.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html",
    "title": "Output Formats",
    "section": "",
    "text": "For the requests that provide image output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\nimage/png - lossless image format for 1 (grayscale) or 3 (RGB) components\nimage/jpeg - lossy image format for 1 (grayscale) or 3 (RGB) components, without alpha channel. The quality can be controlled via the \"QUALITY\" URL parameter.\nimage/tiff - lossless image format for any number of the components.\n\nFind out more on how the values are reflected in the output.\n\n\nTo generate the output as jpeg, use the following example. Please replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=image/jpeg"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html#output-image-formats",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html#output-image-formats",
    "title": "Output Formats",
    "section": "",
    "text": "For the requests that provide image output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\nimage/png - lossless image format for 1 (grayscale) or 3 (RGB) components\nimage/jpeg - lossy image format for 1 (grayscale) or 3 (RGB) components, without alpha channel. The quality can be controlled via the \"QUALITY\" URL parameter.\nimage/tiff - lossless image format for any number of the components.\n\nFind out more on how the values are reflected in the output.\n\n\nTo generate the output as jpeg, use the following example. Please replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=image/jpeg"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/OutputFormats.html#output-vector-formats",
    "href": "APIs/SentinelHub/OGC/OutputFormats.html#output-vector-formats",
    "title": "Output Formats",
    "section": "Output Vector Formats",
    "text": "Output Vector Formats\nFor the requests that provide vector output, Sentinel-2 WMS/WMTS/WCS services can generate these output formats:\n\napplication/x-esri-shape - zip containing shape files\napplication/json - GeoJSON file\n\nBoth formats are returning polygons in vector format only in case when the image does not consists of more than 10 different values. Therefore, this formats only work with custom script layers.\n\nExample requests for vector formats:\nTo generate the output as GeoJSON file, follow the example below. Replace &lt;INSTANCE_ID&gt; with your own.\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?SERVICE=WMS&REQUEST=GetMap&SHOWLOGO=false&VERSION=1.3.0&LAYERS=NDVI&MAXCC=20&WIDTH=640&HEIGHT=640&CRS=EPSG:4326&BBOX=46.697956,16.223885,46.699840,16.2276628&FORMAT=application/json\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"properties\": {\n        \"COLOR_HEX\": \"FFFFFF\",\n        \"ID\": 0\n      },\n      \"geometry\": {\n        \"type\": \"MultiPolygon\",\n        \"crs\": {\n            \"type\": \"name\",\n            \"properties\": {\n                \"name\": \"urn:ogc:def:crs:OGC::CRS84\"\n            }\n        },\n        \"coordinates\": [[[\n            [16.225567302, 46.698948044],\n            [16.225567302, 46.6989451],\n            [16.225561399, 46.6989451],\n            [16.225561399, 46.698942156],\n            ...\n        ]]]\n      }\n    },\n    ...\n  ]\n}\nTo generate the output as x-esri-shape, replace the FORMAT with application/x-esri-shape, which will enable you to get the zip containing shape files."
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Metadata.html",
    "href": "APIs/SentinelHub/UserGuides/Metadata.html",
    "title": "Working with metadata in evalscript",
    "section": "",
    "text": "This user guide will show you how to work with metadata in evalscripts. We will focus on using objects scenes, inputMetadata, and outputMetadata. Use cases, covered with the examples below, include accessing metadata and using it in processing, passing the metadata to an output file userdata.json, and adding your own metadata to the file.\nNote that metadata normally provided in raster format is available as bands in Sentinel Hub. Such metadata can be accessed and processed in evalscript in the same manner as any other input band. This is not covered in this guide, but you can find basic examples and such metadata listed in the Data section for each data collection e.g. sunAzimuthAngles.\nEach example below begins with a description that highlights the important points of the example. All examples output also processed satellite images (average values of NDVI or band B02) but we do not display them here, since the focus is on metadata. To run the examples, you only need to have Python installed on your machine and an active Sentinel Hub account. You will always need to run the code in the chapter \"Authentication\" while the rest of the examples can be run independently."
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Metadata.html#check-which-metadata-is-available",
    "href": "APIs/SentinelHub/UserGuides/Metadata.html#check-which-metadata-is-available",
    "title": "Working with metadata in evalscript",
    "section": "Check which metadata is available",
    "text": "Check which metadata is available\nThe metadata is stored in two objects, which we call inputMetadata and scenes. Their properties are documented here and here, respectively. However, the properties of the scenes object can be different depending on the selected:\n\nmosaicking (e.g. ORBIT or TILE),\ndata collection (Sentinel-2 L2A, Sentinel-1, Sentinel-5p, ...),\nfunction in the evalscript (evaluatePixel, preProcessScenes, updateOutputMetadata).\n\nA convenient way to check which metadata is for your request available in scenes is to dump (i.e. write) all properties of the object to userdata.json file. This can be achieved with the Processing API as shown in this basic example. The two examples below show few more tricks that can be used to explore scenes object.\n\nProperties of scenes object and mosaicking ORBIT\nThis example shows:\n\nHow to access metadata when mosaicking is ORBIT using scenes.orbits.\nHow to pass metadata from scenes to userdata.json file using outputMetadata.userData in updateOutputMetadata function.\n\nurl = 'https://sh.dataspace.copernicus.eu'\n\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"dataMask\"],\n    mosaicking: Mosaicking.ORBIT,\n    output: {\n      id: \"default\",\n      bands: 1\n    }\n  }\n}\n\nfunction evaluatePixel(samples, scenes, inputMetadata, customData, outputMetadata) {\n  //Average value of band B02 based on the requested scenes\n  var sumOfValidSamplesB02 = 0\n  var numberOfValidSamples = 0\n  for (i = 0; i &lt; samples.length; i++) {\n    var sample = samples[i]\n    if (sample.dataMask == 1){\n        sumOfValidSamplesB02 += sample.B02\n        numberOfValidSamples += 1\n    }\n  }\n  return [sumOfValidSamplesB02 / numberOfValidSamples]\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = {\n    \"inputMetadata\": inputMetadata\n  }\n  outputMetadata.userData[\"orbits\"] = scenes.orbits\n}\n\"\"\"\n\nrequest = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [13.8, 45.8, 13.9, 45.9]\n    },\n    \"data\": [{\n      \"type\": \"sentinel-2-l1c\",\n      \"dataFilter\": {\n        \"timeRange\": {\n          \"from\": \"2020-12-01T00:00:00Z\",\n          \"to\": \"2020-12-06T23:59:59Z\"\n        }\n      }\n    }]\n  },\n  \"output\": {\n    \"responses\": [{\n        \"identifier\": \"default\",\n        \"format\": {\n          \"type\": \"image/tiff\"\n        }\n      },\n      {\n        \"identifier\": \"userdata\",\n        \"format\": {\n          \"type\": \"application/json\"\n        }\n      }\n    ]\n  },\n  \"evalscript\": evalscript\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/x-tar'\n}\n\nresponse = oauth.post(f\"{url}/api/v1/process\", headers=headers, json = request)\ntar = tarfile.open(fileobj=io.BytesIO(response.content))\nuserdata = json.load(tar.extractfile(tar.getmember('userdata.json')))\nuserdata\n{'inputMetadata': {'serviceVersion': '4.263.0', 'normalizationFactor': 0.0001},\n 'orbits': [{'tiles': [{'date': '2020-12-06T10:08:08Z',\n     'shId': 15161628,\n     'cloudCoverage': 100,\n     'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/UL/2020/12/6/0'},\n    {'date': '2020-12-06T10:08:05Z',\n     'shId': 15161463,\n     'cloudCoverage': 98.26,\n     'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/VL/2020/12/6/0'}],\n   'dateTo': '2020-12-06T23:59:59Z',\n   '__idx': 0,\n   'dateFrom': '2020-12-06T00:00:00Z'},\n  {'tiles': [{'date': '2020-12-04T10:18:05Z',\n     'shId': 15142759,\n     'cloudCoverage': 99.93,\n     'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/UL/2020/12/4/0'},\n    {'date': '2020-12-04T10:17:56Z',\n     'shId': 15142728,\n     'cloudCoverage': 98.5,\n     'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/VL/2020/12/4/0'}],\n   'dateTo': '2020-12-04T23:59:59Z',\n   '__idx': 1,\n   'dateFrom': '2020-12-04T00:00:00Z'},\n  {'tiles': [{'date': '2020-12-01T10:08:10Z',\n     'shId': 15117250,\n     'cloudCoverage': 22.85,\n     'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/UL/2020/12/1/0'},\n    {'date': '2020-12-01T10:08:06Z',\n     'shId': 15117286,\n     'cloudCoverage': 46.81,\n     'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/VL/2020/12/1/0'}],\n   'dateTo': '2020-12-01T23:59:59Z',\n   '__idx': 2,\n   'dateFrom': '2020-12-01T00:00:00Z'}]}\n\n\nProperties of scenes object and mosaicking TILE\nThis example shows how to:\n\nAccess scenes metadata when mosaicking is TILE using scenes.tiles and write it to userdata.json file.\nHow to calculate a maximum value of band B02 and write it to userdata.json file. Note that we use a global variable maxValueB02 so that we can assign a value to it in evaluatePixel function but write its value to metadata in updateOutputMetadata function. The advantage of this approach is that maxValueB02 is written to metadata only once and not for each output pixel.\n\nurl = 'https://sh.dataspace.copernicus.eu'\n\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"dataMask\"],\n    mosaicking: Mosaicking.TILE,\n    output: {\n      id: \"default\",\n      bands: 1\n    }\n  }\n}\n\nvar maxValueB02 = 0\n\nfunction evaluatePixel(samples, scenes, inputMetadata, customData, outputMetadata) {\n  //Average value of band B02 based on the requested tiles\n  var sumOfValidSamplesB02 = 0\n  var numberOfValidSamples = 0\n  for (i = 0; i &lt; samples.length; i++) {\n    var sample = samples[i]\n    if (sample.dataMask == 1){\n        sumOfValidSamplesB02 += sample.B02\n        numberOfValidSamples += 1\n        if (sample.B02 &gt; maxValueB02){\n            maxValueB02 = sample.B02\n        }\n    }\n  }\n  return [sumOfValidSamplesB02 / numberOfValidSamples]\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { \"tiles\":  scenes.tiles }\n  outputMetadata.userData.maxValueB02 = maxValueB02\n}\n\"\"\"\n\nrequest = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [13.8, 45.8, 13.9, 45.9]\n    },\n    \"data\": [{\n      \"type\": \"sentinel-2-l1c\",\n      \"dataFilter\": {\n        \"timeRange\": {\n          \"from\": \"2020-12-01T00:00:00Z\",\n          \"to\": \"2020-12-06T23:59:59Z\"\n        }\n      }\n    }]\n  },\n  \"output\": {\n    \"responses\": [{\n        \"identifier\": \"default\",\n        \"format\": {\n          \"type\": \"image/tiff\"\n        }\n      },\n      {\n        \"identifier\": \"userdata\",\n        \"format\": {\n          \"type\": \"application/json\"\n        }\n      }\n    ]\n  },\n  \"evalscript\": evalscript\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/x-tar'\n}\n\nresponse = oauth.post(f\"{url}/api/v1/process\", headers=headers, json = request)\ntar = tarfile.open(fileobj=io.BytesIO(response.content))\nuserdata = json.load(tar.extractfile(tar.getmember('userdata.json')))\nuserdata\n{'tiles': [{'date': '2020-12-06T10:08:08Z',\n   'shId': 15161628,\n   'cloudCoverage': 100,\n   '__idx': 0,\n   'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/UL/2020/12/6/0'},\n  {'date': '2020-12-06T10:08:05Z',\n   'shId': 15161463,\n   'cloudCoverage': 98.26,\n   '__idx': 1,\n   'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/VL/2020/12/6/0'},\n  {'date': '2020-12-04T10:18:05Z',\n   'shId': 15142759,\n   'cloudCoverage': 99.93,\n   '__idx': 2,\n   'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/UL/2020/12/4/0'},\n  {'date': '2020-12-04T10:17:56Z',\n   'shId': 15142728,\n   'cloudCoverage': 98.5,\n   '__idx': 3,\n   'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/VL/2020/12/4/0'},\n  {'date': '2020-12-01T10:08:10Z',\n   'shId': 15117250,\n   'cloudCoverage': 22.85,\n   '__idx': 4,\n   'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/UL/2020/12/1/0'},\n  {'date': '2020-12-01T10:08:06Z',\n   'shId': 15117286,\n   'cloudCoverage': 46.81,\n   '__idx': 5,\n   'dataPath': 's3://sentinel-s2-l1c/tiles/33/T/VL/2020/12/1/0'}],\n 'maxValueB02': 0.8795000000000001}"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Metadata.html#output-metadata-into-userdatajson-file",
    "href": "APIs/SentinelHub/UserGuides/Metadata.html#output-metadata-into-userdatajson-file",
    "title": "Working with metadata in evalscript",
    "section": "Output metadata into userdata.json file",
    "text": "Output metadata into userdata.json file\nIn this example, we write several pieces of information to the userdata.json file:\n\nA version of the software with which the data was processed. We take this information from inputMetadata.\nDates when the data used for processing was acquired. We take this information from scene.tiles.\nValues set by user and used for processing, such as thresholds (e.g. ndviThreshold) and array of values (e.g. notAllowedDates).\nDates of all tiles available before we filtered out those acquired on dates given in notAllowedDates array. These dates are listed in tilesPPSDates property of userData. Note how we used a global variable tilesPPS: we assigned it a value in preProcessScenes and output it in updateOutputMetadata function.\nDates of all tiles available after the filtering. These dates are listed in tilesDates property of userData.\nDescription of the processing implemented in the evalscript and links to external resources.\n\nurl = 'https://sh.dataspace.copernicus.eu'\n\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B04\", \"dataMask\"],\n    mosaicking: Mosaicking.TILE,\n    output: {\n      id: \"default\",\n      bands: 1\n    }\n  }\n}\n\n// User's inputs\nvar notAllowedDates = [\"2020-12-06\", \"2020-12-09\"]\nvar ndviThreshold = 0.2\n\nvar tilesPPS = []\nfunction preProcessScenes(collections) {\n  tilesPPS = collections.scenes.tiles\n  collections.scenes.tiles = collections.scenes.tiles.filter(function(tile) {\n    var tileDate = tile.date.split(\"T\")[0];\n    return !notAllowedDates.includes(tileDate);\n  })\n  return collections\n}\n\nfunction evaluatePixel(samples, scenes, inputMetadata, customData, outputMetadata) {\n\n  var valid_ndvi_sum = 0\n  var numberOfValidSamples = 0\n  for (i = 0; i &lt; samples.length; i++) {\n    var sample = samples[i]\n    if (sample.dataMask == 1){\n        var ndvi = (sample.B08 - sample.B04)/(sample.B08 + sample.B04)\n        if (ndvi &lt;= ndviThreshold){\n          valid_ndvi_sum += ndvi\n          numberOfValidSamples += 1\n        }\n    }\n  }\n\n  return [valid_ndvi_sum / numberOfValidSamples]\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = {\n    \"inputMetadata.serviceVersion\": inputMetadata.serviceVersion\n  }\n\n  outputMetadata.userData.description = \"The evalscript calculates average ndvi \" +\n  \"in a requested time period. Data collected on notAllowedDates is excluded. \" +\n  \"ndvi values greater than ndviThreshold are excluded. \" +\n  \"More about ndvi: https://www.indexdatabase.de/db/i-single.php?id=58.\"\n\n  // Extract dates for all available tiles (before filtering)\n  var tilePPSDates = []\n  for (i = 0; i &lt; tilesPPS.length; i++){\n    tilePPSDates.push(tilesPPS[i].date)\n  }\n  outputMetadata.userData.tilesPPSDates = tilePPSDates\n\n  // Extract dates for tiles after filtering out tiles with \"notAllowedDates\"\n  var tileDates = []\n  for (i = 0; i &lt; scenes.tiles.length; i++){\n    tileDates.push(scenes.tiles[i].date)\n  }\n  outputMetadata.userData.tilesDates = tileDates\n\n  outputMetadata.userData.notAllowedDates = notAllowedDates\n  outputMetadata.userData.ndviThreshold = ndviThreshold\n}\n\"\"\"\n\nrequest = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [13.8, 45.8, 13.9, 45.9]\n    },\n    \"data\": [{\n      \"type\": \"sentinel-2-l1c\",\n      \"dataFilter\": {\n        \"timeRange\": {\n          \"from\": \"2020-12-01T00:00:00Z\",\n          \"to\": \"2020-12-15T23:59:59Z\"\n        }\n      }\n    }]\n  },\n  \"output\": {\n    \"responses\": [{\n        \"identifier\": \"default\",\n        \"format\": {\n          \"type\": \"image/tiff\"\n        }\n      },\n      {\n        \"identifier\": \"userdata\",\n        \"format\": {\n          \"type\": \"application/json\"\n        }\n      }\n    ]\n  },\n  \"evalscript\": evalscript\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/x-tar'\n}\n\nresponse = oauth.post(f\"{url}/api/v1/process\", headers=headers, json = request)\ntar = tarfile.open(fileobj=io.BytesIO(response.content))\nuserdata = json.load(tar.extractfile(tar.getmember('userdata.json')))\nuserdata\n{'notAllowedDates': ['2020-12-06', '2020-12-09'],\n 'tilesDates': ['2020-12-11T10:08:07Z',\n  '2020-12-11T10:08:03Z',\n  '2020-12-04T10:18:05Z',\n  '2020-12-04T10:17:56Z',\n  '2020-12-01T10:08:10Z',\n  '2020-12-01T10:08:06Z'],\n 'inputMetadata.serviceVersion': '4.263.0',\n 'description': 'The evalscript calculates average ndvi in a requested time period. Data collected on notAllowedDates is excluded. ndvi values greater than ndviThreshold are excluded. More about ndvi: https://www.indexdatabase.de/db/i-single.php?id=58. ',\n 'tilesPPSDates': ['2020-12-11T10:08:07Z',\n  '2020-12-11T10:08:03Z',\n  '2020-12-09T10:18:04Z',\n  '2020-12-09T10:17:56Z',\n  '2020-12-06T10:08:08Z',\n  '2020-12-06T10:08:05Z',\n  '2020-12-04T10:18:05Z',\n  '2020-12-04T10:17:56Z',\n  '2020-12-01T10:08:10Z',\n  '2020-12-01T10:08:06Z'],\n 'ndviThreshold': 0.2}"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Datamask.html",
    "href": "APIs/SentinelHub/UserGuides/Datamask.html",
    "title": "Data Mask",
    "section": "",
    "text": "With evalscript v3 we are now providing full control to you over what is to be returned for image parts (pixels) where there is “no data”. In the setup function, you can request dataMask as an element of the input array and then use it in the evaluatePixel function in the same manner as any other input band.\n\n\ndataMask has value 0 for “no data” pixels and 1 elsewhere.\nBy “no data” pixels we mean:\n\nAll pixels which lay outside of the requested polygon (if specified).\nAll pixels for which no source data was found.\nAll pixels for which source data was found and is explicitly “no data”.\n\nThings to note:\n\nAll “no data” pixels as defined above have a dataMask value of 0. All band values for these pixels are also 0, except for Landsat data collections, where band values for no data pixels are NaN.\n\"No data\" pixels are treated like any other in the evalscript. Their value, namely zero (or NaN in case of Landsat data collections), is applied to your evalscript just like any other other pixel. E.g. return [sample.B04*sample.B03] will return 0 for “no data” pixels, while return [sample.B04/sample.B03] would return \"Infinity\" (if requested sampleType is FLOAT32) due to division by zero (or \"NaN\" for Landsat data collection where the division would be by \"NaN\"). To treat \"no data\" pixels differently, explicitly handle them in your evalscript. See the examples below.\n\n\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1)  {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  } else {\n    return [99, 99, 99]\n  }\n}\n\n\n\n//VERSION=3\nif (dataMask == 1)  {\n  return [2.5 * B04, 2.5 * B03, 2.5 * B02]\n} else {\n  return [99/255, 99/255, 99/255] //normalized with 255 for visualization in EO Browser\n}\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you'd like to use this example, you must set the output.responses.format.type parameter of your process API request to image/png or image/tiff. The png format will automatically interpret the fourth band as transparency.\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 4 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02, sample.dataMask]\n}\n\n\n\n//VERSION=3\nreturn [2.5 * B04, 2.5 * B03, 2.5 * B02, dataMask]"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Datamask.html#datamask---handling-of-pixels-with-no-data",
    "href": "APIs/SentinelHub/UserGuides/Datamask.html#datamask---handling-of-pixels-with-no-data",
    "title": "Data Mask",
    "section": "",
    "text": "With evalscript v3 we are now providing full control to you over what is to be returned for image parts (pixels) where there is “no data”. In the setup function, you can request dataMask as an element of the input array and then use it in the evaluatePixel function in the same manner as any other input band.\n\n\ndataMask has value 0 for “no data” pixels and 1 elsewhere.\nBy “no data” pixels we mean:\n\nAll pixels which lay outside of the requested polygon (if specified).\nAll pixels for which no source data was found.\nAll pixels for which source data was found and is explicitly “no data”.\n\nThings to note:\n\nAll “no data” pixels as defined above have a dataMask value of 0. All band values for these pixels are also 0, except for Landsat data collections, where band values for no data pixels are NaN.\n\"No data\" pixels are treated like any other in the evalscript. Their value, namely zero (or NaN in case of Landsat data collections), is applied to your evalscript just like any other other pixel. E.g. return [sample.B04*sample.B03] will return 0 for “no data” pixels, while return [sample.B04/sample.B03] would return \"Infinity\" (if requested sampleType is FLOAT32) due to division by zero (or \"NaN\" for Landsat data collection where the division would be by \"NaN\"). To treat \"no data\" pixels differently, explicitly handle them in your evalscript. See the examples below.\n\n\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1)  {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  } else {\n    return [99, 99, 99]\n  }\n}\n\n\n\n//VERSION=3\nif (dataMask == 1)  {\n  return [2.5 * B04, 2.5 * B03, 2.5 * B02]\n} else {\n  return [99/255, 99/255, 99/255] //normalized with 255 for visualization in EO Browser\n}\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you'd like to use this example, you must set the output.responses.format.type parameter of your process API request to image/png or image/tiff. The png format will automatically interpret the fourth band as transparency.\n\n\n\n\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"dataMask\"],\n    output: { bands: 4 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02, sample.dataMask]\n}\n\n\n\n//VERSION=3\nreturn [2.5 * B04, 2.5 * B03, 2.5 * B02, dataMask]"
  },
  {
    "objectID": "APIs/SentinelHub/OGC.html",
    "href": "APIs/SentinelHub/OGC.html",
    "title": "OGC service",
    "section": "",
    "text": "Our OGC services offer the access to the Sentinel Hub functionalists via interfaces, which conform to the Open Geospatial Consortium (OGC) standards: WMS, WCS, WFS, and WMTS.\nUsing the OGC services you can avoid the complexities of preprocessing of satellite data. No need to download the data, no dealing with the JP2 format, no re-projecting, or mosaicking. No need for large storage volumes and lots of processing power. Simply add a new data collection in your GIS application (ArcGIS, QGIS, OpenLayers, Google Earth or any other app supporting standard services) and start using the data right away! Find more information on:\n\nWMS - Web Mapping Service\nWCS - Web Coverage Service\nWFS - Web Feature Service\nWMTS - Web Mapping Tile Service\n\n\nConfiguration Instance and Authentication\nTo use any of our OGC services you will need a \"configuration instance\" (or shortly \"instance\"). A configuration instance defines which layers are part of your OGC service, how the data shall be processed and visualized for each of these layers, and its id is used to authenticate your OGC requests. You can create a configuration instance using our Configuration API or in the Sentinel Hub Dashboard in the \"Configuration Utility\" tab. \"Simple WMS Instance\" is a pre-created configuration instance, which comes with your Sentinel Hub account and you can use its id (\"9d559...\" in the example below but yours will have a different id) to run the OGC examples.\n\n\n\nTutorials and Other Related Materials\nTo get you started, we have prepared a webinar on OGC API with QGIS integration, explaining the structure of OGC requests, how to run them in web browser, Postman and Python and integrate them into your own GIS. November 4, 2020"
  },
  {
    "objectID": "APIs/SentinelHub/Data/DataFusion.html",
    "href": "APIs/SentinelHub/Data/DataFusion.html",
    "title": "Data Fusion",
    "section": "",
    "text": "Sentinel Hub (SH) allows you to combine the data from various data sources in the same request. To use this functionality you need to prepare a request with several data sources as explained below. Data fusion can be used for any data available in Sentinel Hub including PlanetScope, Pleiades, SPOT (TPDI) and your own data (BYOC) and with all SH data-processing APIs (Process, Statistical, Batch, etc).\nAll SH endpoint locations support data fusion of collections hosted at that endpoint. However, only the Processing API endpoint sh.dataspace.copernicus.eu/api/v1/process also allows combining collections hosted at different SH endpoints, such as this example.\nWe invite you to read our Data Fusion blog post, where you will find 6 interesting use cases and a short guide on how to use data fusion in Sentinel Hub."
  },
  {
    "objectID": "APIs/SentinelHub/Data/DataFusion.html#preparing-a-data-fusion-request",
    "href": "APIs/SentinelHub/Data/DataFusion.html#preparing-a-data-fusion-request",
    "title": "Data Fusion",
    "section": "Preparing a Data Fusion Request",
    "text": "Preparing a Data Fusion Request\nPreparing a data fusion request is very similar to preparing any process API request that uses a single data source. Thus, only the parts which differ when performing data fusion requests are described below.\n\nRequest Body\nIn the body of the request, more specifically in the input.data array, you need to add more than one data object. For each of these objects you can optionally specify the property:\n\nid (optional) - a string of your choosing. It is used as an identifier for this input so that it can be referred to in the evalscript. It is not mandatory to define it but we recommend to do so, see examples below. Note that the type (e.g., \"sentinel-2-l1c\") is insufficient as an identifier because you may use multiple inputs from the same data collection.\n\nAn example of the input.data array with two elements:\n{\n  \"input\": {\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l1c\",\n        \"id\": \"l1c\",\n        \"dataFilter\": {\n          \"timeRange\": {\n            \"from\": \"2018-10-01T00:00:00Z\",\n            \"to\": \"2018-11-01T00:00:00Z\"\n          },\n          \"mosaickingOrder\": \"leastRecent\"\n        }\n      },\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"id\": \"l2a\",\n        \"dataFilter\": {\n          \"timeRange\": {\n            \"from\": \"2018-10-01T00:00:00Z\",\n            \"to\": \"2018-11-01T00:00:00Z\"\n          },\n          \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  }\n}\nAs you can see in the example above all data collection specific options are still available.\n\n\nEvalscript\n\nSetup\nIn the evalscript, under the input array in the setup function, specify all input collections. Optionally, match the id from the input.data object of the request body to the datasource parameter of each input collection. This ensures that the correct collection will be used for input bands. For example:\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n        {datasource: \"l2a\", bands: [\"SCL\"], units: \"DN\"},\n        {datasource: \"l1c\", bands: [\"B02\", \"B03\", \"B04\"], units: \"REFLECTANCE\"}\n    ],\n    output: [\n      {bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\nSince the datasource parameter is optional, in case you choose to omit it, the order of the input objects becomes relevant and must be the same as in the request body.\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {bands: [\"B02\", \"B03\", \"B04\"], units: \"REFLECTANCE\"}, // sentinel-2-l1c\n      {bands: [\"SCL\"], units: \"DN\"} // sentinel-2-l2a\n    ],\n    output: [\n      {bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\nSpecifying mosaicking for each input is also possible. Simply add the mosaicking parameter to each input object. This overrides the global mosaicking parameter which you typically use outside the input object. Combinations of both are therefore possible, and when present, the value within the input object is used. The default remains SIMPLE. In the example below, the global default SIMPLE mosaicking value is never used as ORBIT is specified for all inputs.\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {bands: [\"B02\", \"B03\", \"B04\"], units: \"REFLECTANCE\", mosaicking: \"ORBIT\"}, // sentinel-2-l1c\n      {bands: [\"SCL\"], units: \"DN\", mosaicking: \"ORBIT\"} // sentinel-2-l2a\n    ],\n    output: [\n      {bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\n\n\nData Access\nData from each collection can be accessed inside the evaluatePixel function, however as now multiple inputs are accessible the syntax is slightly different to the single data collection case. Assuming the evaluatePixel parameter is called samples, this object is always a key-value pair (dictionary). Obtain data for each collection in one of two ways.\nIf you are using the datasource object in your setup function, simply use its values as keys to the samples object. This gets an array of mosaicked values. Each array behaves exactly the same way as a non-datafusion non-SIMPLE mosaicking samples object. Note that this is an array even for datafusion with SIMPLE mosaicking, unlike non-datafusion requests; of course in this case the array either contains exactly one object or is empty.\nIf datasource was specified in setup:\nfunction evaluatePixel(samples) {\n  // \"l1c\" and \"l2a\" match the datasource values specified in the setup function\n  var l1cMosaics = samples.l1c;  // gets the array of sentinel-2-l1c mosaics\n  var l1cSample = l1cMosaics[0]; // gets the first mosaic. access bands from this object\n  var scl = samples.l2a[0].SCL;  // gets the SCL band of the first sentinel-2-l2a mosaic\n  if (2 &lt;= scl && scl &lt;= 7) {\n    return [l1cSample.B04, l1cSample.B03, l1cSample.B02];\n  }\n  return [0,0,0];\n}\nIf datasource wasn't specified in setup, you can access the data with keys being ordinal numbers starting with 0. Again, the order is as specified in the request body.\nfunction evaluatePixel(samples) {\n  // '0' is the identifier of the first input in the input.data array (sentinel-2-l1c)\n  // '1' is the identifier of the second input in the input.data array (sentinel-2-l2a)\n  var l1cMosaics = samples['0']; // gets the array of mosaics of the first input (sentinel-2-l1c)\n  var l1cSample = l1cMosaics[0]; // gets the first mosaic. access bands from this object\n  var scl = samples['1'][0].SCL; // gets the SCL band of the first mosaic of the second input (sentinel-2-l2a)\n  if (2 &lt;= scl && scl &lt;= 7) {\n    return [l1cSample.B04, l1cSample.B03, l1cSample.B02];\n  }\n  return [0,0,0];\n}\n\n\n\n\n\n\nNote\n\n\n\nWhile the above example works for all mosaicking types, it makes most sense for SIMPLE mosaicking. This is because only one mosaic is accessed for each input in the script, any additional mosaics, which would get generated if ORBIT or TILE mosaicking was used, are ignored."
  },
  {
    "objectID": "APIs/SentinelHub/Data/DataFusion.html#examples",
    "href": "APIs/SentinelHub/Data/DataFusion.html#examples",
    "title": "Data Fusion",
    "section": "Examples",
    "text": "Examples\n\nData Fusion Examples"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3OLCI.html",
    "href": "APIs/SentinelHub/Data/S3OLCI.html",
    "title": "Sentinel-3 OLCI L1B",
    "section": "",
    "text": "General information about Sentinel-3 mission can be found here. Sentinel Hub offers Sentinel-3 OLCI Level 1B products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3OLCI.html#about-sentinel-3-olci-l1b-data",
    "href": "APIs/SentinelHub/Data/S3OLCI.html#about-sentinel-3-olci-l1b-data",
    "title": "Sentinel-3 OLCI L1B",
    "section": "",
    "text": "General information about Sentinel-3 mission can be found here. Sentinel Hub offers Sentinel-3 OLCI Level 1B products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3OLCI.html#accessing-sentinel-3-olci-l1b-data",
    "href": "APIs/SentinelHub/Data/S3OLCI.html#accessing-sentinel-3-olci-l1b-data",
    "title": "Sentinel-3 OLCI L1B",
    "section": "Accessing Sentinel-3 OLCI L1B Data",
    "text": "Accessing Sentinel-3 OLCI L1B Data\nTo access data you need to send a POST request to our process API. The requested data will be returned as the response to your request. Each POST request can be tailored to get you exactly the data you require. To do this requires setting various parameters which depend on the datasource you are querying. This chapter will help you understand the parameters for S3OLCI data. To see examples of such requests go here, and for an overview of all API parameters see the API Reference.\n\nData type identifier: sentinel-3-olci\nUse sentinel-3-olci (previously S3OLCI) as the value of the input.data.type parameter in your API requests. This is mandatory and will ensure you get Sentinel-3 OLCI L1B data.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object of the S3OLCI process API.\n\nmosaickingOrder\nSets the order of overlapping tiles from which the output result is mosaicked. The tiling is based on ESA's Product Dissemination Units for easier distribution.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nmostRecent\nthe pixel will be selected from the most recently acquired tile\nIf there are multiple products with the same timestamp then NTC will be used over NRT. Default value.\n\n\nleastRecent\nthe pixel will be selected from the oldest acquired tile\nIf there are multiple products with the same timestamp then NTC will be used over NRT.\n\n\n\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the S3OLCI process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing, regardless of the resolution\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nNot used, use upsampling instead\nN/A\nIgnored\n\n\n\n\n\nAvailable Bands and Data\nThis chapter will explain the bands and data which can be set in the evalscript input object. Any string listed in the column Name can be an element of the input.bands array in your evalscript.\n\n\n\nName\nDescription\nWavelength centre (nm)\nResolution (m)\n\n\n\n\nB01\nAerosol correction, improved water constituent retrieval\n400\n300\n\n\nB02\nYellow substance and detrital pigments (turbidity)\n412.5\n300\n\n\nB03\nChlorophyll absorption maximum, biogeochemistry, vegetation\n442.5\n300\n\n\nB04\nChlorophyll\n490\n300\n\n\nB05\nChlorophyll, sediment, turbidity, red tide\n510\n300\n\n\nB06\nChlorophyll reference (minimum)\n560\n300\n\n\nB07\nSediment loading\n620\n300\n\n\nB08\n2nd Chlorophyll absorption maximum, sediment, yellow substance / vegetation\n665\n300\n\n\nB09\nImproved fluorescence retrieval\n673.75\n300\n\n\nB10\nChlorophyll fluorescence peak, red edge\n681.25\n300\n\n\nB11\nChlorophyll fluorescence baseline, red edge transition\n708.75\n300\n\n\nB12\nO2 absorption / clouds, vegetation\n753.75\n300\n\n\nB13\nO2 absorption / aerosol correction\n761.25\n300\n\n\nB14\nAtmospheric correction\n764.375\n300\n\n\nB15\nO2 absorption used for cloud top pressure, fluorescence over land\n767.5\n300\n\n\nB16\nAtmospheric / aerosol correction\n778.75\n300\n\n\nB17\nAtmospheric / aerosol correction, clouds, pixel co-registration\n865\n300\n\n\nB18\nWater vapour absorption reference. Common reference band with SLSTR. Vegetation monitoring\n885\n300\n\n\nB19\nWater vapour absorption, vegetation monitoring (maximum REFLECTANCE)\n900\n300\n\n\nB20\nWater vapour absorption, atmospheric / aerosol correction\n940\n300\n\n\nB21\nAtmospheric / aerosol correction, snow grain size\n1020\n300\n\n\nQUALITY_FLAGS\nClassification and quality flags\nN/A\n300\n\n\nSAA\nSun azimuth angle\nN/A\n19000\n\n\nSZA\nSun zenith angle\nN/A\n19000\n\n\nVAA\nViewing (observation) azimuth angle\nN/A\n19000\n\n\nVZA\nViewing (observation) zenith angle\nN/A\n19000\n\n\nHUMIDITY\nRelative humidity (meteo band)\nN/A\n19000\n\n\nSEA_LEVEL_PRESSURE\nMean sea level pressure (meteo band)\nN/A\n19000\n\n\nTOTAL_COLUMN_OZONE\nTotal column ozone (meteo band)\nN/A\n19000\n\n\nTOTAL_COLUMN_WATER_VAPOUR\nTotal column water vapour (meteo band)\nN/A\n19000\n\n\ndataMask\nThe mask of data/no data pixels (more).\nN/A*\nN/A**\n\n\n\n*dataMask has no wavelength information, as it carries only boolean information on whether a pixel has data or not. See the chapter on Units for more.  **dataMask has no source resolution as it is calculated for each output pixel.\nFor more about Sentinel-3 OLCI bands, visit this Copernicus website.\n\n\nUnits\nThe data values for each band in your custom script are presented in the units as specified here. In case more than one unit is available for a given band, you may optionally set the value of input.units in your evalscript setup function to one of the values in the Sentinel Hub Units column. Doing so will present data in that unit. The Sentinel Hub units parameter combines the physical quantity and corresponding units of measurement values. As such, some names more closely resemble physical quantities, others resemble units of measurement.\nThe Source Format specifies how and with what precision the digital numbers (DN) from which the unit is derived are encoded. Bands requested in DN units contain exactly the pixel values of the source data. Note that resampling may produce interpolated values. DN is also used whenever a band is derived computationally (like dataMask); such bands can be identified by having DN units and N/A source format. DN values are typically not offered if they do not simply represent any physical quantity, in particular, when DN values require source-specific (i.e. non-global) conversion to physical quantities.\nValues in non-DN units are computed from the source (DN) values with at least float32 precision. Note that the conversion might be nonlinear, therefore the full value range and quantization step size of such a band can be hard to predict. Band values in evalscripts always behave as floating point numbers, regardless of the actual precision.\nThe Typical Range indicates what values are common for a given band and unit, however outliers can be expected.\n\n\n\nBand\nPhysical Quantity (units)\nSentinel Hub Units\nSource Format\nTypical Range\nNotes\n\n\n\n\nOptical bands  B01-B21\nReflectance (unitless)\nREFLECTANCE\nUINT16\n0 - 0.4\nHigher values in infrared bands. Highly reflective pixels, such as clouds, can have reflectance values above 1.\n\n\nVAA\nAngle (degrees)\nDEGREES\nINT16\n-180 - 180\n\n\n\nVZA\nAngle (degrees)\nDEGREES\nUINT16\n0 - 180\n\n\n\nSAA\nAngle (degrees)\nDEGREES\nINT16\n-180 - 180\n\n\n\nSZA\nAngle (degrees)\nDEGREES\nUINT16\n0 - 180\n\n\n\nHUMIDITY\nHumidity (percent)\nPERCENT\nFLOAT32\n0 - 100\n\n\n\nSEA_LEVEL_PRESSURE\nPressure (hectopascals)\nHECTOPASCALS\nFLOAT32\n980 - 1030\nExtreme weather can be outside this range\n\n\nTOTAL_COLUMN_OZONE\nTotal column ozone (kg/m2)\nKG_M2\nFLOAT32\n0.004 - 0.008\n\n\n\nTOTAL_COLUMN_WATER_VAPOUR\nTotal column water vapour (kg/m2)\nKG_M2\nFLOAT32\n0 - 70\n\n\n\nQUALITY_FLAGS\nN/A\nDN\nUINT32\n0 - 4,294,967,294\nBit packed value. Use decodeS3OLCIQualityFlags to unpack.\n\n\ndataMask\nN/A\nDN\nN/A\n0 - no data 1 - data\n\n\n\n\n\n\nMosaicking\nAll mosaicking types are supported.\n\n\nScenes Object\nscenes object stores metadata. An example of metadata available in scenes object for Sentinel-3 OLCI when mosaicking is ORBIT:\n\n\n\nProperty name\nValue\n\n\n\n\ntiles[i].date\n'2019-04-02T17:05:39Z'\n\n\ntiles[i].shId\n881338\n\n\ntiles[i].dataPath\n'http://data.cloudferro.com/EODATA/Sentinel-3/OLCI/OL_1_EFR/2020/04/04/S3A_OL_1_EFR____20200404T093158_20200404T093458_20200405T131253_0179_056_364_2160_LN1_O_NT_002.SEN3'\n\n\n\nProperties of a scenes object can differ depending on the selected mosaicking and in which evalscript function the object is accessed. Working with metadata in evalscript user guide explains all details and provides examples."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3OLCI.html#catalog-api-capabilities",
    "href": "APIs/SentinelHub/Data/S3OLCI.html#catalog-api-capabilities",
    "title": "Sentinel-3 OLCI L1B",
    "section": "Catalog API Capabilities",
    "text": "Catalog API Capabilities\nTo access Sentinel 3 OLCI product metadata you need to send search request to our Catalog API. The requested metadata will be returned as JSON formatted response to your request.\n\nCollection identifier: sentinel-3-olci\n\n\nDistinct extension\n\ndate"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3OLCI.html#examples",
    "href": "APIs/SentinelHub/Data/S3OLCI.html#examples",
    "title": "Sentinel-3 OLCI L1B",
    "section": "Examples",
    "text": "Examples\nS3OLCI examples"
  },
  {
    "objectID": "APIs/SentinelHub/Data/Byoc.html",
    "href": "APIs/SentinelHub/Data/Byoc.html",
    "title": "Bring Your Own COG / Batch",
    "section": "",
    "text": "Bring Your Own COG (BYOC) and Batch data is data ingested by Sentinel Hub users using BYOC API and Batch API, respectively."
  },
  {
    "objectID": "APIs/SentinelHub/Data/Byoc.html#about-byoc--batch-data",
    "href": "APIs/SentinelHub/Data/Byoc.html#about-byoc--batch-data",
    "title": "Bring Your Own COG / Batch",
    "section": "",
    "text": "Bring Your Own COG (BYOC) and Batch data is data ingested by Sentinel Hub users using BYOC API and Batch API, respectively."
  },
  {
    "objectID": "APIs/SentinelHub/Data/Byoc.html#accessing-data",
    "href": "APIs/SentinelHub/Data/Byoc.html#accessing-data",
    "title": "Bring Your Own COG / Batch",
    "section": "Accessing data",
    "text": "Accessing data\nData is accessed using Sentinel Hub APIs, just like any other data you are used to. In all cases collection id is needed, which can be obtained from your dashboard. You also need to access data from the correct endpoint.\n\nData type identifier\nUse byoc-&lt;collectionId&gt; for BYOC, and batch-&lt;collectionId&gt; for Batch as the value of the input.data.type parameter in your API requests. For example, set it to byoc-017aa0ae-33a6-45d3-8548-0f7d1041b40c for BYOC collection with id 017aa0ae-33a6-45d3-8548-0f7d1041b40c.\n\n\nRequest resolution limit\nFor the limit, we take five times the median resolution of the lowest resolution overview of all tiles in the collection. If this resolution is higher than 500 meters per pixel, the limit is set at 500 meters per pixel. This is to allow for more zoomed out viewing. Note, only overviews which are at least 256 pixels in either width or height are used for this computation. Adding or removing tiles from a collection will recompute its limit.\nYou can see the computed resolution limit for a collection in the collection details in your dashboard. Alternatively, in the response if querying a collection using the BYOC API.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object.\n\nmosaickingOrder\nSets the order of overlapping tiles from which the output result is mosaicked. The tiling is defined by the user when ingesting the data in the collection.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nmostRecent\nThe pixel will be selected from the tile, which the most recent sensing time.\nIn case there are more tiles available with the same sensing time, the one, which was created later will be used.\n\n\nleastRecent\nSimilar to mostRecent but in reverse order.\n\n\n\n\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing when the pixel resolution is greater than the source resolution (e.g. 5m/px with a 10m/px source)\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nAs above except when the resolution is lower.\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\n\n\n\nAvailable Bands and Data\nSince collections contains your data this means that the available bands are the ones you have prepared. The band names to use in you evalscript are also listed in each collection in your dashboard.\ndataMask is also available. In BYOC, dataMask value equals 1 only when a pixel is contained within cover geometry of a BYOC tile and when a pixel has data at the same time. All other instances (e.g. a pixel with data outside tile's cover geometry or a pixel with no-data within tile's cover geometry) will result in dataMask 0. Note also that for floating point rasters, NaN is always treated as no data. See here for more information.\n\n\nUnits\nThe only units available are digital numbers (DN) so any unit conversions, if necessary, are the responsibility of your evalscript.\n\n\nOGC API\nTo access your data via OGC you need to create a layer in the Configuration utility in either an existing or new configuration. When adding a layer you should set Source to Bring Your Own COG and Collection id to the id of your collection. You should also enter a custom script in Data processing field. This should return the appropriate values based on bands that are defined in the collection.\nOnce this is done the layer can be used via OGC API in the usual way.\nFor example: https://sh.dataspace.copernicus.eu/ogc/wms/&lt;MyInstanceID&gt;?REQUEST=GetMap&BBOX=15959450,8695500,16059450,8795500&CRS=EPSG:3857&WIDTH=500&HEIGHT=500&LAYERS=&lt;MyLayerName&gt;\n\nWFS\nTo query your tiles using WFS you need to set the WFS feature type (TYPENAMES parameter) to byoc-&lt;MyCollectionID&gt; for BYOC, and batch-&lt;MyCollectionID&gt; for Batch, e.g. byoc-a550f5e9-84d0-441a-8338-bbb04d42a72e.\nHere is an example of a WFS GetFeature request:\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;MyInstanceID&gt;?SERVICE=wfs&REQUEST=GetFeature&BBOX=-90,180,90,-180&SRSNAME=EPSG:4326&OUTPUTFORMAT=application/json&TYPENAMES=byoc-&lt;MyCollectionID&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/Data/Byoc.html#catalog-api-capabilities",
    "href": "APIs/SentinelHub/Data/Byoc.html#catalog-api-capabilities",
    "title": "Bring Your Own COG / Batch",
    "section": "Catalog API Capabilities",
    "text": "Catalog API Capabilities\nTo access Landsat BYOC or Batch product metadata you need to send search request to our Catalog API. The requested metadata will be returned as JSON formatted response to your request.\n\nCollection identifier: &lt;collection id&gt;\n\n\nDistinct extension\n\ndate"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L1C.html",
    "href": "APIs/SentinelHub/Data/S2L1C.html",
    "title": "Sentinel-2 L1C",
    "section": "",
    "text": "General information about Sentinel-2 mission can be found here. Sentinel Hub offers Sentinel-2 Level 1C products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L1C.html#about-sentinel-2-l1c-data",
    "href": "APIs/SentinelHub/Data/S2L1C.html#about-sentinel-2-l1c-data",
    "title": "Sentinel-2 L1C",
    "section": "",
    "text": "General information about Sentinel-2 mission can be found here. Sentinel Hub offers Sentinel-2 Level 1C products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L1C.html#accessing-sentinel-2-l1c-data",
    "href": "APIs/SentinelHub/Data/S2L1C.html#accessing-sentinel-2-l1c-data",
    "title": "Sentinel-2 L1C",
    "section": "Accessing Sentinel-2 L1C Data",
    "text": "Accessing Sentinel-2 L1C Data\nTo access data you need to send a POST request to our process API. The requested data will be returned as the response to your request. Each POST request can be tailored to get you exactly the data you require. To do this requires setting various parameters which depend on the datasource you are querying. This chapter will help you understand the parameters for S2L1C data. To see examples of such requests go here, and for an overview of all API parameters see the API Reference.\n\nData type identifier: sentinel-2-l1c\nUse sentinel-2-l1c (previously S2L1C) as the value of the input.data.type parameter in your API requests. This is mandatory and will ensure you get Sentinel-2 L1C data.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object of the S2L1C process API.\n\nmosaickingOrder\nSets the order of overlapping tiles from which the output result is mosaicked. Note that tiles will in most cases come from the same orbit/acquisition. The tiling is done by ESA for easier distribution.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nmostRecent\nselected by default. The pixel will be selected from the tile, which was acquired most recently\nin case there are more tiles available with the same timestamp (some tiles are processed by many ground stations, some are reprocessed, etc.), the one, which was downloaded from SciHub later will be used.\n\n\nleastRecent\nsimilar to mostRecent but in reverse order\n\n\n\nleastCC\npixel is selected from tile with the least cloud coverage metadata\nnote that \"per tile\" information is used here, each covering about a 12,000 sq. km area, so this information is only an estimate .\n\n\n\n\n\nmaxCloudCoverage\nSets the upper limit for cloud coverage in percent based on the precomputed cloud coverage estimate for each Sentinel-2 tile as present in the tile metadata. Satellite data will therefore not be retrieved for tiles with a higher cloud coverage estimate. For example, by setting the value to 20, only tiles with at most 20% cloud coverage will be used. Note that this parameter is set per tile and might not be directly applicable to the chosen area of interest.\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the S2L1C process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing when the pixel resolution is greater than the source resolution (e.g. 5m/px with a 10m/px source)\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nAs above except when the resolution is lower.\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\n\n\n\nAvailable Bands and Data\nThis chapter will explain the bands and data which can be set in the evalscript input object: Any string listed in the column Name can be an element of the input.bands array in your evalscript.\n\n\n\nName\nDescription\nResolution\nNotes\n\n\n\n\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m\n\n\n\nB04\nRed, 664.6 nm (S2A), 665.0 nm (S2B)\n10m\n\n\n\nB05\nVegetation red edge, 704.1 nm (S2A), 703.8 nm (S2B)\n20m\n\n\n\nB06\nVegetation red edge, 740.5 nm (S2A), 739.1 nm (S2B)\n20m\n\n\n\nB07\nVegetation red edge, 782.8 nm (S2A), 779.7 nm (S2B)\n20m\n\n\n\nB08\nNIR, 832.8 nm (S2A), 833.0 nm (S2B)\n10m\n\n\n\nB8A\nNarrow NIR, 864.7 nm (S2A), 864.0 nm (S2B)\n20m\n\n\n\nB09\nWater vapour, 945.1 nm (S2A), 943.2 nm (S2B)\n60m\n\n\n\nB10\nSWIR – Cirrus, 1373.5 nm (S2A), 1376.9 nm (S2B)\n60m\n\n\n\nB11\nSWIR, 1613.7 nm (S2A), 1610.4 nm (S2B)\n20m\n\n\n\nB12\nSWIR, 2202.4 nm (S2A), 2185.7 nm (S2B)\n20m\n\n\n\nsunAzimuthAngles\nSun azimuth angle\n5000m\n[1]\n\n\nsunZenithAngles\nSun zenith angle\n5000m\n[1]\n\n\nviewAzimuthMean\nViewing azimuth angle\n5000m\n[1]\n\n\nviewZenithMean\nViewing zenith angle\n5000m\n[1]\n\n\ndataMask\nThe mask of data/no data pixels (more).\nN/A\n[2]\n\n\n\n[1]: The data of this band is always resampled using nearest neighbor interpolation, regardless of the requested interpolation type.\n[2]: dataMask has no source resolution as it is calculated for each output pixel.\n\n\nUnits\nThe data values for each band in your custom script are presented in the units as specified here. In case more than one unit is available for a given band, you may optionally set the value of input.units in your evalscript setup function to one of the values in the Sentinel Hub Units column. Doing so will present data in that unit. The Sentinel Hub units parameter combines the physical quantity and corresponding units of measurement values. As such, some names more closely resemble physical quantities, others resemble units of measurement.\nThe Source Format specifies how and with what precision the digital numbers (DN) from which the unit is derived are encoded. Bands requested in DN units contain exactly the pixel values of the source data (see also Harmonize Values). Note that resampling may produce interpolated values. DN is also used whenever a band is derived computationally (like dataMask); such bands can be identified by having DN units and N/A source format. DN values are typically not offered if they do not simply represent any physical quantity, in particular, when DN values require source-specific (i.e. non-global) conversion to physical quantities.\nValues in non-DN units are computed from the source (DN) values with at least float32 precision. Note that the conversion might be nonlinear, therefore the full value range and quantization step size of such a band can be hard to predict. Band values in evalscripts always behave as floating point numbers, regardless of the actual precision.\nThe Typical Range indicates what values are common for a given band and unit, however outliers can be expected.\nFor Sentinel-2 optical data, the relation between DN and REFLECTANCE (default unit) is: DN = 10000 * REFLECTANCE. See also Harmonize Values.\n\n\n\nBand\nPhysical Quantity (units)\nSentinel Hub Units\nSource Format\nTypical Range\n\n\n\n\nOptical bands\nReflectance (unitless)\nREFLECTANCE (default)\nUINT15\n0 - 0.4*\n\n\nOptical bands\nDigital numbers (unitless)\nDN\nUINT15\n0 - 4000*\n\n\nsunAzimuthAngles\nAngle (degrees)\nDEGREES\nFLOAT32\n30 - 200\n\n\nviewAzimuthMean\nAngle (degrees)\nDEGREES\nFLOAT32\n90 - 300\n\n\nsunZenithAngles\nAngle (degrees)\nDEGREES\nFLOAT32\n15 - 80\n\n\nviewZenithMean\nAngle (degrees)\nDEGREES\nFLOAT32\n0 - 12\n\n\ndataMask\nN/A\nDN\nN/A\n0 - no data 1 - data\n\n\n\n*Higher values are expected in infrared bands. Reflectance values can easily be above 1.\n\nHarmonize Values\nESA updated the Sentinel-2 processing baseline to version 04.00 in January, 2022, which introduced breaking changes to the interpretation of digital numbers (DN). The optional harmonizeValues parameter gives you extra control over the values which enter your evalscript.\nharmonizeValues can be true (default) or false, and it's behavior depends on the units chosen:\n\nREFLECTANCE:\n\nharmonizeValues = true: negative reflectance values are clamped to zero. In other words, pixels with negative reflectance return zero reflectance instead.\nharmonizeValues = false: negative reflectance values can be returned.\n\nDN:\n\nharmonizeValues = true: DN values are harmonized so they are comparable with data from previous baselines. Therefore it still holds that DN = 10000 * REFLECTANCE. In addition, negative values are clamped to zero.\nharmonizeValues = false: DN values are exactly as provided in the source files themselves. The \"true\" DN value, you could say. Don't forget that values have different definitions with different processing baselines, careful with mosaicking!\n\n\n\n\n\nMosaicking\nAll mosaicking types are supported.\n\n\nScenes Object\nscenes object stores metadata. An example of metadata available in scenes object for Sentinel-2 L1C when mosaicking is ORBIT:\n\n\n\nProperty name\nValue\n\n\n\n\ndateFrom\n'2020-09-15T00:00:00Z'\n\n\ndateTo\n'2020-09-15T00:00:00Z'\n\n\ntiles[i].date\n'2020-09-15T10:17:52Z'\n\n\ntiles[i].shId\n11583048\n\n\ntiles[i].cloudCoverage\n2.09\n\n\ntiles[i].dataPath\n's3://sentinel-s2-l2a/tiles/33/T/VM/2020/9/15/0'\n\n\n\nProperties of a scenes object can differ depending on the selected mosaicking and in which evalscript function the object is accessed. Working with metadata in evalscript user guide explains all details and provide examples."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L1C.html#catalog-api-capabilities",
    "href": "APIs/SentinelHub/Data/S2L1C.html#catalog-api-capabilities",
    "title": "Sentinel-2 L1C",
    "section": "Catalog API Capabilities",
    "text": "Catalog API Capabilities\nTo access Sentinel 2 L1C product metadata you need to send search request to our Catalog API. The requested metadata will be returned as JSON formatted response to your request. This chapter will help with understanding Sentinel 2 L1C specific parameters for search request.\n\nCollection identifier: sentinel-2-l1c\n\n\nFilter extension\n\neo:cloud_cover cloud cover percentage\n\n\n\nDistinct extension\n\ndate"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L1C.html#examples",
    "href": "APIs/SentinelHub/Data/S2L1C.html#examples",
    "title": "Sentinel-2 L1C",
    "section": "Examples",
    "text": "Examples\nS2L1C examples"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S5PL2.html",
    "href": "APIs/SentinelHub/Data/S5PL2.html",
    "title": "Sentinel-5P L2",
    "section": "",
    "text": "General information about Sentinel-5p mission can be found here. Sentinel Hub offers Sentinel-5p Level 2 products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S5PL2.html#about-sentinel-5p-data",
    "href": "APIs/SentinelHub/Data/S5PL2.html#about-sentinel-5p-data",
    "title": "Sentinel-5P L2",
    "section": "",
    "text": "General information about Sentinel-5p mission can be found here. Sentinel Hub offers Sentinel-5p Level 2 products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S5PL2.html#accessing-sentinel-5p-data",
    "href": "APIs/SentinelHub/Data/S5PL2.html#accessing-sentinel-5p-data",
    "title": "Sentinel-5P L2",
    "section": "Accessing Sentinel-5P Data",
    "text": "Accessing Sentinel-5P Data\nTo access data you need to send a POST request to our process API. The requested data will be returned as the response to your request. Each POST request can be tailored to get you exactly the data you require. To do this requires setting various parameters which depend on the datasource you are querying. This chapter will help you understand the parameters for S5PL2 data. To see examples of such requests go here, and for an overview of all API parameters see the API Reference.\n\nData type identifier: sentinel-5p-l2\nUse sentinel-5p-l2 (previously S5PL2) as the value of the input.data.type parameter in your API requests. This is mandatory and will ensure you get Sentinel-5P L2 data.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object of the S5PL2 process API.\n\ntimeRange\nFor simple mosaicking, the time range which is requested is clipped to start at most 24 hours before the to date-time. The reason for this is that Sentinel-5P covers the globe in one day therefore longer time ranges are not neccessary. The limitation also improves the responsiveness of Sentinel Hub.\n\n\nmosaickingOrder\nSets the order of sources from which the output result is mosaicked. If there are multiple sources available for the same time, unless explicitly set otherwise, Sentinel Hub will take the source with the slowest timeliness (i.e. RPRO prefered to OFFL prefered to NRTI).\n\n\n\nValue\nDescription\n\n\n\n\nmostRecent\nthe pixel will be selected from the tile, which was acquired most recently\n\n\nleastRecent\nsimilar to mostRecent but in reverse order\n\n\n\n\n\ntimeliness\nYou can force the timeliness of the requested data. If not set and there are multiple sources available for the same time, Sentinel Hub will take the source with the slowest timeliness (RPRO prefered to OFFL prefered to NRTI). To explicitly set, the options are:\n\nNRTI for near realtime,\nOFFL for offline,\nRPRO for reprocessing.\n\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the S5PL2 process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing, regardless of the resolution\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nNot used, use upsampling instead\nN/A\nIgnored\n\n\nminQa\nSentinel-5P data is flagged with quality values (“qa_value”). minQa is the minimum (inclusive) pixel quality to be displayed in percent. For example, setting minQa = 75 will only display pixels with qa_value &gt;= 75%\nValues between 0 and 100.\n75 For NO250 for other products\n\n\n\n\n\nAvailable Bands and Data\nInformation in this chapter is useful when defining input object in evalscript: any string listed in the column Name can be an element of the input.bands array in your evalscript.\n\n\n\nName\nDescription\n\n\n\n\nCO\nCarbon monoxide, more.\n\n\nHCHO\nFormaldehyde, more.\n\n\nNO2\nNitrogen oxide, more.\n\n\nO3\nOzone, more.\n\n\nSO2\nSulphur dioxide, more.\n\n\nCH4\nMethane, more.\n\n\nAER_AI_340_380\nUV (Ultraviolet) Aerosol Index calculated based on wavelengths of 340 nm and 380 nm. More.\n\n\nAER_AI_354_388\nUV (Ultraviolet) Aerosol Index calculated based on wavelengths of 354 nm and 388 nm. More.\n\n\nCLOUD_BASE_PRESSURE\nCloud base pressure, more.\n\n\nCLOUD_TOP_PRESSURE\nCloud top pressure, more.\n\n\nCLOUD_BASE_HEIGHT\nCloud base height, more.\n\n\nCLOUD_TOP_HEIGHT\nCloud top height, more.\n\n\nCLOUD_OPTICAL_THICKNESS\nCloud optical thickness, more.\n\n\nCLOUD_FRACTION\nEffective radiometric cloud fraction, more.\n\n\ndataMask\nThe mask of data/no data pixels, more.\n\n\n\n\n\nUnits\nThe data values for each band in your custom script are presented in the units as specified here. In case more than one unit is available for a given band, you may optionally set the value of input.units in your evalscript setup function to one of the values in the Sentinel Hub Units column. Doing so will present data in that unit. The Sentinel Hub units parameter combines the physical quantity and corresponding units of measurement values. As such, some names more closely resemble physical quantities, others resemble units of measurement.\nThe Source Format specifies how and with what precision the digital numbers (DN) from which the unit is derived are encoded. Bands requested in DN units contain exactly the pixel values of the source data. Note that resampling may produce interpolated values. DN is also used whenever a band is derived computationally (like dataMask); such bands can be identified by having DN units and N/A source format. DN values are typically not offered if they do not simply represent any physical quantity, in particular, when DN values require source-specific (i.e. non-global) conversion to physical quantities.\nValues in non-DN units are computed from the source (DN) values with at least float32 precision. Note that the conversion might be nonlinear, therefore the full value range and quantization step size of such a band can be hard to predict. Band values in evalscripts always behave as floating point numbers, regardless of the actual precision.\nThe Typical Range indicates what values are common for a given band and unit, however outliers can be expected.\n\n\n\nProduct/Band\nPhysical Quantity (units)\nSentinel Hub Units\nSource Format\nTypical Range\nNotes\n\n\n\n\nCO\nCarbon monoxide total column (mol/m^2)\nMOL_M2\nFLOAT32\n0 - 0.1\nCertain events (wildfires) may cause these limits to be exceeded.\n\n\nHCHO\nFormaldehyde troposheric vertical column (mol/m^2)\nMOL_M2\nFLOAT32\n0 - 0.001\nCertain events (wildfires) may cause these limits to be exceeded.\n\n\nNO2\nNitrogen dioxide tropospheric column (mol/m^2)\nMOL_M2\nFLOAT32\n0 - 0.0003\nPeak values for polluted cities may reach two or three times the upper value.\n\n\nO3\nOzone total column (mol/m^2)\nMOL_M2\nFLOAT32\n0 - 0.36\n\n\n\nSO2\nSulfur dioxide total column (mol/m^2)\nMOL_M2\nFLOAT32\n0 - 0.01\nExplosive volcanic eruptions can exceed 0.35 mol/m^2 and instrumental noise can produce negative values.\n\n\nCH4\nColumn averaged dry air mixing ratio of methane (parts per billion)\nPPB\nFLOAT32\n1,600 - 2,000\n\n\n\nAER_AI_340_380\nUV aerosol index from 380 and 340 nm (unitless)\nINDEX\nFLOAT32\n-1 - 5\n\n\n\nAER_AI_354_388\nUV aerosol index from 388 and 354 nm (unitless)\nINDEX\nFLOAT32\n-1 - 5\n\n\n\nCLOUD_BASE_PRESSURE\nCloud base pressure (pascals)\nPASCALS\nFLOAT32\n1,000 - 110,000\n\n\n\nCLOUD_TOP_PRESSURE\nCloud top pressure (pascals)\nPASCALS\nFLOAT32\n1,000 - 110,000\n\n\n\nCLOUD_BASE_HEIGHT\nCloud base height (meters)\nMETERS\nFLOAT32\n0 - 20,000\n\n\n\nCLOUD_TOP_HEIGHT\nCloud top height (meters)\nMETERS\nFLOAT32\n0 - 20,000\n\n\n\nCLOUD_OPTICAL_THICKNESS\nCloud optical thickness (unitless)\nOPTICAL_DEPTH\nFLOAT32\n0 - 250\n\n\n\nCLOUD_FRACTION\nEffective radiometric cloud fraction (unitless)\nFRACTION\nFLOAT32\n0 - 1\n\n\n\ndataMask\nN/A\nDN\nN/A\n0 - no data 1 - data\n\n\n\n\n\n\nMosaicking\nSIMPLE and ORBIT mosaicking types are supported.\n\n\nScenes Object\nscenes object stores metadata. An example of metadata available in scenes object for Sentinel-5p L2 when mosaicking is ORBIT:\n\n\n\nProperty name\nValue\n\n\n\n\ntiles[i].date\n'2018-12-30T10:43:00Z'\n\n\ntiles[i].shId\n1900340\n\n\ntiles[i].dataPath\n'http://data.cloudferro.com/EODATA/Sentinel-5P/TROPOMI/L2__CO____/2018/12/30/S5P_OFFL_L2__CO_____20181230T104300_20181230T122430_06286_01_010202_20190105T100707/S5P_OFFL_L2__CO_____20181230T104300_20181230T122430_06286_01_010202_20190105T100707.nc'\n\n\n\nProperties of a scenes object can differ depending on the selected mosaicking and in which evalscript function the object is accessed. Working with metadata in evalscript user guide explains all details and provide examples.\n\n\nCollection Specific Constraints\nThe raw data is encoded as 32-bit float samples. For scientific usage it is best to set tiff as an output format and sampleType: SampleType.FLOAT32.\nSentinel-5P data can potentially contain many no data pixels which is a consequence of the way it is measured. We therefore suggest using the dataMask band to differentiate between actual zero values and no data."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S5PL2.html#catalog-api-capabilities",
    "href": "APIs/SentinelHub/Data/S5PL2.html#catalog-api-capabilities",
    "title": "Sentinel-5P L2",
    "section": "Catalog API Capabilities",
    "text": "Catalog API Capabilities\nTo access Sentinel 5P L2 product metadata you need to send search request to our Catalog API. The requested metadata will be returned as JSON formatted response to your request.\n\nCollection identifier: sentinel-5p-l2\n\n\nFilter extension\n\nsat:absolute_orbit\ns5p:type (available types)\ns5p:timeliness (possible values)\n\n\n\nDistinct extension\n\ndate\ns5p:type (available types)\n\n\n\nExamples\nS5PL2 Examples"
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html",
    "href": "APIs/SentinelHub/Batch.html",
    "title": "Batch Processing API",
    "section": "",
    "text": "The Batch Processing API is only available for users with Copernicus Service accounts. Please refer to our FAQ on account typology change and Submit an account change request to our Copernicus Data Space Ecosystem Support Team to request your Copernicus Service account.\nBatch Processing API (or shortly \"Batch API\") enables you to request data for large areas and/or longer time periods for any Sentinel Hub supported collection, including BYOC (bring your own data).\nIt is an asynchronous REST service. This means that data will not be returned immediately in a request response but will be delivered to your object storage, which needs to be specified in the request (e.g. bucket, see bucket settings below). The processing results will be divided in tiles as described below."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#workflow",
    "href": "APIs/SentinelHub/Batch.html#workflow",
    "title": "Batch Processing API",
    "section": "Workflow",
    "text": "Workflow\nThe batch processing API comes with the set of REST APIs which support the execution of various workflows. The diagram below shows all possible statuses of a batch processing request (CREATED, ANALYSING, ANALYSIS_DONE, PROCESSING, DONE, FAILED, CANCELED, PARTIAL) and user's actions (ANALYSE, START, RESTART, CANCEL) which trigger transitions among them.\n\n\n\n\nstateDiagram\n    [*]--&gt;CREATED\n    state fork_state_created &lt;&lt;fork&gt;&gt;\n    CREATED--&gt;fork_state_created\n    fork_state_created--&gt;PROCESSING: #128100; START\n    fork_state_created--&gt;ANALYSING: #128100; ANALYSE\n    ANALYSING --&gt; ANALYSIS_DONE\n    state fork_state_analysis_done &lt;&lt;fork&gt;&gt;\n    ANALYSIS_DONE--&gt;fork_state_analysis_done\n    fork_state_analysis_done--&gt;PROCESSING: #128100; START\n    PROCESSING--&gt;CANCELED: #128100; CANCEL\n    fork_state_analysis_done--&gt;CANCELED: #128100; CANCEL\n    fork_state_created--&gt;CANCELED: #128100; CANCEL\n    PROCESSING--&gt;DONE\n    PROCESSING--&gt;PARTIAL\n    PROCESSING--&gt;FAILED\n    PARTIAL--&gt;PROCESSING: #128100; RESTART\n    DONE--&gt;[*]\n    PARTIAL--&gt;[*]\n    FAILED--&gt;[*]\n    CANCELED--&gt;[*]\n\n\n\n\n\nThe workflow starts when a user posts a new batch processing request. In this step the system:\n\ncreates new batch processing request with status CREATED,\nvalidates the user's inputs, and\nreturns an estimated number of output tiles that will be processed.\n\nUser can then decide to either request an additional analysis of the request, start the processing or cancel the request. When additional analysis is requested:\n\nthe status of the request changes to ANALYSING,\nthe evalscript is validated,\na list of required tiles is created, and\nthe request's cost is estimated, i.e. the estimated number of processing units (PU) needed for the requested processing. Note that in case of ORBIT or TILE mosaicking the cost estimate can be significantly inaccurate, as described below.\nAfter the analysis is finished the status of the request changes to ANALYSIS_DONE.\n\nIn the evalscript validation for ORBIT and TILE mosaicking, we select a few orbits or tiles that match your request, and test if your evalscript can process them. We also test, if your evalscript can process the case, when no orbit or tile is passed. So make sure your evalscript handles this.\nIf the user chooses to directly start processing, the system still executes the analysis but when the analysis is done it automatically starts with processing. This is not explicitly shown in the diagram in order to keep it simple.\nThe user can now request a list of tiles for their request, start the processing, or cancel the request. When the user starts the processing:\n\nthe estimated number of PU is reserved,\nthe status of the request changes to PROCESSING (this may take a while),\nthe processing starts.\n\nWhen the processing finishes, the status of the request changes to:\n\nFAILED when all tiles failed processing,\nPARTIAL when some tiles were processed and some failed,\nDONE when all tiles were processed.\n\nAlthough the process has built-in fault tolerance, occasionally, tile processing may fail. In this case, the batch request ends up in status PARTIAL and user can request restart its processing as shown in this example. This will restart processing of all FAILED tiles.\n\nCanceling the request\nUser may cancel the request at any time. However:\n\nif the status is ANALYSING, the analysis will complete,\nif the status is PROCESSING, all tiles that have been processed or are being processed at that moment are charged for. The remaining PUs are returned to the user.\n\n\n\nAutomatic deletion of stale data\nStale requests will be deleted after some time. Specifically, the following requests will be deleted:\n\nfailed requests (request status FAILED),\nrequests that were created but never started (request statuses CREATED, ANALYSIS_DONE),\nsuccessful requests (request statuses DONE and PARTIAL) for which it was not requested to add the results to your collections. Note that only such requests themselves will be deleted, while the requests' result (created imagery) will remain under your control in your bucket.\n\n\n\nCost estimate\nThe cost estimate, provided in the analysis stage, is based on the rules for calculating processing units. It takes the number of output pixels, the number of input bands, and the output format into account. However, for mosaicking ORBIT or TILE the number of data samples (i.e. the no. of observations available in the requested time range) can not be calculated accurately during the analysis. Our cost estimate is thus based on the assumption that one data sample is available every three days within the requested time range. For example, we assume 10 available data samples between 1.1.2021 and 31.1.2021. If you request batch processing of more/fewer data samples, the actual cost will be proportionally higher/lower.\nThe actual costs can be significantly different from the estimate if:\n\nthe number of data samples is reduced in your evalscript by preProcessScenes function or by filters such as maxCloudCoverage. The actual cost will be lower than the estimate.\nyour AOI (area of interest) includes large areas with no data, e.g. when requesting Sentinel-2 data over oceans. The actual cost will be lower than the estimate.\nyou request processing of data collections with revisit period shorter/longer than three days (e.g. your BYOC collection). The actual cost will be proportionally higher/lower than the estimate. Revisit period depends also on selected AOI, e.g. the actual costs of processing Sentinel-2 data close to the equator/at high latitudes will be lower/higher than the estimate.\n\nIf you know how many data samples per pixel will be processed, you can adjust the estimate yourself. For example, if you request processing for data that is available daily, the cost will be 3 times higher than our estimate.\nNote that the cost estimate does not take the multiplication factor of 1/3 for batch processing into account. The actual costs will be 3 times lower than the estimate.\n\n\nTile status\nUsers can follow the progress of tile processing by checking for their current status. This can be done directly in Dashboard, or via the API. The statuses are as follows:\n\nIn the analysis phase, tiles are created with status PENDING.\nWhen tiles move into scheduling queue, their status changes to SCHEDULED.\nWhen a tile is pulled from the queue and processing starts, it becomes PROCESSING.\nWhen tile processing succeeds/fails, it's DONE/FAILED.\nIf a tile gets stuck, it goes back into PENDING up to twice. If it gets stuck the third time, it becomes a FAILED tile.\nWhen a batch request with status PARTIAL is restarted, all its FAILed tiles go back into PENDING.\n\n\n\n\n\nstateDiagram\n    [*]--&gt;PENDING: Analyzer creates tiles\n    PENDING--&gt;SCHEDULED: Move to scheduling queue\n    SCHEDULED --&gt; PROCESSING: Start processing\n    PROCESSING--&gt;DONE: Finished\n    PROCESSING--&gt;FAILED: Error\n    PROCESSING--&gt;PENDING: Stuck (up to 2x)"
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#tiling-grids",
    "href": "APIs/SentinelHub/Batch.html#tiling-grids",
    "title": "Batch Processing API",
    "section": "Tiling grids",
    "text": "Tiling grids\nFor more effective processing we divide the area of interest into tiles and process each tile separately. While process API uses grids which come together with each datasource for processing of the data, the batch API uses one of the predefined tiling grids. The predefined tiling grids 0-2 are based on the Sentinel-2 tiling in WGS84/UTM projection with some adjustments:\n\nThe width and height of tiles in the original Sentinel 2 grid is 100 km while the width and height of tiles in our grids are given in the table below.\nAll redundant tiles (i.e. fully overlapped tiles) are removed.\n\nAll available tiling grids can be requested with (NOTE: To run this example you need to first create an OAuth client as is explained here):\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/batch/tilinggrids/\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()\nThis will return the list of available grids and information about tile size and available resolutions for each grid. Currently, available grids are:\n\n\n\nname\nid\ntile size\nresolutions\ncoverage\noutput CRS\ndownload the grid [zip with shp file] **\n\n\n\n\nUTM 20km grid\n0\n20040 m\n10 m, 20 m, 30m*, 60 m\nWorld, latitudes from -80.7° to 80.7°\nUTM\nUTM 20km grid\n\n\nUTM 10km grid\n1\n10000 m\n10 m, 20 m\nWorld, latitudes from -80.6° to 80.6°\nUTM\nUTM 10km grid\n\n\nUTM 100km grid\n2\n100080 m\n30m*, 60 m, 120 m, 240 m, 360 m\nWorld, latitudes from -81° to 81°\nUTM\nUTM 100km grid\n\n\nWGS84 1 degree grid\n3\n1 °\n0.0001°, 0.0002°\nWorld, all latitudes\nWGS84\nWGS84 1 degree grid\n\n\nLAEA 100km grid\n6\n100000 m\n40 m, 50 m, 100 m\nEurope, including Turkey, Iceland, Svalbald, Azores, and Canary Islands\nEPSG:3035\nLAEA 100km grid\n\n\nLAEA 20km grid\n7\n20000 m\n10 m, 20 m\nEurope, including Turkey, Iceland, Svalbald, Azores, and Canary Islands\nEPSG:3035\nLAEA 20km grid\n\n\n\n** The geometries of the tiles are reprojected to WGS84 for download. Because of this and other reasons the geometries of the output rasters may differ from the tile geometries provided here.\nTo use 20km grid with 60 m resolution, for example, specify id and resolution parameters of the tilingGrid object when creating a new batch request (see an example of full request) as:\n{\n  ...\n  \"tilingGrid\": {\n    \"id\": 0,\n    \"resolution\": 60.0\n  },\n  ...\n}\nContact us if you would like to use any other grid for processing."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#batch-collection",
    "href": "APIs/SentinelHub/Batch.html#batch-collection",
    "title": "Batch Processing API",
    "section": "Batch collection",
    "text": "Batch collection\nBatch processing results can also be uploaded into a BYOC-like collection, which makes it possible to:\n\nAccess data with Processing API, by using the collection ID\nCreate a configuration with custom layers\nMake OGC requests to a configuration\nView data in EO Browser\n\nThe users can either upload data to an existing batch collection by specyfing the collectionId, or create a new one by using the createCollection parameter. Read about both options in BATCH API reference.\nWhen creating a new batch collection, one has to be careful to:\n\nMake sure that \"cogOutput\"=true\nMake sure the evalscript returns only single-band outputs\nKeep sampleType in mind, as the values the evalscript returns when creating a collection will be the values available when making a request to access it\n\nRegardless of whether the user specifies an existing collection or requests a new one, processed data will still upload to the users bucket, where they will be available for download and analysis."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#processing-results",
    "href": "APIs/SentinelHub/Batch.html#processing-results",
    "title": "Batch Processing API",
    "section": "Processing results",
    "text": "Processing results\nThe outputs of a batch processing will be stored to your object storage in either GeoTIFF (and JSON for metadata) or in Zarr format.\n\nGeoTIFF output format\nGeoTIFF format will be used if your request contains the output field. An example of a batch request with GeoTIFF output is available here.\nBy default, the results will be organized in sub-folders where one sub-folder will be created for each tile. Each sub-folder might contain one or more images depending on how many outputs were defined in the evalscript of the request.\nYou can also customize the sub-folder structure and file naming as described in the defaultTilePath parameter under output in BATCH API reference .\nYou can choose to return your GeoTIFF files as Cloud Optimized GeoTIFF (COG), by setting the cogOutput parameter under output in your request as true. Several advanced COG options can be selected as well - read about the parameter in BATCH API reference.\nThe results of batch processing will be in the projection of the selected tiling grid. For UTM-based grids, each part of the AOI (area of interest) is delivered in the UTM zone with which it intersects. In other words, in case your AOI intersects with more UTM zones, the results will be delivered as tiles in different UTM zones (and thus different CRSs).\n\n\nZarr output format\nZarr format will be used if your request contains the zarrOutput field. An example of a batch request with Zarr output is available here. Your request must only have one band per output and the application/json format in responses is not supported.\nThe outputs of batch processing will be stored as a single Zarr group containing one data array for each evalscript output and multiple coordinate arrays. By default, the Zarr will be stored in the folder you pass to the batch processing api in the path parameter under zarrOutput (see BATCH API reference). The folder must not contain any existing Zarr files. We recommend using a placeholder &lt;requestId&gt; as explained in the API reference to keep the results of your processing better organized.\nThe results of batch processing will be in the projection of the selected tiling grid. The tiling grids where output CRS is UTM zone are not supported for Zarr format output."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#bucket-settings",
    "href": "APIs/SentinelHub/Batch.html#bucket-settings",
    "title": "Batch Processing API",
    "section": "Bucket settings",
    "text": "Bucket settings\nThe results will be delivered in your own bucket hosted at Copernicus Data Space Ecosystem.\nIf you do not yet have a bucket at Copernicus Data Space Ecosystem, please follow these steps to get one.\nYou will have to configure your bucket to allow full access to Sentinel Hub. To do this, update your bucket policy to include the following statement (don’t forget to replace &lt;bucket_name&gt; with your actual bucket name):\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::ddf4c98b5e6647f0a246f0624c8341d9:root\"\n            },\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;\",\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}\nA python script to set a bucket policy can be downloaded here."
  },
  {
    "objectID": "APIs/SentinelHub/Batch.html#examples",
    "href": "APIs/SentinelHub/Batch.html#examples",
    "title": "Batch Processing API",
    "section": "Examples",
    "text": "Examples\nExample of Batch Processing Workflow"
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html",
    "href": "APIs/SentinelHub/Catalog.html",
    "title": "Catalog API",
    "section": "",
    "text": "Sentinel Hub Catalog API (or shortly \"Catalog\") is an API implementing the STAC Specification, describing geospatial information about different data used with Sentinel Hub."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#api-reference",
    "href": "APIs/SentinelHub/Catalog.html#api-reference",
    "title": "Catalog API",
    "section": "API Reference",
    "text": "API Reference\nAPI Reference for Sentinel Hub Catalog is available as an OpenAPI description.\nSimple search request for Sentinel-1 GRD with a bounding box (the coordinate reference system of the values is WGS84 longitude/latitude), available on 10th December 2019.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = requests.post(url, json=data)"
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#authentication",
    "href": "APIs/SentinelHub/Catalog.html#authentication",
    "title": "Catalog API",
    "section": "Authentication",
    "text": "Authentication\nAuthentication for the Catalog API works completely the same as authentication for other Sentinel Hub services, see Authentication chapter."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#pagination",
    "href": "APIs/SentinelHub/Catalog.html#pagination",
    "title": "Catalog API",
    "section": "Pagination",
    "text": "Pagination\nExecuting the request specified above returns search context fields at the end of the response, looking like this:\n{\n  \"context\": {\n    \"next\": 5,\n    \"limit\": 5,\n    \"returned\": 5\n  }\n}\nThe presence of the next attribute indicates there is more data available for this query, but the server chose to only return 5 results, because the limit specified was 5 (if limit is not specified, default value is 10). To query the next page of items, our request needs to include the next attribute with its value in the query, like so:\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"next\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = requests.post(url, json=data)\nThe response now includes the next page of items; in this case there is no next token in context, meaning no more items exist for this query."
  },
  {
    "objectID": "APIs/SentinelHub/Catalog.html#extensions",
    "href": "APIs/SentinelHub/Catalog.html#extensions",
    "title": "Catalog API",
    "section": "Extensions",
    "text": "Extensions\n\nFilter\nThe search endpoint by default only accepts the parameters described in OpenAPI. The Filter extension enables users to specify an additional parameter to filter on, while searching through data.\nThe syntax for filter is CQL2:\n{\n  \"filter\": {\n    \"op\": \"&lt;operator&gt;\",\n    \"args\": [\n      {\n        \"property\": \"&lt;property_name&gt;\"\n      },\n      \"&lt;value&gt;\"\n    ]\n  },\n  \"filter-lang\": \"cql2-json\"\n}\nIt is also possible to use simple cql2-text:\n{\n  \"filter\": \"eo:cloud_cover &gt; 90\"\n}\nThe available operators are eq, neq, lt, lte, gt, gte, between and not. Only and is currently supported as a logical operator. Be careful - different collections have different properties for the query filter available. The information describing this is available inside the documentation for each specific collection (ex. Sentinel-1 GRD).\n\n\nFields\nBy default, the search endpoint returns all the available attributes of each item. The fields extension provides a way for the client to specify which attributes should not be part of the output, making it easy for the client to not have to deal with unnecessary data.\nSyntax for the fields is:\n{\n  \"fields\": {\n    \"include\": [\n      \"&lt;property_name_1&gt;\",\n      \"&lt;property_name_2&gt;\"\n    ],\n    \"exclude\": [\n      \"&lt;property_name_3&gt;\",\n      \"&lt;property_name_4&gt;\",\n      \"&lt;property_name_5&gt;\"\n    ]\n  }\n}\n\nInclude/Exclude behaviour\n\nWhen no fields attribute is specified in the request, all the available attributes will be included in the response.\nIf the fields attribute is specified with an empty object, or both include and exclude are set to null or an empty array is returned, the attributes for each item will be as if include was set to a default set of [\"id\", \"type\", \"geometry\", \"bbox\", \"links\", \"assets\", \"properties.datetime\"].\nIf only include is specified, the attributes in include will be merged with the default set above.\nIf only exclude is specified, the attributes in exclude will be removed from the default set above.\nIf both include and exclude are specified, the rule is that an attribute must be included in and not excluded from the response.\n\n\n\n\nDistinct\nSometimes we don't want to search for product metadata, but want some general information about the product, such as for example, which acquisition dates are available for Sentinel-1 inside the specified bbox and time interval. distinct attribute inside a search request makes this possible.\nSyntax for distinct attribute is:\n{\n  \"distinct\": \"&lt;property_name&gt;\"\n}\nAs with the filter attribute, distinct is also a collection limited to some specific properties. Information describing these properties can be found inside each collection's documentation (ex. Sentinel-1 GRD)."
  },
  {
    "objectID": "APIs/SentinelHub/Data.html",
    "href": "APIs/SentinelHub/Data.html",
    "title": "Data",
    "section": "",
    "text": "Some of the data collections available in the Copernicus Data Space Ecosystem are indexed (or we could say “imported”) in Sentinel Hub, which means you can use Sentinel Hub APIs to work with these data collections. Each of the data collections available in Sentinel Hub has its own subchapter below, which describes how the data is pre-processed and how you can access it with Sentinel Hub. For a general description of these data collections and related satellite missions, please refer to the general Copernicus Data Space Ecosystem Data chapter.\n\n\n\n\n\n\n\nSentinel-1 GRD\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-2 L1C\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-2 L2A\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 OLCI L1B\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3 SLSTR L1B\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P L2\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Elevation Model (DEM) Data\n\n\n\n\n\n\n\n\n\n\n\n\n\nBring Your Own COG / Batch\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Fusion\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "APIs/SentinelHub/Catalog/Examples.html",
    "href": "APIs/SentinelHub/Catalog/Examples.html",
    "title": "Catalog API examples",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCatalog API Entry page\nCatalog API Entry page with link to other catalog API endpoints and available collections.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/\"\nresponse = oauth.get(url)\n\n\nList collections\nList all available collections. The list will include deployment specific collections and collections available to users through BYOC, Batch or Third Party Data Import functionalities.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections\"\nresponse = oauth.get(url)\n\n\nSentinel 2 L1C collection\nList single collection, in this case Sentinel 2 L1C collection.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections/sentinel-2-l1c/\"\nresponse = oauth.get(url)\n\n\nSimple GET search\nSimple version of search available via GET request is also available. The only query parameters that can be specified in this simpler version are: bbox, datetime, collections, limit and next.\nquery = {\n    \"bbox\": \"13,45,14,46\",\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": \"sentinel-1-grd\",\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.get(url, params=query)\n\n\nSimple POST search\nThe same parameters can also be specified a POST request, query parameters need to be specified as json formatted body and sent to server like:\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSimple POST search with pagination\nnext token can be specified in the request to get back the next page of results.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"next\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with GeoJSON\nInstead of bbox it is possible to add intersects attribute, which can be any type of GeoJSON object (Point, LineString, Polygon, MultiPoint, MultiPolygon).\ndata = {\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"intersects\": {\n        \"type\": \"Point\",\n        \"coordinates\": [\n            13,\n            45,\n        ],\n    },\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Filter\nfilter object can be used to instruct server to only return a specific subset of data.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 5,\n    \"filter\": \"sat:orbit_state='ascending'\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nGet Filter parameters for collection\nList all available filter parameters represented as JSON Schema.\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/collections/sentinel-1-grd/queryables\"\nresponse = oauth.get(url)\n\n\nSearch with Fields: No fields\nDefault outputs from the server can be quite verbose for some collections. By default, all available item properties are included in the response.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Empty fields\nfields attribute can be specific to return less information. When fields object is empty only a default set of properties is included: id, type, geometry, bbox, links, assets.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Include\nBy specifying additional attributes in the include list, those attributes are added to the output along with the default ones.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {\"include\": [\"properties.gsd\"]},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with Fields: Exclude\nexlude list can be used to exclude even the default ones from the output.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": [\"sentinel-2-l1c\"],\n    \"limit\": 1,\n    \"fields\": {\"exclude\": [\"properties.datetime\"]},\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch with distinct\nUsing distinct it is possible to get some overview of the data available inside the specified query. For example specifying date as an option will return a list of dates where data is available.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-01T00:00:00Z/2020-01-01T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 100,\n    \"distinct\": \"date\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\nOr see different Sentinel 1 instrument modes used.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-01T00:00:00Z/2020-01-01T00:00:00Z\",\n    \"collections\": [\"sentinel-1-grd\"],\n    \"limit\": 100,\n    \"distinct\": \"sar:instrument_mode\",\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\n\n\nSearch on BYOC/BATCH collections\nYou can search for features on your own BYOC or Batch collections. The functionality described above regarding GET and POST search is the same. The only difference is that you have to specify the collection id with the appropriate prefix on collections parameter (e.g: byoc-&lt;your-collection-id&gt; for byoc or batch-&lt;your-collection-id&gt; for batch). Remember that you will have to use the appropriate deployment endpoint depending on where your collection is hosted.\ndata = {\n    \"bbox\": [13, 45, 14, 46],\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-10T23:59:59Z\",\n    \"collections\": [\"byoc-&lt;byoc-collection-id&gt;\"],\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.post(url, json=data)\nOr using GET simple search endpoint:\nquery = {\n    \"bbox\": \"13,45,14,46\",\n    \"datetime\": \"2019-12-10T00:00:00Z/2019-12-11T00:00:00Z\",\n    \"collections\": \"batch-&lt;batch-collection-id&gt;\",\n    \"limit\": 5,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search\"\nresponse = oauth.get(url, params=query)"
  },
  {
    "objectID": "APIs/SentinelHub/Batch/Examples.html",
    "href": "APIs/SentinelHub/Batch/Examples.html",
    "title": "Examples of Batch Processing Workflow",
    "section": "",
    "text": "The requests below are written in Python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCreate a batch processing request\n\nOption 1: GeoTiff format output\nThis request defines which data is requested and how it will be processed. In this particular example we will calculate maximum NDVI over two months period for an area in Corsica and visualize the results using a built-in visualizer. The resulting image will in a Geotiff format. To create a batch processing request replace &lt;MyBucket&gt; with the name of your S3 bucket and run:\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/batch/process\"\n\nevalscript = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B04\", \"B08\"]\n            }],\n            output: [{\n                id: \"default\",\n                bands: 3\n            }],\n            mosaicking: Mosaicking.ORBIT\n        }\n    }\n\n    function calcNDVI(sample) {\n        var denom = sample.B04 + sample.B08\n        return ((denom != 0) ? (sample.B08 - sample.B04) / denom : 0.0)\n    }\n\n    const maxNDVIcolors = [\n        [-0.2, 0xbfbfbf],\n        [0, 0xebebeb],\n        [0.1, 0xc8c682],\n        [0.2, 0x91bf52],\n        [0.4, 0x4f8a2e],\n        [0.6, 0x0f540c]\n    ]\n\n    const visualizer = new ColorRampVisualizer(maxNDVIcolors);\n\n    function evaluatePixel(samples) {\n        var max = 0\n        for (var i = 0; i &lt; samples.length; i++) {\n            var ndvi = calcNDVI(samples[i])\n            max = ndvi &gt; max ? ndvi : max\n        }\n        ndvi = max\n        return visualizer.process(ndvi)\n    }\n\"\"\"\n\npayload = {\n    \"processRequest\": {\n        \"input\": {\n            \"bounds\": {\n                \"bbox\": [\n                    8.44,\n                    41.31,\n                    9.66,\n                    43.1\n                ],\n                \"properties\": {\n                    \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n                }\n            },\n            \"data\": [{\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-01T00:00:00Z\",\n                        \"to\": \"2019-06-30T00:00:00Z\"\n                    },\n                \"maxCloudCoverage\": 70.0\n                },\n                \"type\": \"sentinel-2-l2a\"\n            }]\n        },\n        \"output\": {\n            \"responses\": [{\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/tiff\"\n                }\n            }]\n        },\n        \"evalscript\": evalscript\n    },\n    \"tilingGrid\": {\n        \"id\": 0,\n        \"resolution\": 60.0\n    },\n    \"bucketName\": \"&lt;MyBucket&gt;\",\n\n    \"description\": \"Max NDVI over Corsica\"\n}\n\nheaders = {\n  'Content-Type': 'application/json'\n}\n\nresponse = oauth.request(\"POST\", url, headers=headers, json = payload)\n\nresponse.json()\nExtracting the batch request id from the response:\nbatch_request_id = response.json()['id']\n\n\nOption 2: Zarr format output\nIn this example we will calculate maximum NDVI over two months period for an area in Corsica. Besides maximum NDVI, we will also return values of bands B04 and B08, which were used to calculate maximum NDVI. All three results will be stored as arrays of an output Zarr file. To create a batch processing request replace &lt;MyBucket&gt; with the name of your S3 bucket and run:\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/batch/process\"\n\nevalscript = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B04\", \"B08\"]\n            }],\n            output: [{\n                id: \"maxNDVI\",\n                sampleType: \"FLOAT32\",\n                bands: 1\n            },\n            {\n                id: \"band04\",\n                sampleType: \"UINT16\",\n                bands: 1\n            },\n            {\n                id: \"band08\",\n                sampleType: \"UINT16\",\n                bands: 1\n            }],\n            mosaicking: Mosaicking.ORBIT\n        }\n    }\n\n    function calcNDVI(sample) {\n        var denom = sample.B04 + sample.B08\n        return ((denom != 0) ? (sample.B08 - sample.B04) / denom : 0.0)\n    }\n\n    function evaluatePixel(samples) {\n        var maxNDVI = 0\n        var band04 = 0\n        var band08 = 0\n        for (var i = 0; i &lt; samples.length; i++) {\n            var ndvi = calcNDVI(samples[i])\n            if (ndvi &gt; maxNDVI){\n                maxNDVI = ndvi\n                band04 = samples[i].B04\n                band08 = samples[i].B08\n            }\n        }\n\n        return {\n            maxNDVI: [maxNDVI],\n            band04: [band04],\n            band08: [band08]\n        }\n    }\n\"\"\"\n\npayload = {\n    \"processRequest\": {\n        \"input\": {\n            \"bounds\": {\n                \"bbox\": [\n                    8.44,\n                    41.31,\n                    9.66,\n                    43.1\n                ],\n                \"properties\": {\n                    \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n                }\n            },\n            \"data\": [{\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-01T00:00:00Z\",\n                        \"to\": \"2019-06-30T00:00:00Z\"\n                    },\n                \"maxCloudCoverage\": 70.0\n                },\n                \"type\": \"sentinel-2-l2a\"\n            }]\n        },\n        \"output\": {\n            \"responses\": [{\n                \"identifier\": \"band08\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            },\n                {\n                \"identifier\": \"band04\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            },\n                {\n                \"identifier\": \"maxNDVI\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            }]\n        },\n        \"evalscript\": evalscript\n    },\n    \"tilingGrid\": {\n        \"id\": 6,\n        \"resolution\": 100.0\n    },\n    \"zarrOutput\": {\n        \"path\": \"&lt;MyBucket&gt;/&lt;requestId&gt;\",\n        \"group\": {\n            \"zarr_format\": 2\n        },\n        \"arrayParameters\": {\n            \"dtype\": \"&lt;u2\",\n            \"order\": \"C\",\n            \"chunks\": [1, 1000, 1000],\n            \"fill_value\": 0\n        },\n        \"arrayOverrides\": {\n            \"maxNDVI\": {\n                \"dtype\": \"&lt;f4\",\n                \"fill_value\": \"NaN\"\n            },\n        }\n    },\n    \"description\": \"Max NDVI over Corsica with Zarr format output\"\n}\n\nheaders = {\n  'Content-Type': 'application/json'\n}\n\nresponse = oauth.request(\"POST\", url, headers=headers, json = payload)\n\nresponse.json()\nExtracting the batch request id from the response:\nbatch_request_id = response.json()['id']\n\n\n\nGet information about all your batch processing requests\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()\n\n\nGet information about a batch processing request\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()\n\n\nGet current status of a batch processing request\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()['status']\n\n\nRequest detailed analysis (ANALYSE)\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/analyse\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\n\nGet tiles for a batch processing request (optional)\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/tiles\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()\n\n\nRequest the start of processing (START)\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/start\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\n\nGet the latest user's action for a batch processing request\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()['userAction']\n\n\nCancel a batch processing request (CANCEL)\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/cancel\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\n\nRestart a partially processed batch processing request (RESTART)\nIf case your batch processing fails only for some tiles while some are processed successfully (i.e. your batch processing request has status PARTIAL), you can restart the processing for all FAILED tiles by running the following code.\nurl = f\"https://sh.dataspace.copernicus.eu/api/v1/batch/process/{batch_request_id}/restartpartial\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\n\nCreate a new batch collection\nAdd the parameters cogOutput and createCollection as true to your request output. Add also description\": \"&lt;Name&gt;\" to the request, to name your collection.\n\"description\": \"&lt;Name&gt;\",\n\"output\": {\n  \"defaultTilePath\": \"s3://&lt;MyBucket&gt;/&lt;MyFolder&gt;\",\n  \"cogOutput\": true,\n  \"createCollection\": true\n}\nNote that custom collections can only contain single-band TIFFs. To create a multi-band collection, return separate bands as multiple outputs in the evalscript and connect them to multiple identifiers in the request.\nThe output format of batch requests determines the data format of the collection. By default, the output format of batch requests will be in sampleType.AUTO, which means that batch results 0..1 will be scaled to 0..255 and stored as UINT8. Processing API request on the resulting collection will thus get values 0..255 as input. We recommend you instead use FLOAT32 as the sampleType for the batch request, so the batch request output is exactly the same as what you get with a process requests on the resulting collection."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html",
    "href": "APIs/SentinelHub/Evalscript/V3.html",
    "title": "Evalscript V3",
    "section": "",
    "text": "Start your evalscript with //VERSION=3 so the system will interpret it as such.\nFor evalscript V3 you need to specify two functions (described in detail below):\nThis is an example of a simple V3 evalscript which returns a true color image:"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#setup-function",
    "href": "APIs/SentinelHub/Evalscript/V3.html#setup-function",
    "title": "Evalscript V3",
    "section": "setup function",
    "text": "setup function\nThis function is required as it sets up the input and output settings.\n\nSpecifics\nSetup needs to return a javascript object with the following properties:\n\ninput - an array of strings representing band names or an array of input objects.\noutput - a single output object or an array of output objects.\nmosaicking (optional) -  defines input sample preparation, see mosaicking. Defaults to SIMPLE.\n\n\nInput object properties\n\nbands - an array of strings representing band names\nunits (optional) - a string (all bands will use this unit) or an array of strings listing the units of each band. For a description of units see the documentation of the collection you are querying. Defaults to the default units for each band.\nmetadata (optional) - an array of strings representing properties which can be added to the metadata. Options:\n\n\"bounds\" - specifying this will add dataGeomtery and dataEnvelope to tiles\n\n\n\n\nOutput object properties\n\nid (optional) - any string of your choosing. Must be unique if multiple output objects are defined. Defaults to default.\nbands - the number of bands in this output.\nsampleType (optional) - sets the SampleType constant defining the returned raster sample type. Defaults to AUTO.\nnodataValue (optional) - sets the GDAL nodata metadata tag to the specified value. Only applicable for tiff files.\n\nNote that the number of bands represent the number of components in the output image. JPEG and PNG, for example, can only support 1 or 3 color components (plus an alpha channel for PNG, if set). The sampleType also needs to be compatible with the output raster format.\n\n\nMosaicking\nMosaicking defines how the source data is mosaicked. Not all collections support all these mosaicking types as it depends on how the source data is distributed. See the collection information pages to determine which ones are supported. It is a constant which is specified by a string. To use, for example, set: mosaicking: \"SIMPLE\".\n\nSIMPLE (default) - the simplest method, it flattens the mosaicked image so only a single sample is passed to evaluation. \nORBIT - the mosaicked image is flattened for each orbit so that there is only one sample per pixel per orbit. Multiple samples can therefore be present if there is more than one orbit for the selected time range at the pixel location.\nTILE - this is essentially the unflattened mosaic. It contains all data available for the selected time range. Multiple samples can be present as each sample comes from a single scene. What a scene is is defined by the datasource. \n\n\n\n\n\n\n\nNote\n\n\n\nORBIT mosaicking currently does not work exactly as described but generates a single scene for each day containing satellite data. For most requests this should not be an issue, however high latitude regions may have more than one acquisition per day. For these consider using TILE mosaicking if getting all available data is paramount. This will be corrected in future releases.\n\n\n\n\nSampleType\nSampleType defines the sample type of the output raster. This needs to be compatible with the raster format (e.g. JPEG cannot be FLOAT32). It is a constant which is specified by a string. To use, for example, set: sampleType: \"AUTO\".\n\nINT8 - signed 8-bit integer (values should range from -128 to 127)\nUINT8 - unsigned 8-bit integer (values should range from 0 to 255)\nINT16 - signed 16-bit integer (values should range from -32768 to\n\n\n\nUINT16 - unsigned 16-bit integer (values should range from 0 to\n\n\n\nFLOAT32 - 32-bit floating point (values have effectively no limits)\nAUTO (default) - values should range from 0-1, which will then automatically be stretched from the interval [0, 1] to [0, 255] and written into an UINT8 raster. Values below 0 and above 1 will be clamped to 0 and 255, respectively. This is the default if sampleType is not set in the output object.\n\nHandling SampleType in an Evalscript\nIt is the responsibility of the evalscript to return the values in the interval expected for the chosen sampleType. For integer SampleTypes, any floating point values will be rounded to the nearest integer and clamped to the value range of the SampleType. There is no need to do this yourself. For example, in case of UINT8 output, a value of 40.6 will be saved as 41, and a value of 310 will be saved as 255. If no sampleType is specified, AUTO is selected and the evalscript should return values ranging from 0-1. This is convenient as handling reflectance (e.g. Sentinel-2) data can be more intuitive.\n\n\n\nExamples\nThis simple Sentinel-2 setup() function gets bands B02, B03, B04 and returns (UINT16) 16 bit unsigned raster values.\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"B02\", \"B03\", \"B04\"], // this sets which bands to use\n      units: \"DN\" // here we optionally set the units. All bands will be in this unit (in this case Digital numbers)\n    }],\n    output: { // this defines the output image type\n      bands: 3, // the output of this evalscript will have RGB colors\n      sampleType: \"UINT16\" // raster format will be UINT16\n    }\n  };\n}\nThis Sentinel-2 setup() function gets bands B02, B03, B04 and returns a single raster with 8-bit integer values. To return values in the correct interval for the UINT8 sampleType, the evaluatePixel() function multiplies the reflectance values by 255. A true color image is returned.\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"B02\", \"B03\", \"B04\"], // this sets which bands to use\n    }],\n    output: {\n      bands: 3,\n      sampleType: \"UINT8\" // raster format will be UINT8\n    }\n  };\n}\nfunction evaluatePixel(sample) {\n  return [sample.B04 * 255, sample.B03 * 255, sample.B02 * 255]; // bands need to be multiplied by 255\n}\nIn case of UINT16, the multiplication factor in evaluatePixel() would be 65535 instead of 255.\nThe following example uses bands with different units and produces two rasters:\nfunction setup() {\n    return {\n      input: [{\n          bands: [\"B02\", \"B03\", \"B04\", \"B08\"],\n          units: [\"reflectance\", \"reflectance\", \"reflectance\", \"DN\"] // B08 will be in digital numbers, the rest reflectance\n      }],\n      output: [{ // this is now an array since there are multiple output objects\n          id: \"rgb\"\n          bands: 3\n      }, {\n          id: \"falseColor\"\n          bands: 3\n      }]\n    }\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#evaluatepixel-function",
    "href": "APIs/SentinelHub/Evalscript/V3.html#evaluatepixel-function",
    "title": "Evalscript V3",
    "section": "evaluatePixel function",
    "text": "evaluatePixel function\nThe evaluatePixel function is a mapping which maps the input bands in their input units to the values in the output raster(s). The function is executed once for each output pixel.\n\nParameters\nThe evaluatePixel function has five positional parameters:\nfunction evaluatePixel(samples, scenes, inputMetadata, customData, outputMetadata)\nThe first two parameters can be objects or arrays depending on requested mosaicking as explained below. They are additionally changed for data fusion requests, which is documented separately here. The remaining parameters are always objects.\n\nsamples\n\nWhen mosaicking is SIMPLE:\n\nsamples - an object containing the band values of the single mosaicked sample, in the specified units, as its properties. The property names equal the names of all the input bands, pixel values of a band can be accessed as e.g. samples.B02.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen using mosaicking SIMPLE we usually call this parameter sample in our examples to emphasize that it is an object and not an array.\n\n\n\nWhen mosaicking is TILE or ORBIT:\n\nsamples - an array of samples as defined in the SIMPLE case. None1, one or multiple samples can therefore be present depending on how many orbits/tiles there are for the selected time range and area of interest. Pixel values of a band can be accessed for each sample as an item of the array, e.g. samples[0].B02.\n\n\n\n\nscenes\n\nWhen mosaicking is SIMPLE:\n\nscenes object is empty.\n\nWhen mosaicking is ORBIT:\n\nscenes - an object containing a property orbits. scenes.orbits is an array of objects, where each of them contains metadata for one orbit (day). The length of scenes.orbits array is always the same as the length of samples array. A property, for example dateFrom, can be accessed as scenes.orbits[0].dateFrom. Each object's properties include:\n\ndateFrom (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. Together with orbits.dateTo it represents the time interval of one day. All tiles acquired on this day are mosaicked into this scene.\ndateTo (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. Together with orbits.dateFrom it represents the time interval of one day. All tiles acquired on this day are mosaicked into this scene.\ntiles (array) - an array of metadata for each tile used for mosaicking of this orbit. Each element has the same properties as elements of scenes.tiles (listed just below for mosaicking TILE).\n\n\nWhen mosaicking is TILE:\n\nscenes - an object containing a property tiles. scenes.tiles is an array of objects, where each of them contains metadata for one tile. The length of scenes.tiles array is always the same as the length of samples array. A property, for example cloudCoverage, can be accessed as scenes.tiles[0].cloudCoverage. Which properties are available for each tiles element depends on requested data and is documented in the \"Scenes Object\" chapter for each data collection, e.g. here for Sentinel-2 L1C. All possible properties are:\n\ndate (string) - ISO date and time in \"YYYY-MM-DDTHH:MM:SSZ\" format. It represents a date when the tile was acquired.\ncloudCoverage (number) - Estimated percentage of pixels covered by clouds in the tile. This field is not available for all data collections. A value 2.09 means that 2.09% of pixels in the tile are cloudy.\ndataPath (string) - Path to where the tile is stored on a cloud. For example \"s3://sentinel-s2-l2a/tiles/33/T/VM/2020/9/15/0\".\ndataGeometry (geojson - like object, see example) - an optional property, added only when requested. Represents a geometry of data coverage within the tile.\ndataEnvelope (geojson - like object, see example) - an optional property, added only when requested. Represents a bbox of dataGeometry.\nshId (number) - Sentinel Hub internal identifier of the tile. For example 11583048.\n\n\n\nNOTE 1: Objects may contain also fields prefixed by __ (double underscore). Such fields are used internally by Sentinel Hub services. Evalscripts should not make use of them because they can be changed or removed at any time and must never modify or delete such fields. Doing so may cause your request to fail or return incorrect results.\nNOTE 2: In the first implementation, scenes was an array of objects, where each of them contained metadata for one orbit or tile (depending on selected mosaicking). It was possible to access metadata as e.g. scenes[0].date. This approach is now deprecated and we strongly advise to use scenes as described above.\n\n\ninputMetadata\ninputMetadata is an object containing metadata used for processing by Sentinel Hub. Its properties are:\n\nserviceVersion - the version of Sentinel Hub which was used for processing.\nnormalizationFactor - the factor used by Sentinel Hub to convert digital numbers (DN) to reflectance using REFLECTANCE = DN * normalizationFactor. This is useful when requesting bands for which both units - DN and REFLECTANCE - are supported.\n\n\n\ncustomData\ncustomData is an object reserved for possible future use.\n\n\noutputMetadata\noutputMetadata is an object which can be used to output any user defined metadata including passing scenes objects, user defined thresholds or ids of original tiles used for processing. It contains:\n\nuserData - is a property to which you can assign a generic object that can contain any data. This can be pushed to the API response by adding a userdata identified output response object to your API request (see this for details or an example here).\n\n\n\n\nReturns\nThe evaluatePixel function can return:\n\nAn object whose keys are the output ids and its values are arrays of numbers. The length of the array is bound by the output object bands number and the values by sampleType.\nAn array of numbers with the same rules as above. This option can be used only when a single image output is defined.\nNothing; the return statement is not specified. This is useful when only information in outputMetadata.userData is needed.\n\n\nInput Units and Output Values\nThe values of each sample is the units specified in the input object. See the input object documentation for more information. How the output values are written to the output raster depends on the sample type. AUTO will stretch values in the interval [0, 1] to [0, 255] and then write those values into an UINT8 raster. The remaining sample types expect values within the range of the sample format.\n\n\n\nExamples\nExample evaluatePixel script returns a simple True Color image based on bands B04, B03, B02:\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02];\n}\nWhen we have multiple outputs in the setup function we can provide them as such:\nfunction evaluatePixel(sample) {\n  return {\n    trueColor: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n    falseColor: [2.5 * sample.B08, 2.5 * sample.B04, 2.5 * sample.B03]\n  };\n}\nCalculate the average value of band B04 when using ORBIT or TILE mosaicking:\nfunction evaluatePixel(samples) {\n  var sum = 0;\n  var nonZeroSamples = 0;\n  for (var i = 0; i &lt; samples.length; i++) {\n    var value = samples[i].B04;\n    if (value != 0) {\n      sum += value;\n      nonZeroSamples++;\n    }\n  }\n  return [sum / nonZeroSamples];\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#updateoutput-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#updateoutput-function-optional",
    "title": "Evalscript V3",
    "section": "updateOutput function (optional)",
    "text": "updateOutput function (optional)\nThis function can be used to adjust the number of output bands. This is useful, for example, to request all observations in a given time period as bands of an output file. The function is executed after the setup and preProcessScenes functions but before the evaluatePixel.\n\nParameters\n\noutput - an object containing ids of all outputs and their number of bands as specified in the setup function (Note: This is not the same object as output in the setup function.). The number of bands of each output is stored under output.&lt;output id&gt;.bands where &lt;output id&gt; is equal to values in the setup.output object. For example:\n\n{\n    \"default\": {\n        \"bands\": 2\n    },\n    \"my_output\": {\n        \"bands\": 3\n    }\n}\n\ncollection - an object containing one array per requested data collection. The length of each array equals the number of scenes available for processing. If only one data collection is requested, use collection.scenes.length to get the number of available scenes. For data fusion requests, use collection.&lt;data collection identifier&gt;.scenes.length. Each element in an array has a property:\n\ndate (type Date) - the date when the corresponding scene was acquired.\n\n\n\n\nReturns\nThis function updates the number of output bands and does not return anything.\n\n\nExample\nSuppose we request sentinel-2-l1c data from January 2020 with a maximum of 50% cloud coverage. All of this is specified in the body of a request. We would then like to return all available scenes as bands of an output file. Since we generally do not know how many scenes are available, we can not set the number of output bands directly in a setup function. Using the updateOutput function we can get the number of available scenes from collection and assign it as the value of output.&lt;output id&gt;.bands:\n//VERSION=3\nfunction setup() {\n    return {\n        input: [{\n                bands: [\"B02\"],\n            }\n        ],\n        output: [{\n                id: \"my_output\",\n                bands: 1,\n                sampleType: SampleType.UINT16\n            }\n        ],\n        mosaicking: Mosaicking.ORBIT\n    }\n}\n\nfunction updateOutput(output, collection) {\n    output.my_output.bands = collection.scenes.length\n}\n\nfunction evaluatePixel(samples) {\n    var n_scenes = samples.length\n    let band_b02 = new Array(n_scenes)\n\n    // Arrange values of band B02 in an array\n    for (var i = 0; i &lt; n_scenes; i++){\n        band_b02[i] = samples[i].B02\n    }\n\n    return {\n        my_output: band_b02\n    }\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#updateoutputmetadata-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#updateoutputmetadata-function-optional",
    "title": "Evalscript V3",
    "section": "updateOutputMetadata function (optional)",
    "text": "updateOutputMetadata function (optional)\nThis function is optional and if present is called at the end of evalscript evaluation. It provides a convenient way to forward information pertaining to the returned data as a whole (as opposed to evaluatePixel which is run for each pixel) into an output object. Do this by assigning any object you require to the userData property of the outputMetadata parameter.\n\nParameters\nThese are the full parameters of the updateOutputMetadata function:\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata)\nSee description of parameters in the \"evaluatePixel function\" chapter:\n\nscenes - scenes\ninputMetadata - inputMetadata\noutputMetadata - outputMetadata"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#preprocessscenes-function-optional",
    "href": "APIs/SentinelHub/Evalscript/V3.html#preprocessscenes-function-optional",
    "title": "Evalscript V3",
    "section": "preProcessScenes function (optional)",
    "text": "preProcessScenes function (optional)\nThis function is optional, and if present is called at the beginning of the script evaluation before the actual satellite data is processed. Use it when mosaicking is set to ORBIT or TILE. It provides additional filtering functionality for scenes, after the constraints set in the request parameters are already applied. This is useful, for example, to reduce the number of scenes needed, thereby reducing processing time and the number of processing units for the request.\n\nParameters\nThese are the full parameters of the preProcessScenes function:\nfunction preProcessScenes(collections)\n\ncollections\ncollections is an object, which contains different properties depending on which mosaicking option is selected.\n\nIf mosaicking is ORBIT, collections contains:\n\nfrom (type Date) - the value given as timeRange.from in the body of the request, representing the start of the search interval\nto (type Date) - the value given as timeRange.to in the body of the request, representing the end of the search interval\nscenes.orbits - corresponds to scenes.orbits as described for evalautePixel function and mosaicking ORBIT here but it doesn't contain tiles.\n\nIf mosaicking is TILE, collections contains:\n\nscenes.tiles - corresponds to scenes.tiles as described for evalautePixel function and mosaicking TILE here.\n\n\n\n\n\nReturns\nThe preProcessScenes function must return an objects of the same type as collections. Most often, a sub-set of the input collections will be returned, e.g. to keep only the data acquired before 1.2.2019:\nfunction preProcessScenes(collections){\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (scene) {\n        return new Date(scene.dateFrom) &lt; new Date(\"2019-02-01T00:00:00Z\")\n    });\n    return collections\n}\n\n\nExamples\n\nFilter scenes by particular days\nIn this example, we use preProcessScenes function to select images acquired on two particular dates within the requested timeRange. This example was taken (and adopted) from the evalscript for delineation of burned areas, based on the comparison of Sentinel-2 images acquired before (i.e. on \"2017-05-15\") and after (i.e. on \"2017-06-24\") the event.\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    var allowedDates = [\"2017-05-15\", \"2017-06-24\"]; //before and after Knysna fires\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var orbitDateFrom = orbit.dateFrom.split(\"T\")[0];\n        return allowedDates.includes(orbitDateFrom);\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    var allowedDates = [\"2017-05-15\", \"2017-06-24\"]; //before and after Knysna fires\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (tile) {\n        var tileDate = tile.date.split(\"T\")[0];\n        return allowedDates.includes(tileDate);\n    })\n    return collections\n}\n\n\n\nFilter scenes by time interval\nHere, we filter out (= remove) all the scenes acquired between the two selected dates, which both fall within the requested time range.\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        return (new Date(orbit.dateFrom) &lt; new Date(\"2019-01-31T00:00:00Z\")) ||\n               (new Date(orbit.dateFrom) &gt;= new Date(\"2019-06-01T00:00:00Z\"))\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (tile) {\n        return (new Date(tile.date) &lt; new Date(\"2019-01-31T00:00:00Z\")) ||\n               (new Date(tile.date) &gt;= new Date(\"2019-06-01T00:00:00Z\"))\n    })\n    return collections\n}\n\n\n\nSpecify the number of months taken into account\nValues of timeRange.from and timeRange.to parameters as given in the request, are available in the preProcessScenes function as collections.to and collections.from, respectively. Mosaicking must be ORBIT to use these parameters. They can be used to e.g. filter out scenes acquired more than 3 months before the given to date and time.\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var orbitDateFrom = new Date(orbit.dateFrom)\n        return orbitDateFrom.getTime() &gt;= (collections.to.getTime()-3*31*24*3600*1000);\n    })\n    return collections\n}\nThe 3*31*24*3600*1000 represents the 3 months converted to milliseconds. This is needed, so that a 3-month time span can be compared to scene.dateFrom and collections.to, which are all returned as milliseconds since 1970-1-1 by the getTime() function. Note: The result is the same as if the timeRange.from parameter in the body of the request is set to 3 months prior to the timeRange.to.\n\n\nSelect one image per month\nIn this example, we filter the available scenes, so that only the first scene acquired in each month is sent to the evaluatePixel function:\n\nIf mosaicking is ORBIT:\nfunction preProcessScenes (collections) {\n    collections.scenes.orbits.sort(function (s1, s2) {\n            var date1 = new Date(s1.dateFrom);\n            var date2 = new Date(s2.dateFrom);\n            return date1 - date2}) // sort the scenes by dateFrom in ascending order\n\n    firstOrbitDate = new Date(collections.scenes.orbits[0].dateFrom)\n    var previousOrbitMonth = firstOrbitDate.getMonth() - 1\n    collections.scenes.orbits = collections.scenes.orbits.filter(function (orbit) {\n        var currentOrbitDate = new Date(orbit.dateFrom)\n        if (currentOrbitDate.getMonth() != previousOrbitMonth){\n            previousOrbitMonth = currentOrbitDate.getMonth();\n            return true;\n        } else return false;\n    })\n    return collections\n}\n\n\nIf mosaicking is TILE:\nfunction preProcessScenes (collections) {\n    collections.scenes.tiles.sort(function (s1, s2) {\n            var date1 = new Date(s1.date);\n            var date2 = new Date(s2.date);\n            return date1 - date2}) // sort the scenes by dateFrom in ascending order\n\n    firstTileDate = new Date(collections.scenes.tiles[0].date)\n    var previousTileMonth = firstTileDate.getMonth() - 1\n    collections.scenes.tiles = collections.scenes.tiles.filter(function (scene) {\n        var currentTileDate = new Date(scene.date)\n        if (currentTileDate.getMonth() != previousTileMonth){\n            previousTileMonth = currentTileDate.getMonth();\n            return true;\n        } else return false;\n    })\n    return collections\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#ogc-services-specifics",
    "href": "APIs/SentinelHub/Evalscript/V3.html#ogc-services-specifics",
    "title": "Evalscript V3",
    "section": "OGC services specifics",
    "text": "OGC services specifics\nThere are some specifics when using evalscript V3 with WMS, WTS, WCS services:\n\nThese services return only the default output. Only one image can be returned with each request and it is not possible to request metadata in JSON format.\nTRANSPARENCY and BGCOLOR parameters are ignored. You can use dataMask band in evalscript V3 to handle transparency, as described here.\nBit depth, which is given as the part of a FORMAT parameter (e.g. FORMAT=image/tiff;depth=8) is ignored. You can use sampleType in evalscript V3 to request the bit depth of your choice."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/V3.html#footnotes",
    "href": "APIs/SentinelHub/Evalscript/V3.html#footnotes",
    "title": "Evalscript V3",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn case samples is an empty array, calling samples[0].B02 will raise an error and it is up to users to handle this in their evalscript.↩︎"
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html",
    "href": "APIs/SentinelHub/Byoc.html",
    "title": "Bring Your Own COG API",
    "section": "",
    "text": "Bring Your Own COG API is only available for users with Copernicus Service accounts. Please refer to our FAQ on account typology change and Submit an account change request to our Copernicus Data Space Ecosystem Support Team to request your Copernicus Service account accordingly."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#overview",
    "href": "APIs/SentinelHub/Byoc.html#overview",
    "title": "Bring Your Own COG API",
    "section": "Overview",
    "text": "Overview\nBring Your Own COG API (or shortly \"BYOC\") enables you to import your own data in Sentinel Hub and access it just like any other data you are used to. To be able to do so, the following conditions should be met:\n\nStore your raster data in the cloud optimized geotiff (COG) format on your own S3 bucket in the supported region.\nConfigure the bucket's permissions so that Sentinel Hub can read them.\nImport tiles using the Dashboard or API.\n\nYour data needs to be organized into collections of tiles. Each tile needs to contain a set of bands and (optionally) an acquisition date and time. Tiles with the same bands can be grouped into collections. Think of the Sentinel-2 data as a collection of Sentinel-2 tiles.\n\nA note about COG overviews used for processing\nWhen processing data, we select the nearest overview level which has higher resolution than your request, or the full resolution image.\n\n\nSentinel Hub BYOC Tool\nThe Sentinel Hub BYOC Tool is software which can be used to prepare your data for use in Sentinel Hub. It can be run either in Docker or as a Java JAR. It takes care of the entire process; it is simple to use for simple cases but is also highly configurable allowing for more complex requirements. The same steps can be done manually and are detailed below, should you prefer or require more control over the process. Get the tool here."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#converting-to-cog",
    "href": "APIs/SentinelHub/Byoc.html#converting-to-cog",
    "title": "Bring Your Own COG API",
    "section": "Converting to COG",
    "text": "Converting to COG\n\nConstraints and settings\nCOGs can contain either a single band or multiple bands. For multi-band COGs we support both planar configurations formats - chunky and planar format.\nThere are a few additional constraints in addition to having COG files. These are:\n\nThe COG header size must not exceed one megabyte.\nThe internal tile size must be between 256 x 256 and 2048 x 2048.\nThe projection needs to be one of: WGS84 (EPSG:4326), WebMercator (EPGS:3857), any UTM zone (EPSG:32601-32660, 32701-32760), or Europe LAEA (EPSG:3035).\nThe COG must not cross any of the two poles.\nThe band name should be a valid JavaScript identifier so it can be safely used in evalscripts; valid identifiers are case-sensitive, can contain Unicode letters, $, _, and digits (0-9), but may not start with a digit, and should not be one of the reserved JavaScript keywords.\nThere can be at most 100 bands.\nMulti-band COGs in chunky format can have at most 10 bands.\nThe file names need to be consistent for all tiles in a collection. For example, if you have B1.tiff in one tile then you also need B1.tiff in all the other tiles in your collection.\nAll files of each tile needs to have consistent extension (so a tile cannot contain both B1.tiff and B2.TIF).\nThe maximum allowable difference between the intersection of all file bounding boxes and each individual file is one pixel of that file [1].\nAll files of each band need to have the same bit depth.\nFiles can be compressed with DEFLATE, ZLIB, ZSTD, PIXTIFF_ZIP, PACKBITS or LZW compression method. JPEG compression is not supported.\nSupported sample types and bit depths are the same as those supported for outputs, as well as reading unsigned integer 1, 2, 4 bit files. See also sampleType.\n\nBands can have different resolutions.\nFor best performance we recommend the following setting for COGs: deflate compressed with 1024x1024 pixel internal tiling.\n\n[1]: Here's one example of files with slightly different bounding boxes. One file has the bounding box [0, 0, 10, 10] and resolution of one meter per pixel, and the other file has the bounding box [0.5, 0.5, 10.5, 10.5] and 0.5 meter resolution. The intersection [0.5, 0.5, 10, 10] is not more than one pixel away from each individual file, therefore such files are valid for BYOC.\n\n\n\nGDAL example command\nCOGs can be generated in a single step with GDAL 3.1 or newer using the COG raster driver. For older GDAL versions or if you want planar multi-band COGs, see below. Even though you can use any GDAL version, we highly recommend you use v3.1 or newer, as older versions have issues with average downsampling (see https://gdal.org/programs/gdaladdo.html).\nThe input file must conform to the constraints regarding the projection, units per pixel, and pixel formats. To generate a COG from an input file:\ngdal_translate -of COG -co COMPRESS=DEFLATE -co BLOCKSIZE=1024 -co RESAMPLING=AVERAGE -co OVERVIEWS=IGNORE_EXISTING input.extension output.tiff\nAdditional parameters may be needed:\n\nif the input file contains multiple bands, but you only need one or only some of them, add -b &lt;bandA&gt; -b &lt;bandB&gt; ..., where &lt;bandX&gt; is the band number, starting from 1.\nif your input data has nodata values, add them to this command using: -a_nodata NO_DATA_VALUE, e.g. for zero: -a_nodata 0.\nfor many types of data adding a predictor can further reduce the file size. It is best to test this on your own data, to enable the predictor add -co PREDICTOR=YES.\n\nMulti-band COGs generated this way, are encoded in chunky format and you cannot change it to planar format. To get a COG in planar format, follow the next chapter.\n\nOlder GDAL versions or planar multi-band COGs\nFor GDAL older than 3.1 or if you want planar multi-band COGs, multiple commands are needed. To extract individual bands, add -b &lt;band&gt;, where &lt;band&gt; is the band number, starting from 1, to the first command.\ngdal_translate -of GTIFF input.extension intermediate.tiff\n\n\n\n\n\n\nNote\n\n\n\nIf your input data has nodata values, add them to this command using: -a_nodata NO_DATA_VALUE, e.g. for zero: -a_nodata 0.\n\n\ngdaladdo -r average --config GDAL_TIFF_OVR_BLOCKSIZE 1024 intermediate.tiff 2 4 8 16 32\n(The number of overview levels you need depends on your source data. A good rule of thumb is to have as many overview levels as necessary for the entire source image to fit on one 1024x1024 tile).\ngdal_translate -co TILED=YES -co COPY_SRC_OVERVIEWS=YES --config GDAL_TIFF_OVR_BLOCKSIZE 1024 -co BLOCKXSIZE=1024 -co BLOCKYSIZE=1024 -co COMPRESS=DEFLATE intermediate.tiff output.tiff\nTo generate a planar multi-band COG, add -co INTERLEAVE=BAND. For chunky format, you don't need to pass anything, as this is the default format.\n\n\n\n\n\n\nNote\n\n\n\nfor many types of data adding a predictor can further reduce the file size. It is best you test this on your own data. To enable the predictor, add to the above command -co PREDICTOR=2 for integers, and -co PREDICTOR=3 for floating points.\n\n\nOnce the commands finish, you can delete the intermediate.tiff file.\nFor more information about each command see the GDAL documentation:\n\ngdal_translate\ngdaladdo"
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#bucket-settings",
    "href": "APIs/SentinelHub/Byoc.html#bucket-settings",
    "title": "Bring Your Own COG API",
    "section": "Bucket settings",
    "text": "Bucket settings\nIf you do not yet have a bucket at Copernicus Data Space Ecosystem, please follow these steps to get one.\nYou will have to configure your bucket to allow read access to Sentinel Hub. To do this, update your bucket policy to include the following statement (don’t forget to replace &lt;bucket_name&gt; with your actual bucket name):\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::ddf4c98b5e6647f0a246f0624c8341d9:root\"\n            },\n            \"Action\": [\n                \"s3:GetBucketLocation\",\n                \"s3:ListBucket\",\n                \"s3:GetObject\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;\",\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}\nA python script to set a bucket policy can be downloaded here."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#configuring-collections",
    "href": "APIs/SentinelHub/Byoc.html#configuring-collections",
    "title": "Bring Your Own COG API",
    "section": "Configuring collections",
    "text": "Configuring collections\nWhen creating a collection:\n\nyou need to provide the S3 bucket where you data is; if you have data in CreoDIAS or CODE-DE, prefix the bucket name by your CreoDIAS or CODE-DE Project ID as follows: PROJECT_ID:bucket_name ,\nyou can define bands, but only using BYOC API,\nyou can provide the no data value using Dashboard or BYOC API.\n\nThe no data value cannot be configured to NaN (not a number). However, there is no need to do this, as NaNs are by default treated as no data value.\n\nAutomatic configuration\nIf bands are not configured, BYOC service automatically configures them based on the files of the first ingested tile. In this case the bands are named after the files, while for multi-band files the band index in 1-based numbering is also added at the end. For example, the bands in a multi-band file named RGB.tiff would be named RGB_1, RGB_2, etc. You can rename any band later.\nIn this process, the service also configures the \"no data\" value, if it's not set by the user. The service automatically extracts \"no data\" values from the TIFF tag GDAL_NODATA (TIFF entry ID = 42113) of the files of the first ingested tile, and sets the value as the collection \"no data\" value, if all files have the exactly same value and if the value is a number. Otherwise, it sets values per band.\n\n\nManual band configuration\nThe below example shows how to configure manually instead of relying on the automatic configuration described above. Suppose your tiles are composed of two files - \"RGB.tiff\" with three 16-bit bands and \"CLOUD_MASK.tiff\" with a single 8-bit band. You would provide such configuration in additionalData.bands field of a new collection:\n{\n  \"Red\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 16\n  },\n  \"Green\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 2,\n    \"bitDepth\": 16\n  },\n  \"Blue\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 3,\n    \"bitDepth\": 16\n  },\n  \"CloudMask\": {\n    \"source\": \"CLOUD_MASK\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 8\n  }\n}\nThe keys \"Red\", \"Green\", \"Blue\", and \"CloudMask\" are the names of the bands that you are going to use in evalscripts. These names can be changed at any time. Inside each band specification you specify where the band is stored using the fields source and bandIndex. The source, together with tile path, defines the file (see below for details), while bandIndex is the band index in 1-based numbering.\n\n\nBand renaming\nBands can be easily renamed in Dashboard. To do this using API, you need to provide the same band specs, but with new names. To obtain the current band specs, use this endpoint. For example, let's say your bands are defined like this, and you would like to rename bands \"RGB_1\", \"RGB_2\", \"RGB_3\" to \"Red\", \"Green\", and \"Blue\", respectively:\n{\n  \"RGB_1\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 16\n  },\n  \"RGB_2\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 2,\n    \"bitDepth\": 16\n  },\n  \"RGB_3\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 3,\n    \"bitDepth\": 16\n  },\n  \"CLOUD_MASK\": {\n    \"source\": \"CLOUD_MASK\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 8\n  }\n}\nTo achieve this, you need to use this endpoint. You need to provide the new names at the top level, but leave the band properties (\"source\", \"bandIndex\", etc) and values the same. So the content of additionalData.bands would be:\n{\n  \"Red\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 16\n  },\n  \"Green\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 2,\n    \"bitDepth\": 16\n  },\n  \"Blue\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 3,\n    \"bitDepth\": 16\n  },\n  \"CLOUD_MASK\": {\n    \"source\": \"CLOUD_MASK\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 8\n  }\n}\nKeep in mind:\n\nthat the bucket cannot be changed after the collection is created,\nthat once bands have been configured you can only change band names or remove bands,\nand that the no data value can be changed at anytime using Dashboard or BYOC API.\n\n\n\nConfiguring band sample format\nThe sample format is TIFF info that defines the band data type. It can be set to signed integers, unsigned integers, or floating points. Learn more about sample format here. These values are in BYOC defined as INT, UINT and FLOAT, respectively.\nYou can configure format manually in BYOC using API or Dashboard. If not set, it will get set to the value of the first ingested tile.\nTo configure it manually, set sampleFormat field for each band like this:\n{\n  \"Red\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 16,\n    \"sampleFormat\": \"INT\"\n  },\n  \"Green\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 2,\n    \"bitDepth\": 16,\n    \"sampleFormat\": \"INT\"\n  },\n  \"Blue\": {\n    \"source\": \"RGB\",\n    \"bandIndex\": 3,\n    \"bitDepth\": 16,\n    \"sampleFormat\": \"INT\"\n  },\n  \"CLOUD_MASK\": {\n    \"source\": \"CLOUD_MASK\",\n    \"bandIndex\": 1,\n    \"bitDepth\": 8,\n    \"sampleFormat\": \"UINT\"\n  }\n}\nAfter formats are set, the formats of all new files must match the formats defined in BYOC. If they do not match, files do not get ingested."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#ingesting-the-tiles",
    "href": "APIs/SentinelHub/Byoc.html#ingesting-the-tiles",
    "title": "Bring Your Own COG API",
    "section": "Ingesting the tiles",
    "text": "Ingesting the tiles\nThere are two ways of doing this. The easier version is using the dashboard.\nTo create a new collection click the New collection button. The name can be anything and is there for your own reference. The S3 bucket name is the bucket name containing your data.\nOnce the collection is created you can add tiles. Note that only a single tile can be added in one step.\nTo add a tile, click the Add tile button. Provide a path to the COG files inside the s3 bucket. For example, if your files are stored in s3://bucket-name/folder/, simply set folder as the tile path. Optionally, set the sensing time of the tile here as well.\nWhen the tile is ingested its path will be automatically changed to folder/(BAND).tiff or similar, depending on the extension of the files in folder. Note that (BAND) is a placeholder that is replaced by the source of a band to obtain the actual file where the band is stored. In the example above your collection uses sources \"RGB\" and \"CLOUD_MASK\", thus the two files of the tile will be folder/RGB.tiff and folder/CLOUD_MASK.tiff.\nFor more complicated cases you must provide the path with the (BAND) placeholder and extension. For example, suppose your folder contains the files for multiple tiles:\n\ns3://bucket-name/folder/tile_1_B1_2019.tif,\ns3://bucket-name/folder/tile_1_B2_2019.tif,\ns3://bucket-name/folder/tile_2_B1_2019.tif,\ns3://bucket-name/folder/tile_2_B2_2019.tif.\n\nCreate the first tile with the path folder/tile_1_(BAND)_2019.tif to use the first two files and the second tile with the path folder/tile_2_(BAND)_2019.tif to use the next two files.\nDo not forget that all tiles must contain the same set of files (with different data of course); that is, if a tile is missing one or more files it will fail to ingest.\nTo ingest tiles via API requests instead of the dashboard, see BYOC API reference or Python examples.\n\nA note about changing files\nWhile you may freely modify the data in your buckets, for it to continue to work reliably through Sentinel Hub you need to reingest tiles with changed data. You can do this in Dashboard, by clicking the \"Refresh\" button next to the tile, or using the API, by calling the reingest endpoint with the collection and tile id. This is needed as it will update metadata required for processing and failing to do so can result in odd behavior.\n\n\nA note about cover geometries\nEach tile ingested also requires a cover geometry. A cover geometry is a geometry which outlines the valid data part of the tile. Nodata therefore should not be contained in the cover geometry. In the simplest case, the cover geometry will equal the bounding box of the file being ingested.\nThe cover geometry is important because it tells the system where it can expect to find data. As a consequence, this determines how data is rendered where tiles overlap. If you have tiles with overlapping cover geometries, only the data from one tile can be rendered where two (or more) cover geometries intersect. This is true even if this data is nodata or if it lies outside the tile bounding box. Having quality cover geometries is therefore important for collections where many tiles containing nodata overlap. Not all cases need precise cover geometries, however. A single tile or a regularly gridded collection with a single date and coordinate reference system can get away with cover geometries equalling the bounding box.\n\n\n\n\nOverlapping tiles\n\n\nIf the cover geometry is not specified during ingestion it will automatically be set to the tile bounding box. Sentinel Hub will not attempt to generate a more precise geometry as it is impossible to prepare such a process which will work well for all users. It is therefore your responsibility to provide quality cover geometries and in doing so allow you to extract the most out of your data. If ingesting tiles using the API, set the cover geometry using the coverGeometry field in the API request. It must be in the GeoJSON format and in a projected or geodetic coordinate reference system which is supported by Sentinel Hub. Cover geometries in practice mean one polygon or multipolygon. They must also contain no more than 100 points.\n\nGenerating cover geometries\n\nGDAL\nOne way of getting a cover geometry is using the GDAL utility script gdal_trace_outline which takes a raster and returns a cover geometry in the WKT format. This then needs to be converted to GeoJSON. In this example a single band file is traced:\ngdal_trace_outline band.tif -out-cs en -wkt-out wkt.txt\nThe process might take a while if you have a large file. To speed up the process you can pass a subsampled file which you can get with gdal_translate. To get a file that is 1% of the original size:\ngdal_translate band.tif subsampled.tif -outsize 1% 1%\nor if it's stored on AWS S3:\ngdal_translate /vsis3/bucket-name/folder/band.tif subsampled.tif -outsize 1% 1%\nNote that calculating the cover geometry on subsampled rasters may not be sufficiently accurate for touching but not intersecting tiles as the imprecision caused by downsampling may leave gaps.\nFinally, you need to convert the WKT file to GeoJSON and specify the CRS under crs.properties.name (except when WGS84 when it can be omitted). CRSs with the EPSG code &lt;EpsgCode&gt; should be specified as urn:ogc:def:crs:EPSG::&lt;EpsgCode&gt;. Here is a GeoJSON example in ESPG:32633.\n{\n    \"type\": \"MultiPolygon\",\n    \"crs\": {\n        \"type\": \"name\",\n        \"properties\": {\n            \"name\": \"urn:ogc:def:crs:EPSG::32633\"\n        }\n    },\n    \"coordinates\": [\n        [\n            [\n                [\n                    370270.52147506207,\n                    5085707.891369364\n                ],\n                ...\n            ]\n        ]\n    ]\n}\n\n\nSentinel Hub BYOC Tool\nThe Sentinel Hub BYOC Tool can also help you update the cover geometry of existing tiles on Sentinel Hub. Use the set-coverage command. On Docker, get help and parameters by running: docker run sentinelhub/byoc-tool set-coverage --help\n\n\n\nWorkarounds\nIn case your input data is complex and cannot be adequately simply outlined it is nevertheless possible to obtain pixel-precise rendering. In this case, set the cover geometry to any which covers all the valid input pixels. The file bounding box as the default is such an example. What follows is doing the mosaicking in the custom script with the help of dataMask.\nFirst, set the mosaicking parameter within setup to TILE (mosaicking: Mosaicking.TILE) and add the dataMask to the array of input bands.\nThen use something like the following as your evalscript. Since dataMask precisely determines which pixels are valid and which ones are not, the moment a valid pixel is found this can be returned, alternatively the next scene should be checked.\nfunction evaluatePixel(samples, scenes) {\n  for (let i = 0; i &lt; samples.length; i++) {\n    let sample = samples[i];\n    if (sample.dataMask == 1) {\n      return someCombination(sample);\n    }\n  }\n  return someNodataValueArray;\n}\nOptionally, you may additionally use the preProcessScenes function to potentially reduce the number of tiles which will be processed. This is useful to set an upper limit for the number of processing units which will be used. The following limits the maximum number of tiles to 5, for example.\nfunction preProcessScenes (collections) {\n  collections.scenes.tiles = collections.scenes.tiles.splice(5);\n  return collections;\n}\nNote that getting data in such a manner will use more processing units than SIMPLE mosaicking with precise cover geometries."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#collection-metadata",
    "href": "APIs/SentinelHub/Byoc.html#collection-metadata",
    "title": "Bring Your Own COG API",
    "section": "Collection metadata",
    "text": "Collection metadata\nCollections have the following metadata available under additionalData:\n\nextent: the collection extent in WGS84\nhasSensingTimes: information if tiles have sensing time\nfromSensingTime the sensing time in ISO 8601 of the least recent tile\ntoSensingTime: the sensing time in ISO 8601 of the most recent tile\n\nThe metadata is updated in a few minutes after a tile is added or removed. To find out if your collection requires metadata updates, check out the flag requiresMetadataUpdate."
  },
  {
    "objectID": "APIs/SentinelHub/Byoc.html#examples",
    "href": "APIs/SentinelHub/Byoc.html#examples",
    "title": "Bring Your Own COG API",
    "section": "Examples",
    "text": "Examples\nBYOC API Examples"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html",
    "href": "APIs/SentinelHub/Process/Crs.html",
    "title": "CRS support",
    "section": "",
    "text": "The list of coordinate reference systems supported by Sentinel Hub API is provided below. The coordinate reference system must be set with an URL starting with http://www.opengis.net/def/crs/ and it must be set under the field input.bounds.properties.crs, e.g. request in WGS 84 reference system, defined with the URL http://www.opengis.net/def/crs/EPSG/0/4326:"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#wgs-84",
    "href": "APIs/SentinelHub/Process/Crs.html#wgs-84",
    "title": "CRS support",
    "section": "WGS 84:",
    "text": "WGS 84:\n\nhttp://www.opengis.net/def/crs/OGC/1.3/CRS84\nhttp://www.opengis.net/def/crs/EPSG/0/4326"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#wgs-84--pseudo-mercator",
    "href": "APIs/SentinelHub/Process/Crs.html#wgs-84--pseudo-mercator",
    "title": "CRS support",
    "section": "WGS 84 / Pseudo-Mercator:",
    "text": "WGS 84 / Pseudo-Mercator:\n\nhttp://www.opengis.net/def/crs/EPSG/0/3857"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#utm-northern-hemisphere",
    "href": "APIs/SentinelHub/Process/Crs.html#utm-northern-hemisphere",
    "title": "CRS support",
    "section": "UTM northern hemisphere:",
    "text": "UTM northern hemisphere:\n\nhttp://www.opengis.net/def/crs/EPSG/0/32601\nhttp://www.opengis.net/def/crs/EPSG/0/32602\n...\nhttp://www.opengis.net/def/crs/EPSG/0/32660\n\nThe last two digits of EPSG codes above represent the number of corresponding UTM zone in northern hemisphere, e.g. use http://www.opengis.net/def/crs/EPSG/0/32612 for UTM zone 12N."
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#utm-southern-hemisphere",
    "href": "APIs/SentinelHub/Process/Crs.html#utm-southern-hemisphere",
    "title": "CRS support",
    "section": "UTM southern hemisphere:",
    "text": "UTM southern hemisphere:\n\nhttp://www.opengis.net/def/crs/EPSG/0/32701\nhttp://www.opengis.net/def/crs/EPSG/0/32702\n...\nhttp://www.opengis.net/def/crs/EPSG/0/32760\n\nThe last two digits of EPSG codes above represent the number of corresponding UTM zone in southern hemisphere, e.g. use http://www.opengis.net/def/crs/EPSG/0/32712 for UTM zone 12S."
  },
  {
    "objectID": "APIs/SentinelHub/Process/Crs.html#others",
    "href": "APIs/SentinelHub/Process/Crs.html#others",
    "title": "CRS support",
    "section": "Others:",
    "text": "Others:\n\nhttp://www.opengis.net/def/crs/EPSG/0/2154\nhttp://www.opengis.net/def/crs/EPSG/0/2180\nhttp://www.opengis.net/def/crs/EPSG/0/2193\nhttp://www.opengis.net/def/crs/EPSG/0/3003\nhttp://www.opengis.net/def/crs/EPSG/0/3004\nhttp://www.opengis.net/def/crs/EPSG/0/3006\nhttp://www.opengis.net/def/crs/EPSG/0/3031\nhttp://www.opengis.net/def/crs/EPSG/0/3035\nhttp://www.opengis.net/def/crs/EPSG/0/3346\nhttp://www.opengis.net/def/crs/EPSG/0/3413\nhttp://www.opengis.net/def/crs/EPSG/0/3416\nhttp://www.opengis.net/def/crs/EPSG/0/3765\nhttp://www.opengis.net/def/crs/EPSG/0/3794\nhttp://www.opengis.net/def/crs/EPSG/0/3844\nhttp://www.opengis.net/def/crs/EPSG/0/3912\nhttp://www.opengis.net/def/crs/EPSG/0/3995\nhttp://www.opengis.net/def/crs/EPSG/0/4026\nhttp://www.opengis.net/def/crs/EPSG/0/5514\nhttp://www.opengis.net/def/crs/EPSG/0/28992"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/DataFusion.html",
    "href": "APIs/SentinelHub/Process/Examples/DataFusion.html",
    "title": "Examples of Data Fusion",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nPan-sharpen Sentinel-3 OLCI with Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s2l1c\",\n        bands: [\"B02\", \"B03\", \"B04\"],\n      },\n      {\n        datasource: \"s3olci\",\n        bands: [\"B04\", \"B06\", \"B08\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  let s3 = samples.s3olci[0]\n  let s2 = samples.s2l1c[0]\n  let amount_s2 = 0.5\n  let gain = 3.0\n  return [\n    gain * (s3.B08 * (1 - amount_s2) + s2.B04 * amount_s2),\n    gain * (s3.B06 * (1 - amount_s2) + s2.B03 * amount_s2),\n    gain * (s3.B04 * (1 - amount_s2) + s2.B02 * amount_s2),\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                7.388827,\n                53.537043,\n                8.35627,\n                53.901102,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s2l1c\",\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-01T00:00:00Z\",\n                        \"to\": \"2020-06-01T23:59:00Z\",\n                    }\n                },\n            },\n            {\n                \"id\": \"s3olci\",\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-01T00:00:00Z\",\n                        \"to\": \"2020-06-01T23:59:00Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 1024,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI with Sentinel-1 and Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s1\",\n        bands: [\"VV\", \"VH\"],\n      },\n      {\n        datasource: \"l2a\",\n        bands: [\"B08\", \"B04\", \"SCL\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction toDb(linear) {\n  // Convert the linear backscatter to DB (Filgueiras et al. (2019), eq. 3)\n  return 10 * Math.LN10 * linear\n}\n\nfunction calc_s1_ndvi(sigmaVV, sigmaVH) {\n  // Convert sigma0 to Decibels\n  let vh_Db = toDb(sigmaVH)\n  let vv_Db = toDb(sigmaVV)\n  // Calculate NRPB (Filgueiras et al. (2019), eq. 4)\n  let NRPB = (vh_Db - vv_Db) / (vh_Db + vv_Db)\n  // Calculate NDVI_nc with approach A3 (Filgueiras et al. (2019), eq. 14)\n  let NDVInc = 2.572 - 0.05047 * vh_Db + 0.176 * vv_Db + 3.422 * NRPB\n  return NDVInc\n}\n\n// Create an NDVI visualiser\nvar viz = new ColorMapVisualizer([\n  [0.0, 0xa50026],\n  [0.0, 0xd73027],\n  [0.2, 0xf46d43],\n  [0.3, 0xfdae61],\n  [0.4, 0xfee08b],\n  [0.5, 0xffffbf],\n  [0.6, 0xd9ef8b],\n  [0.7, 0xa6d96a],\n  [0.8, 0x66bd63],\n  [0.9, 0x1a9850],\n  [1.0, 0x006837],\n])\n\nfunction evaluatePixel(samples) {\n  var s1 = samples.s1[0]\n  var s2 = samples.l2a[0]\n\n  // Use the S2-L2A classification to identify clouds\n  if ([7, 8, 9, 10].includes(s2.SCL)) {\n    // If clouds are present use S1 NDVI\n    let s1_ndvi = calc_s1_ndvi(s1.VV, s1.VH) // Calculate S1 NDVI\n    return viz.process(s1_ndvi)\n  } else {\n    // Otherwise use s2 NDVI\n    let ndvi = index(s2.B08, s2.B04) // Calculate S2 NDVI\n    return viz.process(ndvi)\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -100.9204,\n                37.5718,\n                -100.4865,\n                37.864,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s1\",\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-26T00:00:00Z\",\n                        \"to\": \"2019-04-26T23:59:00Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            },\n            {\n                \"id\": \"l2a\",\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-26T00:00:00Z\",\n                        \"to\": \"2019-04-26T23:59:00Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 1024,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nShip detection with Sentinel-1 and Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s2l2a\",\n        bands: [\"B02\", \"B03\", \"B04\", \"B08\"],\n      },\n      {\n        datasource: \"s1grd\",\n        bands: [\"VV\", \"VH\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  var S2L2A = samples.s2l2a[0]\n  var S1 = samples.s1grd[0]\n\n  let ndwi = (S2L2A.B03 - S2L2A.B08) / (S2L2A.B03 + S2L2A.B08)\n  if (ndwi &gt; 0.1) {\n    if (S1.VV &gt; 0.3 || S1.VH &gt; 0.3) {\n      return [1, 1, 1]\n    }\n    return [4 * S2L2A.B04 - 0.2, 4 * S2L2A.B03 - 0.2, 5 * S2L2A.B02 - 0.2]\n  }\n  return [4 * S2L2A.B04 - 0.2, 4 * S2L2A.B03 - 0.2, 4 * S2L2A.B02 - 0.2]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                119.60987091064452,\n                32.176774851931214,\n                119.91474151611328,\n                32.3640132852233,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s1grd\",\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-05-23T00:00:00Z\",\n                        \"to\": \"2020-05-23T23:59:00Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            },\n            {\n                \"id\": \"s2l2a\",\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-05-23T00:00:00Z\",\n                        \"to\": \"2020-05-23T23:59:00Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 742,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nBuilt up areas detection with Sentinel-1 and Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s2l1c\",\n        bands: [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\"],\n      },\n      {\n        datasource: \"s1grd\",\n        bands: [\"VV\", \"VH\"],\n      },\n      {\n        datasource: \"s2l2a\",\n        bands: [\"B02\", \"B03\", \"B04\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(samples) {\n  var S2L1C = samples.s2l1c[0]\n  var S2L2A = samples.s2l2a[0]\n  var S1 = samples.s1grd[0]\n  let ndvi = (S2L1C.B08 - S2L1C.B04) / (S2L1C.B08 + S2L1C.B04)\n  if (ndvi &gt; 0.5) {\n    return [3 * S2L2A.B04, 3 * S2L2A.B03, 3 * S2L2A.B02]\n  }\n  let ndmi = (S2L1C.B08 - S2L1C.B11) / (S2L1C.B08 + S2L1C.B11)\n  if (ndmi &gt; 0) {\n    return [3 * S2L2A.B04, 3 * S2L2A.B03, 4 * S2L2A.B02]\n  }\n  if (S1.VH &gt; 0.2 || S1.VV &gt; 0.2) {\n    return [S1.VH * 5.5, S1.VV, S1.VH * 8]\n  }\n  return [3 * S2L1C.B04 - 0.2, 3 * S2L1C.B03 - 0.2, 3 * S2L1C.B02 - 0.2]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                12.280998229980469,\n                45.40206593659076,\n                12.43274688720703,\n                45.47361429775641,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s2l1c\",\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-12-10T00:00:00Z\",\n                        \"to\": \"2019-12-10T23:59:00Z\",\n                    }\n                },\n            },\n            {\n                \"id\": \"s1grd\",\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-12-10T00:00:00Z\",\n                        \"to\": \"2019-12-10T23:59:00Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            },\n            {\n                \"id\": \"s2l2a\",\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-12-10T00:00:00Z\",\n                        \"to\": \"2019-12-10T23:59:00Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 1024,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFire monitoring with Sentinel-1 and Sentinel-2\nevalscript = \"\"\"\n//VERSION=3\n// Multitemporal forest fire progression monitoring script utilizing a) Sentinel-2 data from 7 September 2019 for the visualization of burned areas\n// and b) Sentinel-1 SAR data to monitor forest fire progression in overcast conditions on 12 September 2019.\n\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s1_t1\",\n        bands: [\"VH\"],\n      }, // S1 data from 7 September 2019 (t1)\n      {\n        datasource: \"s1_t2\",\n        bands: [\"VV\", \"VH\"],\n      }, // S1 data from 12 September 2019 (t2)\n      {\n        datasource: \"l2a_t1\",\n        bands: [\"B03\", \"B04\", \"B08\", \"B11\", \"B12\"],\n      },\n    ], // S2 data from 7 September 2019 (t1)\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  var s1_1 = samples.s1_t1[0] //Assigns S1 data from t1\n  var s1_2 = samples.s1_t2[0] //Assigns S1 data from t2\n  var s2_1 = samples.l2a_t1[0] //Assigns S2 data from t1\n\n  // Calculate indices with S2 data from t1 for Burned Area visualization by Monja Sebela\n  var NDWI = index(s2_1.B03, s2_1.B08)\n  var NDVI = index(s2_1.B08, s2_1.B04)\n  var INDEX = (s2_1.B11 - s2_1.B12) / (s2_1.B11 + s2_1.B12) + s2_1.B08\n\n  // Calculate difference in S1 VH backscatter between second (t2) and first scene (t1) (Belenguer-Plomer et al. 2019)\n  var VH_diff = s1_2.VH - s1_1.VH\n\n  // Set classification threshholds\n  var thr_VH = 0.03\n  var thr_VH_diff = -0.015\n  var thr_VV = 0.2\n\n  if (NDWI &gt; 0.15 || NDVI &gt; 0.35 || INDEX &gt; 0.2) {\n    // If non-burned areas in S2 image from t1\n    if (s1_2.VH &lt; thr_VH && VH_diff &lt; thr_VH_diff) {\n      // are classified as burned in S1 image from t2 via thresholds for VH backscatter and the calculated difference layer\n      return [1, 0, 0] // Return red color\n    } else {\n      return [2.5 * s2_1.B12, 2.5 * s2_1.B08, 2.5 * s2_1.B04] // Else return SWIR composite\n    }\n  } else {\n    if (s1_2.VV &lt; thr_VV) {\n      // Else, if already burnt area is also burned in S1 image from t2\n      return [0.9, 0.9, 0.7] // Return beige color\n    } else {\n      return [0, 0, 1] // Else return blue for areas that are no longer burned in S1 image from t2\n    }\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -59.75738525390625,\n                -19.919130502461016,\n                -58.7274169921875,\n                -19.062117883514652,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"id\": \"l2a_t1\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-09-06T00:00:00Z\",\n                        \"to\": \"2019-09-08T23:59:59Z\",\n                    }\n                },\n            },\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"id\": \"s1_t1\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-09-06T00:00:00Z\",\n                        \"to\": \"2019-09-08T23:59:59Z\",\n                    }\n                },\n            },\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"id\": \"s1_t2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-09-11T00:00:00Z\",\n                        \"to\": \"2019-09-13T23:59:59Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 1024,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nMonitoring low pressure clouds with Sentinel-3 OLCI and Sentinel-5P\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s3olci\",\n        bands: [\"B04\", \"B06\", \"B08\"],\n      },\n      {\n        datasource: \"s5pl2\",\n        bands: [\"CLOUD_TOP_PRESSURE\"],\n      },\n    ],\n    output: [\n      {\n        bands: 3,\n      },\n    ],\n  }\n}\n\nvar minVal = 10000.0\nvar maxVal = 110000.0\nvar diff = maxVal - minVal\nvar limits = [\n  minVal,\n  minVal + 0.125 * diff,\n  minVal + 0.375 * diff,\n  minVal + 0.625 * diff,\n  minVal + 0.875 * diff,\n  maxVal,\n]\nvar colors = [\n  [0, 0, 0.5],\n  [0, 0, 1],\n  [0, 1, 1],\n  [1, 1, 0],\n  [1, 0, 0],\n  [0.5, 0, 0],\n]\n\nfunction evaluatePixel(\n  samples,\n  inputData,\n  inputMetadata,\n  customData,\n  outputMetadata\n) {\n  var S5 = samples.s5pl2[0]\n  var S3 = samples.s3olci[0]\n  var CLOUD_TOP_PRESSURE = S5.CLOUD_TOP_PRESSURE\n\n  if (CLOUD_TOP_PRESSURE &gt; 0) {\n    return colorBlend(CLOUD_TOP_PRESSURE, limits, colors)\n  }\n  return [S3.B08 * 3, S3.B06 * 3, S3.B04 * 3.5]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -154.82,\n                21.96,\n                -135.66,\n                13.56,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n        },\n        \"data\": [\n            {\n                \"id\": \"s3olci\",\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-07-24T00:00:00Z\",\n                        \"to\": \"2020-07-24T23:59:59Z\",\n                    }\n                },\n            },\n            {\n                \"id\": \"s5pl2\",\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-07-24T00:00:00Z\",\n                        \"to\": \"2020-07-24T23:59:59Z\",\n                    }\n                },\n            },\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 449,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S3SLSTR.html",
    "href": "APIs/SentinelHub/Process/Examples/S3SLSTR.html",
    "title": "Examples for S3SLSTR",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nFalse Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                8.558382,\n                41.359678,\n                9.579525,\n                43.055688,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color, resolution (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2 * sample.S3, 2 * sample.S2, 2 * sample.S1]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 250,\n        \"resy\": 250,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nThermal IR fire emission band, gradient visualizer (K)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"F1\"],\n    output: {\n      bands: 3,\n    },\n  }\n}\n\n// Create a Red gradient visualiser from 274-450 K\nvar viz = ColorGradientVisualizer.createRedTemperature(274, 450)\n\nfunction evaluatePixel(sample) {\n  return viz.process(sample.F1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                -120.141,\n                37.5282,\n                -119.4131,\n                37.8716,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-08-06T00:00:00Z\",\n                        \"to\": \"2018-08-06T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFalse Color and metadata (multi-part GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S3\", \"S2\", \"S1\"],\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"INT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n    mosaicking: \"TILE\",\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.tiles }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [sample[0].S3 * 10000, sample[0].S2 * 10000, sample[0].S1 * 10000] //the values are multiplied by 10000 because output sampleType is UINT16\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                8.558382,\n                41.359678,\n                9.579525,\n                43.055688,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bouds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"S2\", \"S3\"],\n    output: {\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let NDVI = index(sample.S3, sample.S2)\n  const viz = ColorGradientVisualizer.createWhiteGreen(-0.1, 1.0)\n  return viz.process(NDVI)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                        [\n                            542559.6872296461,\n                            4744749.907737136,\n                        ],\n                        [\n                            550448.1401370098,\n                            4660606.41005859,\n                        ],\n                        [\n                            521523.8128100095,\n                            4570327.449007649,\n                        ],\n                        [\n                            474193.0953658272,\n                            4600128.271102134,\n                        ],\n                        [\n                            461045.67385355436,\n                            4630805.5879641045,\n                        ],\n                        [\n                            453157.22094619065,\n                            4698295.685060439,\n                        ],\n                        [\n                            497858.45408791833,\n                            4741243.928667196,\n                        ],\n                        [\n                            520647.3180425246,\n                            4744749.907737136,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/jpeg\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S2\", \"S3\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: \"INT16\",\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: \"AUTO\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let NDVI = index(sample.S3, sample.S2)\n  const viz = ColorGradientVisualizer.createWhiteGreen(-0.1, 1.0)\n  return {\n    default: [NDVI * 10000],\n    ndvi_image: viz.process(NDVI),\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                        [\n                            542559.6872296461,\n                            4744749.907737136,\n                        ],\n                        [\n                            550448.1401370098,\n                            4660606.41005859,\n                        ],\n                        [\n                            521523.8128100095,\n                            4570327.449007649,\n                        ],\n                        [\n                            474193.0953658272,\n                            4600128.271102134,\n                        ],\n                        [\n                            461045.67385355436,\n                            4630805.5879641045,\n                        ],\n                        [\n                            453157.22094619065,\n                            4698295.685060439,\n                        ],\n                        [\n                            497858.45408791833,\n                            4741243.928667196,\n                        ],\n                        [\n                            520647.3180425246,\n                            4744749.907737136,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            525906.2866474338,\n                            4771044.750761681,\n                        ],\n                        [\n                            535547.7290897672,\n                            4767538.771691742,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nVNIR and SWIR bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      bands: 6,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance or BT values, simply divide the resulting pixel values by 10000.\n  return [\n    10000 * sample.S1,\n    10000 * sample.S2,\n    10000 * sample.S3,\n    10000 * sample.S4,\n    10000 * sample.S5,\n    10000 * sample.S6,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 500,\n        \"resy\": 500,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTIR bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"S7\", \"S8\", \"S9\", \"F1\", \"F2\"],\n      },\n    ],\n    output: {\n      bands: 5,\n      sampleType: \"UINT16\",\n    },\n  }\n}\n\nfunction multiplyband(sample) {\n  // Multiply by 100\n  return 100 * sample\n}\n\nfunction evaluatePixel(sample) {\n  // Return the bands multiplied by 100 as integers to save processing units.\n  // To obtain reflectance or BT values, simply divide the resulting pixel values by 100.\n  return [\n    multiplyband(sample.S7),\n    multiplyband(sample.S8),\n    multiplyband(sample.S9),\n    multiplyband(sample.F1),\n    multiplyband(sample.F2),\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-slstr\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-20T00:00:00Z\",\n                        \"to\": \"2020-06-20T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"DESCENDING\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 500,\n        \"resy\": 500,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S2L1C.html",
    "href": "APIs/SentinelHub/Process/Examples/S2L1C.html",
    "title": "Examples for S2L1C",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 100,\n        \"resy\": 100,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTIff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue Color, mosaicking with leastRecent\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-10-11T00:00:00Z\",\n                        \"to\": \"2018-11-18T00:00:00Z\",\n                    },\n                    \"mosaickingOrder\": \"leastRecent\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    mosaicking: Mosaicking.ORBIT,\n    output: { id: \"default\", bands: 3 },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.orbits }\n}\n\nfunction evaluatePixel(samples) {\n  return [2.5 * samples[0].B04, 2.5 * samples[0].B03, 2.5 * samples[0].B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ]\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-27T00:00:00Z\",\n                        \"to\": \"2018-12-27T23:59:59Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nTrue color multi-part-reponse (different formats and SampleType)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B03\", \"B02\"],\n        units: \"REFLECTANCE\", // default units\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 3,\n        sampleType: \"AUTO\", // default  - scales the output values from input values [0,1] to [0,255].\n      },\n      {\n        id: \"true_color_8bit\",\n        bands: 3,\n        sampleType: \"UINT8\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_16bit\",\n        bands: 3,\n        sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_32float\",\n        bands: 3,\n        sampleType: \"FLOAT32\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return {\n    // output band values are scaled from [0,1] to [0,255]. Multiply by 2.5 to increase brightness\n    default: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n\n    // Multiply input reflectance values by 2.5 to increase brighness and by 255 to return the band values clamped to [0, 255] unsigned 8 bit range.\n    true_color_8bit: [\n      2.5 * sample.B04 * 255,\n      2.5 * sample.B03 * 255,\n      2.5 * sample.B02 * 255,\n    ],\n\n    // Multiply input reflectance values by 2.5 to increase brightness and by 65535 to return the band values clamped to [0, 65535] unsigned 16 bit range.\n    true_color_16bit: [\n      2.5 * sample.B04 * 65535,\n      2.5 * sample.B03 * 65535,\n      2.5 * sample.B02 * 65535,\n    ],\n\n    // Returns band reflectance.\n    true_color_32float: [sample.B04, sample.B03, sample.B02],\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                12.206251,\n                41.627351,\n                12.594042,\n                41.856879,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-06-01T00:00:00Z\",\n                        \"to\": \"2018-08-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/jpeg\"},\n            },\n            {\n                \"identifier\": \"true_color_8bit\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"true_color_16bit\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"true_color_32float\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) return [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) return [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) return [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) return [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) return [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) return [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) return [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) return [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) return [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) return [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) return [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) return [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) return [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) return [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) return [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) return [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) return [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) return [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) return [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) return [0.06, 0.33, 0.04]\n  else return [0, 0.27, 0]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 80,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nExact NDVI values using a floating point GeoTIFF\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  return [ndvi]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI values as INT16 raster\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.INT16, //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  // Return NDVI multiplied by 10000 as integers to save processing units. To obtain NDVI values, simply divide the resulting pixel values by 10000.\n  return [ndvi * 10000]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: SampleType.FLOAT32,\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: SampleType.AUTO,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) image = [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) image = [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) image = [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) image = [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) image = [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) image = [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) image = [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) image = [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) image = [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) image = [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) image = [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) image = [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) image = [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) image = [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) image = [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) image = [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) image = [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) image = [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) image = [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) image = [0.06, 0.33, 0.04]\n  else image = [0, 0.27, 0]\n\n  return {\n    default: [ndvi],\n    ndvi_image: image,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S2L1C raw bands, original data (no harmonization)\nLearn about harmonization here.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B8A\",\n          \"B09\",\n          \"B10\",\n          \"B11\",\n          \"B12\",\n        ],\n        units: \"DN\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 13,\n      sampleType: SampleType.UINT16,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [\n    sample.B01,\n    sample.B02,\n    sample.B03,\n    sample.B04,\n    sample.B05,\n    sample.B06,\n    sample.B07,\n    sample.B08,\n    sample.B8A,\n    sample.B09,\n    sample.B10,\n    sample.B11,\n    sample.B12,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l1c\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"false\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S5PL2.html",
    "href": "APIs/SentinelHub/Process/Examples/S5PL2.html",
    "title": "Examples for S5PL2",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCarbon Monoxide, CO (RGB visualization and transparency with dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CO\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 0.1\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CO)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNitrogen Dioxide, NO2 (NRTI timeliness, RGB visualization and transparency with dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"NO2\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 0.0001\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.NO2)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    },\n                    \"timeliness\": \"NRTI\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nFormaldehyde, HCHO (float32 format, specific value for no data, GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"HCHO\", \"dataMask\"],\n    output: { bands: 1, sampleType: \"FLOAT32\" },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.dataMask == 1) {\n    return [sample.HCHO]\n  } else {\n    return [-9999]\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nOzone, O3 (RPRO timeliness, streched values and dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"O3\", \"dataMask\"],\n    output: { bands: 2 },\n  }\n}\n\nfunction evaluatePixel(sample, scene) {\n  var maxVal = 0.36\n  return [sample.O3 / maxVal, sample.dataMask]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-22T00:00:00Z\",\n                        \"to\": \"2019-04-23T00:00:00Z\",\n                    },\n                    \"timeliness\": \"RPRO\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nSulfur Dioxide, SO2 (minQa=20 applied, streched values)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"SO2\", \"dataMask\"],\n    output: { bands: 2 },\n  }\n}\n\nfunction evaluatePixel(sample, scene) {\n  var maxVal = 0.01\n  return [sample.SO2 / maxVal, sample.dataMask]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-30T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"minQa\": 20},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nMethane, CH4\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CH4\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 1600.0\nconst maxVal = 2000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CH4)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                10,\n                20,\n                15,\n                25,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nAER AI 340 and 380\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"AER_AI_340_380\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = -1.0\nconst maxVal = 5.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.AER_AI_340_380)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nAER AI 354 and 388\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"AER_AI_354_388\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = -1.0\nconst maxVal = 5.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.AER_AI_354_388)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud base height\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_BASE_HEIGHT\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0\nconst maxVal = 20000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_BASE_HEIGHT)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud base pressure\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_BASE_PRESSURE\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 10000.0\nconst maxVal = 110000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_BASE_PRESSURE)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nEffective radiometric cloud fraction\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_FRACTION\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 1.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_FRACTION)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud optical thickness\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_OPTICAL_THICKNESS\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 250.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_OPTICAL_THICKNESS)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud top height\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_TOP_HEIGHT\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 0.0\nconst maxVal = 20000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_TOP_HEIGHT)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCloud top pressure\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"CLOUD_TOP_PRESSURE\", \"dataMask\"],\n    output: { bands: 4 },\n  }\n}\n\nconst minVal = 10000.0\nconst maxVal = 110000.0\nconst diff = maxVal - minVal\n\nconst rainbowColors = [\n  [minVal, [0, 0, 0.5]],\n  [minVal + 0.125 * diff, [0, 0, 1]],\n  [minVal + 0.375 * diff, [0, 1, 1]],\n  [minVal + 0.625 * diff, [1, 1, 0]],\n  [minVal + 0.875 * diff, [1, 0, 0]],\n  [maxVal, [0.5, 0, 0]],\n]\n\nconst viz = new ColorRampVisualizer(rainbowColors)\n\nfunction evaluatePixel(sample) {\n  var rgba = viz.process(sample.CLOUD_TOP_PRESSURE)\n  rgba.push(sample.dataMask)\n  return rgba\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13,\n                45,\n                15,\n                47,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-5p-l2\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2018-12-28T00:00:00Z\",\n                        \"to\": \"2018-12-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process.html",
    "href": "APIs/SentinelHub/Process.html",
    "title": "Processing API",
    "section": "",
    "text": "The Processing API (or shortly \"Process API\") is the most commonly used API in Sentinel Hub as it provides images based on satellite data. Users can request raw satellite data, simple band combinations such as false colour composites, calculations of simple remote sensing indices like NDVI, or more advanced processing such as calculation of Leaf area index (LAI).\nEven though satellite imagery data are often distributed in \"tiles\", we do not want users to be limited to these. Tiles are an artificially introduced entity to make data distribution easier to handle. However, users should not have to care about whether their AOI is on one tile or another, or perhaps on the border of two tiles. This is why Sentinel Hub API hides this complexity and simply makes the data available over chosen area of interest and temporal period of interest. Tiles are therefore automatically stitched together based on defined parameters (AOI, time period, cloud coverage, priority, etc., depending on the data type)."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ErrorHandling.html",
    "href": "APIs/SentinelHub/Overview/ErrorHandling.html",
    "title": "Error handling",
    "section": "",
    "text": "Whenever an error occurs, whether it be the fault of the user or an internal system, an error object will be returned. HTTP response codes of 4xx suggest a bad request. If you receive a 4xx response, we recommend reviewing the API docs for more context to help you troubleshoot. 5xx errors suggest a problem on Sentinel Hub's end, so if you receive a 5xx error, please contact support."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/RateLimiting.html",
    "href": "APIs/SentinelHub/Overview/RateLimiting.html",
    "title": "Rate limiting",
    "section": "",
    "text": "In order to ensure the stability of the system and to guarantee good performance for all users we have to protect it against deliberate attacks or runaway scripts. Every request which reaches our system will therefore go through a rate limiting filter. As long as the agreed upon rate limiting policies are conformed to, responses by our services shall be delivered in timely fashion. On the other hand, requests which violate any of the agreed upon policies will be responded to with a HTTP 429 response.\nWe are able to adjust rate limit policies for each individual user so do contact our Support for specific requirements.\n\nRate limiting policy\nA rate limiting policy defines either how many processing units or HTTP requests can be used per given time period or in total. Both processing units and requests are rate limited and the level of rate limiting depends on your account (see pricing plans).\nAn API is usually protected by multiple rate limiting policies. For example, Processing API has both a processing unit and request rate limiting policies. To conform to the rate limiter, all rate limiting policies have to be satisfied. For example, lets say you have a policy of 100 requests per minute and a policy of 100 processing units per minute. By issuing 100 requests from each every request is valued at 2 processing units in one minute, only 50 requests will pass, all others will fail with HTTP status 429. Even though you have a limit of 100 requests per minute, 50 requests would violate the 100 processing units per minute policy and thus be rate limited.\nUnused processing units and requests do not accumulate. If you have a rate limit policy with 100 request per minute and you don't consume any request for a longer period you are still able to do just 100 requests within the next minute.\n\n\nRate limiting ramp up\nFor all SH subscriptions, the rate limiting is configured also on a \"per minute\" basis (i.e. 600 requests per minute and 1000 processing units per minute for the Enterprise S subscription). For optimal performance, it is best to spread this number of requests over a whole minute, i.e. to send one request every 0.1 seconds. As we understand that this might be difficult to do, we allow some variation from this optimum. However, if you will burst the full number of requests at once, some of them will be rate limited. For such requests, we recommend that you simply resend them - the process should reach the optimal level in a few minutes.\n\n\nResponse Headers\nAll requests going through rate limiting include headers to allow for programmatic adaption to Rate Limiting:\n\nRetry-After: Time in milliseconds until the next request is available.\n\n\nExample:\n\nResponse code and message\n{\n  \"status\": 429,\n  \"reason\": \"Too Many Requests\",\n  \"message\": \"You have exceeded your rate limit\",\n  \"code\": \"RATE_LIMIT_EXCEEDED\"\n}\n\n\nResponse header\n{\n  \"Date\": \"Tue, 16 Aug 2022 13:15:02 GMT\",\n  \"retry-after\": \"3398\",\n  ...\n}\nThe HTTP status code in this example is 429 meaning that the request was rate limited. The value of the Retry-After header is 3398, which means that next request will be available in 3398 ms.\n\n\n\n\nTry it out\nWe have set up a test user with two very restrictive rate limiting policies:\n\n10 requests per minute and\n10 processing units per minute\n\nYou can use its instance (for OGC requests) or Oauth client credentials (for API requests) to test how our rate limiting works and for integration purposes.\nAn example of a WMS request using the test user's instance:\n\n[https://services.sentinel-hub.com/ogc/wms/7702fda8-f583-4ae0-a581-1b34e7a6d350](https://services.sentinel-hub.com/ogc/wms/7702fda8-f583-4ae0-a581-1b34e7a6d350){target=“_blank”}?\n\nThe test user's Oauth client credentials below can be used to get an access token, which can then be included in header of a process API requests (for examples of requests see here):\n\nClient id: fa02a066-fc80-4cb4-af26-aae0af26cbf1 Client secret: rate_limit_secret\n\nNote that many people may be using it at the same moment so there is a chance that it will be over the limit more or less all the time. Its purpose is to evaluate response headers anyway.\n\n\nTips to Avoid Being Rate Limited\n\nCaching\nStore API responses that you expect to use a lot. For example, don’t call same requests on every page load but try to store responses in local storage.\n\n\nRequest only what you need\nBe defensive in fetching and try to request only the data that you actually need.\n\n\nExponential backoff\nWhen your limits have been exceeded, we recommend implementing retries with a exponential backoff. An exponential backoff means that you wait for exponentially longer intervals between each retry of a single failing request."
  },
  {
    "objectID": "APIs/Others/ReleaseNotes.html",
    "href": "APIs/Others/ReleaseNotes.html",
    "title": "Release notes",
    "section": "",
    "text": "This page includes the list of changes made to Catalog APIs for each release."
  },
  {
    "objectID": "APIs/Others/ReleaseNotes.html#opensearch-catalog-api-updates",
    "href": "APIs/Others/ReleaseNotes.html#opensearch-catalog-api-updates",
    "title": "Release notes",
    "section": "OpenSearch Catalog API updates",
    "text": "OpenSearch Catalog API updates\n\nOpenSearch API error handling update [2023-10-24]\nPlease be informed that the OpenSearch API error handling was updated on 24th October 2023.\nPlease note that new responses with errors provide the RequestId, which is intended to help identify the requests with errors. Including the RequestId in your issues submitted to the support team is strongly recommended in case of Catalog API problems.\nThe new error handling is described below.\n\nIncorrect collection name\n\nPrevious responseNew response\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"loadFromStore - Not Found\",\n        \"ErrorCode\": 404\n    }\n}\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown collection.\",\n        \"ErrorCode\": 404,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [\n                    \"collection\"\n                ],\n                \"msg\": \"Collection '&lt;collection name presented in query&gt;' does not exist.\",\n            },\n        ],\n        \"RequestId\": &lt;request_id&gt;,\n    }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinl2/search.json\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown collection.\",\n        \"ErrorCode\": 404,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [\n                    \"collection\"\n                ],\n                \"msg\": \"Collection 'Sentinl2' does not exist.\"\n            },\n        ],\n        \"RequestID\": \"70970f42-e374-4e26-8778-41a1463e700d\"\n    }\n}\n\n\n\n\n\n\nIncorrect name of the query parameter\n(when the collection is not specified)\n\nPrevious responseNew response\n\n\nNo error is returned. The incorrect query parameter is ignored and not reflected in appliedFilters.\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown query parameter(s).\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [&lt;list of unexisting parameters&gt;],\n                \"msg\": \"Query parameters do not exist.\",\n            },\n        ],\n        \"RequestId\": &lt;request_id&gt;,\n    }\n}\n\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?productsType=S2MSI1C\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown query parameter(s).\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": {\n            \"loc\": [\n                \"productsType\"\n            ],\n            \"msg\": \"Query parameters do not exist.\"\n        },\n        \"RequestID\": \"d9f22173-4d56-44fd-ab18-35d6018c49d7\"\n    }\n}\n\n\n\n\n\nIncorrect name of the query parameter\n(when the collection is specified)\n\nPrevious responseNew response\n\n\nNo error is returned. The incorrect query parameter is ignored and not reflected in appliedFilters.\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown query parameter(s).\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [&lt;list of unexisting parameters&gt;],\n                \"msg\": \"Query parameters do not exist or are not available for specified collection.\",\n            },\n        ],\n        \"RequestId\": &lt;request_id&gt;,\n  }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?productType=S2MSI1C&startDat=2023-06-11&completionDte=2023-06-22\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown query parameter(s).\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": {\n            \"loc\": [\n                \"startDat\",\n                \"completionDte\",\n                        ],\n            \"msg\": \"Query parameters do not exist or are not available for specified collection.\"\n        },\n        \"RequestID\": \"25d522af-ba4e-4152-a368-9635d560e649\"\n    }\n}\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nPlease note that dataset parameter is not supported anymore. Any query with the dataset parameter results in an error.\n\n\n\n\nIncorrect value of the query parameter\n(maxRecords, index, page, sortParam, sortOrder, exactCount, geometry, box, lon, lat, radius, startDate, completionDate, updated, published, publishedAfter, publishedBefore, status)\n\nPrevious responseNew response\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": &lt;error message&gt;,\n        \"ErrorCode\": 400\n    }\n}\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Validation error.\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [&lt;list of parameters that error \"msg\" field relate to&gt;],\n                \"msg”: &lt;error message&gt;}&gt;,\n            },\n        ]\n        \"RequestId\": &lt;request_id&gt;,\n  }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&maxRecords=2001\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Validation error.\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [\n                    \"maxRecords\"\n                ],\n                \"msg\": \"Input should be less than or equal to 2000.\"\n            }\n        ],\n        \"RequestID\": \"b3b4c0bb-9697-4ff8-b90c-4eb1b97a9914\"\n    }\n}\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe kindly remind you that for status parameter the only acceptable values are:\n\nONLINE\nOFFLINE\nALL\n\nAny other value results in an error.\n\n\n\n\nIncorrect value type of the query parameter\n\nPrevious responseNew response\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": &lt;error message&gt;,\n        \"ErrorCode\": 400\n    }\n}\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Validation error.\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [&lt;list of parameters that error \"msg\" field relate to&gt;],\n                \"msg”: &lt;error message&gt;}&gt;,\n            },\n        ]\n        \"RequestId\": &lt;request_id&gt;,\n  }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?orbitNumber=ascending\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Validation error.\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [\n                    \"orbitNumber\"\n                ],\n                \"msg\": \"Proper value types for specified attribute query parameters are: 'orbitNumber'-integer\"\n            }\n        ],\n        \"RequestID\": \"33e3ebb0-7d44-4dcd-8cb2-f60216c11cef\"\n    }\n}\n\n\n\nPlease also note about the following change:\n\nupdate of the last link\n\nThe last link is provided only when exactCount is used in the request.\n\nLink last example\n\n\n{\n    \"rel\": \"last\",\n    \"type\": \"application/json\",\n    \"title\": \"last\",\n    \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?page=19168&processingLevel=S2MSI1C&startDate=2023-07-01&completionDate=2023-07-31&sortParam=startDate&exactCount=1\"\n}\n\n\n\n\n\nupdate of the exactCount parameter\n\nThe exactCount parameter is not set by default to 1 (True) anymore. Now, users need to declare its value as 1 to receive totalResults count."
  },
  {
    "objectID": "APIs/Others/ReleaseNotes.html#odata-catalog-api-updates",
    "href": "APIs/Others/ReleaseNotes.html#odata-catalog-api-updates",
    "title": "Release notes",
    "section": "OData Catalog API updates",
    "text": "OData Catalog API updates\n\nOData API single product response update [2023-10-02]\nTo comply with the OData PRIP interfaces, the OData API response for a single product query was updated. The response returns the product itself instead of a list containing the product (assigned to the field value). The example reflecting the change is presented below:\n\nOData API request example\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products(f5439b10-deb4-420e-9b84-146035fbb16c)\n\n\n\n\nOData API response change\n\nNew responsePrevious response\n\n\n{\n    \"@odata.context\": \"$metadata#Products\",\n    \"@odata.mediaContentType\": \"application/octet-stream\",\n    \"Id\": \"f5439b10-deb4-420e-9b84-146035fbb16c\",\n    \"Name\": \"S3B_SL_2_LST____20230824T223252_20230824T223552_20230825T011047_0179_083_158_1080_PS2_O_NR_004.SEN3\",\n    \"ContentType\": \"application/octet-stream\",\n    \"ContentLength\": 63028951,\n    \"OriginDate\": \"2023-08-25T01:11:48.997Z\",\n    \"PublicationDate\": \"2023-08-25T01:17:46.464Z\",\n    \"ModificationDate\": \"2023-08-25T01:18:00.817Z\",\n    \"Online\": true,\n    \"EvictionDate\": \"2023-09-09T00:00:00.000Z\",\n    \"S3Path\": \"/eodata/Sentinel-3/SLSTR/SL_2_LST___/2023/08/24/S3B_SL_2_LST____20230824T223252_20230824T223552_20230825T011047_0179_083_158_1080_PS2_O_NR_004.SEN3\",\n    \"Checksum\": [\n        {\n            \"Value\": \"ef069a2764616473ad472a5eb844ec5a\",\n            \"Algorithm\": \"MD5\",\n            \"ChecksumDate\": \"2023-08-25T01:18:00.289795Z\"\n        },\n        {\n            \"Value\": \"8d70cd42aed5626184a3a314a939153c937ea030a7a593b8a1f121b375faa77f\",\n            \"Algorithm\": \"BLAKE3\",\n            \"ChecksumDate\": \"2023-08-25T01:18:00.495218Z\"\n        }\n    ],\n    \"ContentDate\": {\n        \"Start\": \"2023-08-24T22:32:51.550Z\",\n        \"End\": \"2023-08-24T22:35:51.550Z\"\n    },\n    \"Footprint\": \"geography'SRID=4326;POLYGON ((...))'\",\n    \"GeoFootprint\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [...\n        ]\n    }\n}\n\n\n\n{\n    \"@odata.context\": \"$metadata#Products\",\n    \"value\": [\n        {\n            \"@odata.mediaContentType\": \"application/octet-stream\",\n            \"Id\": \"f5439b10-deb4-420e-9b84-146035fbb16c\",\n            \"Name\": \"S3B_SL_2_LST____20230824T223252_20230824T223552_20230825T011047_0179_083_158_1080_PS2_O_NR_004.SEN3\",\n            \"ContentType\": \"application/octet-stream\",\n            \"ContentLength\": 63028951,\n            \"OriginDate\": \"2023-08-25T01:11:48.997Z\",\n            \"PublicationDate\": \"2023-08-25T01:17:46.464Z\",\n            \"ModificationDate\": \"2023-08-25T01:18:00.817Z\",\n            \"Online\": true,\n            \"EvictionDate\": \"2023-09-09T00:00:00.000Z\",\n            \"S3Path\": \"/eodata/Sentinel-3/SLSTR/SL_2_LST___/2023/08/24/S3B_SL_2_LST____20230824T223252_20230824T223552_20230825T011047_0179_083_158_1080_PS2_O_NR_004.SEN3\",\n            \"Checksum\": [\n                {\n                    \"Value\": \"ef069a2764616473ad472a5eb844ec5a\",\n                    \"Algorithm\": \"MD5\",\n                    \"ChecksumDate\": \"2023-08-25T01:18:00.289795Z\"\n                },\n                {\n                    \"Value\": \"8d70cd42aed5626184a3a314a939153c937ea030a7a593b8a1f121b375faa77f\",\n                    \"Algorithm\": \"BLAKE3\",\n                    \"ChecksumDate\": \"2023-08-25T01:18:00.495218Z\"\n                }\n            ],\n            \"ContentDate\": {\n                \"Start\": \"2023-08-24T22:32:51.550Z\",\n                \"End\": \"2023-08-24T22:35:51.550Z\"\n            },\n            \"Footprint\": \"geography'SRID=4326;POLYGON ((...))'\",\n            \"GeoFootprint\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [...]\n            }\n        }\n    ]\n}"
  },
  {
    "objectID": "APIs/Others/ReleaseNotes.html#stac-catalog-api-updates",
    "href": "APIs/Others/ReleaseNotes.html#stac-catalog-api-updates",
    "title": "Release notes",
    "section": "STAC Catalog API updates",
    "text": "STAC Catalog API updates\n\nSTAC API interface update [2023-10-09]\nThe STAC API interface was updated to comply with the STAC item specification. The beginningDateTime and endingDateTime attributes were replaced by start_datetime and end_datetime.\n\nSTAC Request Example\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-3/items?\n\n\n\n\nSTAC API response change\n\nNew responsePrevious response\n\n\n{\n    \"type\": \"FeatureCollection\",\n    \"features\": [\n        {\n            \"type\": \"Feature\",\n            \"stac_version\": \"1.0.0\",\n            \"stac_extensions\": [],\n            \"id\": \"S3B_SY_2_VG1____20230901T000000_20230901T235959_20230902T123317_WEST_ASIA_________PS2_O_ST_002.SEN3\",\n            \"collection\": \"SENTINEL-3\",\n            \"geometry\": {...},\n            \"properties\": {\n                \"landCover\": 42.043158,\n                \"cloudCover\": 4.955728,\n                \"timeliness\": \"ST\",\n                \"cycleNumber\": 83,\n                \"orbitNumber\": 27607,\n                \"processorName\": \"PUG\",\n                \"orbitDirection\": \"ascending\",\n                \"processingDate\": \"2023-09-02T12:41:10+00:00\",\n                \"snowOrIceCover\": 0.135336,\n                \"operationalMode\": \"Earth Observation\",\n                \"processingLevel\": \"2\",\n                \"processorVersion\": \"03.49\",\n                \"platformShortName\": \"SENTINEL-3\",\n                \"baselineCollection\": \"002\",\n                \"instrumentShortName\": \"SYNERGY\",\n                \"relativeOrbitNumber\": 0,\n                \"platformSerialIdentifier\": \"B\",\n                \"datetime\": null,\n                \"end_datetime\": \"2023-09-01T23:59:59.000Z\",\n                \"start_datetime\": \"2023-09-01T00:00:00.000Z\",\n                \"productType\": \"SY_2_VG1___\"\n            },\n            \"bbox\": [...],\n            \"links\": [...],\n            \"assets\": {...}\n        }\n    ]\n}\n\n\n{\n    \"type\": \"FeatureCollection\",\n    \"features\": [\n        {\n            \"type\": \"Feature\",\n            \"stac_version\": \"1.0.0\",\n            \"stac_extensions\": [],\n            \"id\": \"S3B_SY_2_VG1____20230901T000000_20230901T235959_20230902T123317_WEST_ASIA_________PS2_O_ST_002.SEN3\",\n            \"collection\": \"SENTINEL-3\",\n            \"geometry\": {...},\n            \"properties\": {\n                \"landCover\": 42.043158,\n                \"cloudCover\": 4.955728,\n                \"timeliness\": \"ST\",\n                \"cycleNumber\": 83,\n                \"orbitNumber\": 27607,\n                \"processorName\": \"PUG\",\n                \"orbitDirection\": \"ascending\",\n                \"processingDate\": \"2023-09-02T12:41:10+00:00\",\n                \"snowOrIceCover\": 0.135336,\n                \"operationalMode\": \"Earth Observation\",\n                \"processingLevel\": \"2\",\n                \"processorVersion\": \"03.49\",\n                \"platformShortName\": \"SENTINEL-3\",\n                \"baselineCollection\": \"002\",\n                \"instrumentShortName\": \"SYNERGY\",\n                \"relativeOrbitNumber\": 0,\n                \"platformSerialIdentifier\": \"B\",\n                \"datetime\": null,\n                \"end_datetime\": \"2023-09-01T23:59:59.000Z\",\n                \"start_datetime\": \"2023-09-01T00:00:00.000Z\",\n                \"endingDateTime\": \"2023-09-01T23:59:59.000Z\",\n                \"beginningDateTime\": \"2023-09-01T00:00:00.000Z\",\n                \"productType\": \"SY_2_VG1___\"\n            },\n            \"bbox\": [...],\n            \"links\": [...],\n            \"assets\": {...}\n        }\n    ]\n}"
  },
  {
    "objectID": "APIs/On-Demand Production API.html",
    "href": "APIs/On-Demand Production API.html",
    "title": "On-Demand Production API",
    "section": "",
    "text": "On-demand processing capability for CARD-BS and CARD-COH6/12 is available in the Copernicus Data Space Ecosystem. This service is offered via a limited pool of resources, shared across all users, and can be used to process the data free of charge. This is suitable for users who need to process smaller batches of products. There is no guarantee that processing will be completed in a specific time. For commercial use, the price list is available in the CREODIAS portal. The service is available via an On-Demand Processing API that allows the users to interact with the service to issue and control the orders. It provides functionalities such as creating, updating, cancelling, pausing and monitoring of orders. This allows the users to have better control over the workflow execution process."
  },
  {
    "objectID": "APIs/On-Demand Production API.html#ondemand-processing-api-with-odata-interface",
    "href": "APIs/On-Demand Production API.html#ondemand-processing-api-with-odata-interface",
    "title": "On-Demand Production API",
    "section": "OnDemand Processing API with OData interface",
    "text": "OnDemand Processing API with OData interface\nThe OnDemand Processing API allows the users to interact with the service to issue and control the orders. It provides functionalities like creation, update, cancellation, pausing and monitoring of orders. This allows the users to have better control over the workflow execution process."
  },
  {
    "objectID": "APIs/On-Demand Production API.html#general-information",
    "href": "APIs/On-Demand Production API.html#general-information",
    "title": "On-Demand Production API",
    "section": "General information",
    "text": "General information\nThis documentation provides an overview of the OnDemand Processing (ODP) API based on the Open Data Protocol (OData) standard. The ODP API provides a RESTful interface for accessing data and metadata from the Copernicus data catalogue. Access to the API is limited by the Authentication service. Quotas are assigned according to the user typology and include limits on the number of concurrent orders and available processing workflows. The API allows the discovery of all available workflows that can be run in the Copernicus Data Space Ecosystem platform, indicating which data types can be processed and what the available parameters and output modes are.\n\nAPI Endpoint\nThe ODP API endpoint is https://odp.dataspace.copernicus.eu/odata/v1.\nOpenAPI documentation is located at https://odp.dataspace.copernicus.eu/odata/docs\n\n\nAPI Operations\nThe ODP API supports the following operations: - GET: This operation retrieves data and metadata from the ODP. The GET operation supports various query options to filter, order, and limit the data retrieved. - POST: This operation creates new entities in the ODP. The POST operation requires a payload in JSON format that specifies the properties of the new entity. - PATCH: This operation is used to update existing entities in the ODP. The PATCH operation requires a JSON payload that specifies the entity’s properties to update. - DELETE: This operation deletes existing entities from the ODP. The DELETE operation requires the URL of the entity to be deleted.\n\n\nAPI Resources\nThe ODP API provides access to the following resources: - Workflow: predefined processor which creates a single output product or series of products based on the input parameters provided by the user. Typical inputs are the name of the source product and parameters specific to the processing chain. - Production Order: request for production using a Workflow chosen by the user. - Batch Order: request to produce multiple products using a chosen Workflow. - Order Item: single processing job within and a Production Order or Batch Order.\n\n\nAuthentication\nTo access the ODP API, you need an authorization token, as only authorized users are allowed to interact with the processing service. To get the token, you can use the following script:\nexport KEYCLOAK_TOKEN=$(curl -d 'client_id=cdse-public' \\\n-d 'username=&lt;LOGIN&gt;' \\\n-d 'password=&lt;PASSWORD&gt;' \\\n-d 'grant_type=password' \\\n'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | \\\npython -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}')\nOnce you have your token, you can execute a request to the API, including the token in the request header. For example, to list available Workflows, you can use the following command:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \"https://odp.dataspace.copernicus.eu/odata/v1/Workflows\"\nMore information on the tokens and authentication can be found here: https://documentation.dataspace.copernicus.eu/APIs/OData.html#product-download"
  },
  {
    "objectID": "APIs/On-Demand Production API.html#querying-the-api",
    "href": "APIs/On-Demand Production API.html#querying-the-api",
    "title": "On-Demand Production API",
    "section": "Querying the API",
    "text": "Querying the API\n\nWorkflows\n\nListing available Workflows\nTo list all processing Workflows available to the user:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/Workflows\"\nTo search for specific Workflows you can use filters on the attributes. To find workflow named “coh”:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/Workflows?$filter=Name%20eq%20coh\"\nIn a similar way to find all Workflows suitable for processing Sentinel-1 SLC products:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/Workflows?$filter=contains(InputProductType,'SLC')\"\nDetails of the Workflow in the response list the parameters which are needed to create a new Production Order:\n        {\n            \"Id\": \"47\",\n            \"Name\": \"card_coh12_public\",\n            \"DisplayName\": \"Sentinel-1: Coherence (12 days)\",\n            \"Documentation\": null,\n            \"Description\": \"The Sentinel-1 CARD COH12 (Copernicus Analysis Ready\n             Data Coherence) processor generates a Sentinel-1 Level 2 product describing \n             the coherence of a pair of images - 12 days apart. \n             Concurrently, a terrain-correction (using DEM) is performed. This processor \n             provided by the Joint Research Centre is based on a GPT graph that can be run \n             with ESA SNAP.\",\n            \"InputProductType\": \"SLC\",\n            \"InputProductTypes\": [\n                \"SLC\",\n                \"S1_SLC__1S\",\n                \"S2_SLC__1S\",\n                \"S3_SLC__1S\",\n                \"S4_SLC__1S\",\n                \"S5_SLC__1S\",\n                \"S6_SLC__1S\",\n                \"IW_SLC__1S\",\n                \"EW_SLC__1S\",\n                \"WV_SLC__1S\"\n            ],\n            \"OutputProductType\": \"CARD-COH12\",\n            \"WorkflowVersion\": \"3.1.0\"\n        }\n\n\n\nProduction Orders\n\nCreate a new Production Order\nTo submit a new processing job, you need to use the POST method and send the parameters as a JSON message according to the requirements of a specific Workflows:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder/OData.CSC.Order\" \\\n-d '&lt;json_message&gt;'\nProduction orders accept the following general parameters: - WorkflowName: the identifier of the workflow – “Name” attribute in the /Workflows response - InputProductReference: information about the input data to be used by the processor - Reference: identifier of a single input product or multiple products (example – mosaicking processors) - ContentDate: time period which should be used by the Workflows (example - time-series based processors) - WorkflowOptions: parameters specific to the Workflows (example – DEM version, cloud coverage) - Priority: priority of the order in the users job queue. Orders with higher priority will be processed first - NotificationEndpoint: (not used) URL of the endpoint which should receive the information once the order is completed (done or failed) - Name: non-unique name for the order to help identify the orders The structure of the JSON message:\n{\n  \"WorkflowName\": \"string\",\n  \"InputProductReference\": {\n    \"Reference\": \"string\",\n    \"ContentDate\": {\n      \"Start\": \"YYYY-MM-DDTHH:mm:ss.SSSZ\",\n      \"End\": \"YYYY-MM-DDTHH:mm:ss.SSSZ\"\n    }\n  },\n  \"WorkflowOptions\": [\n    {\n      \"Name\": \"string\",\n      \"Value\": \"string\"\n    }\n  ],\n  \"Priority\": 0,\n  \"NotificationEndpoint\": \"string\",\n  \"Name\": \"string\"\n}\nExample: to submit an order for the Sentinel-1 CARD Backscatter product:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder/OData.CSC.Order\" \\\n-d '{ \\\n  \"WorkflowName\": \"card_bs\",\n  \"InputProductReference\": {\n    \"Reference\": \"S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\"\n  },\n  \"Priority\": 1,\n  \"Name\": \"card_bs_order_1\"\n}'\nSample response after successful submission of the order:\n{\n  \"@odata.context\": \"$metadata#OData.CSC.Order\",\n  \"value\": {\n    \"Id\": \"9999999\",\n    \"Status\": \"queued\",\n    \"StatusMessage\": \"queued\",\n    \"SubmissionDate\": \"2023-04-05T10:03:25.474Z\",\n    \"Name\": \"S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\",\n    \"EstimatedDate\": \"2023-04-05T10:33:16.161Z\",\n    \"InputProductReference\": {\n      \"Reference\": S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE\",\n      \"ContentDate\": null\n    },\n    \"WorkflowOptions\": [],\n    \"WorkflowName\": \"card_bs\",\n    \"WorkflowId\": null,\n    \"Priority\": 1\n  }\n}\n\n\nCheck list of Production Orders\nTo list all Production Orders requested by the user:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders\"\nWhen looking for completed orders for a specific processor:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders?$filter=WorkflowName%20eq%20coh%20and%20Status%20eq%20completed\"\n\n\nCheck the status of a single Production Order\nTo check details of the single order using the order Id:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders(&lt;order_id&gt;)\"\n\n\nCancel a Production Order\nTo cancel an existing order:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/OData.CSC.Cancel\"\nThe orders that are in the queue and have not yet been processed will be removed instantly. For the orders in processing, the Order Items (single item within a Production Order) being processed will complete but the remaining part of the Order will be cancelled. #### Display details of the result The order generates a new product which can be downloaded from the public repository or private storage. To check the details of the result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/Product\"\n\n\nDownload the result\nOnce the order is successfully processed, the status changes to complete, and the result is ready for download. The user may choose to instruct the service to put the results in a specified location (mandatory if custom parameters have been passed to the Workflow), and standard results (for Workflows like CARD-BS or CARD-COH12) are stored in the CDSE public repository and can be retrieved through the API. To download the result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(&lt;order_id&gt;)/Product/$value\" \\\n-o result.zip\n\n\n\nBatch Orders\n\nCreate a new Batch Order\nIn a way similar to a single Production Order, you can request processing of multiple input products as a Batch Order. The Batch Order will run a selected Workflow with the same parameters for all inputs and output the results to the same location. Using Batch Orders makes it easier to process time series or large AOIs. Batch Order endpoint uses the same mechanism as described for the Production Order:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \n\"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder/OData.CSC.Order\" \\\n-d '&lt;json_message&gt;'\nBatch Orders accept the following general parameters: - WorkflowName: the identifier of the workflow – “Name” attribute in the /Workflows response - IdentifierList: information about the input data to be used by the processor - identifiers of products - WorkflowOptions: parameters specific to the Workflows (example – DEM version, cloud coverage) - Priority: priority of the order in the users job queue. Orders with higher priority will be processed first - Callback: (not used) URL of the endpoint which should receive the information once the order is completed (done or failed) - Name: non-unique name for the order to help identify the orders - BatchSize: maximum number of items in the batch - BatchVolume: maximum size of output data The structure of the JSON message:\n{\n  \"Name\": \"string\",\n  \"Priority\": 0,\n  \"WorkflowName\": \"string\",\n  \"Callback\": \"string\",\n  \"WorkflowOptions\": [\n    {\n      \"Name\": \"string\",\n      \"Value\": \"string\"\n    }\n  ],\n  \"IdentifierList\": [\n    \"string\"\n  ],\n  \"BatchSize\": 0,\n  \"BatchVolume\": 0\n}\n\n\nCheck list of Batch Orders\nTo list all Production Orders requested by the user:\ncurl -X POST -H 'Content-Type:application/json' \\\n-H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\ \n\"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder\"\nWhen looking for batch orders for a specific processor (in example ‘coh’):\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder?$filter=WorkflowName%20eq%20%coh\"\n\n\nCheck the status of a single Batch Order\nTo check details of the single order using the order Id:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)\"\n\n\nList products generated in a Batch Order\nWhen the batch order is processed, for each input product an output is generated. To list the output of a batch:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)/Products\"\n\n\nDisplay details of the results\nEach item in the batch is an individual Production Order. To check the details of the single result:\ncurl -H \"Authorization: Bearer $KEYCLOAK_TOKEN\" \\\n\"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(&lt;batch_order_id&gt;)/Product(&lt;order_id&gt;)\""
  },
  {
    "objectID": "APIs/SentinelHub.html",
    "href": "APIs/SentinelHub.html",
    "title": "Sentinel Hub",
    "section": "",
    "text": "Sentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use APIs to retrieve satellite data over their AOI and specific time range from complete archives in a few seconds."
  },
  {
    "objectID": "Quotas.html#copernicus-general-users",
    "href": "Quotas.html#copernicus-general-users",
    "title": "Quotas and Limitations",
    "section": "Copernicus General Users",
    "text": "Copernicus General Users\n\n\n\n\n\n\nLimitations\n\n\nS3, OData, STAC\n\n\nData Workspace API\n\n\nopenEO API / Algorithm plaza\n\n\nSentinel Hub APIs⁸\n\n\nDirect HTTP access to COGs\n\n\n\n\n\n\nRequests per month\n\n\n-\n\n\n-\n\n\n-\n\n\n10 000\n\n\n50 000⁷ ⁹\n\n\n\n\nRequests per minute\n\n\n-\n\n\n-\n\n\n12¹¹ ¹³\n\n\n300\n\n\n-\n\n\n\n\nProcessing units (PU) per month\n\n\n-\n\n\n-\n\n\n-\n\n\n10 000\n\n\n-\n\n\n\n\nProcessing units (PU) per minute\n\n\n-\n\n\n-\n\n\n-\n\n\n300\n\n\n-\n\n\n\n\nBandwidth limit per connection (MB/s) (IAD¹)\n\n\n20\n\n\n-\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nNumber of concurrent connections limit (IAD¹)\n\n\n4\n\n\n-\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nMonthly transfer limit (TB) (IAD¹)¹⁰\n\n\n6\n\n\n-\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nNumber of concurrent orders limit (DAD²)\n\n\n-\n\n\n1\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nMonthly transfer limit (TB) (DAD²)\n\n\n-\n\n\n0,1\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nProcessed Products per month\n\n\n-\n\n\n25\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nConcurrent Processing\n\n\n-\n\n\n2¹²\n\n\n2\n\n\n-\n\n\n-\n\n\n\n\nNumber of active sessions³\n\n\n100\n\n\n-\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nA token stays active for⁴\n\n\n10 minutes\n\n\n-\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nA token can be refreshed in⁵\n\n\n60 minutes\n\n\n-\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nNumber of products that be accessed with one token⁶\n\n\nNo limits\n\n\n-\n\n\n-\n\n\n-\n\n\n-\n\n\n\n\nCredits per month\n\n\n-\n\n\n-\n\n\n4000\n\n\n-\n\n\n-\n\n\n\n\nConcurrent API requests\n\n\n-\n\n\n-\n\n\n2\n\n\n-\n\n\n-\n\n\n\n\n\n\n ¹ IAD: Immediately Available Data.  ² DAD: Deferred Available Data (known as Offline data). It is not possible to order DAD by using OData,STAC or S3, Copernicus Browser or any of the Sentinel Hub APIs. DAD (Offline data) can only be ordered by using the Data Workspace. Only after ordering, it can be downloaded from the catalogue by using the download APIs.  ³ This includes, among others, a newly generated token and logging in to the user panel. Please refer to: Device Activity and see the number of signed in devices - It is not possible to increase this number to a bigger value than 100, with a paid plan. Each session starts when the user generates a new token and use it for the downloading process. One session ends when the token reaches its expiry time (a token stays active for 10 min).  ⁴ After reaching this limit, the Access Token must either be refreshed by using the Refresh Token or be re-generated.  ⁵ Anytime within 60 minutes after the access token is generated.  ⁶ As long as any other limit(s) are not breached.  ⁷ Extensions are available via CREODIAS offering (see 3.2.3, “Product Generation Service” section of the Service Description and Evolution Roadmap).  ⁸ Similar principles apply for all SentinelHub APIs while the differences and details are covered in the Processing Unit section of our documentation. Note that there are APIs that are not available to Copernicus General Users such as Sentinel Hub Batch Processing API.  ⁹ Technical limitation may be applied to maintain platform stability.  ¹⁰ After reaching this monthly transfer limit, the maximum bandwidth drops to 1MB/s and the number of concurrent connections drops to 1.  ¹¹ Only enabled for openEO synchronous execution requests (POST /result) and batch execution requests (POST /{job_id}/result).  ¹² The maximum number of simultaneous production orders running in parallel, i.e. the orders in “In progress” status.  ¹³ 1 request per 5 seconds."
  },
  {
    "objectID": "Data/ComplementaryData/CMEMS.html",
    "href": "Data/ComplementaryData/CMEMS.html",
    "title": "Copernicus Marine Environment Monitoring Service (CMEMS)",
    "section": "",
    "text": "The Copernicus Marine Environment Monitoring Service (CMEMS) provides open, free, regular and systematic reference data on the blue (physical), white (sea ice), and green (biogeochemical) state of the marine environment, as well as data on variability and dynamics across the global ocean and European seas.\nCopernicus Data Space Ecosystem data catalogue provides resources for water analysis in all dimensions, from local to global and from visible to radar techniques. The CMEMS products available via Copernicus Data Space Ecosystem platform are particularly dedicated to water application.\nTwo main kinds of products are offered by Copernius Data Space Ecosystem: Near Real Time (NRT) and Reprocessed including climate analysis (REP)."
  },
  {
    "objectID": "Data/ComplementaryData/CMEMS.html#copernicus-marine-environment-monitoring-service-cmems---near-real-time-nrt",
    "href": "Data/ComplementaryData/CMEMS.html#copernicus-marine-environment-monitoring-service-cmems---near-real-time-nrt",
    "title": "Copernicus Marine Environment Monitoring Service (CMEMS)",
    "section": "Copernicus Marine Environment Monitoring Service (CMEMS) - Near Real Time (NRT)",
    "text": "Copernicus Marine Environment Monitoring Service (CMEMS) - Near Real Time (NRT)\n\nOverview\nThe CMEMS Near Real Time (NRT) service provides oceanic and marine data in near real-time, with a delay of typically less than three hours from the time of observation. The NRT service is particularly important for emergency response operations and weather forecasting, as well as for maritime transport, fisheries, oil and gas exploration, and other applications where near real-time data is critical. The CMEMS NRT service utilizes a network of in situ (buoys, drifters, etc.) and satellite-based sensors to collect high-quality oceanic and marine data in near real-time.\n\nOffered Data\n\n\nGLO - Global\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nGLOBAL_ANALYSIS_FORECAST_BIO_001_028\n\n\nJan 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/BIO/GLOBAL_ANALYSIS_FORECAST_BIO_001_028/\n\n\nDetails\n\n\n\n\nGLOBAL_ANALYSIS_FORECAST_BIO_001_014\n\n\nDec 2011 - Jan 2021\n\n\n/eodata/CMEMS/NRT/GLO/BIO/GLOBAL_ANALYSIS_FORECAST_BIO_001_014/\n\n\nN/A\n\n\n\n\nCAR (Carbon)\n\n\nINSITU_GLO_CARBON_NRT_OBSERVATIONS_013_049\n\n\nMar 2019 - Dec 2021\n\n\n/eodata/CMEMS/NRT/GLO/CAR/INSITU_GLO_CARBON_NRT_OBSERVATIONS_013_049/\n\n\nN/A\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_GLO_CHL_L3_NRT_OBSERVATIONS_009_032\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/GLO/CHL/OCEANCOLOUR_GLO_CHL_L3_NRT_OBSERVATIONS_009_032/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_CHL_L4_NRT_OBSERVATIONS_009_033\n\n\nJan 2016 - Jan 2022\n\n\n/eodata/CMEMS/NRT/GLO/CHL/OCEANCOLOUR_GLO_CHL_L4_NRT_OBSERVATIONS_009_033/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_GLO_NRT_OBSERVATIONS_013_030\n\n\nFeb 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/GLO/OBS/INSITU_GLO_NRT_OBSERVATIONS_013_030/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_GLO_OPTICS_L3_NRT_OBSERVATIONS_009_030\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L3_NRT_OBSERVATIONS_009_030/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_OPTICS_L4_NRT_OBSERVATIONS_009_083\n\n\nJan 2016 - Jun 2022\n\n\n/eodata/CMEMS/NRT/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L4_NRT_OBSERVATIONS_009_083/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nGLOBAL_ANALYSIS_FORECAST_PHY_001_024\n\n\nAug 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/PHY/GLOBAL_ANALYSIS_FORECAST_PHY_001_024/\n\n\nDetails\n\n\n\n\nGLOBAL_ANALYSIS_FORECAST_PHYS_001_015\n\n\nDec 2015 - Jan 2022\n\n\n/eodata/CMEMS/NRT/GLO/PHY/GLOBAL_ANALYSIS_FORECAST_PHYS_001_015/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_NRT_015_001\n\n\nJan 2018 - Mar 2023\n\n\n/eodata/CMEMS/NRT/GLO/PHY/MULTIOBS_GLO_PHY_NRT_015_001/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_NRT_015_003\n\n\nMay 2019 - Aug 2019\n\n\n/eodata/CMEMS/NRT/GLO/PHY/MULTIOBS_GLO_PHY_NRT_015_003/\n\n\nDetails\n\n\n\n\nSEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046\n\n\nApr 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/PHY/SEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_001\n\n\nMar 2005 Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/SI/SEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_001/\n\n\nDetails\n\n\n\n\nSEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_006\n\n\nMar 2010 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/SI/SEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_006/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_GLO_SST_L3S_NRT_OBSERVATIONS_010_010\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/GLO/SST/SST_GLO_SST_L3S_NRT_OBSERVATIONS_010_010/\n\n\nDetails\n\n\n\n\nSST_GLO_SST_L4_NRT_OBSERVATIONS_010_001\n\n\nJan 2007 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/SST/SST_GLO_SST_L4_NRT_OBSERVATIONS_010_001/\n\n\nDetails\n\n\n\n\nSST_GLO_SST_L4_NRT_OBSERVATIONS_010_005\n\n\nSep 2017 - Dec 2022\n\n\n/eodata/CMEMS/NRT/GLO/SST/SST_GLO_SST_L4_NRT_OBSERVATIONS_010_005/\n\n\nN/A\n\n\n\n\nSST_GLO_SST_L4_NRT_OBSERVATIONS_010_014\n\n\nFeb 2015 - Dec 2022\n\n\n/eodata/CMEMS/NRT/GLO/SST/SST_GLO_SST_L4_NRT_OBSERVATIONS_010_014/\n\n\nN/A\n\n\n\n\nTS_OA (Real time in-situ observations objective analysis)\n\n\nINSITU_GLO_TS_OA_NRT_OBSERVATIONS_013_002_a\n\n\nJan 2015 - Dec 2022\n\n\n/eodata/CMEMS/NRT/GLO/TS_OA/INSITU_GLO_TS_OA_NRT_OBSERVATIONS_013_002_a/\n\n\nDetails\n\n\n\n\nUV (water velocity)\n\n\nINSITU_GLO_UV_NRT_OBSERVATIONS_013_048\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/GLO/UV/INSITU_GLO_UV_NRT_OBSERVATIONS_013_048/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nGLOBAL_ANALYSIS_FORECAST_WAV_001_023\n\n\nApr 2015 - Aug 2019\n\n\n/eodata/CMEMS/NRT/GLO/WAV/GLOBAL_ANALYSIS_FORECAST_WAV_001_023/\n\n\nN/A\n\n\n\n\nGLOBAL_ANALYSIS_FORECAST_WAV_001_027\n\n\nMay 2017 - Mar 2023\n\n\n/eodata/CMEMS/NRT/GLO/WAV/GLOBAL_ANALYSIS_FORECAST_WAV_001_027/\n\n\nDetails\n\n\n\n\nGLOBAL_ANALYSIS_FORECAST_WAV_001_028\n\n\nAug 2019 - Aug 2019\n\n\n/eodata/CMEMS/NRT/GLO/WAV/GLOBAL_ANALYSIS_FORECAST_WAV_001_028/\n\n\nDetails\n\n\n\n\nSEALEVEL_GLO_WAV_L3_NRT_OBSERVATIONS_008_052\n\n\nJul 2017 - Nov 2018\n\n\n/eodata/CMEMS/NRT/GLO/WAV/SEALEVEL_GLO_WAV_L3_NRT_OBSERVATIONS_008_052/\n\n\nN/A\n\n\n\n\nWAVE_GLO_WAV_L3_SPC_NRT_OBSERVATIONS_014_002\n\n\nApr 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/WAV_SPC/WAVE_GLO_WAV_L3_SPC_NRT_OBSERVATIONS_014_002/\n\n\nDetails\n\n\n\n\nWAVE_GLO_WAV_L3_SWH_NRT_OBSERVATIONS_014_001\n\n\nOct 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/WAV_SWH/WAVE_GLO_WAV_L3_SWH_NRT_OBSERVATIONS_014_001/\n\n\nDetails\n\n\n\n\nWAVE_GLO_WAV_L4_SWH_NRT_OBSERVATIONS_014_003\n\n\nJun 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/WAV_SWH/WAVE_GLO_WAV_L4_SWH_NRT_OBSERVATIONS_014_003/\n\n\nDetails\n\n\n\n\nWIN (Wind)\n\n\nWIND_GLO_WIND_L3_NRT_OBSERVATIONS_012_002\n\n\nJan 2016 - Apr 2023\n\n\n/eodata/CMEMS/NRT/GLO/WIN/WIND_GLO_WIND_L3_NRT_OBSERVATIONS_012_002/\n\n\nDetails\n\n\n\n\nWIND_GLO_WIND_L4_NRT_OBSERVATIONS_012_004\n\n\nJan 2018 - Nov 2021\n\n\n/eodata/CMEMS/NRT/GLO/WIN/WIND_GLO_WIND_L4_NRT_OBSERVATIONS_012_004/\n\n\nDetails\n\n\n\n\n\n\nANT - Antarctic Ocean\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_ANT_SEAICE_L4_NRT_OBSERVATIONS_011_012\n\n\nJan 2011 - Mar 2022\n\n\n/eodata/CMEMS/NRT/ANT/SI/SEAICE_ANT_SEAICE_L4_NRT_OBSERVATIONS_011_012/\n\n\nDetails\n\n\n\n\n\n\nARC - Arctic Ocean\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nARCTIC_ANALYSISFORECAST_BGC_002_004\n\n\nJan 2019 - May 2023\n\n\n/eodata/CMEMS/NRT/ARC/BGC/ARCTIC_ANALYSISFORECAST_BGC_002_004/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_ARC_BGC_HR_L3_NRT_009_201\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/BGC/OCEANCOLOUR_ARC_BGC_HR_L3_NRT_009_201/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_ARC_BGC_HR_L4_NRT_009_207\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/ARC/BGC/OCEANCOLOUR_ARC_BGC_HR_L4_NRT_009_207/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nARCTIC_ANALYSIS_FORECAST_BIO_002_004\n\n\nDec 2011 - Jul 2021\n\n\n/eodata/CMEMS/NRT/ARC/BIO/ARCTIC_ANALYSIS_FORECAST_BIO_002_004/\n\n\nDetails\n\n\n\n\nARCTIC_ANALYSIS_FORECAST_WAV_002_006\n\n\nJul 2019 - Aug 2019\n\n\n/eodata/CMEMS/NRT/ARC/BIO/ARCTIC_ANALYSIS_FORECAST_WAV_002_006/\n\n\nN/A\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_ARC_CHL_L3_NRT_OBSERVATIONS_009_047\n\n\nMar 2016 - Aug 2022\n\n\n/eodata/CMEMS/NRT/ARC/CHL/OCEANCOLOUR_ARC_CHL_L3_NRT_OBSERVATIONS_009_047/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ARC_CHL_L4_NRT_OBSERVATIONS_009_087\n\n\nApr 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/ARC/CHL/OCEANCOLOUR_ARC_CHL_L4_NRT_OBSERVATIONS_009_087/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_ARC_NRT_OBSERVATIONS_013_031\n\n\nJan 1990 - Jan 2023\n\n\n/eodata/CMEMS/NRT/ARC/OPT/INSITU_ARC_NRT_OBSERVATIONS_013_031/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_ARC_OPTICS_L3_NRT_OBSERVATIONS_009_046\n\n\nMar 2016 - Aug 2022\n\n\n/eodata/CMEMS/NRT/ARC/OPT/OCEANCOLOUR_ARC_OPTICS_L3_NRT_OBSERVATIONS_009_046/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ARC_OPTICS_L4_NRT_OBSERVATIONS_009_089\n\n\nApr 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/ARC/OPT/OCEANCOLOUR_ARC_OPTICS_L4_NRT_OBSERVATIONS_009_089/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nARCTIC_ANALYSIS_FORECAST_PHYS_002_001_a\n\n\nOct 2016 - May 2023\n\n\n/eodata/CMEMS/NRT/ARC/PHY/ARCTIC_ANALYSIS_FORECAST_PHYS_002_001_a/\n\n\nDetails\n\n\n\n\nARCTIC_ANALYSISFORECAST_PHY_ICE_002_011\n\n\nNov 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/PHY/ARCTIC_ANALYSISFORECAST_PHY_ICE_002_011/\n\n\nDetails\n\n\n\n\nSEAICE_ARC_PHY_AUTO_L4_NRT_011_015\n\n\nDec 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/PHY/SEAICE_ARC_PHY_AUTO_L4_NRT_011_015/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_002\n\n\nJan 2010 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/SI/SEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_002/\n\n\nDetails\n\n\n\n\nSEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_003\n\n\nJun 2008 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/SI/SEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_003/\n\n\nN/A\n\n\n\n\nSEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_007\n\n\nApr 2010 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/SI/SEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_007/\n\n\nDetails\n\n\n\n\nSEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_008\n\n\nJan 1982 - Apr 2023\n\n\n/eodata/CMEMS/NRT/ARC/SI/SEAICE_ARC_SEAICE_L4_NRT_OBSERVATIONS_011_008/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nARCTIC_ANALYSIS_FORECAST_WAV_002_006\n\n\nDec 2016 - Feb 2020\n\n\n/eodata/CMEMS/NRT/ARC/WAV/ARCTIC_ANALYSIS_FORECAST_WAV_002_006/\n\n\nN/A\n\n\n\n\nARCTIC_ANALYSIS_FORECAST_WAV_002_010\n\n\nDec 2016 - Feb 2020\n\n\n/eodata/CMEMS/NRT/ARC/WAV/ARCTIC_ANALYSIS_FORECAST_WAV_002_010/\n\n\nN/A\n\n\n\n\n\n\nATL - Atlantic North\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_ATL_CHL_L3_NRT_OBSERVATIONS_009_036\n\n\nFeb 2016 - Aug 2022\n\n\n/eodata/CMEMS/NRT/ATL/CHL/OCEANCOLOUR_ATL_CHL_L3_NRT_OBSERVATIONS_009_036/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_CHL_L4_NRT_OBSERVATIONS_009_037\n\n\nMay 2019 - Aug 2021\n\n\n/eodata/CMEMS/NRT/ATL/CHL/OCEANCOLOUR_ATL_CHL_L4_NRT_OBSERVATIONS_009_037/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_CHL_L4_NRT_OBSERVATIONS_009_090\n\n\nApr 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/ATL/CHL/OCEANCOLOUR_ATL_CHL_L4_NRT_OBSERVATIONS_009_090/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_ATL_OPTICS_L3_NRT_OBSERVATIONS_009_034\n\n\nApr 2016 - Aug 2022\n\n\n/eodata/CMEMS/NRT/ATL/OPT/OCEANCOLOUR_ATL_OPTICS_L3_NRT_OBSERVATIONS_009_034/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_OPTICS_L4_NRT_OBSERVATIONS_009_092\n\n\nApr 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/ATL/OPT/OCEANCOLOUR_ATL_OPTICS_L4_NRT_OBSERVATIONS_009_092/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_ATL_SST_L4_NRT_OBSERVATIONS_010_025\n\n\nJan 2018 - Nov 2022\n\n\n/eodata/CMEMS/NRT/ATL/SST/SST_ATL_SST_L4_NRT_OBSERVATIONS_010_025/\n\n\nDetails\n\n\n\n\n\n\nBAL - Baltic Sea\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nOCEANCOLOUR_BAL_BGC_HR_L3_NRT_009_202\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/BGC/OCEANCOLOUR_BAL_BGC_HR_L3_NRT_009_202/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_BAL_BGC_HR_L4_NRT_009_208\n\n\nFeb 2020 - Jan 2023\n\n\n/eodata/CMEMS/NRT/BAL/BGC/OCEANCOLOUR_BAL_BGC_HR_L4_NRT_009_208/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nBALTICSEA_ANALYSIS_FORECAST_BIO_003_007\n\n\nMar 2016 - Feb 2021\n\n\n/eodata/CMEMS/NRT/BAL/BIO/BALTICSEA_ANALYSIS_FORECAST_BIO_003_007/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_BAL_CHL_L3_NRT_OBSERVATIONS_009_049\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BAL/CHL/OCEANCOLOUR_BAL_CHL_L3_NRT_OBSERVATIONS_009_049/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_BAL_NRT_OBSERVATIONS_013_032\n\n\nJan 2015 - Jan 2023\n\n\n/eodata/CMEMS/NRT/BAL/OBS/INSITU_BAL_NRT_OBSERVATIONS_013_032/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_BAL_OPTICS_L3_NRT_OBSERVATIONS_009_048\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BAL/OPT/OCEANCOLOUR_BAL_OPTICS_L3_NRT_OBSERVATIONS_009_048/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nBALTICSEA_ANALYSIS_FORECAST_PHY_003_006\n\n\nMar 2016 - Feb 2021\n\n\n/eodata/CMEMS/NRT/BAL/PHY/BALTICSEA_ANALYSIS_FORECAST_PHY_003_006/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_BAL_SEAICE_L4_NRT_OBSERVATIONS_011_004\n\n\nJan 2010 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/SI/SEAICE_BAL_SEAICE_L4_NRT_OBSERVATIONS_011_004/\n\n\nDetails\n\n\n\n\nSEAICE_BAL_SEAICE_L4_NRT_OBSERVATIONS_011_011\n\n\nJan 2011 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/SI/SEAICE_BAL_SEAICE_L4_NRT_OBSERVATIONS_011_011/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_BAL_SST_L3S_NRT_OBSERVATIONS_010_032\n\n\nMar 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/SST/SST_BAL_SST_L3S_NRT_OBSERVATIONS_010_032/\n\n\nDetails\n\n\n\n\nSST_BAL_SST_L4_NRT_OBSERVATIONS_010_007_b\n\n\nJan 2016 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/SST/SST_BAL_SST_L4_NRT_OBSERVATIONS_010_007_b/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nBALTICSEA_ANALYSIS_FORECAST_WAV_003_010\n\n\nJul 2017 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BAL/WAV/BALTICSEA_ANALYSIS_FORECAST_WAV_003_010/\n\n\nDetails\n\n\n\n\n\n\nBLA, BLK and BS (Black Sea)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nOCEANCOLOUR_BLK_BGC_HR_L3_NRT_009_206\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BLK/BGC/OCEANCOLOUR_BLK_BGC_HR_L3_NRT_009_206/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_BLK_BGC_HR_L4_NRT_009_212\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/BLK/BGC/OCEANCOLOUR_BLK_BGC_HR_L4_NRT_009_212/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nBLKSEA_ANALYSIS_FORECAST_BIO_007_009\n\n\nMay 2019 - Aug 2019\n\n\n/eodata/CMEMS/NRT/BLA/BIO/BLKSEA_ANALYSIS_FORECAST_BIO_007_009/\n\n\nN/A\n\n\n\n\nBLKSEA_ANALYSIS_FORECAST_BIO_007_010\n\n\nJan 2018 - Feb 2023\n\n\n/eodata/CMEMS/NRT/BLA/BIO/BLKSEA_ANALYSIS_FORECAST_BIO_007_010/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_BS_CHL_L3_NRT_OBSERVATIONS_009_044\n\n\nJun 2013 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BLA/CHL/OCEANCOLOUR_BS_CHL_L3_NRT_OBSERVATIONS_009_044/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_BS_CHL_L4_NRT_OBSERVATIONS_009_045\n\n\nJun 2013 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BLA/CHL/OCEANCOLOUR_BS_CHL_L4_NRT_OBSERVATIONS_009_045/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_BS_NRT_OBSERVATIONS_013_034\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/BLA/OBS/INSITU_BS_NRT_OBSERVATIONS_013_034/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_BS_OPTICS_L3_NRT_OBSERVATIONS_009_042\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/BLA/OPT/OCEANCOLOUR_BS_OPTICS_L3_NRT_OBSERVATIONS_009_042/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_BS_OPTICS_L4_NRT_OBSERVATIONS_009_043\n\n\nJan 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/BLA/OPT/OCEANCOLOUR_BS_OPTICS_L4_NRT_OBSERVATIONS_009_043/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nBLKSEA_ANALYSISFORECAST_PHY_007_001\n\n\nJan 2019 - Feb 2023\n\n\n/eodata/CMEMS/NRT/BLA/PHY/BLKSEA_ANALYSISFORECAST_PHY_007_001/\n\n\nDetails\n\n\n\n\nSEALEVEL_BS_PHY_L3_NRT_OBSERVATIONS_008_039\n\n\nMar 2017 - Jun 2019\n\n\n/eodata/CMEMS/NRT/BLA/PHY/SEALEVEL_BS_PHY_L3_NRT_OBSERVATIONS_008_039/\n\n\nN/A\n\n\n\n\nSEALEVEL_BS_PHY_L4_NRT_OBSERVATIONS_008_041\n\n\nJan 2017 - Jun 2019\n\n\n/eodata/CMEMS/NRT/BLA/PHY/SEALEVEL_BS_PHY_L4_NRT_OBSERVATIONS_008_041/\n\n\n\n\n\n\nSEALEVEL_BLK_PHY_MDT_L4_STATIC_008_067\n\n\nJan 1970 - Jan 1970\n\n\n/eodata/CMEMS/NRT/BLK/PHY/SEALEVEL_BLK_PHY_MDT_L4_STATIC_008_067/\n\n\nDetails\n\n\n\n\nSST_BS_PHY_SUBSKIN_L4_NRT_010_035\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/BS/PHY/SST_BS_PHY_SUBSKIN_L4_NRT_010_035/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_BS_SST_L3S_NRT_OBSERVATIONS_010_013\n\n\nJan 2008 -Apr 2023\n\n\n/eodata/CMEMS/NRT/BLA/SST/SST_BS_SST_L3S_NRT_OBSERVATIONS_010_013/\n\n\nDetails\n\n\n\n\nSST_BS_SST_L4_NRT_OBSERVATIONS_010_006\n\n\nJan 2008 -Apr 2023\n\n\n/eodata/CMEMS/NRT/BLA/SST/SST_BS_SST_L4_NRT_OBSERVATIONS_010_006/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nBLKSEA_ANALYSIS_FORECAST_WAV_007_003\n\n\nJul 2018 -Feb 2021\n\n\n/eodata/CMEMS/NRT/BLA/WAV/BLKSEA_ANALYSIS_FORECAST_WAV_007_003/\n\n\nDetails\n\n\n\n\n\n\nEUR - EUROPE\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_EUR_CHL_L3_NRT_OBSERVATIONS_009_050\n\n\nJan 2017 - Jun 2022\n\n\n/eodata/CMEMS/NRT/EUR/CHL/OCEANCOLOUR_EUR_CHL_L3_NRT_OBSERVATIONS_009_050/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nSEALEVEL_EUR_PHY_L3_NRT_OBSERVATIONS_008_059\n\n\nApr 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/EUR/PHY/SEALEVEL_EUR_PHY_L3_NRT_OBSERVATIONS_008_059/\n\n\nDetails\n\n\n\n\nSEALEVEL_EUR_PHY_L4_NRT_OBSERVATIONS_008_060\n\n\nApr 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/EUR/PHY/SEALEVEL_EUR_PHY_L4_NRT_OBSERVATIONS_008_060/\n\n\nDetails\n\n\n\n\nPHY_ASS (Physics_assimilation)\n\n\nSEALEVEL_EUR_PHY_ASSIM_L3_NRT_OBSERVATIONS_008_043\n\n\nMar 2017 - Jun 2019\n\n\n/eodata/CMEMS/NRT/EUR/PHY_ASS/SEALEVEL_EUR_PHY_ASSIM_L3_NRT_OBSERVATIONS_008_043/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_EUR_SST_L3C_NRT_OBSERVATIONS_010_009_b\n\n\nAug 2010 - Jan 2022\n\n\n/eodata/CMEMS/NRT/EUR/SST/SST_EUR_SST_L3C_NRT_OBSERVATIONS_010_009_b/\n\n\nN/A\n\n\n\n\nSST_EUR_SST_L3S_NRT_OBSERVATIONS_010_009_a\n\n\nJan 2016 - Jan 2022\n\n\n/eodata/CMEMS/NRT/EUR/SST/SST_EUR_SST_L3S_NRT_OBSERVATIONS_010_009_a/\n\n\nN/A\n\n\n\n\n\n\nIBI - Atlantic: Iberia-Biscay-Ireland\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nOCEANCOLOUR_IBI_BGC_HR_L3_NRT_009_204\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/IBI/BGC/OCEANCOLOUR_IBI_BGC_HR_L3_NRT_009_204/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_IBI_BGC_HR_L4_NRT_009_210\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/IBI/BGC/OCEANCOLOUR_IBI_BGC_HR_L4_NRT_009_210/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nIBI_ANALYSIS_FORECAST_BIO_005_004\n\n\nDec 2015 - Feb 2021\n\n\n/eodata/CMEMS/NRT/IBI/BIO/IBI_ANALYSIS_FORECAST_BIO_005_004/\n\n\nDetails\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_IBI_NRT_OBSERVATIONS_013_033\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/IBI/OBS/INSITU_IBI_NRT_OBSERVATIONS_013_033/\n\n\nDetails\n\n\n\n\nPHY (Physics)\n\n\nIBI_ANALYSIS_FORECAST_PHYS_005_001\n\n\nDec 2011 - Feb 2021\n\n\n/eodata/CMEMS/NRT/IBI/PHY/IBI_ANALYSIS_FORECAST_PHYS_005_001/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nIBI_ANALYSIS_FORECAST_WAV_005_005\n\n\nJan 2015 - Apr 2023\n\n\n/eodata/CMEMS/NRT/IBI/WAV/IBI_ANALYSIS_FORECAST_WAV_005_005/\n\n\nDetails\n\n\n\n\n\n\nMED - Mediterranean Sea\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nMEDSEA_ANALYSISFORECAST_BGC_006_014\n\n\nNov 2019 - Feb 2023\n\n\n/eodata/CMEMS/NRT/MED/BGC/MEDSEA_ANALYSISFORECAST_BGC_006_014/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_MED_BGC_HR_L3_NRT_009_205\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/MED/BGC/OCEANCOLOUR_MED_BGC_HR_L3_NRT_009_205/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_MED_BGC_HR_L4_NRT_009_211\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/MED/BGC/OCEANCOLOUR_MED_BGC_HR_L4_NRT_009_211/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nMEDSEA_ANALYSIS_FORECAST_BIO_006_014\n\n\nJul 2017 - Aug 2019\n\n\n/eodata/CMEMS/NRT/MED/BIO/MEDSEA_ANALYSIS_FORECAST_BIO_006_014/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_MED_CHL_L3_NRT_OBSERVATIONS_009_040\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/MED/CHL/OCEANCOLOUR_MED_CHL_L3_NRT_OBSERVATIONS_009_040/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_MED_CHL_L4_NRT_OBSERVATIONS_009_041\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/MED/CHL/OCEANCOLOUR_MED_CHL_L4_NRT_OBSERVATIONS_009_041/\n\n\nN/A\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_MED_NRT_OBSERVATIONS_013_035\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/MED/OBS/INSITU_MED_NRT_OBSERVATIONS_013_035/\n\n\nDetails\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_MED_OPTICS_L3_NRT_OBSERVATIONS_009_038\n\n\nApr 2016 - Sep 2022\n\n\n/eodata/CMEMS/NRT/MED/OPT/OCEANCOLOUR_MED_OPTICS_L3_NRT_OBSERVATIONS_009_038/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_MED_OPTICS_L4_NRT_OBSERVATIONS_009_039\n\n\nApr 2016 - May 2022\n\n\n/eodata/CMEMS/NRT/MED/OPT/OCEANCOLOUR_MED_OPTICS_L4_NRT_OBSERVATIONS_009_039/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nMEDSEA_ANALYSIS_FORECAST_PHY_006_013\n\n\nJul 2017 - Aug 2019\n\n\n/eodata/CMEMS/NRT/MED/PHY/MEDSEA_ANALYSIS_FORECAST_PHY_006_013/\n\n\nDetails\n\n\n\n\nMEDSEA_ANALYSISFORECAST_PHY_006_013\n\n\nMay 2019 - Feb 2023\n\n\n/eodata/CMEMS/NRT/MED/PHY/MEDSEA_ANALYSISFORECAST_PHY_006_013/\n\n\nDetails\n\n\n\n\nSEALEVEL_MED_PHY_L4_NRT_OBSERVATIONS_008_050\n\n\nJan 2017 -Jun 2019\n\n\n/eodata/CMEMS/NRT/MED/PHY/SEALEVEL_MED_PHY_L4_NRT_OBSERVATIONS_008_050/\n\n\nN/A\n\n\n\n\nSEALEVEL_MED_PHY_MDT_L4_STATIC_008_066\n\n\nJan 1970 - Jan 1970\n\n\n/eodata/CMEMS/NRT/MED/PHY/SEALEVEL_MED_PHY_MDT_L4_STATIC_008_066/\n\n\nDetails\n\n\n\n\nSST_MED_PHY_SUBSKIN_L4_NRT_010_036\n\n\nJan 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/MED/PHY/SST_MED_PHY_SUBSKIN_L4_NRT_010_036/\n\n\nDetails\n\n\n\n\nPHY_ASS (Physics_assimilation)\n\n\nSEALEVEL_MED_PHY_ASSIM_L3_NRT_OBSERVATIONS_008_048\n\n\nMar 2017 - Jun 2019\n\n\n/eodata/CMEMS/NRT/MED/PHY_ASS/SEALEVEL_MED_PHY_ASSIM_L3_NRT_OBSERVATIONS_008_048/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_MED_SST_L3S_NRT_OBSERVATIONS_010_012\n\n\nJan 2008 - Apr 2023\n\n\n/eodata/CMEMS/NRT/MED/SST/SST_MED_SST_L3S_NRT_OBSERVATIONS_010_012/\n\n\nDetails\n\n\n\n\nSST_MED_SST_L4_NRT_OBSERVATIONS_010_004\n\n\nJan 2008 - Apr 2023\n\n\n/eodata/CMEMS/NRT/MED/SST/SST_MED_SST_L4_NRT_OBSERVATIONS_010_004/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nMEDSEA_ANALYSIS_FORECAST_WAV_006_011\n\n\nJul 2017 - May 2018\n\n\n/eodata/CMEMS/NRT/MED/WAV/MEDSEA_ANALYSIS_FORECAST_WAV_006_011/\n\n\nN/A\n\n\n\n\nMEDSEA_ANALYSIS_FORECAST_WAV_006_017\n\n\nJul 2017 - Aug 2019\n\n\n/eodata/CMEMS/NRT/MED/WAV/MEDSEA_ANALYSIS_FORECAST_WAV_006_017/\n\n\nDetails\n\n\n\n\nMEDSEA_ANALYSISFORECAST_WAV_006_017\n\n\nNov 2019 - Nov 2022\n\n\n/eodata/CMEMS/NRT/MED/WAV/MEDSEA_ANALYSISFORECAST_WAV_006_017/\n\n\nDetails\n\n\n\n\n\n\nNWS (Atlantic: NW European Shelf)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nNWSHELF_ANALYSISFORECAST_BGC_004_002\n\n\nMay 2019 - Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/BGC/NWSHELF_ANALYSISFORECAST_BGC_004_002/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_NWS_BGC_HR_L3_NRT_009_203\n\n\nJan 2020 - Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/BGC/OCEANCOLOUR_NWS_BGC_HR_L3_NRT_009_203/\n\n\nDetails\n\n\n\n\nOCEANCOLOUR_NWS_BGC_HR_L4_NRT_009_209\n\n\nJan 2020 - Mar 2023\n\n\n/eodata/CMEMS/NRT/NWS/BGC/OCEANCOLOUR_NWS_BGC_HR_L4_NRT_009_209/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nNORTHWESTSHELF_ANALYSIS_FORECAST_BIO_004_002_b\n\n\nJul 2018 - Aug 2021\n\n\n/eodata/CMEMS/NRT/NWS/BIO/NORTHWESTSHELF_ANALYSIS_FORECAST_BIO_004_002_b/\n\n\nDetails\n\n\n\n\nOBS (In-situ observation)\n\n\nINSITU_NWS_NRT_OBSERVATIONS_013_036\n\n\nJan 2016 - Jan 2023\n\n\n/eodata/CMEMS/NRT/NWS/OBS/INSITU_NWS_NRT_OBSERVATIONS_013_036/\n\n\nDetails\n\n\n\n\nPHY (Physics)\n\n\nNORTHWESTSHELF_ANALYSIS_FORECAST_PHY_004_013\n\n\nAug 2018 -Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/PHY/NORTHWESTSHELF_ANALYSIS_FORECAST_PHY_004_013/\n\n\nDetails\n\n\n\n\nNORTHWESTSHELF_ANALYSIS_FORECAST_PHYS_004_001_b\n\n\nJan 2018 - Aug 2021\n\n\n/eodata/CMEMS/NRT/NWS/PHY/NORTHWESTSHELF_ANALYSIS_FORECAST_PHYS_004_001_b/\n\n\nN/A\n\n\n\n\nNWSHELF_ANALYSISFORECAST_PHY_LR_004_001\n\n\nAug 2021 - Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/PHY/NWSHELF_ANALYSISFORECAST_PHY_LR_004_001/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nNORTHWESTSHELF_ANALYSIS_FORECAST_WAV_004_014\n\n\nAug 2018 - Apr 2023\n\n\n/eodata/CMEMS/NRT/NWS/WAV/NORTHWESTSHELF_ANALYSIS_FORECAST_WAV_004_014/\n\n\nDetails\n\n\n\n\n\nN/A - data no longer provided by CMEMS"
  },
  {
    "objectID": "Data/ComplementaryData/CMEMS.html#copernicus-marine-environment-monitoring-service-cmems---reprocessed-rep",
    "href": "Data/ComplementaryData/CMEMS.html#copernicus-marine-environment-monitoring-service-cmems---reprocessed-rep",
    "title": "Copernicus Marine Environment Monitoring Service (CMEMS)",
    "section": "Copernicus Marine Environment Monitoring Service (CMEMS) - Reprocessed (REP)",
    "text": "Copernicus Marine Environment Monitoring Service (CMEMS) - Reprocessed (REP)\n\nOverview\nThe CMEMS Reprocessed (REP) service provides historical oceanic and marine data that has been reprocessed using new versions of algorithms, as well as new reference data and quality assessment procedures. The REP service provides access to high-quality, consistent and homogenized data over long time series, allowing for long-term monitoring and trend analysis. The service is particularly useful for scientists seeking to better understand the impacts of climate change on the ocean, as well as for those involved in marine resource management and policy decisions. The CMEMS REP service utilizes a range of in situ and satellite-based data sources, including historical records of ocean observations, satellite measurements, and model simulations.\n\nOffered Data\n\n\nGLO - Global\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nGLOBAL_MULTIYEAR_BGC_001_033\n\n\nJan 1998 - May 2020\n\n\n/eodata/CMEMS/REP/GLO/BGC/GLOBAL_MULTIYEAR_BGC_001_033/\n\n\nDetails\n\n\n\n\nINSITU_GLO_BGC_REP_OBSERVATIONS_013_046\n\n\nJan 1990 - Dec 2021\n\n\n/eodata/CMEMS/REP/GLO/BGC/INSITU_GLO_BGC_REP_OBSERVATIONS_013_046/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nGLOBAL_REANALYSIS_BIO_001_029\n\n\nJan 1992 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/BIO/GLOBAL_REANALYSIS_BIO_001_029/\n\n\nDetails\n\n\n\n\nGLOBAL_REANALYSIS_BIO_001_033\n\n\nJan 2001 - Jun 2019\n\n\n/eodata/CMEMS/REP/GLO/BIO/GLOBAL_REANALYSIS_BIO_001_033/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_BIO_REP_015_005\n\n\nJan 1985 - Dec 2019\n\n\n/eodata/CMEMS/REP/GLO/BIO/MULTIOBS_GLO_BIO_REP_015_005/\n\n\nDetails\n\n\n\n\nMULTIOBS_GLO_BIO_REP_015_006\n\n\nSep 2002 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/BIO/MULTIOBS_GLO_BIO_REP_015_006/\n\n\n\n\n\n\nCAR (Carbon)\n\n\nINSITU_GLO_CARBON_REP_OBSERVATIONS_013_050\n\n\n\n\n/eodata/CMEMS/REP/GLO/CAR/INSITU_GLO_CARBON_REP_OBSERVATIONS_013_050/\n\n\nDetails\n\n\n\n\nMULTIOBS_GLO_BIO_CARBON_SURFACE_REP_015_008\n\n\nJan 1985 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/CAR/MULTIOBS_GLO_BIO_CARBON_SURFACE_REP_015_008/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_GLO_CHL_L3_REP_OBSERVATIONS_009_065\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/CHL/OCEANCOLOUR_GLO_CHL_L3_REP_OBSERVATIONS_009_065/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_CHL_L3_REP_OBSERVATIONS_009_085\n\n\nSep 1997 - Jun 2018\n\n\n/eodata/CMEMS/REP/GLO/CHL/OCEANCOLOUR_GLO_CHL_L3_REP_OBSERVATIONS_009_085/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_082\n\n\nSep 1997 - Jun 2018\n\n\n/eodata/CMEMS/REP/GLO/CHL/OCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_082/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_093\n\n\nSep 1997 - Jun 2018\n\n\n/eodata/CMEMS/REP/GLO/CHL/OCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_093/\n\n\nN/A\n\n\n\n\nOHC (Ocean Heat Content)\n\n\nGLOBAL_OMI_OHC_anomalies (anomalies in respect to various years)\n\n\nAnomalies in respect to various years\n\n\n/eodata/CMEMS/REP/GLO/OHC/GLOBAL_OMI_OHC_anomalies/\n\n\n\n\n\n\nGLOBAL_OMI_OHC_area_averaged_anomalies (anomalies in respect to various years)\n\n\nAnomalies in respect to various years\n\n\n/eodata/CMEMS/REP/GLO/OHC/GLOBAL_OMI_OHC_area_averaged_anomalies/\n\n\n\n\n\n\nGLOBAL_OMI_OHC_trend (trends in respect to various years)\n\n\nTrends in respect to various years\n\n\n/eodata/CMEMS/REP/GLO/OHC/GLOBAL_OMI_OHC_trend/\n\n\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_GLO_OPTICS_L3_REP_OBSERVATIONS_009_064\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L3_REP_OBSERVATIONS_009_064/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_OPTICS_L3_REP_OBSERVATIONS_009_086\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L3_REP_OBSERVATIONS_009_086/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_GLO_OPTICS_L4_REP_OBSERVATIONS_009_081\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/OPT/OCEANCOLOUR_GLO_OPTICS_L4_REP_OBSERVATIONS_009_081/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nGLOBAL_REANALYSIS_PHY_001_025\n\n\nJan 1993 - Dec 2015\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHY_001_025/\n\n\nN/A\n\n\n\n\nGLOBAL_REANALYSIS_PHY_001_026\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHY_001_026/\n\n\nDetails\n\n\n\n\nGLOBAL_REANALYSIS_PHY_001_030\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHY_001_030/\n\n\nDetails\n\n\n\n\nGLOBAL_REANALYSIS_PHY_001_031\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHY_001_031/\n\n\nDetails\n\n\n\n\nGLOBAL_REANALYSIS_PHY_001_017\n\n\nJan 1979 - Dec 2013\n\n\n/eodata/CMEMS/REP/GLO/PHY/GLOBAL_REANALYSIS_PHYS_001_017/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_REP_015_002\n\n\nJan 1993 - Dec 2018\n\n\n/eodata/CMEMS/REP/GLO/PHY/MULTIOBS_GLO_PHY_REP_015_002/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_REP_015_004\n\n\nJan 1993 - Dec 2021\n\n\n/eodata/CMEMS/REP/GLO/PHY/MULTIOBS_GLO_PHY_REP_015_004/\n\n\nN/A\n\n\n\n\nMULTIOBS_GLO_PHY_W_3D_REP_015_007\n\n\nJan 1993 - Dec 2018\n\n\n/eodata/CMEMS/REP/GLO/PHY/MULTIOBS_GLO_PHY_W_3D_REP_015_007/\n\n\nDetails\n\n\n\n\nSEALEVEL_GLO_PHY_L3_REP_OBSERVATIONS_008_062\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/GLO/PHY/SEALEVEL_GLO_PHY_L3_REP_OBSERVATIONS_008_062/\n\n\nDetails\n\n\n\n\nSEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047\n\n\nJan 1993 - Feb 2022\n\n\n/eodata/CMEMS/REP/GLO/PHY/SEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047/\n\n\nDetails\n\n\n\n\nPHY_CLIM (Physics climate)\n\n\nSEALEVEL_GLO_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_057\n\n\nJan 1993 - Feb 2022\n\n\n/eodata/CMEMS/REP/GLO/PHY_CLIM/SEALEVEL_GLO_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_057/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nSEAICE_GLO_SEAICE_L4_REP_OBSERVATIONS_011_009\n\n\nOct 1978 - Dec 2019\n\n\n/eodata/CMEMS/REP/GLO/SI/SEAICE_GLO_SEAICE_L4_REP_OBSERVATIONS_011_009/\n\n\nDetails\n\n\n\n\nSL (Sea level)\n\n\nGLOBAL_OMI_SL_regional_trends (anomalies in respect to various years)\n\n\nJan 1993 - Jan 1993\n\n\n/eodata/CMEMS/REP/GLO/SL/GLOBAL_OMI_SL_regional_trends/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_GLO_SST_L4_REP_OBSERVATIONS_010_011\n\n\nOct 1981 - May 2022\n\n\n/eodata/CMEMS/REP/GLO/SST/SST_GLO_SST_L4_REP_OBSERVATIONS_010_011/\n\n\nDetails\n\n\n\n\nSST_GLO_SST_L4_REP_OBSERVATIONS_010_024\n\n\nNov 1991 - Dec 2010\n\n\n/eodata/CMEMS/REP/GLO/SST/SST_GLO_SST_L4_REP_OBSERVATIONS_010_024/\n\n\nDetails\n\n\n\n\nTS (Temperature and salinity)\n\n\nINSITU_GLO_TS_OA_REP_OBSERVATIONS_013_002_b\n\n\nJan 1990 - Jun 2021\n\n\n/eodata/CMEMS/REP/GLO/TS/INSITU_GLO_TS_OA_REP_OBSERVATIONS_013_002_b/\n\n\nDetails\n\n\n\n\nINSITU_GLO_TS_REP_OBSERVATIONS_013_001_b\n\n\nJan 1950 - Dec 2018\n\n\n/eodata/CMEMS/REP/GLO/TS/INSITU_GLO_TS_REP_OBSERVATIONS_013_001_b/\n\n\nDetails\n\n\n\n\nUV (water velocity)\n\n\nINSITU_GLO_UV_L2_REP_OBSERVATIONS_013_044\n\n\nJan 2012 - Dec 2021\n\n\n/eodata/CMEMS/REP/GLO/UV/INSITU_GLO_UV_L2_REP_OBSERVATIONS_013_044/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nGLOBAL_REANALYSIS_WAV_001_032\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/WAV/GLOBAL_REANALYSIS_WAV_001_032/\n\n\nDetails\n\n\n\n\nINSITU_GLO_WAVE_REP_OBSERVATIONS_013_045\n\n\nJan 1990 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/WAV/INSITU_GLO_WAVE_REP_OBSERVATIONS_013_045/\n\n\nDetails\n\n\n\n\nWIN (Wind)\n\n\nSST_NWS_SST_L4_REP_OBSERVATIONS_010_023\n\n\nMar 1992 - Nov 2021\n\n\n/eodata/CMEMS/REP/GLO/WIN/SST_NWS_SST_L4_REP_OBSERVATIONS_010_023/\n\n\nN/A\n\n\n\n\nWIND_GLO_WIND_L3_REP_OBSERVATIONS_012_005\n\n\nMar 1992 - Dec 2017\n\n\n/eodata/CMEMS/REP/GLO/WIN/WIND_GLO_WIND_L3_REP_OBSERVATIONS_012_005/\n\n\nDetails\n\n\n\n\nWIND_GLO_WIND_L4_REP_OBSERVATIONS_012_003\n\n\nMay 2007 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/WIN/WIND_GLO_WIND_L4_REP_OBSERVATIONS_012_003/\n\n\nDetails\n\n\n\n\nWIND_GLO_WIND_L4_REP_OBSERVATIONS_012_006\n\n\nJan 1992 - Dec 2020\n\n\n/eodata/CMEMS/REP/GLO/WIN/WIND_GLO_WIND_L4_REP_OBSERVATIONS_012_006/\n\n\nDetails\n\n\n\n\n\n\nANT - Antarctic Ocean\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSI (Sea Ice)\n\n\nANTARCTIC_OMI_SI_extent (anomalies in respect to various years)\n\n\nJan 1993 - Mar 2022\n\n\n/eodata/CMEMS/REP/ANT/SI/ANTARCTIC_OMI_SI_extent/\n\n\nN/A\n\n\n\n\n\n\nARC - Arctic Ocean\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nARCTIC_MULTIYEAR_BGC_002_005\n\n\nJan 2007 - Dec 2020\n\n\n/eodata/CMEMS/REP/ARC/BGC/ARCTIC_MULTIYEAR_BGC_002_005/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nARCTIC_REANALYSIS_BIO_002_005\n\n\nJan 2007 - Dec 2010\n\n\n/eodata/CMEMS/REP/ARC/BIO/ARCTIC_REANALYSIS_BIO_002_005/\n\n\nN/A\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_ARC_CHL_L3_REP_OBSERVATIONS_009_069\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/ARC/CHL/OCEANCOLOUR_ARC_CHL_L3_REP_OBSERVATIONS_009_069/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ARC_CHL_L4_REP_OBSERVATIONS_009_088\n\n\nAug 1997 - Dec 2018\n\n\n/eodata/CMEMS/REP/ARC/CHL/OCEANCOLOUR_ARC_CHL_L4_REP_OBSERVATIONS_009_088/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_ARC_OPTICS_L3_REP_OBSERVATIONS_009_068\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/ARC/OPT/OCEANCOLOUR_ARC_OPTICS_L3_REP_OBSERVATIONS_009_068/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nARCTIC_REANALYSIS_PHYS_002_003\n\n\nJan 1991 - Dec 2019\n\n\n/eodata/CMEMS/REP/ARC/PHY/ARCTIC_REANALYSIS_PHYS_002_003/\n\n\nDetails\n\n\n\n\nSEAICE_ARC_PHY_CLIMATE_L4_MY_011_016\n\n\nJan 1982 - May 2021\n\n\n/eodata/CMEMS/REP/ARC/PHY/SEAICE_ARC_PHY_CLIMATE_L4_MY_011_016/\n\n\nDetails\n\n\n\n\nSI (Sea Ice)\n\n\nARCTIC_OMI_SI_extent (Anomalies in respect to various years)\n\n\nAnomalies in respect to various years\n\n\n/eodata/CMEMS/REP/ARC/SI/ARCTIC_OMI_SI_extent/\n\n\nN/A\n\n\n\n\nSEAICE_ARC_SEAICE_L3_REP_OBSERVATIONS_011_010\n\n\nSep 1999 - May 2022\n\n\n/eodata/CMEMS/REP/ARC/SI/SEAICE_ARC_SEAICE_L3_REP_OBSERVATIONS_011_010/\n\n\nDetails\n\n\n\n\n\n\nATL - Atlantic North\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_ATL_CHL_L3_REP_OBSERVATIONS_009_067\n\n\nSep 1997 - Dec 2018\n\n\n/eodata/CMEMS/REP/ATL/CHL/OCEANCOLOUR_ATL_CHL_L3_REP_OBSERVATIONS_009_067/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_CHL_L4_REP_OBSERVATIONS_009_091\n\n\nAug 1997 - Dec 2018\n\n\n/eodata/CMEMS/REP/ATL/CHL/OCEANCOLOUR_ATL_CHL_L4_REP_OBSERVATIONS_009_091/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_ATL_CHL_L4_REP_OBSERVATIONS_009_098\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/ATL/CHL/OCEANCOLOUR_ATL_CHL_L4_REP_OBSERVATIONS_009_098/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_ATL_OPTICS_L3_REP_OBSERVATIONS_009_066\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/ATL/OPT/OCEANCOLOUR_ATL_OPTICS_L3_REP_OBSERVATIONS_009_066/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_ATL_SST_L4_REP_OBSERVATIONS_010_026\n\n\nJan 1982 - Dec 2018\n\n\n/eodata/CMEMS/REP/ATL/SST/SST_ATL_SST_L4_REP_OBSERVATIONS_010_026/\n\n\nDetails\n\n\n\n\n\n\nBAL - Baltic Sea\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nBALTICSEA_REANALYSIS_BIO_003_012\n\n\nJan 1993 - Dec 2021\n\n\n/eodata/CMEMS/REP/BAL/BIO/BALTICSEA_REANALYSIS_BIO_003_012/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_BAL_CHL_L3_REP_OBSERVATIONS_009_080\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BAL/CHL/OCEANCOLOUR_BAL_CHL_L3_REP_OBSERVATIONS_009_080/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_BAL_OPTICS_L3_REP_OBSERVATIONS_009_097\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BAL/OPT/OCEANCOLOUR_BAL_OPTICS_L3_REP_OBSERVATIONS_009_097/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nBALTICSEA_REANALYSIS_PHY_003_011\n\n\nSep 1997 - Dec 2021\n\n\n/eodata/CMEMS/REP/BAL/PHY/BALTICSEA_REANALYSIS_PHY_003_011/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSEALEVEL_MED_PHY_L4_REP_OBSERVATIONS_008_051\n\n\nJul 1982 - Dec 2011\n\n\n/eodata/CMEMS/REP/BAL/SST/SEALEVEL_MED_PHY_L4_REP_OBSERVATIONS_008_051/\n\n\nN/A\n\n\n\n\nSST_BAL_SST_L4_REP_OBSERVATIONS_010_016\n\n\nJan 1982 - Dec 2011\n\n\n/eodata/CMEMS/REP/BAL/SST/SST_BAL_SST_L4_REP_OBSERVATIONS_010_016/\n\n\nDetails\n\n\n\n\n\n\nBLA (Black Sea)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nBLKSEA_REANALYSIS_BIO_007_005\n\n\nJan 1992 - Oct 2022\n\n\n/eodata/CMEMS/REP/BLA/BIO/BLKSEA_REANALYSIS_BIO_007_005/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_BS_CHL_L3_REP_OBSERVATIONS_009_071\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BLA/CHL/OCEANCOLOUR_BS_CHL_L3_REP_OBSERVATIONS_009_071/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_BS_CHL_L4_REP_OBSERVATIONS_009_079\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BLA/CHL/OCEANCOLOUR_BS_CHL_L4_REP_OBSERVATIONS_009_079/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_BS_OPTICS_L3_REP_OBSERVATIONS_009_096\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/BLA/OPT/OCEANCOLOUR_BS_OPTICS_L3_REP_OBSERVATIONS_009_096/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nBLKSEA_REANALYSIS_PHYS_007_004\n\n\nJan 1992 - Jun 2019\n\n\n/eodata/CMEMS/REP/BLA/PHY/BLKSEA_REANALYSIS_PHYS_007_004/\n\n\nDetails\n\n\n\n\nSEALEVEL_BS_PHY_L4_REP_OBSERVATIONS_008_042\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/BLA/PHY/SEALEVEL_BS_PHY_L4_REP_OBSERVATIONS_008_042/\n\n\nN/A\n\n\n\n\nPHY_CLIM (Physics climate)\n\n\nSEALEVEL_BS_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_058\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/BLA/PHY_CLIM/SEALEVEL_BS_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_058/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_BS_SST_L4_REP_OBSERVATIONS_010_022\n\n\nAug 1981 - Jun 2022\n\n\n/eodata/CMEMS/REP/BLA/SST/SST_BS_SST_L4_REP_OBSERVATIONS_010_022/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nBLKSEA_REANALYSIS_WAV_007_006\n\n\nJan 2002 - Jun 2019\n\n\n/eodata/CMEMS/REP/BLA/WAV/BLKSEA_REANALYSIS_WAV_007_006/\n\n\nDetails\n\n\n\n\n\n\nEUR - EUROPE\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nPHY (Physics)\n\n\nSEALEVEL_EUR_PHY_L3_REP_OBSERVATIONS_008_061\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/EUR/PHY/SEALEVEL_EUR_PHY_L3_REP_OBSERVATIONS_008_061/\n\n\nDetails\n\n\n\n\n\n\nIBI - Atlantic: Iberia-Biscay-Ireland\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nIBI_REANALYSIS_BIO_005_003\n\n\nJan 1992 - Dec 2019\n\n\n/eodata/CMEMS/REP/IBI/BIO/IBI_REANALYSIS_BIO_005_003/\n\n\nDetails\n\n\n\n\nIBI_REANALYSIS_PHYS_005_002\n\n\nJan 2014 - Dec 2019\n\n\n/eodata/CMEMS/REP/IBI/BIO/IBI_REANALYSIS_PHYS_005_002/\n\n\nDetails\n\n\n\n\nPHY (Physics)\n\n\nIBI_REANALYSIS_PHYS_005_002\n\n\nJan 1992 - Dec 2019\n\n\n/eodata/CMEMS/REP/IBI/PHY/IBI_REANALYSIS_PHYS_005_002/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nIBI_REANALYSIS_WAV_005_006\n\n\nJan 1992 - Dec 2019\n\n\n/eodata/CMEMS/REP/IBI/WAV/IBI_REANALYSIS_WAV_005_006/\n\n\nDetails\n\n\n\n\n\n\nMED - Mediterranean Sea\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBGC (Biogeochemistry)\n\n\nMEDSEA_MULTIYEAR_BGC_006_008\n\n\nJan 1999 - Dec 2019\n\n\n/eodata/CMEMS/REP/MED/BGC/MEDSEA_MULTIYEAR_BGC_006_008/\n\n\nDetails\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nMEDSEA_REANALYSIS_BIO_006_008\n\n\nJan 1999 - Dec 2018\n\n\n/eodata/CMEMS/REP/MED/BIO/MEDSEA_REANALYSIS_BIO_006_008/\n\n\nDetails\n\n\n\n\nCHL (Ocean colour)\n\n\nOCEANCOLOUR_MED_CHL_L3_REP_OBSERVATIONS_009_073\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/MED/CHL/OCEANCOLOUR_MED_CHL_L3_REP_OBSERVATIONS_009_073/\n\n\nN/A\n\n\n\n\nOCEANCOLOUR_MED_CHL_L4_REP_OBSERVATIONS_009_078\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/MED/CHL/OCEANCOLOUR_MED_CHL_L4_REP_OBSERVATIONS_009_078/\n\n\nN/A\n\n\n\n\nOPT (Optics)\n\n\nOCEANCOLOUR_MED_OPTICS_L3_REP_OBSERVATIONS_009_095\n\n\nSep 1997 - Jun 2021\n\n\n/eodata/CMEMS/REP/MED/OPT/OCEANCOLOUR_MED_OPTICS_L3_REP_OBSERVATIONS_009_095/\n\n\nN/A\n\n\n\n\nPHY (Physics)\n\n\nMEDSEA_REANALYSIS_PHYS_006_004\n\n\nJan 1987 - Dec 2018\n\n\n/eodata/CMEMS/REP/MED/PHY/MEDSEA_REANALYSIS_PHYS_006_004/\n\n\nDetails\n\n\n\n\nSEALEVEL_MED_PHY_L4_REP_OBSERVATIONS_008_051\n\n\nJan 1993 - Dec 2020\n\n\n/eodata/CMEMS/REP/MED/PHY/SEALEVEL_MED_PHY_L4_REP_OBSERVATIONS_008_051/\n\n\nN/A\n\n\n\n\nPHY_CLIM (Physics climate)\n\n\nSEALEVEL_MED_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_056\n\n\nJan 1993 - Jun 2020\n\n\n/eodata/CMEMS/REP/MED/PHY_CLIM/SEALEVEL_MED_PHY_CLIMATE_L4_REP_OBSERVATIONS_008_056/\n\n\nN/A\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_MED_SST_L4_REP_OBSERVATIONS_010_021\n\n\nAug 1981 - Jun 2022\n\n\n/eodata/CMEMS/REP/MED/SST/SST_MED_SST_L4_REP_OBSERVATIONS_010_021/\n\n\nDetails\n\n\n\n\nWAV (Waves)\n\n\nMEDSEA_HINDCAST_WAV_006_012\n\n\nFeb 2006 - Jan 2020\n\n\n/eodata/CMEMS/REP/MED/WAV/MEDSEA_HINDCAST_WAV_006_012/\n\n\nDetails\n\n\n\n\nMEDSEA_MULTIYEAR_WAV_006_012\n\n\nJan 1993 - Dec 2019\n\n\n/eodata/CMEMS/REP/MED/WAV/MEDSEA_MULTIYEAR_WAV_006_012/\n\n\nDetails\n\n\n\n\n\n\nNWS (Atlantic: NW European Shelf)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBIO (Biochemistry, chemistry)\n\n\nNORTHWESTSHELF_REANALYSIS_BIO_004_009\n\n\nJan 1993 - July 2022\n\n\n/eodata/CMEMS/REP/NWS/BIO/NORTHWESTSHELF_REANALYSIS_BIO_004_009/\n\n\nDetails\n\n\n\n\nNORTHWESTSHELF_REANALYSIS_BIO_004_011\n\n\nJan 1993 - Jun 2022\n\n\n/eodata/CMEMS/REP/NWS/BIO/NORTHWESTSHELF_REANALYSIS_BIO_004_011/\n\n\nDetails\n\n\n\n\nPHY (Physics)\n\n\nNORTHWESTSHELF_REANALYSIS_PHY_004_009\n\n\nJan 1992 - Dec 2017\n\n\n/eodata/CMEMS/REP/NWS/PHY/NORTHWESTSHELF_REANALYSIS_PHY_004_009/\n\n\nDetails\n\n\n\n\nSST (Sea Surface Temperature)\n\n\nSST_NWS_SST_L4_REP_OBSERVATIONS_010_023\n\n\nJan 1982 - Nov 2021\n\n\n/eodata/CMEMS/REP/NWS/SST/SST_NWS_SST_L4_REP_OBSERVATIONS_010_023/\n\n\nN/A\n\n\n\n\n\nN/A - data no longer provided by CMEMS\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://data.marine.copernicus.eu/products"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat5.html",
    "href": "Data/ComplementaryData/Landsat5.html",
    "title": "Landsat-5",
    "section": "",
    "text": "The Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters.\nLandsat products in the Copernicus Data Space Ecosystem originate from the ESA processing. For more information please visit here.\nLandsat-5 was launched on 1 March 1984 and ended its mission on 5 June 2013. It carried the Thematic Mapper (TM), a multispectral scanning radiometer operating in the visible and infrared regions of the electromagnetic spectrum. It was characterized by 185 km swath width and 30 m resolution for visible (VIS), near infrared (NIR) and shortwave infrared (SWIR), and 120 m for thermal infrared (TIR). The acquired Landsat TM scene covers an area of approximately 183 km x 172.8 km. A standard full scene is nominally centred on the intersection of a path and a row (the actual image centre can vary by up to 100 m). A full image consists of 6920 pixels x 5760 lines and each uncompressed band in the VIS, NIR, SWIR and TIR spectral regions requires 40 MB of storage space.\nThe objective of Landsat-5 and every Landsat mission has been to repeatedly image Earth’s land and coastal areas in order to monitor changes to these areas over time.\nAccess to Landsat-5 data is possible via API\nIn order to get access to data at specific processing level as well as specific product types, you are advised to use queries provided in each section below.\nIf it is required to customize query in respect to spatial and time coverage, satellite features etc. please, follow instructions on:\n• OpenSearch\n• OData\nLevel-1"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat5.html#landsat-5-tm-l1g",
    "href": "Data/ComplementaryData/Landsat5.html#landsat-5-tm-l1g",
    "title": "Landsat-5",
    "section": "Landsat-5 TM-L1G",
    "text": "Landsat-5 TM-L1G\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-5 TM-L1G stands for Landsat-5 Thematic Mapper Level-1 Ground data. The data is calibrated and corrected to remove distortions, and then orthorectified to provide systematic geometric accuracy. It is widely used for environmental monitoring, land-use mapping, and natural resource management.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nTM__GEO_1P\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nApr 1984 - Nov 2011\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatTM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-tm-esa-archive"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat5.html#landsat-5-tm-l1t",
    "href": "Data/ComplementaryData/Landsat5.html#landsat-5-tm-l1t",
    "title": "Landsat-5",
    "section": "Landsat-5 TM-L1T",
    "text": "Landsat-5 TM-L1T\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-5 TM-L1T stands for Landsat-5 Thematic Mapper Level-1 Terrain corrected data. The Level-1 terrain-corrected data refer to the correction of the topographic displacement effects in the images, also known as relief displacement or parallax. The L1T processing level provides more precise geolocation information, which is particularly important for applications such as land-cover mapping and change detection. This product allows for more accurate and consistent image interpretation and analysis, making it a valuable tool for scientific research and environmental management.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nTM__GTC_1P\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nApr 1984 - Nov 2011\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatTM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-tm-esa-archive"
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html",
    "href": "Data/ComplementaryData/Additional.html",
    "title": "Additional Data",
    "section": "",
    "text": "Copernicus Data Space Ecosystem provides data that are not associated with any of the Copernicus Services or are generated by third parties. These datasets include Sentinel-1 related products such as RTC (Radiometrically Terrain Corrected), CARD-BS (Terrain-Corrected Backscatter), Orbits; Sentinel-2 based global mosaics; land cover for Europe and Poland (S2GLC) and Digital Elevation Models (COP DEM and SRTM DEM)."
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html#sentinel-1-rtc",
    "href": "Data/ComplementaryData/Additional.html#sentinel-1-rtc",
    "title": "Additional Data",
    "section": "Sentinel-1 RTC",
    "text": "Sentinel-1 RTC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nSenitnel-1 RTC (Radiometrically Terrain Corrected) provides radiometrically terrain corrected product derived from the Ground Range Detected (GRD) Level-1 products.\n\nOffered Data\n\n\n\n\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nEurope, Africa\n\n\nJan 2018 - Present"
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html#sentinel-1-card-bs",
    "href": "Data/ComplementaryData/Additional.html#sentinel-1-card-bs",
    "title": "Additional Data",
    "section": "Sentinel-1 CARD-BS",
    "text": "Sentinel-1 CARD-BS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe product Sentinel-1 L2 BackScatter (CARD-BS) provides terrain corrected backscatter data over Europe. Usually a data set is available shortly after the Sentinel-1 SLC data is available. IW operational mode is available within this dataset.\n\nOffered Data\n\n\n\n\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nEurope\n\n\nOct 2014 - Present"
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html#sentinel-1-orbits",
    "href": "Data/ComplementaryData/Additional.html#sentinel-1-orbits",
    "title": "Additional Data",
    "section": "Sentinel-1 Orbits",
    "text": "Sentinel-1 Orbits\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nTwo kind of product are provided within this dataset: POEORB and RESORB. The period of time for PREORB and RESORB products correspond to the latest RSR report.\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nPOEORB\n\n\nWorld\n\n\nApr 2014 - Oct 2022\n\n\n\n\nRESORB\n\n\nWorld\n\n\nApr 2014 - Nov 2022"
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html#sentinel-2-level-2a-worldcover-annual-cloudless-mosaics-rgbnir",
    "href": "Data/ComplementaryData/Additional.html#sentinel-2-level-2a-worldcover-annual-cloudless-mosaics-rgbnir",
    "title": "Additional Data",
    "section": "Sentinel-2 Level 2A WorldCover Annual Cloudless Mosaics (RGBNIR)",
    "text": "Sentinel-2 Level 2A WorldCover Annual Cloudless Mosaics (RGBNIR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-2 L2A WorldCover Annual composites are global cloud-free analysis ready mosaics at 10m resolution. They are obtained from the yearly Sentinel-2 archives, for the years 2020 and 2021. From the yearly time-series of each band, clouds are masked and the median value is computed.\nThe RGBNIR mosaics contain the 10m bands (B04, B03, B02, B08) and are delivered as Cloud Optimized Geotiffs (COGs).\n\nOffered Data\n\n\n\n\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nWorld\n\n\n2020 - 2021"
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html#sentinel-2-mosaics",
    "href": "Data/ComplementaryData/Additional.html#sentinel-2-mosaics",
    "title": "Additional Data",
    "section": "Sentinel-2 Mosaics",
    "text": "Sentinel-2 Mosaics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nSentinel-2 L2A 120m mosaic is a derived product, which contains best pixel values for 10-daily periods, modeled by removing the cloudy pixels and then performing interpolation among remaining values.\n\nOffered Data\n\n\n\n\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nWorld\n\n\n2019 - 2020"
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html#sentinel-2-glc-s2glc",
    "href": "Data/ComplementaryData/Additional.html#sentinel-2-glc-s2glc",
    "title": "Additional Data",
    "section": "Sentinel-2 GLC (S2GLC)",
    "text": "Sentinel-2 GLC (S2GLC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-2 Global Land Cover (S2GLC) provides high resolution Poland (2019-2021) and Europe (2017) land cover map based on Sentinel-2 imagery.\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\n\n\n\n\nEurope\n\n\nEurope\n\n\n2017\n\n\n\n\nPoland\n\n\nPoland\n\n\n2019 - 2021"
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html#copernicus-digital-elevation-model-cop-dem",
    "href": "Data/ComplementaryData/Additional.html#copernicus-digital-elevation-model-cop-dem",
    "title": "Additional Data",
    "section": "Copernicus Digital Elevation Model (COP DEM)",
    "text": "Copernicus Digital Elevation Model (COP DEM)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nTwo kinds of product are provided GLO-30 and GLO-90. GLO-90 offers global coverage at a resolution of 90 metres.\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\n\n\n\n\nCOP_DEM, COP_DEM_COG\n\n\nWorld"
  },
  {
    "objectID": "Data/ComplementaryData/Additional.html#shuttle-radar-topography-mission-dem-srtm-dem",
    "href": "Data/ComplementaryData/Additional.html#shuttle-radar-topography-mission-dem-srtm-dem",
    "title": "Additional Data",
    "section": "Shuttle Radar Topography Mission DEM (SRTM DEM)",
    "text": "Shuttle Radar Topography Mission DEM (SRTM DEM)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Shuttle Radar Topography Mission (SRTM) aimed to obtain elevation data on a near-global scale in order to generate the complete and high-resolution digital topographic database of Earth.\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\n\n\n\n\nSRTMGL1\n\n\nWorld"
  },
  {
    "objectID": "Data/ComplementaryData/MERIS.html",
    "href": "Data/ComplementaryData/MERIS.html",
    "title": "ENVISAT- Medium Resolution Imaging Spectrometer (MERIS)",
    "section": "",
    "text": "Access to ENVISAT MERIS data is possible via API:  - OpenSearch  - OData\nIn order to get access to data at specific processing level as well as for specific product types, you are advised to use queries provided in each section below.\nIf it is required to customize query in respect to spatial and time coverage, satellite features etc. please, follow instructions on:  - OpenSearch  - OData"
  },
  {
    "objectID": "Data/ComplementaryData/MERIS.html#medium-resolution-imaging-spectrometer-meris---envisat",
    "href": "Data/ComplementaryData/MERIS.html#medium-resolution-imaging-spectrometer-meris---envisat",
    "title": "ENVISAT- Medium Resolution Imaging Spectrometer (MERIS)",
    "section": "Medium Resolution Imaging Spectrometer (MERIS) - ENVISAT",
    "text": "Medium Resolution Imaging Spectrometer (MERIS) - ENVISAT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Medium Resolution Imaging Spectrometer (MERIS) was a programmable spectrometer on board the Envisat mission, operating in the solar reflective spectral range. Although primarily dedicated to ocean colour observations, MERIS extended its objectives to atmospheric- and land-surface-related studies. MERIS had high spectral and radiometric resolution and a dual spatial resolution of 260m x 290m over land and coastal regions and reduced resolution of 1040m x 1160m over ocean.\nMERIS was operational throughout the Envisat mission lifetime, from 2002 to 2012, and the first data from the instrument were available from May 2002.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nMER_FRS_1P\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMay 2002 - Apr 2012\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://meris-ds.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/instruments/meris"
  },
  {
    "objectID": "Data/ComplementaryData/SMOS.html",
    "href": "Data/ComplementaryData/SMOS.html",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "",
    "text": "The Soil Moisture and Ocean Salinity (SMOS) mission was launched on 2 November 2009. It is one of the European Space Agency’s Earth Explorer missions, which form the science and research element of ESA’s Living Planet Programme.\nThe SMOS payload consists of the Microwave Imaging Radiometer using Aperture Synthesis (MIRAS) instrument, a passive microwave 2-D interferometric radiometer operating in the L-band (1.413 GHz, 21 cm) within a protected wavelength/frequency band. The SMOS mission operates on a sun-synchronous orbit (dusk-dawn 6am/6pm). SMOS measurements are made over a range of incidence angles (0 to 55°) across a swath of approximately 1000 km with a spatial resolution of 35 to 50 km. MIRAS can provide measurements in dual and full polarisation, the latter being its current mode of operation.\nSMOS Level 1 data products are designed for scientific and operational users who need to work with calibrated MIRAS instrument measurements, while SMOS Level 2 data products are designed for scientific and operational users who need to work with geo-located estimates of soil moisture and sea surface salinity as retrieved from the Level 1 dataset.\nAccess to SMOS data is possible via API\nIn order to get access to data at specific processing level as well as specific product types, you are advised to use queries provided in each section below.\nIf it is required to customize query in respect to spatial and time coverage, satellite features etc. please, follow instructions on:\n• OpenSearch\n• OData\nLevel-1 Level-2"
  },
  {
    "objectID": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l1b",
    "href": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l1b",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L1B",
    "text": "Soil Moisture and Ocean Salinity - L1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nSoil Moisture and Ocean Salinity - L1B are processed data of the SMOS mission. These are geolocated brightness temperatures that have been calibrated and corrected to provide valuable input for further processing into higher-level products like soil moisture and ocean salinity maps.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nMIR_SC_F1B\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\nMIR_SC_D1B\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l1cl",
    "href": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l1cl",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L1CL",
    "text": "Soil Moisture and Ocean Salinity - L1CL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Soil Moisture and Ocean Salinity (SMOS) The L1CL product is an intermediate SMOS soil moisture and ocean salinity product that is used as input to generate other higher-level SMOS products such as L2 soil moisture and ocean salinity products, which combine SMOS data with other satellite and ground-based observations.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nMIR_BWLF1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\nMIR_BWLD1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\nMIR_BWSF1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\nMIR_BWSD1C - SCLD1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l1cs",
    "href": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l1cs",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L1CS",
    "text": "Soil Moisture and Ocean Salinity - L1CS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nSMOS L1CS is an intermediate product that measures soil moisture and ocean salinity derived from raw data collected by the microwave radiometer onboard the SMOS satellite. It has a spatial resolution of 40 km and provides brightness temperatures and scattering angles to calculate the essential values for understanding the global water cycle. The data is useful for weather forecasting, drought monitoring, crop management, and coastal ecosystem protection. The product is used to generate higher-level SMOS products to manage water resources and monitor ecological systems.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nMIR_SCLF1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\nMIR_SCLD1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\nMIR_SCSF1C/MIR_SCSD1C\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l2os",
    "href": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l2os",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L2OS",
    "text": "Soil Moisture and Ocean Salinity - L2OS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe SMOS L1OS product is an intermediate data product derived from the raw data collected by the microwave radiometer on board the SMOS satellite. It is used to derive higher-level SMOS products, such as L2 soil moisture and ocean salinity products, which are used for various applications, including weather forecasting, climate monitoring, agricultural planning, and water management. The SMOS L1OS data product is important for understanding the earth’s water cycle and the impacts of climate change on water resources. The data is used by scientists, policymakers, and resource managers to better understand and manage water resources, monitor ecological systems, and improve weather and climate forecasting.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nMIR_OSUDP2\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l2sm",
    "href": "Data/ComplementaryData/SMOS.html#soil-moisture-and-ocean-salinity---l2sm",
    "title": "Soil Moisture and Ocean Salinity (SMOS)",
    "section": "Soil Moisture and Ocean Salinity - L2SM",
    "text": "Soil Moisture and Ocean Salinity - L2SM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Level 2 Soil Moisture (SM) product comprises soil moisture measurements geo-located in an equal-area grid system ISEA 4H9. The product contains not only the retrieved soil moisture, but also a series of ancillary data derived from the processing (nadir optical thickness, surface temperature, roughness parameter, dielectric constant and brightness temperature retrieved at top of atmosphere and on the surface) with the corresponding uncertainties.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nMIR_SMUDP2\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2010 - Present\n\n\nOpenSearch\n\n\nOData\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://smos-diss.eo.esa.int/oads/access/\n\n\nMore Information: https://earth.esa.int/eogateway/missions/smos#instruments-section"
  },
  {
    "objectID": "Data/ComplementaryData/CLMS.html",
    "href": "Data/ComplementaryData/CLMS.html",
    "title": "Copernicus Land Monitoring Service (CLMS)",
    "section": "",
    "text": "Copernicus program priorities are to gain from Earth Observation techniques and make research, administration, agriculture, economy, environmental protection of our lands easier, cheaper and more effective. Copernicus Land Monitoring Service (CLMS) constitute rich data hub with archival and near real time environmental resources. Copernicus Data Space Ecosystem platform makes CLMS products accessible over S3 or NFS protocol . Each User can make his own contribution to expanding data land applications using Copernius Data Space Ecosystem resources.\nCLMS provides three kinds of data related to its coverage: Global, Pan-European and Local. It also provides imagery and reference data (IAR)."
  },
  {
    "objectID": "Data/ComplementaryData/CLMS.html#copernicus-land-monitoring-service-clms---global",
    "href": "Data/ComplementaryData/CLMS.html#copernicus-land-monitoring-service-clms---global",
    "title": "Copernicus Land Monitoring Service (CLMS)",
    "section": "Copernicus Land Monitoring Service (CLMS) - Global",
    "text": "Copernicus Land Monitoring Service (CLMS) - Global\n\nOverview\nThe Copernicus Global Land Service continuously provides a series of well-qualified bio-geophysical products on the state and evolution of the land surface on a global scale. The data are provided at medium to low spatial resolution and, for most products, cover the period from 1998 or 1999 till today. It is ready-to-use data that allows comprehensive and immediate analysis for the entire Earth.\n\nOffered Data\n\n\nEnergy\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nLAND SURFACE TEMPERATURE\n\n\nHOURLY_LST_V1,\nHOURLY_LST_V2,\n10DAY_LST_V1,\n10DAY_LST_V2,\n10DAY_TCI_V1,\n10DAY_TCI-V2\n\n\nWorld\n\n\n(*) Jun 2010 - Present\n\n\n/eodata/CLMS/Global/Energy/Land_Surface_Temperature/\n\n\nDetails\n\n\n\n\nSURFACE ALBEDO\n\n\nDIRECTIONAL_1.4_ALDH,\nDIRECTIONAL_1.5_ALDH,\nHEMPISPHERICAL_1.4_ALBH,\nHEMPISPHERICAL_1.5_ALBH\n\n\nWorld\n\n\n(**) Jan 1999 - Jun 2020\n\n\n/eodata/CLMS/Global/Energy/Surface_Albedo/\n\n\nDetails\n\n\n\n\nTOC (TOP OF THE CANOPY) REFLECTANCE\n\n\nTOC_REFLECTANCE\n\n\nWorld\n\n\nJan 1990 - Sep 2018\n\n\n/eodata/CLMS/Global/Energy/Top_Of_Canopy_Reflectances/\n\n\nDetails\n\n\n\n\n\n\nVegetation\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nBURNT AREA\n\n\nBURNT_AREA_V3\n\n\nWorld\n\n\nJul 2020 - Jul 2021\n\n\n/eodata/CLMS/Global/Vegetation/Burnt_Area/\n\n\nDetails\n\n\n\n\nDRY MATTER PRODUCTIVITY\n\n\nDMP_300,\nGDMP_300,\nDMP_1000_V2,\nGDMP_1000_V2\n\n\nWorld\n\n\n(*) Jan 1999 - Jun 2020\n\n\n/eodata/CLMS/Global/Vegetation/Dry_Matter_Productivity/\n\n\nDetails\n\n\n\n\nFAPAR\n\n\nFAPAR_300,\nFAPAR_1000_V1.5,\nFAPAR_1000_V2\n\n\nWorld\n\n\n(**) Jan 1999 - Present\n\n\n/eodata/CLMS/Global/Vegetation/FAPAR/\n\n\nDetails\n\n\n\n\nFCOVER\n\n\nFCOVER_300,\nFCOVER_1000_V1.5,\nFCOVER_1000_V2\n\n\nWorld\n\n\n(**) Jan 1999 - Present\n\n\n/eodata/CLMS/Global/Vegetation/FCOVER/\n\n\nDetails\n\n\n\n\nLEAF AREA INDEX\n\n\nLAI_300,\nLAI_1000_V2\n\n\nWorld\n\n\n(*) Jan 1999 - Present\n\n\n/eodata/CLMS/Global/Vegetation/Leaf_Area_Index/\n\n\nDetails\n\n\n\n\nLAND COVER\n\n\nGLOBAL_LAND_COVER,\nGLOBAL_LAND_COVER_COG\n\n\nWorld\n\n\nAnnual 2015-2019\n\n\n/eodata/CLMS/Global/Vegetation/Global_Land_Cover_COG/\n\n\nDetails\n\n\n\n\nNDVI\n\n\nNDVI_300_V1,\nNDVI_300_V2,\nNDVI_1000_V2.2,\nNDVI_1000_V2.2_LTS,\nNDVI_1000_V3\n\n\nWorld\n\n\n(**) Apr 1998 - Present\n\n\n/eodata/CLMS/Global/Vegetation/NDVI/\n\n\nDetails\n\n\n\n\nSOIL WATER INDEX\n\n\nSWI_1000_EUROPE,\nSWI_GLOBAL,\nSWI10_GLOBAL,\nSTATIC_LAYERS\n\n\nWorld\n\n\n(**) Jan 2007 - Present\n\n\n/eodata/CLMS/Global/Vegetation/Soil_Water_Index/\n\n\nDetails\n\n\n\n\nSURFACE SOIL MOISTURE\n\n\nSSM\n\n\nWorld\n\n\n(**) Oct 2014 - Present\n\n\n/eodata/CLMS/Global/Vegetation/Surface_Soil_Moisture/\n\n\nDetails\n\n\n\n\n\n\nWater\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nLAKE WATER QUALITY\n\n\nLWQ_100,\nLWQ_300_SENTINEL3\n\n\nWorld\n\n\n(**) Apr 2016 - Present\n\n\n/eodata/CLMS/Global/Water/Lake_Water_Quality/\n\n\nDetails\n\n\n\n\nWATER BODIES\n\n\nWB_300_V1,\nWB_1000_PROBA_V1,\nWB_1000_PROBA_V2,\nWB_1000_SPOT_V1\n\n\nWorld (WB_1000_PROBA_V1 - AFRICA)\n\n\n(*) Apr 1998 - Sep 2021\n\n\n/eodata/CLMS/Global/Water/Water_Bodies/\n\n\nDetails\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition.\n(**) Depending on specific product.\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nMore Information: https://land.copernicus.eu/global/"
  },
  {
    "objectID": "Data/ComplementaryData/CLMS.html#copernicus-land-monitoring-service-clms--pan-european",
    "href": "Data/ComplementaryData/CLMS.html#copernicus-land-monitoring-service-clms--pan-european",
    "title": "Copernicus Land Monitoring Service (CLMS)",
    "section": "Copernicus Land Monitoring Service (CLMS)- Pan-European",
    "text": "Copernicus Land Monitoring Service (CLMS)- Pan-European\n\nOverview\nThe production of pan-European data is coordinated by the European Environment Agency (EEA). Copernius Data Space Ecosystem provides access to pan-European datasets such as: CORINE Land Cover datasets, High Resolution Layers and related pan-European products.\nThe CORINE Land Cover (CLC) inventory was initiated in 1985 (reference year 1990). It was updated in 2000, 2006, 2012, and 2018. The CLC database contains an inventory of land cover in 44 classes. The Minimum Mapping Unit (MMU) for the status layer is defined as 25 hectares (ha) for areal phenomena and 100 meters in width for linear phenomena. The time series are complemented by change layers which highlight changes in land cover between the most recent and the previous status layers with an MMU of 5 ha.\nHigh Resolution Layers (HRL) provide information on specific land cover characteristics, including status and changes. The HRLs are complementary to the CLC datasets. The HRLs are produced from satellite imagery through a combination of automatic processing and interactive rule-based classification.\nThe European Settlement Map (ESM) is a raster dataset mapping human settlements in Europe, produced from SPOT-5 and SPOT-6 satellite imagery. It has been produced with Global Human Settlement Layer (GHSL) technology by the European Commission, Joint Research Centre, Institute for the Protection and Security of the Citizen, Global Security and Crisis Management Unit.\n\nOffered Data\n\n\nCORINE LAND COVER (CLC)\n\n\n\n\n\n\nProduct Type\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSTATUS\n\n\nCLC_1990,\nCLC_2000,\nCLC_2006,\nCLC_2012,\nCLC_2018\n\n\nEurope (*)\n\n\n/eodata/CLMS/Pan-European/CORINE_Land_Cover/\n\n\nDetails\n\n\n\n\nCHANGES\n\n\nCHA_1990_2000,\nCHA_2000_2006,\nCHA_2006_2012, CHA_2012_2018\n\n\nEurope (*)\n\n\n/eodata/CLMS/Pan-European/CORINE_Land_Cover/\n\n\nDetails\n\n\n\n\n\n\nHIGH RESOLUTION LAYERS (HRL)\n\n\n\n\n\n\nProduct Type\n\n\nProducts\n\n\nSub-Product\n\n\nSpecific Products\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nIMPERVIOUSNESS\n\n\nSTATUS\n\n\n\n\nIMP_STATUS_2006,\nIMP_STATUS_2009,\nIMP_STATUS_2012,\nIMP_STATUS_2015,\nIMP_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Imperviousness/Status_Maps/\n\n\nDetails\n\n\n\n\nSTATUS (BUILD-UP AREAS)\n\n\n\n\nIMP_BU_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Imperviousness/Status_Maps/Impervious_Built-up_2018/\n\n\nDetails\n\n\n\n\nCHANGES\n\n\n\n\nCHA_2006_2009,\nCHA_2006_2012,\nCHA_2009_2012,\nCHA_2012_2015\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Imperviousness/Change_Maps/\n\n\nDetails\n\n\n\n\nFORESTS\n\n\nSTATUS\n\n\nTREE COVER DENSITY (TCD)\n\n\nTCD_STATUS_2012,\nTCD_STATUS_2015,\nTCD_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Tree_Cover_Density/Status_Maps/\n\n\nDetails\n\n\n\n\nSTATUS\n\n\nDOMINANT LEAF TYPE (DMT)\n\n\nDLT_STATUS_2012,\nDLT_STATUS_2015,\nDLT_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Dominant_Leaf_Type/Status_Maps/\n\n\nDetails\n\n\n\n\nSTATUS\n\n\nFOREST TYPE (FT)\n\n\nFT_STATUS_2012,\nFT_STATUS_2015,\nFT_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Forest_Type/Status_Maps/\n\n\nDetails\n\n\n\n\nCHANGES\n\n\nTREE COVER DENSITY (TCD)\n\n\nTCD_CHA_2012_2015\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Tree_Cover_Density/Change_Maps/\n\n\nDetails\n\n\n\n\nEXPERT PRODUCTS\n\n\n\n\nForest_Additional_Support_Layer_2012,\nForest_Additional_Support_Layer_2015\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Forests/Forest_Type/Expert_Products/Forest_Additional_Support_Layer/\n\n\nDetails\n\n\n\n\nGRASSLANDS\n\n\nSTATUS\n\n\n\n\nGRS_STATUS_2015,\nGRS_STATUS_2018\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Grassland/Status_Maps/\n\n\nDetails\n\n\n\n\nEXPERT PRODUCTS\n\n\n\n\nPloughing_Indicator,\nGrassland_Vegetation_Probability_Index\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Grassland/Expert_Products/\n\n\nDetails\n\n\n\n\nWATER AND WETNESS\n\n\nSTATUS\n\n\n\n\nWAT_STATUS_2015\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Water_Wetness/Status_Maps/\n\n\nDetails\n\n\n\n\nEXPERT PRODUCTS\n\n\n\n\nWater_Wetness_Probability_Index\n\n\n/eodata/CLMS/Pan-European/High_Resolution_Layers/Water_Wetness/Expert_Products\n\n\nDetails\n\n\n\n\n\n\nRELATED PAN-EUROPEAN\n\n\n\n\n\n\nProduct Type\n\n\nProducts\n\n\nSpecific Products\n\n\nSpatial\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSTATUS\n\n\nEuropean Settlement Map\n\n\nESM_2012_V2016,\nESM_2012_V2017\n\n\nEurope\n\n\n/eodata/CLMS/Pan-European/Related_Pan-European_Products/European_Settlement_Map/\n\n\nDetails\n\n\n\n\n\n(*) Number of involved countires (CLC_1990 - 27; CLC_2000 - 39, CLC_2006 - 39; CLC_2012 - 39; CLC 2018 - 39.\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nMore Information: https://land.copernicus.eu/pan-european"
  },
  {
    "objectID": "Data/ComplementaryData/CLMS.html#copernicus-land-monitoring-service-clms--local",
    "href": "Data/ComplementaryData/CLMS.html#copernicus-land-monitoring-service-clms--local",
    "title": "Copernicus Land Monitoring Service (CLMS)",
    "section": "Copernicus Land Monitoring Service (CLMS)- Local",
    "text": "Copernicus Land Monitoring Service (CLMS)- Local\n\nOverview\nThe production of local component’s datasets is coordinated by the European Environment Agency (EEA). The goal of local components products is to provide more detailed information that is complementary to the information obtained through the Pan-European component. The local component focuses on areas which are prone to specific environmental challenges and problems.\nCopernius Data Space Ecosystem provides three components of CLMS - Local: Urban Atlas, Riparian Zones and Natura 2000.\n\nOffered Data\n\n\nLocal\n\n\n\n\n\n\nProduct Type\n\n\nProducts\n\n\nSpecific Products\n\n\nSpatial\n\n\nS3 path\n\n\nProduct Detail\n\n\n\n\n\n\nSTATUS\n\n\nURBAN ATLAS\n\n\nUA_2006,\nUA_2012\n\n\nEurope\n\n\n/eodata/CLMS/Local/Urban_Atlas/Urban_Atlas_2006/,\n/eodata/CLMS/Local/Urban_Atlas/Urban_Atlas_2012/\n\n\nDetails\n\n\n\n\nRIPARIAN ZONES\n\n\nRZ_2012\n\n\nEurope\n\n\n/eodata/CLMS/Local/Riparian_Zones/Land_Cover_Land_Use/\n\n\nDetails\n\n\n\n\nNATURA 2000\n\n\nN2K_2006,\nN2K_2012\n\n\nEurope\n\n\n/eodata/CLMS/Local/Natura_2000/\n\n\nDetails\n\n\n\n\nCHANGES\n\n\nURBAN ATLAS\n\n\nUA_CHA_2006_2012\n\n\nEurope\n\n\n/eodata/CLMS/Local/Urban_Atlas/Change_2006-2012/\n\n\nDetails\n\n\n\n\nOTHER\n\n\nURBAN ATLAS\n\n\nBUILDING HEIGHT 2012 (BH_2012)\n\n\nEuropean’s capital cities\n\n\n/eodata/CLMS/Local/Urban_Atlas/Building_Height_2012/\n\n\nDetails\n\n\n\n\nRIPARIAN ZONES\n\n\nDELINEATION_RZ,\nGREEN_LINEAR_ELEMENTS\n\n\nEurope\n\n\n/eodata/CLMS/Local/Riparian_Zones/Green_Linear_Elements/,\n/eodata/CLMS/Local/Riparian_Zones/Delineation_of_Riparian_Zones/\n\n\nDetails\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nMore Information: https://land.copernicus.eu/local"
  },
  {
    "objectID": "Data/Others/Sentinel2_L1C_baseline.html",
    "href": "Data/Others/Sentinel2_L1C_baseline.html",
    "title": "Sentinel-2 L1C Baselines",
    "section": "",
    "text": "The Sentinel-1 L1C collection within the Copernicus Data Space Ecosystem originates from the operational Copernicus processing, i.e. data previously accessible on the Copernicus Open Access Hub (formerly known as Sentinels Scientific Data Hub).\nThese products can be differentiated by the OData and OpenSearch processingBaseline attribute. Processing Baseline is presented on Copernicus Browser as a “Processor version” attribute.\nThe current state of the archive of the Sentinel-L1C data is as follows:\n\n\n\n\n\nAvailability of S-2 L1C products based on sensing date\n\n\nProcessing Baseline\n\n\n\n\n\n\n15/12/2015 - 03/05/2016\n\n\nProcessing Baseline 02.01 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 2.01)\n\n\n\n\n03/05/2016 - 15/06/2016\n\n\nProcessing Baseline 02.02 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.02 or 2.01)\n\n\n\n\n04/07/2015 - 26/05/2017\n\n\nProcessing Baseline 02.04 (To replace 02.03) (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.04 or 2.04)\n\n\n\n\n19/03/2017 - 23/10/2017\n\n\nProcessing Baseline 02.05 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.05 or 2.05)\n\n\n\n\n10/04/2016 - 06/11/2018\n\n\nProcessing Baseline 02.06 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.06 or 2.06)\n\n\n\n\n06/11/2018 - 22/07/2019\n\n\nProcessing Baseline 02.07 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.07 or 2.07)\n\n\n\n\n10/04/2016 - 04/02/2020\n\n\nProcessing Baseline 02.08 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 2.08)\n\n\n\n\n29/09/2015 – 30/03/2021\n\n\nProcessing Baseline 02.09 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 2.09)\n\n\n\n\n30/03/2021 - 30/06/2021\n\n\nProcessing Baseline 03.00 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 3.0)\n\n\n\n\n30/06/2021 - 25/01/2022\n\n\nProcessing Baseline 03.01 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 03.01 or 3.01)\n\n\n\n\n25/01/2022 - 06/12/2022\n\n\nProcessing Baseline 04.00 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 04.00 or 4.0)\n\n\n\n\n29/04/2022 – 13/12/2023\n\n\nProcessing Baseline 05.09 (originating from Copernicus Open Access Hub and Copernicus Data Space Ecosystem) (Attribute ‘processorVersion’: 05.09 or 5.09)\n\n\n\n\n13/12/2023 - Now\n\n\nProcessing Baseline 05.10 (originating from Copernicus Data Space Ecosystem) (Attribute ‘processorVersion’: 05.10 or 5.10)\n\n\n\n\n\n\nProcessing Baseline 5.00 for Sentinel-2 L1C and L2A\nThe Sentinel-2 Collection 1 (reprocessed data) featuring processing baseline 5.00 is gradually ingested into the Copernicus Data Space Ecosystem. This ingestion will be completed in the end of Q2 2024.\n\n\n\n\n\nUpdated availability by sensing time period\n\n\nSentinel-2A\n\n\nSentinel-2B\n\n\n\n\n\n\nPublished (*)\n\n\nFrom sensing 2017-11-12T00:00:00.000 to 2021-12-31T00:00:00.000\n\n\nFrom sensing 2017-11-12T00:00:00.000 to 2021-12-31T00:00:00.000\n\n\n\n\nNext period in list\n\n\nNovember 2017 then continuing in reverse chronological order of sensing time\n\n\nNovember 2017 then continuing in reverse chronological order of sensing time\n\n\n\n\n\n(*) There is a known product gap between 2018 and 2019 (2.7 million S-2 Collection-1 products). Missing products will be made available successively.\nPlease refer to the article Copernicus SENTINEL-2 Collection-1 Availability Status that aims at providing up-to-date progress information on the proceedings of the generation of Collection-1 and on the gradual availability of Collection-1 Level-1C and Level-2A products."
  },
  {
    "objectID": "Data/Others/Sentinel1_COG.html",
    "href": "Data/Others/Sentinel1_COG.html",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "",
    "text": "The Sentinel-1 GRD COG_SAFE products can be filtered by the OData API query using three methods:\n\nFiltering ‘COG.SAFE’ substring in the product name:\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T00:00:00.000Z\n\n\n\n\nUsing proper data type with “-COG” suffix. One of: S1_GRDF_1S-COG,S2_GRDF_1S-COG,S3_GRDF_1S-COG,S4_GRDF_1S-COG,S5_GRDF_1S-COG,S6_GRDF_1S-COG,S1_GRDH_1S-COG,S2_GRDH_1S-COG,S3_GRDH_1S-COG,S4_GRDH_1S-COG,S5_GRDH_1S-COG,S6_GRDH_1S-COG,S1_GRDM_1S-COG,S2_GRDM_1S-COG,S3_GRDM_1S-COG,S4_GRDM_1S-COG,S5_GRDM_1S-COG,S6_GRDM_1S-COG,IW_GRDH_1S-COG,IW_GRDM_1S-COG,EW_GRDH_1S-COG,EW_GRDM_1S-COG,WV_GRDM_1S-COG\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27productType%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27IW_GRDH_1S-COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T04:00:00.000Z&$top=10\n\n\n\n\nFiltering ‘GRD’ substring in product name and “origin” attribute equal “CLOUDFERRO”.\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27GRD%27)%20and%20Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27origin%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27CLOUDFERRO%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T04:00:00.000Z&$top=10"
  },
  {
    "objectID": "Data/Others/Sentinel1_COG.html#how-to-search-for-cog_safe-products-with-odata-api",
    "href": "Data/Others/Sentinel1_COG.html#how-to-search-for-cog_safe-products-with-odata-api",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "",
    "text": "The Sentinel-1 GRD COG_SAFE products can be filtered by the OData API query using three methods:\n\nFiltering ‘COG.SAFE’ substring in the product name:\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T00:00:00.000Z\n\n\n\n\nUsing proper data type with “-COG” suffix. One of: S1_GRDF_1S-COG,S2_GRDF_1S-COG,S3_GRDF_1S-COG,S4_GRDF_1S-COG,S5_GRDF_1S-COG,S6_GRDF_1S-COG,S1_GRDH_1S-COG,S2_GRDH_1S-COG,S3_GRDH_1S-COG,S4_GRDH_1S-COG,S5_GRDH_1S-COG,S6_GRDH_1S-COG,S1_GRDM_1S-COG,S2_GRDM_1S-COG,S3_GRDM_1S-COG,S4_GRDM_1S-COG,S5_GRDM_1S-COG,S6_GRDM_1S-COG,IW_GRDH_1S-COG,IW_GRDM_1S-COG,EW_GRDH_1S-COG,EW_GRDM_1S-COG,WV_GRDM_1S-COG\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27productType%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27IW_GRDH_1S-COG%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-21T04:00:00.000Z&$top=10\n\n\n\n\nFiltering ‘GRD’ substring in product name and “origin” attribute equal “CLOUDFERRO”.\n\nExample of a query:\n\nHTTP Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(name,%27GRD%27)%20and%20Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20%27origin%27%20and%20att/OData.CSC.StringAttribute/Value%20eq%20%27CLOUDFERRO%27)%20and%20ContentDate/Start%20gt%202022-05-03T00:00:00.000Z%20and%20ContentDate/Start%20lt%202022-05-03T04:00:00.000Z&$top=10"
  },
  {
    "objectID": "Data/Others/Sentinel1_COG.html#how-to-search-for-cog_safe-products-in-the-browser",
    "href": "Data/Others/Sentinel1_COG.html#how-to-search-for-cog_safe-products-in-the-browser",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "How to search for COG_SAFE products in the Browser?",
    "text": "How to search for COG_SAFE products in the Browser?\nThere are two separate options available for Sentinel-1 GRD products. Selecting the “Level-1 GRD COG” option under Sentinel-1 will return COG_SAFE products while option “Level-1 GRD” will return the original GRD products. If you would like to search for both type of products, select both options."
  },
  {
    "objectID": "Data/Others/Sentinel1_COG.html#how-were-original-sentinel-1-grd-products-converted-to-cog_safe-products",
    "href": "Data/Others/Sentinel1_COG.html#how-were-original-sentinel-1-grd-products-converted-to-cog_safe-products",
    "title": "Handling Sentinel-1 COG_SAFE products",
    "section": "How were original Sentinel-1 GRD products converted to COG_SAFE products?",
    "text": "How were original Sentinel-1 GRD products converted to COG_SAFE products?\nThe following changes were made during the conversion of original Sentinel-1 GRD products to COG_SAFE products:\n\nAll GeoTIFF files available in the measurements folder were converted to cloud optimized GeoTIFF format with the gdal command:\n\n\nCLI\n\n\ngdal_translate -of COG -a_nodata 0 -co OVERVIEW_COUNT=6 -co BLOCKSIZE=1024 -co BIGTIFF=NO -co OVERVIEW_RESAMPLING=RMS -co COMPRESS=ZSTD -co NUM_THREADS=ALL_CPUS -mo GRD_ORIGINAL_HEADER_SIZE=&lt;original_header_size&gt; -mo GRD_ORIGINAL_FOOTER_SIZE=&lt;original_footer_size&gt; &lt;input_tiff&gt;.tiff &lt;input_tiff&gt;-cog.tiff \n\n\n\nMore information about what these options mean can be found in the [GDAL official documentation](https://gdal.org/programs/gdal_translate.html){target='_blank'}. Note that the output filename has a suffix “-cog”, which indicates that the files were converted to COGs.\n\nA suffix “_COG” was added to the name of the product and a new CRC code was calculated. For example, the original product\nS1A_IW_GRDH_1SDV_20230206T165050_20230206T165115_047118_05A716_53C5.safe became\nS1A_IW_GRDH_1SDV_20230206T165050_20230206T165115_047118_05A716_74F9_COG.safe.\nManifest file was adjusted so that it reflects these changes:\n\nsafe:processing element with a name=“COG Conversion” was added. It contains metadata about the conversion and includes the name of the original product under safe:resource child element.\ndataObject elements, which describe the measurements files, have updated values for “size”, “href”, “checksum”."
  },
  {
    "objectID": "Data/Others/Sentinel2_L2A_baseline.html",
    "href": "Data/Others/Sentinel2_L2A_baseline.html",
    "title": "Sentinel-2 L2A Baselines",
    "section": "",
    "text": "The Sentinel-2 L2A collection within the Copernicus Data Space Ecosystem originates from three sources:\n(1) operational Copernicus processing, i.e. data previously accessible on the Copernicus Open Access Hub (formerly known as Sentinels Scientific Data Hub);\n(2) reprocessing of the L2A archive from 2015 until the end of 2021 (Collection 1), and ;\n(3) data generated by CloudFerro using various versions of the publicly available Sen2Cor processor. This data will be removed once replaced by the reprocessing of the L2A (point 2 above), which is planned to be completed in April 2024\nThese products can be differentiated by the OData and OpenSearch (origin) attribute (ESA or CloudFerro) and by the ‘processingBaseline’ attribute. Processing Baseline is presented on Copernicus Browser as a “Processor version” attribute.\nThe current state of the archive of the Sentinel-L2A data is as follows:\n\n\n\n\n\nAvailability of S-2 L2A products based on sensing date\n\n\nProcessing Baseline\n\n\n\n\n\n\n29/09/2015 - 14/01/2023\n\n\nProcessing Baseline 99.99 (generated by CloudFerro) (Attribute ‘processorVersion’: 99.99)\n\n\n\n\n04/07/2015 - 21/05/2021\n\n\nProcessing Baselines 2.05 -2.13 (originating from Copernicus Open Access Hub and generated by CloudFerro)\n\n\n\n\n04/02/2020 - 30/03/2021\n\n\nProcessing Baseline 2.14 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.14)\n\n\n\n\n25/01/2022 - 06/12/2022\n\n\nProcessing Baseline 4.00 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 04.00 or 4.0)\n\n\n\n\n29/04/2022 - 13/12/2023\n\n\nProcessing Baseline 5.09 (originating from Copernicus Open Access Hub and Copernicus Data Space Ecosystem) (Attribute ‘processorVersion’: 05.09 or 5.09)\n\n\n\n\n13/12/2023 - Now\n\n\nProcessing Baseline 5.10 (originating from Copernicus Data Space Ecosystem) (Attribute ‘processorVersion’: 05.10 or 5.10)\n\n\n\n\n\n\nProcessing Baseline 5.00 for Sentinel-2 L1C and L2A\nThe Sentinel-2 Collection 1 (reprocessed data) featuring processing baseline 5.00 is gradually ingested into the Copernicus Data Space Ecosystem. This ingestion will be completed in the end of Q2 2024.\n\n\n\n\n\nUpdated availability by sensing time period\n\n\nSentinel-2A\n\n\nSentinel-2B\n\n\n\n\n\n\nPublished (*)\n\n\nFrom sensing 2017-11-12T00:00:00.000 to 2021-12-31T00:00:00.000\n\n\nFrom sensing 2017-11-12T00:00:00.000 to 2021-12-31T00:00:00.000\n\n\n\n\nNext period in list\n\n\nNovember 2017 then continuing in reverse chronological order of sensing time\n\n\nNovember 2017 then continuing in reverse chronological order of sensing time\n\n\n\n\n\n(*) There is a known product gap between 2018 and 2019 (2.7 million S-2 Collection-1 products). Missing products will be made available successively.\nPlease refer to the article Copernicus SENTINEL-2 Collection-1 Availability Status that aims at providing up-to-date progress information on the proceedings of the generation of Collection-1 and on the gradual availability of Collection-1 Level-1C and Level-2A products."
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html",
    "href": "Data/SentinelMissions/Sentinel5P.html",
    "title": "Sentinel-5P",
    "section": "",
    "text": "The Copernicus Sentinel-5 Precursor mission is the first Copernicus mission dedicated to monitoring our atmosphere.\nThe main objective of the Copernicus Sentinel-5P mission is to perform atmospheric measurements with high spatio-temporal resolution, to be used for air quality, ozone & UV radiation, and climate monitoring & forecasting.\nThere are different data products associated with the three levels of TROPOMI processing: Level-0, Level-1B and Level-2.\nLevel-1 Level-2"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-aerosol-index",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-aerosol-index",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Aerosol Index",
    "text": "Sentinel-5P Level 2 Aerosol Index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 Aerosol Index (AER_AI) dataset provides high-resolution imagery of the UV Aerosol Index (UVAI), also called the Absorbing Aerosol Index (AAI). The AAI is based on wavelength-dependent changes in Rayleigh scattering in the UV spectral range for a pair of wavelengths. The difference between observed and modelled reflectance results in the AAI. When the AAI is positive, it indicates the presence of UV-absorbing aerosols like dust and smoke. It is useful for tracking the evolution of episodic aerosol plumes from dust outbreaks, volcanic ash, and biomass burning.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-carbon-monoxide",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-carbon-monoxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Carbon Monoxide",
    "text": "Sentinel-5P Level 2 Carbon Monoxide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 CO data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission, specifically focusing on measuring and analyzing the concentration of carbon monoxide in the Earth’s atmosphere. It includes data on the total column carbon monoxide content, as well as vertical profiles that describe how the concentration changes with altitude.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-cloud",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-cloud",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Cloud",
    "text": "Sentinel-5P Level 2 Cloud\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 Cloud dataset provides high-resolution imagery of cloud parameters. The TROPOMI/S5P cloud properties retrieval is based on the OCRA and ROCINN algorithms currently being used in the operational GOME and GOME-2 products. OCRA retrieves the cloud fraction using measurements in the UV/VIS spectral regions and ROCINN retrieves the cloud height (pressure) and optical thickness (albedo) using measurements in and around the oxygen A-band at 760 nm. Additionally, the cloud parameters are also provided for a cloud model which assumes the cloud to be a Lambertian reflecting boundary.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-formaldehyde",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-formaldehyde",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Formaldehyde",
    "text": "Sentinel-5P Level 2 Formaldehyde\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 HCHO data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focus on measuring and analyzing the concentration of formaldehyde in the Earth’s atmosphere. The Level 2 Formaldehyde data also incorporates auxiliary information, such as geolocation, cloud properties, and surface reflectance, which are crucial for contextualizing and interpreting the measurements.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-methane",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-methane",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Methane",
    "text": "Sentinel-5P Level 2 Methane\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 CH4 data from the Copernicus Sentinel-5P satellite shows the methane concentrations globally. This product provides processed and derived measurements of methane concentrations in the Earth’s atmosphere. It is a valuable resource for studying climate change, understanding methane emissions, and informing environmental policies and mitigation efforts.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-nitrogen-dioxide",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-nitrogen-dioxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Nitrogen Dioxide",
    "text": "Sentinel-5P Level 2 Nitrogen Dioxide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 NO2 data comes from the Copernicus Sentinel-5P satellite and shows the nitrogen dioxide concentrations across the globe. Concentrations of short-lived pollutants, such as nitrogen dioxide, are indicators of changes in economic slowdowns and are comparable to changes in emissions.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-ozone",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-ozone",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Ozone",
    "text": "Sentinel-5P Level 2 Ozone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 O3 data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focuses on measuring and analyzing the concentration and distribution of ozone in the Earth’s atmosphere. Researchers and scientists utilize this data for various purposes, that includes monitoring and assessing ozone depletion, particularly in regions like the polar areas, where the ozone layer is crucial. Additionally, the data aids in air quality monitoring, enabling the evaluation of ozone pollution control measures and understanding of pollution sources.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-sulfur-dioxide",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-2-sulfur-dioxide",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 2 Sulfur Dioxide",
    "text": "Sentinel-5P Level 2 Sulfur Dioxide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 2 SO2 data refers to processed and derived datasets obtained from the Sentinel-5P satellite mission that focuses on measuring and analyzing the concentration and distribution of sulfur dioxide in the Earth’s atmosphere. It provides comprehensive information on atmospheric sulfur dioxide’s vertical distribution and spatial variations. It includes data on the total column sulfur dioxide content and vertical profiles that describe how the concentration changes with altitude. This data also incorporates auxiliary information, such as geolocation, cloud properties, and surface reflectance, which are crucial for contextualising and interpreting the measurements. It is a valuable resource for studying air quality, volcanic activity, atmospheric chemistry, and assessing the impacts of sulfur dioxide on human health and the environment.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-1b",
    "href": "Data/SentinelMissions/Sentinel5P.html#sentinel-5p-level-1b",
    "title": "Sentinel-5P",
    "section": "Sentinel-5P Level 1B",
    "text": "Sentinel-5P Level 1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-5P Level 1B data refers to a processed and calibrated dataset derived from the raw measurements acquired by the Sentinel-5P satellite. This level of data undergoes initial processing steps to correct for instrument effects, atmospheric disturbances, and other artifacts.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nApr 2018 - Present\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel2.html",
    "href": "Data/SentinelMissions/Sentinel2.html",
    "title": "Sentinel-2",
    "section": "",
    "text": "The Copernicus Sentinel-2 mission comprises a land monitoring constellation of two polar-orbiting satellites placed in the same sun-synchronous orbit, phased at 180° to each other. It aims at monitoring variability in land surface conditions, and its wide swath width (290 km) and high revisit time (10 days at the equator with one satellite, and 5 days with 2 satellites which results in 2-3 days at mid-latitudes) will support monitoring of Earth’s surface changes.\nEach Sentinel-2 products is composed of approximately 110x110 km tiles in cartographic geometry (UTM/WGS84 projection). Earth is subdivided on a predefined set of tiles, defined in UTM/WGS84 projection and using a 100 km step. However, each tile has a surface of 110x110 km² in order to provide large overlap with the neighbouring.\nLevel-1 Level-2 Level-3"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel2.html#sentinel-2-level-2a-top-of-canopy-toc",
    "href": "Data/SentinelMissions/Sentinel2.html#sentinel-2-level-2a-top-of-canopy-toc",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 2A Top of Canopy (TOC)",
    "text": "Sentinel-2 Level 2A Top of Canopy (TOC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nSentinel-2 Level 2A Level 2A product provides atmospherically corrected Surface Reflectance (SR) images, derived from the associated Level-1C products. The atmospheric correction of Sentinel-2 images includes the correction of the scattering of air molecules (Rayleigh scattering), of the absorbing and scattering effects of atmospheric gases, in particular ozone, oxygen and water vapour and the correction of absorption and scattering due to aerosol particles. Level 2A product are considered an ARD product.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked (original ESA product)\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMarch 2017 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked (Product generated by CloudFerro using sen2cor processor)\n\n\nImmediately available data(IAD)\n\n\nRandom coverage based on user request\n\n\nJuly 2015 - January 2023\n\n\nJan 2023\n\n\n\n\n\n*There is a known product gap (2.7 mln S-2 Collection-1 product). Missing products will be made available successively. \n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2015-07-04’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nB01\n\n\nCoastal aerosol\n\n\n60\n\n\n0.443\n\n\n\n\nB02\n\n\nBlue\n\n\n10\n\n\n0.49\n\n\n\n\nB03\n\n\nGreen\n\n\n10\n\n\n0.56\n\n\n\n\nB04\n\n\nRed\n\n\n10\n\n\n0.665\n\n\n\n\nB05\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.705\n\n\n\n\nB06\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.74\n\n\n\n\nB07\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.783\n\n\n\n\nB08\n\n\nNIR\n\n\n10\n\n\n0.842\n\n\n\n\nB8A\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.865\n\n\n\n\nB09\n\n\nWater vapour\n\n\n60\n\n\n0.945\n\n\n\n\nB10\n\n\nSWIR - Cirrus\n\n\n60\n\n\n1.375\n\n\n\n\nB11\n\n\nSWIR\n\n\n20\n\n\n1.61\n\n\n\n\nB12\n\n\nSWIR\n\n\n20\n\n\n2.19\n\n\n\n\nSCL\n\n\nScene Classification\n\n\n20\n\n\n\n\n\n\nSNW\n\n\nSnow probability\n\n\n20\n\n\n\n\n\n\nCLD\n\n\nCloud probability\n\n\n20\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSTAC: https://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nWMTS: https://services.sentinel-hub.com/ogc/wmts/7d34803f-511c-4caf-9438-6d72f32c8174\n\n\n\n\n\nSentinel-2 L2A Baselines\nThe Sentinel-2 L2A collection within the Copernicus Data Space Ecosystem originates from three sources:\n(1) operational Copernicus processing, i.e. data previously accessible on the Copernicus Open Access Hub (formerly known as Sentinels Scientific Data Hub);\n(2) reprocessing of the L2A archive from 2015 until the end of 2021 (Collection 1), and ;\n(3) data generated by CloudFerro using various versions of the publicly available Sen2Cor processor. This data will be removed once replaced by the reprocessing of the L2A (point 2 above), which is planned to be completed in April 2024\nThese products can be differentiated by the OData and OpenSearch (origin) attribute (ESA or CloudFerro) and by the ‘processingBaseline’ attribute. Processing Baseline is presented on Copernicus Browser as a “Processor version” attribute.\nThe current state of the archive of the Sentinel-L2A data is as follows:\n\n\n\n\n\nAvailability of S-2 L2A products based on sensing date\n\n\nProcessing Baseline\n\n\n\n\n\n\n29/09/2015 - 14/01/2023\n\n\nProcessing Baseline 99.99 (generated by CloudFerro) (Attribute ‘processorVersion’: 99.99)\n\n\n\n\n04/07/2015 - 21/05/2021\n\n\nProcessing Baselines 2.05 -2.13 (originating from Copernicus Open Access Hub and generated by CloudFerro)\n\n\n\n\n04/02/2020 - 30/03/2021\n\n\nProcessing Baseline 2.14 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.14)\n\n\n\n\n25/01/2022 - 06/12/2022\n\n\nProcessing Baseline 4.00 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 04.00 or 4.0)\n\n\n\n\n29/04/2022 - 13/12/2023\n\n\nProcessing Baseline 5.09 (originating from Copernicus Open Access Hub and Copernicus Data Space Ecosystem) (Attribute ‘processorVersion’: 05.09 or 5.09)\n\n\n\n\n13/12/2023 - Now\n\n\nProcessing Baseline 5.10 (originating from Copernicus Data Space Ecosystem) (Attribute ‘processorVersion’: 05.10 or 5.10)\n\n\n\n\n\n\n\nProcessing Baseline 5.00 for Sentinel-2 L1C and L2A\nThe Sentinel-2 Collection 1 (reprocessed data) featuring processing baseline 5.00 is gradually ingested into the Copernicus Data Space Ecosystem. This ingestion will be completed in the end of Q2 2024.\n\n\n\n\n\nUpdated availability by sensing time period\n\n\nSentinel-2A\n\n\nSentinel-2B\n\n\n\n\n\n\nPublished (*)\n\n\nFrom sensing 2017-11-12T00:00:00.000 to 2021-12-31T00:00:00.000\n\n\nFrom sensing 2017-11-12T00:00:00.000 to 2021-12-31T00:00:00.000\n\n\n\n\nNext period in list\n\n\nNovember 2017 then continuing in reverse chronological order of sensing time\n\n\nNovember 2017 then continuing in reverse chronological order of sensing time\n\n\n\n\n\n(*) There is a known product gap between 2018 and 2019 (2.7 million S-2 Collection-1 products). Missing products will be made available successively.\nPlease refer to the article Copernicus SENTINEL-2 Collection-1 Availability Status that aims at providing up-to-date progress information on the proceedings of the generation of Collection-1 and on the gradual availability of Collection-1 Level-1C and Level-2A products."
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel2.html#sentinel-2-level-1c-top-of-atmosphere-toa",
    "href": "Data/SentinelMissions/Sentinel2.html#sentinel-2-level-1c-top-of-atmosphere-toa",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 1C Top of Atmosphere (TOA)",
    "text": "Sentinel-2 Level 1C Top of Atmosphere (TOA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nSentinel-2 Level 1C products are available globally from 2015 onwards. These products are resampled with a constant Ground Sampling Distance (GSD) of 10, 20 and 60 m, depending on the native resolution of the different spectral bands. Pixel coordinates refer to the upper left corner of the pixel.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJul 2015 - Present\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2015-07-04T00:00:00Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nB01\n\n\nCoastal aerosol\n\n\n60\n\n\n0.443\n\n\n\n\nB02\n\n\nBlue\n\n\n10\n\n\n0.49\n\n\n\n\nB03\n\n\nGreen\n\n\n10\n\n\n0.56\n\n\n\n\nB04\n\n\nRed\n\n\n10\n\n\n0.665\n\n\n\n\nB05\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.705\n\n\n\n\nB06\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.74\n\n\n\n\nB07\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.783\n\n\n\n\nB08\n\n\nNIR\n\n\n10\n\n\n0.842\n\n\n\n\nB8A\n\n\nVegetation Red Edge\n\n\n20\n\n\n0.865\n\n\n\n\nB09\n\n\nWater vapour\n\n\n60\n\n\n0.945\n\n\n\n\nB10\n\n\nSWIR - Cirrus\n\n\n60\n\n\n1.375\n\n\n\n\nB11\n\n\nSWIR\n\n\n20\n\n\n1.61\n\n\n\n\nB12\n\n\nSWIR\n\n\n20\n\n\n2.19\n\n\n\n\nSCL\n\n\nScene Classification\n\n\n20\n\n\n\n\n\n\nSNW\n\n\nSnow probability\n\n\n20\n\n\n\n\n\n\nCLD\n\n\nCloud probability\n\n\n20\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSTAC: https://stac-extensions.github.io/datacube/v2.2.0/schema.json\n\n\nWMTS: https://services.sentinel-hub.com/ogc/wmts/ef291c3e-77fd-43f2-a885-dced9ac1e6a7\n\n\n\n\n\nSentinel-2 L1C Baselines\nThe Sentinel-1 L1C collection within the Copernicus Data Space Ecosystem originates from the operational Copernicus processing, i.e. data previously accessible on the Copernicus Open Access Hub (formerly known as Sentinels Scientific Data Hub).\nThese products can be differentiated by the OData and OpenSearch processingBaseline attribute. Processing Baseline is presented on Copernicus Browser as a “Processor version” attribute.\nThe current state of the archive of the Sentinel-L1C data is as follows:\n\n\n\n\n\nAvailability of S-2 L1C products based on sensing date\n\n\nProcessing Baseline\n\n\n\n\n\n\n15/12/2015 - 03/05/2016\n\n\nProcessing Baseline 02.01 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 2.01)\n\n\n\n\n03/05/2016 - 15/06/2016\n\n\nProcessing Baseline 02.02 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.02 or 2.01)\n\n\n\n\n04/07/2015 - 26/05/2017\n\n\nProcessing Baseline 02.04 (To replace 02.03) (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.04 or 2.04)\n\n\n\n\n19/03/2017 - 23/10/2017\n\n\nProcessing Baseline 02.05 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.05 or 2.05)\n\n\n\n\n10/04/2016 - 06/11/2018\n\n\nProcessing Baseline 02.06 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.06 or 2.06)\n\n\n\n\n06/11/2018 - 22/07/2019\n\n\nProcessing Baseline 02.07 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 02.07 or 2.07)\n\n\n\n\n10/04/2016 - 04/02/2020\n\n\nProcessing Baseline 02.08 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 2.08)\n\n\n\n\n29/09/2015 – 30/03/2021\n\n\nProcessing Baseline 02.09 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 2.09)\n\n\n\n\n30/03/2021 - 30/06/2021\n\n\nProcessing Baseline 03.00 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 3.0)\n\n\n\n\n30/06/2021 - 25/01/2022\n\n\nProcessing Baseline 03.01 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 03.01 or 3.01)\n\n\n\n\n25/01/2022 - 06/12/2022\n\n\nProcessing Baseline 04.00 (originating from Copernicus Open Access Hub) (Attribute ‘processorVersion’: 04.00 or 4.0)\n\n\n\n\n29/04/2022 – 13/12/2023\n\n\nProcessing Baseline 05.09 (originating from Copernicus Open Access Hub and Copernicus Data Space Ecosystem) (Attribute ‘processorVersion’: 05.09 or 5.09)\n\n\n\n\n13/12/2023 - Now\n\n\nProcessing Baseline 05.10 (originating from Copernicus Data Space Ecosystem) (Attribute ‘processorVersion’: 05.10 or 5.10)\n\n\n\n\n\n\n\nProcessing Baseline 5.00 for Sentinel-2 L1C and L2A\nThe Sentinel-2 Collection 1 (reprocessed data) featuring processing baseline 5.00 is gradually ingested into the Copernicus Data Space Ecosystem. This ingestion will be completed in the end of Q2 2024.\n\n\n\n\n\nUpdated availability by sensing time period\n\n\nSentinel-2A\n\n\nSentinel-2B\n\n\n\n\n\n\nPublished (*)\n\n\nFrom sensing 2017-11-12T00:00:00.000 to 2021-12-31T00:00:00.000\n\n\nFrom sensing 2017-11-12T00:00:00.000 to 2021-12-31T00:00:00.000\n\n\n\n\nNext period in list\n\n\nNovember 2017 then continuing in reverse chronological order of sensing time\n\n\nNovember 2017 then continuing in reverse chronological order of sensing time\n\n\n\n\n\n(*) There is a known product gap between 2018 and 2019 (2.7 million S-2 Collection-1 products). Missing products will be made available successively.\nPlease refer to the article Copernicus SENTINEL-2 Collection-1 Availability Status that aims at providing up-to-date progress information on the proceedings of the generation of Collection-1 and on the gradual availability of Collection-1 Level-1C and Level-2A products."
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel2.html#sentinel-2-level-1b",
    "href": "Data/SentinelMissions/Sentinel2.html#sentinel-2-level-1b",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 1B",
    "text": "Sentinel-2 Level 1B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-2 Level 1B product provides radiometrically corrected imagery in Top-Of-Atmosphere (TOA) radiance values and in sensor geometry. Additionally, this product includes the refined geometric model which is used to generate the Level 1C product.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) EUP\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast two weeks\n\n\nQ2 2024\n\n\n\n\n\n(*) Access restrictions may apply."
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel2.html#sentinel-2-level-3-quarterly-mosaics",
    "href": "Data/SentinelMissions/Sentinel2.html#sentinel-2-level-3-quarterly-mosaics",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Level 3 Quarterly Mosaics",
    "text": "Sentinel-2 Level 3 Quarterly Mosaics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nSentinel-2 Quarterly Mosaics are mosaics generated from three months of Sentinel-2 level 2A.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\n(*) Jan 2022 - Present\n\n\nNov 2023\n\n\n\n\n\n(*) More will be added\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2023-01-01T00:00:00Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nB02\n\n\nBlue\n\n\n10\n\n\n0.49\n\n\n\n\nB03\n\n\nGreen\n\n\n10\n\n\n0.56\n\n\n\n\nB04\n\n\nRed\n\n\n10\n\n\n0.665\n\n\n\n\nB08\n\n\nNIR\n\n\n10\n\n\n0.842\n\n\n\n\nobservations\n\n\nValid pixels\n\n\n10\n\n\nN/A\n\n\n\n\n\n\n\n\n\n\n\nAlgorithm\nThe following algorithm was run independently for each pixel:\n(1) For each pixel: Take the three-month stack of Sentinel-2 L2A observations. Only bands B02, B03, B04, B08 and SCL are used to create the mosaic. For bands B02-B08 transform the values to reflectance.\n(2) For each observation: Mark an observation as invalid if the value of the Sentinel-2 L2A scene classification band (SCL) has one of the following values:\n\n1-SATURATED_DEFECTIVE,\n3-CLOUD_SHADOW,\n7-CLOUD_LOW_PROBA / UNCLASSIFIED,\n8-CLOUD_MEDIUM_PROBA,\n9-CLOUD_HIGH_PROBA,\n10-THIN_CIRRUS\n\n(3) For each pixel: Discard all invalid observations, what remains is called valid observations. The number of valid observations is generally different for each pixel and is output as a positive integer in the observations output band.\n(4) For each pixel, for each band (B02, B03, B04, B08): Sort all valid observations for each band separately.\n(5) For each pixel, for each band (B02, B03, B04, B08): Take the value of the first quartile and multiply it by 10000 (to get a ‘digital number’). This is an output value.\n(6) For each pixel, for each band (B02, B03, B04, B08): If there are no valid observations, output the value -32768, which represents no data. For the observations band, output the value 0, which also represents no data.\n\n\n\n\n\n\nNote\n\n\n\n\nIf multiple Sentinel-2 observations from the same day are available, only the most recent observation on that day is used.\nNo pre-filtering (e.g. based on cloud coverage) was performed to preserve as many non-cloudy pixels as possible.\n\n\n\nAccess Sentinel-2 Level 3 Quarterly Mosaics with Sentinel Hub\n\n\n\nAccess Sentinel-2 Level 3 Quarterly Mosaics with Sentinel Hub\nSentinel-2 Level 3 Quarterly Mosaics are onboarded to Sentinel Hub as a BYOC data collection. To access the data, you will need the specific pieces of information listed below, for general information about how to access BYOC collections visit our Data BYOC page.\n\nData collection id: byoc-5460de54-082e-473a-b6ea-d5cbe3c17cca\nAvailable Bands and Data:\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nResolution\n\n\n\n\n\n\nB02\n\n\nBlue\n\n\n10 m\n\n\n\n\nB03\n\n\nGreen\n\n\n10 m\n\n\n\n\nB04\n\n\nRed\n\n\n10 m\n\n\n\n\nB08\n\n\nNear Infrared (NIR)\n\n\n10 m\n\n\n\n\nobservations\n\n\nNumber of valid observations\n\n\n10 m\n\n\n\n\ndataMask\n\n\nThe mask of data/no data pixels (more).\n\n\nN/A*\n\n\n\n\n\n*dataMask has no source resolution as it is calculated for each output pixel.\n\nExample of requesting mosaic over Rome with Processing API request\nThe request below is written in python. To execute it, you need to create an OAuth client as is explained here. It is named oauth in this example.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 }\n  };\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04/10000, 2.5 * sample.B03/10000, 2.5 * sample.B02/10000];\n}\n\"\"\"\n\nrequest = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [\n        12.44693,\n        41.870072,\n        12.541001,\n        41.917096\n      ]\n    },\n    \"data\": [\n      {\n        \"dataFilter\": {\n          \"timeRange\": {\n            \"from\": \"2023-01-01T00:00:00Z\",\n            \"to\": \"2023-01-02T23:59:59Z\"\n          }\n        },\n        \"type\": \"byoc-5460de54-082e-473a-b6ea-d5cbe3c17cca\"\n      }\n    ]\n  },\n  \"output\": {\n    \"width\": 780,\n    \"height\": 523,\n    \"responses\": [\n      {\n        \"identifier\": \"default\",\n        \"format\": {\n          \"type\": \"image/jpeg\"\n        }\n      }\n    ]\n  },\n  \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel2.html#sentinel-2-precise-orbit-determination-pod-products",
    "href": "Data/SentinelMissions/Sentinel2.html#sentinel-2-precise-orbit-determination-pod-products",
    "title": "Sentinel-2",
    "section": "Sentinel-2 Precise Orbit Determination (POD) products",
    "text": "Sentinel-2 Precise Orbit Determination (POD) products\n\nOverview\nThe Copernicus POD Service for SENTINEL-2 provides Precise Orbital products with NRT timeliness, including two product types. Near Real-Time (NRT) orbital products are created immediately using real-time GPS data from EGP, while Near Real Time Predicted (PRE) products are calculated in advance of specific astronomical events, such as ascending node crossings.\n\nOffered Data\n\n\n\n\n\n\nProduct ID\n\n\nContent\n\n\nEOF\n\n\nTGZ\n\n\nCatalog API\n\n\nS3 Path\n\n\n\n\n\n\nAUX_GNSSRD\n\n\nRINEX\n\n\n\n\nX\n\n\nOData\n\n\n/eodata/Sentinel-2/AUX/AUX_GNSSRD/\n\n\n\n\nAUX_PROQUA\n\n\nQuaternions\n\n\n\n\nX\n\n\nOData\n\n\n/eodata/Sentinel-2/AUX/AUX_PROQUA/\n\n\n\n\nAUX_POEORB*\n\n\nOrbit\n\n\nX\n\n\n\n\nOData\n\n\n/eodata/Sentinel-2/AUX/AUX_POEORB/\n\n\n\n\n\n*S-2 AUX_POEORB currently not available. The backlog will be generated by CPOD, and made available on CPODIP, but it will require coordination with ESA/Copernicus Data Space Ecosystem."
  },
  {
    "objectID": "FAQ.html",
    "href": "FAQ.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "In comparison to the existing legacy Copernicus Data Hub, what will be the free services other than stac/cog?\n\n\nCompared to the previously existed Copernicus Data Hub, there will be additional APIs - OGC interfaces (WMS, WMTS, WCS), OpenEO, Sentinel Hub API, S3, and others. Please refer to the Roadmap for more information on the timing of these interfaces.\n\n\n\n\nIs there an end user document that describes specific data products and specific services that are available?\n\n\nThe user level details for every service and dataset will be provided in this documentation. In accordance with each and every service and dataset embedded into the ecosystem, this documentation will be updated.\n\n\n\n\nHow long is the project timescale in total?\n\n\nThe time scale of the project is 6 years starting from late 2022 (i.e. to the end of 2028) with an optional extension up to 4 years (i.e. 2032).\n\n\n\n\nCan anyone outside from Europe have free access to any data?\n\n\nYes, data and services will be available to users worldwide and according to the EU Policy. You can visit Terms and Conditions for more information.\n\n\n\n\nIs there any difference between EU users and non-EU users?\n\n\nThere is no difference between EU users and non-EU users. That said, there will be a continuity of the accounts with higher throughput, managed by ESA (i.e. Copernicus Services, International Partners, etc.).\n\n\n\n\nWhich users are qualified for higher tier accounts?\n\nThere are three types of higher tier accounts:\n\n\nCopernicus Services - this account type is meant for European Union institutions and bodies. Organisations working on Copernicus Services are as well included in this tier.\n\n\nCopernicus Collaborative Users - organisations from Copernicus Participating States with an agreement with ESA and European Commission.\n\n\nCopernicus International Users - international partners with an agreement with ESA and European Commission.\n\n\nIf your organisation fits the above-mentioned profile, do submit a request for an account upgrade. If you are not sure about it, do submit a request anyway and it will be evaluated. Please note that Copernicus Data Space Ecosystem monitoring requirements include reporting of aggregated consumption on account level, shared within project stakeholder group. We would also suggest you check the following content:\n\n\nInformation about quotas for specific services\n\n\nThe Ecosystem service providers, where users can get access to extended quotas under commercial terms."
  },
  {
    "objectID": "FAQ.html#general",
    "href": "FAQ.html#general",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "In comparison to the existing legacy Copernicus Data Hub, what will be the free services other than stac/cog?\n\n\nCompared to the previously existed Copernicus Data Hub, there will be additional APIs - OGC interfaces (WMS, WMTS, WCS), OpenEO, Sentinel Hub API, S3, and others. Please refer to the Roadmap for more information on the timing of these interfaces.\n\n\n\n\nIs there an end user document that describes specific data products and specific services that are available?\n\n\nThe user level details for every service and dataset will be provided in this documentation. In accordance with each and every service and dataset embedded into the ecosystem, this documentation will be updated.\n\n\n\n\nHow long is the project timescale in total?\n\n\nThe time scale of the project is 6 years starting from late 2022 (i.e. to the end of 2028) with an optional extension up to 4 years (i.e. 2032).\n\n\n\n\nCan anyone outside from Europe have free access to any data?\n\n\nYes, data and services will be available to users worldwide and according to the EU Policy. You can visit Terms and Conditions for more information.\n\n\n\n\nIs there any difference between EU users and non-EU users?\n\n\nThere is no difference between EU users and non-EU users. That said, there will be a continuity of the accounts with higher throughput, managed by ESA (i.e. Copernicus Services, International Partners, etc.).\n\n\n\n\nWhich users are qualified for higher tier accounts?\n\nThere are three types of higher tier accounts:\n\n\nCopernicus Services - this account type is meant for European Union institutions and bodies. Organisations working on Copernicus Services are as well included in this tier.\n\n\nCopernicus Collaborative Users - organisations from Copernicus Participating States with an agreement with ESA and European Commission.\n\n\nCopernicus International Users - international partners with an agreement with ESA and European Commission.\n\n\nIf your organisation fits the above-mentioned profile, do submit a request for an account upgrade. If you are not sure about it, do submit a request anyway and it will be evaluated. Please note that Copernicus Data Space Ecosystem monitoring requirements include reporting of aggregated consumption on account level, shared within project stakeholder group. We would also suggest you check the following content:\n\n\nInformation about quotas for specific services\n\n\nThe Ecosystem service providers, where users can get access to extended quotas under commercial terms."
  },
  {
    "objectID": "FAQ.html#data",
    "href": "FAQ.html#data",
    "title": "Frequently Asked Questions",
    "section": "Data",
    "text": "Data\n\n\nWhat data will be offered online and what is the timeline for the following months?\n\n\nFor the details on the data offer and timing, please refer to the Roadmap\n\n\n\n\nIs there a page that indicates anomalies with the datasets?\n\n\nThe Copernicus Sentinel Operations Dashboard provides details of events over the past three months that have impact on the completeness of the data production, such as planned calibration activities, manoeuvres, or anomalies. The information of which data is affected is included.\n\n\n\n\nWith regard to cloud native formats/interfaces, will the data also be available in the original data formats (e.g. for data downloading)?\n\n\nYes, data will also be available in original data formats (i.e. .SAFE).\n\n\n\n\nWill data, such as Sentinel-2, be processed to a consistent version?\n\n\nThe Sentinel-2 data will be available at the latest processing baseline. And with the reprocessing of Sentinel-2 happening in parallel (out of scope of this project), these will become available on this service as well. For more information on Sentinel-2 reprocessing campaign, please follow Copernicus SENTINEL-2 Collection-1 Availability Status\n\n\n\n\nIs it possible to download a subset of data corresponding to an AOI, instead of the whole image?\n\n\nYes, it is possible to download a subset of data, by using the dedicated APIs, i.e. Sentinel Hub, OpenEO.\n\n\n\n\nAre there data offered in the Cloud Optimized Geotiffs (COG) format?\n\n\nYes, Sentinel-1 GRD Level 1 data will be available in COG format.\n\n\n\n\nWhen Online data is mentioned, does that mean the data are not on tape?\n\n\nThe Online data (or Immediate Access Data (IAD)) are not on the tapes. Online data is the type of data where in its metadata it reads “Online”: true. These data can be downloaded directly from the Copernicus Data Space Ecosystem. On the other hand, Offline data (“Online”: false or Deferred Available Data(DAD)) first needs to be ordered via the Data Workspace and only after that step, it can be downloaded.\n\n\n\n\nCan we download the data acquired by all Sentinel missions (1, 2, 3, 5P, 6) and the other satellites (e.g. Meteosat) via the new interface? Considering some missions are not managed by ESA, but by EUMETSAT for example.\n\n\nThe Data Roadmap shows how the Copernicus Data Space Ecosystem will be continously enhanced in terms of available data.\n\n\n\n\nWill the new interface offer EO ready-to-use products or just L0 and L1 data?\n\n\nUp to L3 products will be available. Please see the Roadmap and the Data section.\n\n\n\n\nWhat is the highest resolution SAR data available in Copernicus Data Space Ecosystem?\n\n\nThe Sentinel-1 SAR achieves a spatial resolution of approximately 5 by 20 m. More information can be found here.\n\n\n\n\nIs it possible to acquire compressed data?\n\n\nCopernicus Data Space Ecosystem provides access to EO data in zip format without compression(i.e. zero compression applied)."
  },
  {
    "objectID": "FAQ.html#services",
    "href": "FAQ.html#services",
    "title": "Frequently Asked Questions",
    "section": "Services",
    "text": "Services\n\n\nAre the free offering and commercial offering integrated to facilitate the transfer of the users from free to commercial?\n\n\nYes, there will be a common user identity, which will allow registered users to seamlessly transfer between two mentioned systems.\n\n\n\n\nWhen we develop an EO ready-to-use product, could we integrate it into the interface and ask the payment from clients?\n\n\nYes, commercial services can be built on top, similar to the Copernicus Open Licence.\n\n\n\n\nCan users come with wish-list on services?\n\n\nYes, users can come up with suggestions to improve or expand the service portfolio. Users can post their improvement suggestions to Community Forum for further evaluation.\n\n\n\n\nIs there any limitation on the maximum number of downloads at a time?\n\n\nYes, there will be quotas and limitations for different user types. For example, the number of concurrent connections limit for the Copernicus General user type is 4, whereas for the Copernicus Services type, it is 20. Please refer to the Quotas and Limitations section of our documentation for more information regarding quotas and limitations apply to the Copernicus General user type.\n\n\n\n\nIs it possible to download Sentinel-2 data for a large area at a high resolution in the Copernicus Browser?\n\n\nDepending on your use, we suggest to use the high-res print (via the high-res print tab) where you will get large areas in a high resolution (the data is though not georeferenced). If you need georeferenced data, split your area in several smaller images that you download or choose a bit lower resolution to stay within the limits of 2500px.\n\n\n\n\nWhere can I find more information regarding the quotas and limits for accessing data and using the services through your platform?\n\n\nPlease refer to the Quotas and Limitations section of our documentation for more information.\n\n\n\n\nWhich entities are qualified to get higher quotas in scope of “Copernicus Services” group and how can one ask for it?\n\nThe following users and initiatives are qualified for the increased quota:\n\n\nInstitutions and organisations developing or operating Copernicus Services\n\n\nEuropean institutions and Bodies set up under the EU Treaties.\n\n\nEach institution or project can have several individuals’ user accounts, which belong to the same organisation and share the account’s quota (i.e. if one of the organisation users will consume full monthly project quota, the rest will not be able to use it further either). Project owners will be able to add further users to this organisation themselves. Organisations can choose the account type based on their preference, i.e. download-optimised or processing-optimized\n\n\nDownload\n\n\nProcessing - small\n\n\nProcessing - medium\n\n\nProcessing - large\n\n\nIn order to request for increased quota, fill out this form and provide the following information:\n\n\naccount’s e-mail (you have to register before submitting this request, do use your organisation’s e-mail domain)\n\n\norganisation name (including department, if relevant)\n\n\nproject name (i.e. Copernicus Services contract reference, project reference, etc.)\n\n\nproject start date\n\n\nplanned project end date\n\n\ninstitutional contact (i.e. contract officer at European Commission)\n\n\npreferred type of the account (“Download”, “Processing-small”, “Processing-medium”, “Processing-large”)\n\n\nnotes\n\n\nPlease note that Copernicus Data Space Ecosystem monitoring requirements include reporting of aggregated consumption on account level, shared within project stakeholder group."
  },
  {
    "objectID": "FAQ.html#registration-and-authentication",
    "href": "FAQ.html#registration-and-authentication",
    "title": "Frequently Asked Questions",
    "section": "Registration and authentication",
    "text": "Registration and authentication\n\n\nI’m having troubles with registering, what can I do?\n\n\nIf you are having troubles with Recaptcha or receiving the initial confirmation email while registering, please send an e-mail to help-login@dataspace.copernicus.eu for direct support.\n\n\n\n\nI’m having problems when I try to login or submit a request in the Help Center. How can I solve it?\n\n\nThis may be due to your browser settings. Please make sure Enhanced Tracking Protection is turned off and in the Privacy&Security section of your browser, make sure the option Standard (not Strict) is selected. If these doesn’t solve your issue. please contact our support team via Submit a request."
  },
  {
    "objectID": "FAQ.html#apis",
    "href": "FAQ.html#apis",
    "title": "Frequently Asked Questions",
    "section": "APIs",
    "text": "APIs\n\n\nWhere can I find detailed information regarding the duration of Access tokens and Refresh tokens?\n\n\nThe access token is valid for 10 minutes, after 10 minutes, it expires. When Access Token expires, it must  -either be refreshed by using the Refresh Token, -or be re-generated. The refresh token is valid for 60 minutes and can be used multiple times within that 60 minutes. The returned access token is again valid for 10 mins. Please refer to the Quotas and Limitations section of our documentation for more information. Also please refer to the OData section of our documentation for more information on Access and Refresh Tokens.\n\n\n\n\nIs a STAC catalog planned ? Will the data be accessible on cloud object storage (S3)?\n\n\nSTAC Catalog API is indeed planned. The data is already available over S3 as well.\n\n\n\n\nWill Long Term Archive (LTA) process be discontinued when all archived data become Online?\n\n\nThere will still be services available for so called “deferred data access” : data collections that are not commonly used. That said, all of the most relevant collections will be available Online. The Roadmap shows how the Copernicus Data Space Ecosystem will be continously upgraded and how more data become available.\n\n\n\n\nWill the platform use STAC standards?\n\n\nYes, STAC Product Catalog is already available. However there may be issues with using the current version with generic STAC libraries. Our dedicated teams are actively working on its development to ensure a seamless experience for all users. Nevertheless it already supports basic product search.\n\n\n\n\nAny plan to offer the Pangeo platform for a “pythonist”?\n\n\nThis is currently not in the offer or roadmap.\n\n\n\n\nHow do I generate S3 access and secret keys?\n\n\nPlease refer to the Access to EO Data via S3 page for the guidance on generating S3 access and secret keys.\n\n\n\n\nWhich one amongst the 4 catalog APIs (OData, STAC, OpenSearch, Sentinel Hub catalogue) is updated first when new products are published?\n\n\nOpenSearch, OData and STAC catalog APIs all use the same backend database. Sentinel Hub catalog API contains a subset of the collections, hence it works only for the ones that have been imported to Sentinel Hub. Therefore there is no first updated one.\n\n\n\n\nWhat is the limitation of the number of requests that I can do at the time?\n\n\nFor concurrent requests and other limitations please refer to the Quotas and Limitations section of our documentation for more information as the limits are different for each user type.\n\n\n\n\nCan I connect directly to the S3 bucket using AWS S3 commands with the S3 keys provided or do I have to use “s3cmd” to download images?\n\n\nYes, you can connect to S3 bucket using AWS S3 connection. However some functionality may not be supported. It is recommended to use the ‘s3cmd’ command to download products.\n\n\n\n\nDo you have to authenticate for requesting through OpenSearch API?\n\n\nThere’s no need to use any user or authentication when you want to search. User authentication is required for downloading products.\n\n\n\n\nCan we use the Sentinel Hub bucket and fetch the products based on the id we obtained from OpenSearch API?\n\n\nYes, you can use Sentinel Hub bucket in addition to some programming tools by providing product ID obtained by using OpenSearch API or OData of the Copernicus Dataspace Ecosystem.\n\n\n\n\nWhat is the benefit of fetching imagery from Copernicus Dataspace S3 bucket?\n\n\nDownloading products via S3 is faster as it delivers products as a .zip archive, skipping the need of zipper.\n\n\n\n\nOn which region resides the Copernicus Dataspace S3 bucket?\n\n\nThe repo is located in Warsaw/Poland.\n\n\n\n\nHow can I search for the product in S3 bucket?\n\n\nSearching via ID or product name in the OpenSearch or OData will give the S3 path to the product in response."
  },
  {
    "objectID": "FAQ.html#documentation",
    "href": "FAQ.html#documentation",
    "title": "Frequently Asked Questions",
    "section": "Documentation",
    "text": "Documentation\n\n\n\nWhich distribution channels will be available for high-throughput data access? Does the public side have user tiers, or is high-throughput data transfer (such as EODATA ) only a paid service?\n\n\n\nAll distribution options (i.e. OData, S3, Sentinel Hub,..) will be constrained with user quotas, which includes both bandwidth limitation, as well as monthly data transfer limits. Please refer to the Quotas and Limitations section of our documentation for more information.\n\n\n\n\nWhere can I find more information regarding the cost of the “extra” services?\n\n\nPricing will be published soon.\n\n\n\n\nIt is indicated that “For those interested in processing, there will be scalable cloud resources available, optimized for EO tasks”. Does this refer to the current CreoDIAS resources, or something completely new that hasn’t been addressed yet?\n\n\nThis December advertisement of the Copernicus Data Space Ecosystem indicates that scalable cloud resources will be part of the commercial offering and can be obtained at CREODIAS in first instance. ICT-wise, there will be two options, including Open Telekom Cloud.\n\n\n\n\nAre there tutorials (online & physical meetings) to use the new interface?\n\n\nTutorials will be added to the documentation in due time explaining the usage of the different interfaces. We will also be present on different conferences explaining the service & ecosystem."
  },
  {
    "objectID": "Applications/Catalogue-csv.html",
    "href": "Applications/Catalogue-csv.html",
    "title": "Catalogue CSV",
    "section": "",
    "text": "This webpage enables users to access and download Sentinel-1, Sentinel-2, Sentinel-3 and Sentinel-5P product lists in csv format.\n\nCSV Copernicus Catalogue\nDiscover the webpage via CSV Copernicus Catalogue."
  },
  {
    "objectID": "Applications/Browser.html",
    "href": "Applications/Browser.html",
    "title": "About the Browser",
    "section": "",
    "text": "The Copernicus Data Space Ecosystem Browser serves as a central hub for accessing, exploring and utilizing the wealth of Earth observation and environmental data provided by the Copernicus Sentinel constellations, contributing missions, Auxiliary engineering data, on-demand data and more (Check out the documentation on Data for more details) . Based on Sentinel Hub’s EO Browser, users can visualise, compare and analyse and download all this data for a variety of applications, from environmental monitoring and disaster management to urban planning and agriculture. You can access the Browser at:\nhttps://dataspace.copernicus.eu/browser/\nCurrently you need a free account to use the Browser. To register for a free account, click here to the browser. A new window will open where you can click on New user? Click here to create an account and access the data. Once you have created the account, you will automatically be logged in to the Browser. Remember to save your login credentials for the next time you want to log in to the Browser. The Copernicus Browser is also available in multiple languages.\nFig 1: Browser start screen\nThe Browser window is divided into three parts:"
  },
  {
    "objectID": "Applications/Browser.html#visualization",
    "href": "Applications/Browser.html#visualization",
    "title": "About the Browser",
    "section": "Visualization",
    "text": "Visualization\nYou can find the VISUALIZE tab in the upper left corner of the sidebar (selected by default). The VISUALIZE tab will allow you to easily visualize satellite imagery on the map. Change or modify your visualization with just a few clicks.\n\nVisualizing data\nIn order to visualize data on the map, you need to zoom in to your area of interest. You can do this either with the mouse wheel or with the location search in the upper right corner.\nLet’s try to visualize the latest Sentinel-2 L2A imagery over Italy.\n\nEither zoom to Italy with the mouse wheel or type Italy in the search box in the upper right corner.\nIn the sidebar, a maximum cloud coverage of 30% and the product type Sentinel-2 L2A are already preselected. To visualize the latest available data with cloud coverage below 30% click on the Show latest date button.\n\n\nFig 2: VISUALIZE tab with show latest date button and Sentinel-2 L2A collection highlighted\nYou can now see the latest data over Italy on the map. Depending on the latest data available you will see data from one or more orbits (stripes of images on the map).\n\nModifying and Changing a Visualization\nIf you want to improve how the data is displayed on the map, you can modify the visualization by clicking on Show effects and advanced options at the bottom of the sidebar. Change the Gain/Gamma values, the values of the R/G/B colour channels, specify which sampling method is used for the visualization (Layer default, Bilinear, Bicubic, Nearest) or click on Reset to reset all changes made. To return to the visualization layers overview, click on Show visualizations.\nTo visualize different Sentinel-2 band combinations, either use one of the prepared options from the list of layers (e.g., NDVI for the Normalized Difference Vegetation Index using the Sentinel bands B4 and B8) or click Custom at the bottom of the layers list.\n\nFig 3: Custom Layers option with Composite Index and Custom script highlighted\nHere you can create a custom R/G/B composite or Index (band ratio, normalized difference index) by dragging and dropping the Sentinel-2 bands into the appropriate circles or use the Custom script functionality to insert a piece of JavaScript code.\n\n\nChanging Configurations\nYou can change the configuration to create your own layers and visualizations. A configuration instance acts as a separate WMS/WMTS/WFS/WCS service and each can be configured to provide a certain set of layers with different settings. It is therefore possible to create multiple configuration instances, each providing a different set of layers for different needs. The configuration instances can contain any number of layers that can be configured with the settings defined above, e.g., cloud coverage, time range, etc. Each visualizations is based on a predefined visualization option or a custom script. The configuration instance itself also has some global settings for default values on all layers, suach as image quality.\nYou can create your own configuration by accessing the Dashboard via the drop-down menu under your username or directly here. In the panel on the left you will find “Configuration Utility” where you can create, modify and delete your instances. Once you have created a configuration, you can open it in the Copernicus Browser. Alternatively, you can change the configurations directly in the Copernicus Browser by selecting your configuration from the drop-down menu as shown in the figure.\n\nFig 4: Changing the Configuration in Copernicus Browser\n\n\nChanging the Data Collection\nYou can switch visualizing between different data collections by clicking on the arrow next to the Data Collections section in the Visualization tab. Once you click on the arrow as seen in Fig. 4, you will be able to see a drop-down menu with a list of the satellite data that is available. Let us try to visualize Sentinel-2 Quarterly Mosaics data of the same location and date as that of the Sentinel-2 data in Visualizing data section.\n\nClick on the drop-down arrow on the right next to Pins icon.\nClick on the drop-down arrow next to Sentinel-2 and select Sentinel-2 Mosaics. You will get two options to choose from because there are Quarterly and Annual Mosaics available. Choose Sentinel-2 Quarterly Mosaics.\nYou will get two options to choose from because there are Quarterly and Annual Mosaics available. Choose Sentinel-2 Quarterly Mosaics to visualise the Sentinel-2 cloudless mosaics created for each quarter of 2023.\n\nYou can now see the latest Sentinel-2 Quarterly Mosaic.\nAt the moment, the Data Collections available for visualization are Sentinel-1 (SW, IW and EW mode), Sentinel-2 (L1C and L2A), Sentinel-2 Mosaics (Quarterly Mosaics for 2023 and WorldCover Annual Cloudless Mosaics for 2020 and 2021), Sentinel-3 (OLCI Level-1 EFT, SLSTR Level-1 RBT), Sentinel-5P and two Digital Elevation Models (Copernicus 30, Copernicus 90).\n\nFig 5: Changing Data Collection from Visualization tab directly\n\n\nComparing Visualizations\nTo compare two (or more) visualizations you must add them to the compare panel. You can add a visualization to the compare panel by clicking on the Add to compare button in each visualization layer (see Fig. 4). When you have added all the layers you want to compare to the compare panel, you can switch to it by clicking on the compare icon (  ). In the compare panel you can choose between a Split and an Opacity mode. With the Split mode you can compare two images side by side. With the Opacity mode you can compare two (or more) visualizations on top of each other.\n\nFig 6: Add to compare and compare icon\n\n\nSaving Pins\nTo save a visualization for future viewing, you can save it as a pin by clicking on ( ) next to the Layer name and clicking on Add to Pins. You can find the saved pins by clicking on the ( ) icon. If you wish to compare saved pins, you can add them to the compare panel as explained in the previous section. If you have multiple pins saved and want to compare them altogether, you can directly go to the compare panel and add all the pins to compare by clicking on ( ). Another feature of the Browser is that you can export pins as a JSON file and import previously exported pins as well.\n\nFig 7: Add to pins and Pins icon\n\n\n\nProduct Search for Current Visualization\nWhen you are visualizing data (chapter Visualizing data), you can easily find the products associated with the data you see on the map. The product allows you to inspect the full metadata and easily download the raw data. To find connected products, just click the Find products for current view button in the sidebar (under the Show latest date button).\n\nFig 8: Find products for current view button position in the sidebar.\n\n\n3D Visualization\nWith the 3D visualization tool, users can also visualize the terrain. To obtain a 3D visualization, you need to first select a layer to view and then click on the  icon. You can move forward, backward, left, or right by right clicking on the pan console (labelled 1 in the red box in Fig. 8) and rotate around a point by right clicking on the camera console (labelled 2 in the red box in Fig. 8). The viewing angle can be adjusted by scaling vertically and panning in all directions. You can further explore the area by adjusting the sun projected shadows and the shading parameters of the scene in the settings (labelled as box 3 and 4 respectively in Fig. 8). This 3D view can also be downloaded as a PNG or JPEG file. Let us try visualizing Mont Blanc, the highest peak in the Alps.\n\nFollow the steps mentioned in Visualizing data chapter to visualize Mont Blanc and select the “True Color” visualization.\nClick on the  icon placed at the right of the screen.\nYou can navigate around the visualization either with your mouse, keyboard or directly on the map by following the instructions mentioned in the “Help” section (click on the ( ) icon).\nClick on the Settings icon ( ). Set the Vertical terrain scaling to 150% by moving the slider.\nTo adjust shadows, click on the Parameters next to Sun projected shadows toggle switch.\nTo adjust Shading parameters, click on Edit and modify the Ambient factor, Diffuse factor, Specular factor, and Specular power.\nYou can Reset values at any point to return to the default settings.\n\n\n\n\n3D visualization\n\n\nFig 9: 3D visualization in the Browser with pop-up Settings windows on the right"
  },
  {
    "objectID": "Applications/Browser.html#product-search",
    "href": "Applications/Browser.html#product-search",
    "title": "About the Browser",
    "section": "Product Search",
    "text": "Product Search\nWith the product search you can find products from Sentinel missions (Sentinel-1, Sentinel-2, Sentinel-3, Sentinel-5p) and the sensors on board these satellites (C-SAR, MSI, OLCI, SRAL, SLSTR, SYNERGY). You can also find engineering and auxiliary data for all Sentinels (including Sentinel-6). You can explore the metadata for each of those products, download the raw data or visualize the data on the map (at present, Sentinel-1 GRD, Sentinel-2 L1C and L2A, Sentinel-3 OLCI L1B and SLSTR L1B, Sentinel-5P L2 and DEM data can be visualized).\nThe SEARCH tab is located in the sidebar next to the VISUALIZE tab (see Fig. 9).\n\nFig 10: SEARCH tab with different Data Sources, Time range and Search button\n\nHow to find a Product\nTo find products you can either use the keyword search (text input) or select one or more data sources using the checkboxes. To find products for a specific time range only, set the from/to date in the date input boxes. For example, let us find the latest Sentinel-2 L2A image over Italy for the beginning of 2023.\n\nZoom in on Italy on the map with the scroll wheel of your mouse.\nSelect Sentinel-2 &gt; MSI (selected by default) &gt; L2A.\nSet the Time Range to reflect two weeks (e.g., 2023-01-02, 2023-01-16)\nPress the Search button\n\n Fig 11: SEARCH tab with L2A collection selected and map centred on Rome (Italy)\nYou will now see the first 50 search results for your search settings (Sentinel L2A data over Italy for a time range of 2 weeks) in the sidebar and on the map. To load the next 50 results, click on the Load more button at the end of the list in the sidebar. You can view the metadata of a product in the sidebar or by selecting a product on the map. In both cases you can:\n\nDirectly view the basic metadata (preview image (available for most Sentinel-2 L1C, L2A, Sentinel-3 SLSTR and Sentinel-3 OLCI products), name, mission, instrument, acquisition time)\nView the full metadata by clicking on the product info button ( ) in the results (full metadata)\n\n\nAdditional Filters\nTo get more suitable results, you can also select or choose additional filters as shown in Figure 11. 1. Select the Data Source and the appropriate instrument/ processing level. 2. Click on the Filter button and set the filtering parameters. 3. Press the Search button. Here, you can choose various parameters depending on the chosen Data Source. For example, you can see the filter parameters for Sentinel-1 in figure below, letting you filter the results based on satellite platform, orbit direction, relative orbit number, acquisition mode, Beam ID and polarization.\n\nFig 12: Data filters and parameters\n\n\nVisualize the search result\nOnce you have found a product, you can visualize the results in two ways: either by directly selecting the viszualize button (  ) in the sidebar or by selecting the visualize button in the results panel on the map. You can open the results panel by clicking on one of the displayed tile footprints on the map.\n\n\n\nSearch tab\n\n\nFig 13: Product metadata and visualize button\n\n\n\nHow to download a Product\nWhen you have found a product (see How to find a Product) that you would like to download, you can do so by clicking click on the download icon (  ) for the desired product in the results (in the sidebar or in the results panel on the map after selecting a product). After you click the button, a progress bar will appear below the product to indicate the status of your download. If you have started a download by mistake, you can cancel it by clicking on the “x” below the download button.\nYou can continue to use the app as normal while a product is being downloaded.\n\nFig 14: Product download (in progress) with Download product and cancel button highlighted\n\nDownload single files\nA “product” refers to a directory containing a collection of information such as metadata, product information, the satellite image and quality data, auxiliary data and more. If downloading all of this data is not of your interest, you can opt to download single files within this directory but clicking on the single file download icon (). Depending on the product you are trying to download, you will get a list of files within the directory and the  icon next to them to download each file individually.\n\n\n\nAdd Product to Workspace\nTo avoid downloading all the products, you can add the product to your workspace and give as input to your workflow on the Copernicus Dataspace Ecosystem directly. The main objective of the workspace is to:\n\nFurther process single products (with various options to select the algorithm/processing required for your application).\nKeep track of the processed products (status, finished/queued products)\n\nTo do this, click on the Add to Workspace icon () appearing in your search result. The workspace can be accessed by clicking on the dropdown menu under your username or directly here.\n\nFig 15: User dropdown menu to access Workspace."
  },
  {
    "objectID": "Applications/Browser.html#tools",
    "href": "Applications/Browser.html#tools",
    "title": "About the Browser",
    "section": "Tools",
    "text": "Tools\nThe Browser has several tools to help you better understand the data on the map and prepare it for sharing with others. These tools can be found in the upper right corner of the Browser. They can help you select the Area of Interest, measure, download the image, create a timelapse if you want to observe the area over a longer period of time, or analyse the statistics of an index (e.g., the NDVI).\n\nArea/Point of Interest\nUse the Area of Interest (AOI) tool to draw a rectangular or polygonal area of interest by clicking on the  icon in the upper right corner of the browser. You can also upload a KML/KMZ, GPX, WKT (in EPSG:4326) or GEOJSON/JSON file to create an AOI.\nUse the  icon to mark a location and re-centre to the Point of Interest(POI)\nOnce you have selected the AOI, depending on the type of data you are looking at, you can view the spectral signature of the region using the Spectral Explorer() or, in case of indices, look at the change in value over time using the Statistical Info () feature.\n\n\nMeasure\nYou can use the Measure tool by clicking on the  icon to get the distance and area measurements. To measure the distance between two points, simply click on the start and end points on the map, to measure the area, draw a polygon (areas can also be measured using the AOI drawing, as described in Area/Point of Interest).\n\n\nImage Download\nThere are three different download options. You can switch between the options using the tabs at the top of the pop-up window. Each option contains a preview of the data at the bottom. When you are satisfied with your download settings, you will find the  button below the preview:\n\nBasic\n\nYou can use the Show Captions toggle switch to add data source, date, zoom scale and branding information to the exported images.\nYou can also use the Add Map Overlays toggle switch to add place labels, streets and political boundaries to the image or the Show Legend toggle switch to add the legend data.\nYou can use the Crop to AOI toggle switch to crop the image to the bounds of area of interest, if drawn previously.\nIf you want to download the entire image but highlight the AOI, it can be done by enabling the Draw AOI Geometry.\nUse the textbox to add a short description to the exported image.\nChoose between two image formats (JPG, PNG).\nA preview of the image that will be downloaded is displayed under Preview. Previews are available only when you zoom in enough.\n\nAnalytical\n\nAfter preparing the data for download, click the  button to download the image in JPG, PNG, KMZ or GeoTIFF format.\nChoose between different image formats, resolutions and coordinate systems before downloading the image. You can also attach a logo.\nIn the Analytical panel, you can select multiple layers (Visualized/Raw) and download them all in a single ZIP file.\n\nHigh-res print\n\nPrepare the selected visual for high-resolution printing by manually selecting a format, size and DPI. Add captions, legends and descriptions as needed.\n\n\n\n\nTimelapse\nTimelapses are a very popular and useful tool to show how a certain location on Earth changed through time. Using the timelapse tool you can create your own visualization of changes through time and export it as .GIF or .MPEG4 to share it with others online. Let’s create a timelapse of the deforestation in the Brazil from 2018 – 2022.\n\nGo to: https://sentinelshare.page.link/osH4\nClick on the timelapse icon (  ) and click on the play button in the middle of the screen. This opens a pop-up window to create a timelapse.\nChange the settings on the left side to:\n\nDates 2018-01-01 – 2022-12-31\nSelect 1 image per: month Alternatively, you can select only certain months in a year using the filter by months option. Click on Search to see all the results.\n\nIn the Visualizations set the Min. tile coverage to 100% and the Max. cloud coverage to 2% and manually deselect the images from the 2022-05-30 (slightly cloudy) and the 2022-09-07 (blurry).\nOnce you have the list of images you want to display in the timelapse, select the speed, and transition to prepare your timelapse.\nClick on the play button to check the result and download the animation as a GIF-file using the Download button for further use online/offline.\n\n\n\n\nTimelapse\n\n\nFig 16: Browser timelapse tool with settings highlighted\n\n\nStatistical Analysis\nThere are quite a lot of statistical analyses that can be done in the Browser itself. Depending on the type of data you are looking at, you can look at the distribution of the pixel values, view the spectral signature of the region using the Spectral Explorer() or, in case of indices, look at its change over time using the Statistical Info () feature. #### Histogram\nWith the Histogram tool you can display statistical data (the distribution of values) for specific layers by clicking on the  icon. The histogram is calculated for the data within your AOI, if defined or otherwise for the whole screen. This tool currently only works for index layers (e.g., the NDVI).\n\nFig. 17: Example of a distribution plot of NDVI values\n\nSpectral Explorer\nThe Spectral Explorer analyses the various bands of the multi-spectral imagery to extract the spectral signature and helps to identify the scene in the region of interest. You can follow these steps to see a simple example of this feature. Note that this feature is only available for Sentinel-2 imagery at the moment.\n\nGo to the location and draw a bounding box in the open water like shown in the figure.\nClick on the Spectral Explorer icon () within the AOI tool.\n\n\nFig. 18: Screenshot of steps to follow to see an example of spectral signature of open water.\nBy doing this, you can see a graph pop up with the spectral signature (associated with specific chemical composition) averaged over all the pixels within this box. This helps to compare the spectral signature of the scene (in light green) with other known signatures.\n\nFig. 19: Example of spectral signatures plotted in comparison to other known signatures labelled in the bottom of the graph.\n\n\nTime Series\nWith the Statistical Info () feature within the AOI tool, you can see how the value of an index has changed in time. To see this, it is necessary to choose a visualisation which give an index as output, (e.g., NDVI) or any single band. You can follow these steps to see an example Time Series of the NDVI of a single agricultural field.\n\nSelect the Normalized Difference Vegetation Index (NDVI) layer to visualise the scene.\nOutline an agriculutral field with the AOI tool to select the area you want to analyse the changes in.\n\n\nFig. 20: Screenshot of steps to follow to see an example of time series of NDVI over an agricultural field.\n\nSelect the Statistical Info () chart icon within the AOI tools.\nYou can choose the time over which you want to see the changes at the top of the graph that pops up. Due to the clouds being in the way and distorting the NDVI considerably (cloud NDVI values are low), the growth curve isn’t as orderly as one would have hoped. So you can also adjust the cloud cover to visualise the changes without distortion.\n\n\nFig. 21: Example of Time Series plotted for an agricultural field over a period of 1 year with 0% cloud cover."
  },
  {
    "objectID": "Applications/DataWorkspace.html",
    "href": "Applications/DataWorkspace.html",
    "title": "About Data Workspace",
    "section": "",
    "text": "The Data Workspace is a valuable tool for managing and reviewing Earth observation-related products. This platform enables you to aggregate and review products, which can then be further processed or downloaded for various purposes.\nThe Data Workspace enables management and ordering of satellite products. Offline products can be ordered and their retrieval progress can be monitored in the ‘Processing Status’ section. Online products can be selected for processing with higher-level processors or downloaded.\nWhen the products are selected for processing, you are provided with a list of processors that are capable of processing relevant data types. The processors can be further parameterized to fine-tune the results.\nOnce the order for processing is submitted, the progress can be monitored similarly to orders for product retrieval. The status dashboards also include all orders submitted through the ordering API. The status of the orders can be monitored on the status page, and the orders can be updated while being executed, providing the flexibility to cancel unnecessary tasks.\nYou can familiarise yourself with workspace and access it at https://dataspace.copernicus.eu/workspace/."
  },
  {
    "objectID": "Applications/DataWorkspace.html#adding-products-to-workspace",
    "href": "Applications/DataWorkspace.html#adding-products-to-workspace",
    "title": "About Data Workspace",
    "section": "Adding products to Workspace",
    "text": "Adding products to Workspace\nYou can add products by using the Copernicus Browser.\n\n\n\nBrowser\n\n\nThe Copernicus Browser allows you to search for products using various properties, such as time, location and source.\nAfter you find the product you are interested in, you can add it to workspace by using icon visible under its size.\n\n\n\nAdding to workspace\n\n\nThen it will be visible under My Products tab in the Workspace:\n\n\n\nProduct on workspace\n\n\nWhen you have products listed, you can either download them from here or process them in the Processing Center."
  },
  {
    "objectID": "Applications/DataWorkspace.html#downloading-products-from-workspace",
    "href": "Applications/DataWorkspace.html#downloading-products-from-workspace",
    "title": "About Data Workspace",
    "section": "Downloading products from Workspace",
    "text": "Downloading products from Workspace\nIn order to download products from Workspace panel, first select them from the list in My products tab. Then at the bottom right of the page, click on the Download button.\n\n\n\nWorkspace panel\n\n\nA window displaying downloading process will appear. When status bar will reach 100%, it will switch its state to completed and your product will be saved on your device.\n\n\n\nDownload panel"
  },
  {
    "objectID": "Applications/DataWorkspace.html#ordering-products",
    "href": "Applications/DataWorkspace.html#ordering-products",
    "title": "About Data Workspace",
    "section": "Ordering products",
    "text": "Ordering products\nSome products are not avaliable immediately and appear as offline products. To be able to download such products, you need to order them first.\nTo order a product simply find the product with To order avaliability and then click on the Order offline products button.\n\n\n\nOrder panel\n\n\nName your order and click on the Order button.\n\n\n\nOrder window\n\n\nYou will get a confirmation of your order. You can check its status under the Processing status tab.\n\n\n\nOrder confirmation\n\n\nAfter the processing status is Finished/Completed, the ordered product is available in the catalogue and you can look it up via the API using various searches, for example by name:\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,‘S1A_IW_GRDH_1SDV_20230729T092359_20230729T092424_049636_05F7FC_0A61’)\nDownloading from the catalogue is done in the same way as described in the OData Product Download documentation."
  },
  {
    "objectID": "Applications/DataWorkspace.html#processing-products",
    "href": "Applications/DataWorkspace.html#processing-products",
    "title": "About Data Workspace",
    "section": "Processing products",
    "text": "Processing products\nProcessing products in the Processing center allows user to transform products in a way that they could become useful for certain cases. The method of processing and its outcome is defined for each avaliable processor used for the process.\nTo process the product its avaliability needs to be in Immediate status. Now you can add your product to the Processing center tab.\nCheck the boxes next to the product of your interest and click on the Create processing order button. You can select multiple products.\n\n\n\nWorkspace panel\n\n\nClick on the Confirm button.\n\n\n\nConfirm adding product to procesing center\n\n\nClick Go to Processing center.\n\n\n\nConfirm adding product to procesing center\n\n\nSelect the product and pick a processor from the list used for its processing.\n\n\n\nSelect product for processing\n\n\n\n\n\nSelect processor for processing\n\n\nClick on the Create processing order and the the Continue button.\n\n\n\nPlacing order\n\n\nClick on the Order processing button.\n\n\n\nPlacing order\n\n\nClick on the Submit order button.\n\n\n\nSubmitting order\n\n\nClick on the Go to Processing status button.\n\n\n\nRedirection to procesing status tab\n\n\nYou will be redirected to the Processing Status tab.\n\n\n\nProcessing status tab\n\n\nFrom here you can check ongoing processing orders. Once they will be finished, they shall be transfered to the list of orders under Finished tab.\nAfter the processing status is Finished/Completed, the processed product is available in the catalogue and you can look it up via the API using various searches, for example by name:\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,‘S1A_IW_GRDH_1SDV_20230729T092359_20230729T092424_049636_05F7FC_0A61’)\nYou will find both the product on which the product has been processed and the product after processing. Downloading from the catalogue is done in the same way as described in the OData Product Download documentation."
  },
  {
    "objectID": "Applications/JupyterHub.html",
    "href": "Applications/JupyterHub.html",
    "title": "JupyterLab",
    "section": "",
    "text": "JupyterLab is an advanced interactive development environment (IDE) that offers a flexible and feature-rich interface for working with notebooks, code, and data. It allows users to organize their workspaces using a flexible layout system with panels, views, and tabs for various activities. Furthermore, it supports various document formats, including notebooks, text files, code files, and markdown files. With its modular and extensible architecture, JupyterLab enables customization through extensions, additional functionalities, and integration with external tools. It enhances the user experience with features like a file browser, command palette, debugger, and console, making it a versatile tool for interactive data exploration, analysis, and scientific computing.\nYou can access the JupyterLab service by clicking on this link.: https://jupyterhub.dataspace.copernicus.eu/\nUpon clicking the “ACCESS JUPYTERLAB” button, you’ll be directed to the login window. Please use your Copernicus Data Space Ecosystem credentials."
  },
  {
    "objectID": "Applications/JupyterHub.html#notebooks",
    "href": "Applications/JupyterHub.html#notebooks",
    "title": "JupyterLab",
    "section": "Notebooks",
    "text": "Notebooks\nNotebooks in JupyterLab are an interactive Python programming environment for both non-programmers and developers who want to quickly prototype their EO data processing. They provide a user-friendly interface, integrating well with services like Sentinel Hub and openEO. Each notebook has direct access to the EO Data repository, and example notebooks are available to facilitate data interaction. To handle tool dependencies and library versions, multiple notebook kernels are provided and regularly updated with the provided samples. This eliminates the need for users to handle dependency installations, enabling immediate prototyping without technical obstacles."
  },
  {
    "objectID": "Applications/JupyterHub.html#notebook-flavors",
    "href": "Applications/JupyterHub.html#notebook-flavors",
    "title": "JupyterLab",
    "section": "Notebook flavors",
    "text": "Notebook flavors\nWhen you log in to JupyterLab you are presented with a choice of 3 flavors of Jupyter instances: Small, Medium and Large. The size of the instance is determined by number of resources available to the notebook kernels run by the user - CPU cores and memory. All flavors are suitable for performing typical tasks and will be capable of running all samples provided in /samples folder. To ensure fair use of resources by the CDSE users, it is recommended to start with the Small flavor and switch to a bigger only when you experience issues with kernel crashing due to the lack of available memory."
  },
  {
    "objectID": "Applications/JupyterHub.html#jupyterlab-user-interface",
    "href": "Applications/JupyterHub.html#jupyterlab-user-interface",
    "title": "JupyterLab",
    "section": "JupyterLab User Interface",
    "text": "JupyterLab User Interface\nOnce you have successfully signed in, you will be presented with a launcher that offers various Python environments to work in, including Python 3, Geo science, OpenEO, and Sentinel Hub. Each environment is equipped with specific Python packages tailored to different requirements. You can choose to run your code either in a notebook or a console, depending on your preference. Additionally, the launcher provides options to create text files, markdown files, or Python files, allowing you to work with different types of documents as needed.\n\n\nMain Work Area: The main work area in JupyterLab is the central portion of the interface where users perform their tasks. It consists of tabs representing open documents like notebooks, code files, and markdown files. These tabs can be arranged and docked within the work area, allowing users to customize their workspace to suit their needs and preferences.\nSidebar: The sidebar, located on the left side of the interface, provides additional functionality and information. It houses various panels, including a file browser for easy navigation through files and folders, a list of running kernels and terminals, and a table of contents for quick access to different sections of a notebook or document.\nLauncher: The launcher is a central component that enables users to create new documents and launch different activities. Users can access other useful activities such as a command palette for executing commands, a file finder for quickly locating specific files, and a help panel for accessing documentation and assistance.\nMenu Bar: The menu bar, located at the top of the interface, provides a set of menus with various options. Users can perform file operations, edit documents, configure the appearance and behavior of JupyterLab, manage kernels for code execution, and access other advanced features.\nContextual Tabs: Contextual tabs are dynamic and appear top of each notebook. These tabs provide relevant options and settings specific to the selected item, allowing users to perform actions and configurations directly within the interface.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nUsers can drag files from the file browser and drop them into notebooks or code files to import them seamlessly. Additionally, cells within a notebook can be rearranged by simply dragging and dropping them to different positions, facilitating the organization and structuring of notebook content.\n\n\n\nThese components collectively form the JupyterLab user interface, providing users with a flexible and customizable workspace for working with notebooks, code, and data."
  },
  {
    "objectID": "Applications/JupyterHub.html#creating-and-managing-notebooks",
    "href": "Applications/JupyterHub.html#creating-and-managing-notebooks",
    "title": "JupyterLab",
    "section": "Creating and Managing Notebooks",
    "text": "Creating and Managing Notebooks\nBy default, sample notebooks are provided in the folder samples.\nTo create a notebook in JupyterLab, you can easily select your desired kernel from the Notebook section in the launcher. Simply click on the kernel you want, and a new notebook named “Untitled. ipynb” will be created. If you wish to rename the notebook, you can do so by right-clicking on the notebook name in the sidebar and selecting the “rename” option. This gives your notebook a more meaningful and descriptive name for better organisation and clarity."
  },
  {
    "objectID": "Applications/JupyterHub.html#installing-additional-packages",
    "href": "Applications/JupyterHub.html#installing-additional-packages",
    "title": "JupyterLab",
    "section": "Installing additional packages",
    "text": "Installing additional packages\nYou can install additional Python packages if necessary. This can be done both from the Notebook Terminal, which is located in the Launcher tab or within a Notebook cell. For e.g.:\n\nTerminalNotebook\n\n\npip install required_package\n\n\n!pip install required_package"
  },
  {
    "objectID": "Applications/JupyterHub.html#markdown",
    "href": "Applications/JupyterHub.html#markdown",
    "title": "JupyterLab",
    "section": "Markdown",
    "text": "Markdown\nIf you prefer to work with a separate file, you can create a new Markdown (.md) or text (.txt) from the launcher or right click on the side bar and New file. Open the file and start writing your Markdown content using the Markdown syntax. Once you’ve written your content, you can save the file and preview it by double-clicking on it in the file browser, which will open a preview pane showing the rendered Markdown.\nAlternatively, you can include rich text in the cell using Markdown syntax within Notebooks. In a notebook, you can create a new cell and change its type to “Markdown” using the cell type dropdown in the toolbar or by pressing M. Here, you can write your content in the cell using the Markdown syntax. Then execute the cell by pressing Shift + Enter ."
  },
  {
    "objectID": "Applications/JupyterHub.html#collaboration-and-sharing",
    "href": "Applications/JupyterHub.html#collaboration-and-sharing",
    "title": "JupyterLab",
    "section": "Collaboration and Sharing",
    "text": "Collaboration and Sharing\nJupyterLab allows collaborative work with the functionality to share it with multiple users. They can edit and view the same notebooks or projects in real-time. It also offers various sharing options, including exporting notebooks to different formats (HTML, PDF, Markdown) and publishing them on platforms like GitHub or JupyterHub. These features empower users to easily share their work, communicate findings, and collaborate with a broader audience, promoting efficient collaboration and seamless knowledge dissemination.."
  },
  {
    "objectID": "Applications/JupyterHub.html#basic-notebook-commands",
    "href": "Applications/JupyterHub.html#basic-notebook-commands",
    "title": "JupyterLab",
    "section": "Basic notebook commands",
    "text": "Basic notebook commands\nWorking with a Notebook is pretty convenient and the supporting text should enable a quick understanding of the presented code. Some basic Notebook commands are listed below:\n\n\n\nKeyboard Shortcut\nCommand\n\n\n\n\nCtrl + Enter\nRun cell\n\n\nA\nInsert cell above current cell\n\n\nB\nInsert cell below current cell\n\n\nC\nCopy cell code\n\n\nV\nPaste cell code\n\n\nDD\nDelete selected cell\n\n\nM\nChange cell to Markdown (text) mode"
  },
  {
    "objectID": "Applications/JupyterHub.html#storage",
    "href": "Applications/JupyterHub.html#storage",
    "title": "JupyterLab",
    "section": "Storage",
    "text": "Storage\nWhen you start the notebook, in the file navigation pane (the sidebar - #2) you will see three folders:\n\nmystorage\nsamples\n\n\nThe availability of all other folders will be limited to your current session only. See the next chapter on more information on session persistence.\n\n\nmystorage\nThis is a persistent storage with 10GB of space, which is automatically created for each user during the first login to JupyterLab. The storage is hosted in the CloudFerro cloud and can be used to save notebooks between the sessions, store the results or uploaded data files. This storage area is preserved when you logout and the Jupyter kernel is shut down due to inactivity. It will be kept for up to 15 days from your last login, and you will receive a notification to log in to JupyterLab to reset the timer and keep the data preserved. If you do not log in, then after 15 days your files will be deleted from CloudFerro cloud storage.\n\n\nsamples\nThese folders are recreated with every start of the Jupyter kernel. The samples folder is always up-to-date with the latest version of notebooks. If you make changes to the samples please make sure to save the updated notebook in the mystorage area to make sure you can use it when you get back after period of incativity."
  },
  {
    "objectID": "Applications/JupyterHub.html#session-persistence",
    "href": "Applications/JupyterHub.html#session-persistence",
    "title": "JupyterLab",
    "section": "Session persistence",
    "text": "Session persistence\nThe Jupyter instance will be running as long as you interact with it, and will be kept alive for another 8 hours after your last activity. After this time the instance will be shut-off and you will need to launch it during the next log in. All data saved in mystorage will be preserved but all other files will be deleted and additional packages (dependencies) which were installed using pip need to be reinstalled."
  },
  {
    "objectID": "Applications/JupyterHub.html#tips-and-tricks",
    "href": "Applications/JupyterHub.html#tips-and-tricks",
    "title": "JupyterLab",
    "section": "Tips and tricks",
    "text": "Tips and tricks\n\nSwitching from Jupyter Lab to Classic Jupyter Notebook Interface\nIf you would like to switch to the Classic Jupyter Notebook Interface, you can modify the URL of the web application. Simply change the last part of the URL address from “lab” to “tree”.\nFor example, you can change https://jupyterhub.dataspace.copernicus.eu/user/username/lab/ to https://jupyterhub.dataspace.copernicus.eu/user/username/tree/. This way, you can easily access the Classic Jupyter Notebook Interface if desired."
  },
  {
    "objectID": "Applications/JupyterHub.html#resources-and-references",
    "href": "Applications/JupyterHub.html#resources-and-references",
    "title": "JupyterLab",
    "section": "Resources and References:",
    "text": "Resources and References:\nHere are some helpful links for effectively using JupyterLab in Copernicus Dataspace Ecosystem:\n\nJupyterLab Documentation\nNotebook Documentation\nBasic Notebook Tutorials"
  },
  {
    "objectID": "Applications/PlazaDetails/Strength.html",
    "href": "Applications/PlazaDetails/Strength.html",
    "title": "Credit Strength",
    "section": "",
    "text": "The following mentioned are among the popular services available in openEO algorithm plaza. Here we have presented an average credit strength for these services. Please note that depending on the time interval and area of interest, the credits can slightly vary.\nThe purpose of this document is to solely provide users with an assumption on how these credits work and their strength for varying services.\n\nNDVI\nFor the calculation of Normalized Difference Vegetation Index (NDVI), you can acquire ~250 NDVI images, each with an area of 1 hectare, i.e. 1 NDVI image patch of 1 hectare cost 3-5 credits.\n\n\nNDII\nComputation of the Normalized Difference Infrared Index (NDII) provides the user with an indication of the water content in the plant canopies. A straightforward calculation of the NDII can be achieved from openEO algorithm plaza NDII service with the use of 4-8 credits per hectare area, i.e. you can use your 1000 credits for computing NDII in a given area of ~117 hectares.\n\n\nBiomass\nThe Biomass service provided by openEO algorithm plaza can be a critical component in tracking and quantifying carbon capture in agriculture and natural vegetation. Users can use this service with approximately 20-40 credits per hectare, i.e. ~33-hectare area with a total of 1000 credits.\n\n\nCropSAR\nThe operational agricultural monitoring can be a key use case for this service as it uses Sentinel-1 radar observations to augment those of Sentinel-2. By doing so, more continuous vegetation properties monitoring can be performed, including vegetation information for situations where these properties cannot be retrieved from Sentinel-2 observations due to cloud occurrence. Users can use this service with approximately 40-60 credits per hectare, i.e. ~20-hectare area with a total of 1000 credits.\n\nThough the required credit for direct download of the output data is two credits for all the services, it has a time limitation of 10 seconds to run the entire process. Otherwise, the download process will fail."
  },
  {
    "objectID": "Applications/PlazaDetails/PublishService.html",
    "href": "Applications/PlazaDetails/PublishService.html",
    "title": "Publish a Service",
    "section": "",
    "text": "The openEO Algorithm Plaza also provides a self-service onboarding wizard that enables users to publish their services effortlessly. It assigns a service maturity label to each onboarded service.\nUsers can publish their algorithm as a service in the openEO Algorithm Plaza. These algorithms are expected to address Earth Observation solutions and implement them using openEO. When set as public, the service is then available to all users in the same way as any other service in the Algorithm Plaza.\nAs you select “Services” from the sub-menu options under the “Dashboard” section of the portal, you’ll be directed to the screen described above. If you haven’t published any services yet, you’ll see an option to “REGISTER YOUR FIRST SERVICE.” However, if you have already published services, you’ll see a list of the services that you or your organization have published.\nOn already created services, you can see an avatar (at this stage, just a colour and initials from the service name), the service name and a service status indication. As a user, you can click on the avatar or the service’s name to load its detail page. In addition, you can click on the Register service CTA button to load the add service page to create a new service.\nFurthermore, together with the service cards you have created, you can see a card area with a REGISTER NEW SERVICE CTA button. This button will load the add service page to create a new service."
  },
  {
    "objectID": "Applications/PlazaDetails/PublishService.html#develop-an-openeo-algorithm",
    "href": "Applications/PlazaDetails/PublishService.html#develop-an-openeo-algorithm",
    "title": "Publish a Service",
    "section": "Develop an openEO algorithm",
    "text": "Develop an openEO algorithm\nA good integration in openEO algorithm plaza begins as you start programming your algorithm.\nIn openEO, a ‘datacube’ view is used, which hides a lot of the complexity when working with huge EO data archives. It provides full archive access to the most popular datasets. You will have to get familiar with the Application Programming Interface (API), which provides a lot of predefined processes. To integrate existing code, you will have to use the concept of ‘User Defined Functions’ (UDFs). Furthermore, Parallelization and scalability are taken care of.\n\nWorking with openEO\nTo get familiar in working we openEO we recommend to start with a basic introduction on using openEO can be found here. Furthermore, to deploy your openEO algorithm as a service, you can use the ‘user defined process’ functionality."
  },
  {
    "objectID": "Applications/PlazaDetails/PublishService.html#register-and-publish-your-service",
    "href": "Applications/PlazaDetails/PublishService.html#register-and-publish-your-service",
    "title": "Publish a Service",
    "section": "Register and publish your service",
    "text": "Register and publish your service\nOnce your algorithm is ready, you can register and publish your service. The following sections will guide you through the publishing process.\nAs you click the Register your first service button. You will now be presented with a wizard to enter the necessary information regarding your service.\n\nStep 1: Register your service\nThe first step requires you to select the type of service that you want to publish. Currently, only those services integrated with the openEO as an orchestrator are supported.\n\n\n\nStep 2: Input general information\nThe following table outlines the fields required as basic information for your service in this step:\n\n\n\n\n\n\n\n\nField\nRequired\nDescription\n\n\n\n\nService name\nYes\nYour service’s title that will be displayed in the openEO algorithm plaza.\n\n\nSummary\nNo\nShort description of your service. The summary will be visible in the openEO algorithm plaza overview.\n\n\nDescription\nNo\nIn your service description, begin with an algorithm overview, followed by a brief methodology. It is helpful to list required parameters and include examples and output images for user guidance.\n\n\nAvatar\nNo\nURL to an image that can be used an avatar of your service. The avatar will be visible in the openEO algorithm plaza overview.\n\n\n\n\n\nStep 3: Additional Sections\nIn addition to the basic information mentioned above, you can provide more details on your service by adding additional sections. The following sections are available:\n\nParameters: You can list all the parameters that should be fed to the service to execute it. You can specify the name, type, description, and default value for each parameter.\nUsage example(Python code): You can provide a Python code example to demonstrate how to use your service. The code should give a complete example of how to use your service, including the use of the parameters and the namespace.\nResults: You can briefly describe your service’s results and mention the output format of the result.\nCost Estimation: You can give a user an idea of the resource consumption and time required to run your service for a given input.\nReferences: You can provide a list of references to publications, websites, or other resources relevant to your service. Provide details on resource consumption, processing time, and output format to help users effectively understand and utilize your service.\n\n\n\nStep 4: Add labels\nYou can add multiple labels to your service to help users find your service in the openEO algorithm plaza. The labels can be used to filter services within the marketplace and also give an idea of its category.\n\n\nStep 5: Select service visibility\nYou can choose to make your service public or private. If you select public, your service will be visible to all users in the openEO algorithm plaza. If you select private, only you and your organization members will be able to see your service.\nClick on REGISTER SERVICE to finish the basic registration. Finishing the basic registration allows you to provide more details on the service by either clicking the NEXT button or REMOVE to delete the service or even BACK TO SERVICE to exit the editing of the service.\n\n\nStep 6: Add Media Files and Links\nIn the Media Files and Links section you can upload image that will be shown when a user views your service on the catalogue. You can add images by dragging and dropping files into the designated area or click the plus icon. Next to images, you can also specify the different multiple URLs that will be shown in the detailed information of the service.\n\n\nStep 7: Add openEO Settings\nIn the openEO Settings section openEO namespace and service ID of your service should be filed in. Entering this information will enable the Access Service button, allowing visitors of openEO algorithm plaza to execute your service through the openEO Web Editor. The required information is represented in the following table:\n\n\n\nField\nRequired\nDescription\n\n\n\n\nNamespace\nYes\nNamespace of openEO service. When the service was created through a User Defined Process (UDP), the namespace is formatted as u:&lt;publisher username/id&gt;. This information can be extracted from the public URL when creating and sharing the UDP through openEO.\n\n\nService name\nYes\nName of the service as shared within openEO. For a User Defined Process (UDP), the service name corresponds with the ID of the service.\n\n\n\nCongratulations! You have successfully published your service in the openEO algorithm plaza. You can now view your service in the openEO algorithm plaza and share it with others. Furthermore, we recommend you go through the Manage a Service documentation to manage the service."
  },
  {
    "objectID": "Applications/PlazaDetails/Reporting.html",
    "href": "Applications/PlazaDetails/Reporting.html",
    "title": "Reporting",
    "section": "",
    "text": "This documentation section demonstrates how to use the reporting function within the openEO algorithm plaza. Individuals using the platform can track the services they have used and see how credits have been deducted for each service. The purpose of this guide is to help users efficiently track and document their service consumption while also keeping an eye on their credit balance.\nPlease check that you are logged in to your account for accessing the reporting functionality. Once logged in, select the “Reporting” option from the navbar, that will take you to the screen shown in the figure below:\n\nIf you haven’t executed anything yet, there may not be much information displayed on the screen. However, as you start utilizing openEO and the services on the plaza, the screen will populate with relevant data that can be visualized in the following manner:\n\nFiltering Reports: You will have the option to filter the reports based on a specific time interval. This allows you to view the openEO usage and credit deductions within a desired timeframe, providing a more targeted analysis.\nCredit Usage Display: A section will be available to display the credits used, showcasing both the synchronous and batch job execution methods. This information helps you understand how your credits are being utilized for different types of job executions. Hovering over the credit usage details will provide additional information on the specific service used.\nJobs List: The screen will include a list of the jobs that have been executed. This list provides a comprehensive overview of the services that have been utilized. Each job entry will typically include details such as job ID, execution time, and any relevant metadata associated with the job.\n\n\n\nOn the top right corner of the screen, you will notice an “Export” button. By clicking on this button, you will have the option to download the report in either PDF or CSV file format. This feature enables you to save and archive the report for future reference or share it with others as needed.\n\nNext to the “Personal” section, you will find the “Service” tab, specifically designed for user to monitor and track reports on the services published by their organisation. If you haven’t provided service, this tab will appear empty, as mentioned earlier. However, if you have published services, the page will populate with a similar layout. Additionally a “Service Execution” section is shown, displaying the number of times each service within your organization was executed."
  },
  {
    "objectID": "Data.html",
    "href": "Data.html",
    "title": "Data",
    "section": "",
    "text": "This section provides an overview of the EO data available from Copernicus Data Space Ecosystem.\nThe data offer will gradually extend starting from January 2023\nFor the latest information about available satellite data, users and stakeholders can follow them in Copernicus Sentinel Operations Dashboard.\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nSentinel-1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopernicus Land Monitoring Service (CLMS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLandsat-7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoil Moisture and Ocean Salinity (SMOS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopernicus Atmosphere Monitoring Service (CAMS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nENVISAT- Medium Resolution Imaging Spectrometer (MERIS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopernicus Emergency Management Service (CEMS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdditional Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLandsat-5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLandsat-8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopernicus Marine Environment Monitoring Service (CMEMS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-5P\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel-6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "cdse_doc.html",
    "href": "cdse_doc.html",
    "title": "Documentation",
    "section": "",
    "text": "We’re delighted you signed up!\nNow, let’s explore our extensive documentation to gain insights into our comprehensive Earth Observation data collection and the array of data access and data processing capabilities.\nOur documentation is a living resource, continuously updated to provide you with the latest information.\nDiscover within this documentation:\n\nData: Explore large amounts of open and free Earth Observation datasets, including Sentinel Data, Copernicus Contributing Missions, Federated Datasets, and Complementary Data, with detailed information.\nAPIs: Find the perfect interface for your needs in our suite of APIs. Whether you seek catalog access, product downloads, data visualization, or processing capabilities, our offerings encompass a range of options, including S3, STAC, openEO, and Sentinel Hub APIs.\nApplications: Simplify your satellite data journey and engage with data using our user-friendly applications for searching, visualizing, modifying, and downloading data effortlessly.\nQuotas and Limitations: Know the quotas and limitations that come with your user type and plan your data download and processing pipelines accordingly.\n\nFor quick answers to common queries, check out our FAQ section. If you have any questions that remain unanswered on this portal, our Support team is here to assist you. Feel free to reach out at any time.\nWelcome aboard\nReady to get started? Explore our documentation now and unlock the full potential of the Copernicus Data Space Ecosystem.\nLet’s embark on an Earth Observation data-driven journey together!"
  },
  {
    "objectID": "cdse_doc.html#welcome-to-the-copernicus-data-space-ecosystem-documentation-portal",
    "href": "cdse_doc.html#welcome-to-the-copernicus-data-space-ecosystem-documentation-portal",
    "title": "Documentation",
    "section": "",
    "text": "We’re delighted you signed up!\nNow, let’s explore our extensive documentation to gain insights into our comprehensive Earth Observation data collection and the array of data access and data processing capabilities.\nOur documentation is a living resource, continuously updated to provide you with the latest information.\nDiscover within this documentation:\n\nData: Explore large amounts of open and free Earth Observation datasets, including Sentinel Data, Copernicus Contributing Missions, Federated Datasets, and Complementary Data, with detailed information.\nAPIs: Find the perfect interface for your needs in our suite of APIs. Whether you seek catalog access, product downloads, data visualization, or processing capabilities, our offerings encompass a range of options, including S3, STAC, openEO, and Sentinel Hub APIs.\nApplications: Simplify your satellite data journey and engage with data using our user-friendly applications for searching, visualizing, modifying, and downloading data effortlessly.\nQuotas and Limitations: Know the quotas and limitations that come with your user type and plan your data download and processing pipelines accordingly.\n\nFor quick answers to common queries, check out our FAQ section. If you have any questions that remain unanswered on this portal, our Support team is here to assist you. Feel free to reach out at any time.\nWelcome aboard\nReady to get started? Explore our documentation now and unlock the full potential of the Copernicus Data Space Ecosystem.\nLet’s embark on an Earth Observation data-driven journey together!"
  },
  {
    "objectID": "logos.html",
    "href": "logos.html",
    "title": "Documentation",
    "section": "",
    "text": "```{=html}\n&lt;div class=\"logos\"&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/EU.svg\"&gt;\n    &lt;/a&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/copernicus-white-BL.svg\"&gt;\n    &lt;/a&gt;\n    &lt;a href=\"https://dataspace.copernicus.eu\" target=\"_blank\"&gt;\n        &lt;img src=\"_images/logos/ESA_White.svg\"&gt;\n    &lt;/a&gt;\n    \n    ```"
  },
  {
    "objectID": "Home.html",
    "href": "Home.html",
    "title": "Documentation",
    "section": "",
    "text": "We’re delighted you signed up!\nNow, let’s explore our extensive documentation to gain insights into our comprehensive Earth Observation data collection and the array of data access and data processing capabilities.\nOur documentation is a living resource, continuously updated to provide you with the latest information.\nDiscover within this documentation:\n\nData: Explore large amounts of open and free Earth Observation datasets, including Sentinel Data, Copernicus Contributing Missions, Federated Datasets, and Complementary Data, with detailed information.\nAPIs: Find the perfect interface for your needs in our suite of APIs. Whether you seek catalog access, product downloads, data visualization, or processing capabilities, our offerings encompass a range of options, including S3, STAC, openEO, and Sentinel Hub APIs.\nApplications: Simplify your satellite data journey and engage with data using our user-friendly applications for searching, visualizing, modifying, and downloading data effortlessly.\nQuotas and Limitations: Know the quotas and limitations that come with your user type and plan your data download and processing pipelines accordingly.\n\nFor quick answers to common queries, check out our FAQ section. If you have any questions that remain unanswered on this portal, our Support team is here to assist you. Feel free to reach out at any time.\nWelcome aboard\nReady to get started? Explore our documentation now and unlock the full potential of the Copernicus Data Space Ecosystem.\nLet’s embark on an Earth Observation data-driven journey together!"
  },
  {
    "objectID": "Home.html#welcome-to-the-copernicus-data-space-ecosystem-documentation-portal",
    "href": "Home.html#welcome-to-the-copernicus-data-space-ecosystem-documentation-portal",
    "title": "Documentation",
    "section": "",
    "text": "We’re delighted you signed up!\nNow, let’s explore our extensive documentation to gain insights into our comprehensive Earth Observation data collection and the array of data access and data processing capabilities.\nOur documentation is a living resource, continuously updated to provide you with the latest information.\nDiscover within this documentation:\n\nData: Explore large amounts of open and free Earth Observation datasets, including Sentinel Data, Copernicus Contributing Missions, Federated Datasets, and Complementary Data, with detailed information.\nAPIs: Find the perfect interface for your needs in our suite of APIs. Whether you seek catalog access, product downloads, data visualization, or processing capabilities, our offerings encompass a range of options, including S3, STAC, openEO, and Sentinel Hub APIs.\nApplications: Simplify your satellite data journey and engage with data using our user-friendly applications for searching, visualizing, modifying, and downloading data effortlessly.\nQuotas and Limitations: Know the quotas and limitations that come with your user type and plan your data download and processing pipelines accordingly.\n\nFor quick answers to common queries, check out our FAQ section. If you have any questions that remain unanswered on this portal, our Support team is here to assist you. Feel free to reach out at any time.\nWelcome aboard\nReady to get started? Explore our documentation now and unlock the full potential of the Copernicus Data Space Ecosystem.\nLet’s embark on an Earth Observation data-driven journey together!"
  },
  {
    "objectID": "notebook-samples/sentinelhub/ice_monitoring.html",
    "href": "notebook-samples/sentinelhub/ice_monitoring.html",
    "title": "Classification of Ice and Open Water in Nizhnesvirsky Lower Bay using Sentinel-1 IW Product",
    "section": "",
    "text": "The Nizhnesvirsky lower bay is a vital part of a river system characterized by a dynamic freeze-thaw cycle. Understanding the extent of ice coverage and open water in this region is crucial for various applications, including navigation, ecosystem monitoring, and climate research. In this Jupyter notebook, we will leverage satellite imagery from the Sentinel-1 Interferometric Wide (IW) product, along with remote sensing principles, to classify ice and open water over a period of 8 months, from September 2022 to May 2023.\nThe Sentinel-1 satellite offers reliable and frequent radar imaging capabilities, making it ideal for monitoring ice and water bodies. The Sentinel-1 IW product provides Synthetic Aperture Radar (SAR) data, which is unaffected by weather conditions, daylight, or cloud cover. SAR data measures the backscattered electromagnetic waves, allowing us to distinguish between different surface types.\nFirst, let us import all the necessary libraries.\n\nimport datetime\nimport getpass\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nimport numpy as np\nimport geopandas as gpd\nimport json\nfrom ipyleaflet import Map, GeoJSON, basemaps\n\nfrom sentinelhub import (\n    SHConfig,\n    Geometry,\n    DataCollection,\n    MimeType,\n    SentinelHubDownloadClient,\n    SentinelHubRequest,\n    bbox_to_dimensions,\n)\n\n\nCredentials\nCredentials for Sentinel Hub services (client_id & client_secret) can be obtained in your Dashboard. In the User Settings you can create a new OAuth Client to generate these credentials. For more detailed instructions, visit the relevant documentation page.\nNow that you have your client_id & client_secret, it is recommended to configure a new profile in your Sentinel Hub Python package. Instructions on how to configure your Sentinel Hub Python package can be found here. Using these instructions you can create a profile specific to using the package for accessing Copernicus Data Space Ecosystem data collections. This is useful as changes to the the config class are usually only temporary in your notebook and by saving the configuration to your profile you won’t need to generate new credentials or overwrite/change the default profile each time you rerun or write a new Jupyter Notebook.\nIf you are a first time user of the Sentinel Hub Python package for Copernicus Data Space Ecosystem, you should create a profile specific to the Copernicus Data Space Ecosystem. You can do this in the following cell:\n\n# Only run this cell if you have not created a configuration.\n\nconfig = SHConfig()\n# config.sh_client_id = getpass.getpass(\"Enter your SentinelHub client id\")\n# config.sh_client_secret = getpass.getpass(\"Enter your SentinelHub client secret\")\nconfig.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\nconfig.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n# config.save(\"cdse\")\n\nHowever, if you have already configured a profile in Sentinel Hub Python for the Copernicus Data Space Ecosystem, then you can run the below cell entering the profile name as a string replacing profile_name.\n\n# config = SHConfig(\"profile_name\")\n\n\n\nDefining the Bounds\nWe can define the bounds of the area of interest by considering a geojson file of the part of the river Svir.\n\nSHAPE_PATH = \"./data/Nizhnesvirsky_lower_bay.geojson\"\nriver_gdf = gpd.read_file(SHAPE_PATH)\n\n# Convert to EPSG 3035\nriver_gdf = river_gdf.to_crs(\"EPSG:3035\")\n# Geometry of an entire area\nresolution = 20\n\ndata = json.load(open(SHAPE_PATH, \"r\"))\n\n# Set center and zoom level\ncenter = [60.78, 33.68]\nzoom = 12\n\n# Add OSM background\nm = Map(basemap=basemaps.OpenStreetMap.Mapnik, center=center, zoom=zoom)\n\n# Add geojson data\ngeo_json = GeoJSON(data=data)\nm.add_layer(geo_json)\n\n# Display\nm\n\nHere, we can split the entire time period into 24 slots so that we can get 2 acquisitions every month to capture the freeze-thaw dynamics adequately.\n\nstart = datetime.datetime(2022, 9, 1)\nend = datetime.datetime(2023, 4, 30)\nn_chunks = 17\ntdelta = (end - start) / n_chunks\nedges = [(start + i * tdelta).date().isoformat() for i in range(n_chunks)]\nslots = [(edges[i], edges[i + 1]) for i in range(len(edges) - 1)]\n\nprint(\"Monthly time windows:\\n\")\nfor slot in slots:\n    print(slot)\n\nMonthly time windows:\n\n('2022-09-01', '2022-09-15')\n('2022-09-15', '2022-09-29')\n('2022-09-29', '2022-10-13')\n('2022-10-13', '2022-10-27')\n('2022-10-27', '2022-11-10')\n('2022-11-10', '2022-11-25')\n('2022-11-25', '2022-12-09')\n('2022-12-09', '2022-12-23')\n('2022-12-23', '2023-01-06')\n('2023-01-06', '2023-01-20')\n('2023-01-20', '2023-02-03')\n('2023-02-03', '2023-02-18')\n('2023-02-18', '2023-03-04')\n('2023-03-04', '2023-03-18')\n('2023-03-18', '2023-04-01')\n('2023-04-01', '2023-04-15')\n\n\n\n\nRequesting Sentinel-1 (SAR) Data\nWe now obtain Sentinel-1 IW SAR images covering the Nizhnesvirsky lower bay in the above mentioned time periods. An evalscript is used to describe the processing that needs to be performed on the SAR imagery. This script defines the input and output expected in the setup() function and evaluatePixel() function defines operations applied at the pixel level.\nNote 1: The default output sample type is ‘AUTO’. In this case all the values between 0 to 1 are stretched to (0,255) and the values lying outside (0,1) are clipped.\nThe SAR imagery needs to be preprocessed before it can be used. The following pre-processing techniques must be performed to mitigate any noise and errors. - Radiometric calibration to normalize the SAR image intensities (by setting the backscatter coefficient to SIGMA0_ELLPSOID).    - Apply LEE speckle filtering techniques to reduce noise and enhance the visual quality of the images (Window size is set to 3x3).    - Apply geometric correction to ensure geometric accuracy and spatial alignment between the images (by applying COPERNICUS DEM).\nThe images are filtered according to the ascending orbit and the resolution is set to HIGH (20m x 20m)\nNote 2: Here, we need to be careful about the units. THe units of geometry with WGS84 are degrees. To get a 20m resolution, the geometry must be transformed to EPSG:3035.\n\nevalscript_sar = \"\"\"\n  function setup() {\n    return {\n      input: [\"VV\", \"dataMask\"],\n      output: { bands: 2, sampleType: \"FLOAT32\"}                  // Refer to Note 1\n    }\n  }\n\n\n// visualizes decibels from -20 to +10\nfunction toDb(linear) {\n  var log = 10 * Math.log(linear) / Math.LN10\n  return Math.max(0, (log + 20) / 30)\n}\n\nfunction evaluatePixel(sample) {\n  var VV = sample.VV;\n\n  return [toDb(VV),sample.dataMask];\n}\n\"\"\"\n\n\ndef get_sar_request(time_interval):\n    return SentinelHubRequest(\n        evalscript=evalscript_sar,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.SENTINEL1_IW.define_from(\n                    \"s1iw\", service_url=config.sh_base_url\n                ),\n                time_interval=time_interval,\n                other_args={\n                    \"dataFilter\": {\n                        \"resolution\": \"HIGH\",\n                        \"mosaickingOrder\": \"mostRecent\",\n                        \"orbitDirection\": \"ASCENDING\",\n                    },\n                    \"processing\": {\n                        \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                        \"orthorectify\": True,\n                        \"demInstance\": \"COPERNICUS\",\n                        \"speckleFilter\": {\n                            \"type\": \"LEE\",\n                            \"windowSizeX\": 3,\n                            \"windowSizeY\": 3,\n                        },\n                    },\n                },\n            )\n        ],\n        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n        geometry=Geometry(river_gdf.geometry.values[0], crs=river_gdf.crs),\n        resolution=[20, 20],  # Refer to Note 2\n        config=config,\n        data_folder=\"./results\",\n    )\n\nWe can create a list of all the requests for each of the time slots and run them together.\n\n# create a list of requests\nlist_of_requests = [get_sar_request(slot) for slot in slots]\nlist_of_requests = [request.download_list[0] for request in list_of_requests]\n\n# download data with multiple threads\ndata = SentinelHubDownloadClient(config=config).download(\n    list_of_requests, max_threads=5\n)\n\nBelow are a series of maps that show the SAR imagery in VV mode. This means that the electromagnetic waves are transmitted and received by the Radar on board Sentinel-1 are both oriented to the vertical plane.\n\nncols = 4\nnrows = 4\naspect_ratio = 1.5\nsubplot_kw = {\"xticks\": [], \"yticks\": [], \"frame_on\": False}\n\nfig, axs = plt.subplots(\n    ncols=ncols,\n    nrows=nrows,\n    figsize=(2 * ncols * aspect_ratio, 5 * nrows),\n    subplot_kw=subplot_kw,\n)\n\nfor idx, image in enumerate(data):\n    ax = axs[idx // ncols][idx % ncols]\n    ax.imshow(np.clip((image[:, :, 0]) * 3.5 / 255, 0, 1))\n    ax.set_title(f\"{slots[idx][0]}  -  {slots[idx][1]}\", fontsize=10)\n\nplt.tight_layout()\n\n\n\n\n\n\nEstimating a threshold\nIf we look at the images for all time slots, we can see that the pixels in the river become brighter as the winter months approach. This is because the water acts like a mirror and very little backscatter reaches the sensor. However, if there is a structure or disturbance in the water (in this case ice), the electromagnetic waves are scattered in all directions and the chance of detecting this backscatter is higher (Reference). It is possible that not all bright pixels are ice, which can be verified by in-situ measurements.\nTo determine what a good threshold would be to differentiate the water pixels from ice, we can plot the distribution of pixel values within the entire range (0,255).\n\nncols = 4\nnrows = 4\naspect_ratio = 15 / 10\nsubplot_kw = {\"xticks\": range(0, 255, 25), \"yticks\": [], \"frame_on\": True}\n\nfig, axs = plt.subplots(\n    ncols=ncols,\n    nrows=nrows,\n    figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n    subplot_kw=subplot_kw,\n)\n\nfor idx, image in enumerate(data):\n    histogram, bin_edges = np.histogram(\n        2.5 * image[:, :, 0], bins=50, range=(0.0000001, 1)\n    )\n    ax = axs[idx // ncols][idx % ncols]\n    ax.plot(bin_edges[0:-1], histogram)\n    ax.set_xlabel(\"VV value\")\n    ax.set_ylabel(\"Number of Pixels (K)\")\n    ax.set_xlim((0, 1))\n    ax.set_ylim((0, 500))\n    ax.set_title(f\"{slots[idx][0]}  -  {slots[idx][1]}\", fontsize=10)\n\nplt.tight_layout()\n\n\n\n\nConsidering the historic weather information of the region and interpreting the SAR imagery, we can see that the appearance of ice in the river Svir started at the end of November and continued on till mid-March. By looking at the distribution plots above, we can set a threshold at a pixel value 50.\nThe evalscript below creates a visualisation of the ice mask directly after processing the SAR data and checking for the threshold. If the pixel value is more than 50/255, then it is classified at an icy pixel and the iceMask = 1.\n\nevalscript_mask = \"\"\"\n  function setup() {\n    return {\n      input: [\"VV\", \"dataMask\"],\n      output: { bands: 5 , sampleType: \"UINT8\"}\n    }\n  }\n\n// visualizes decibels from -20 to +10\nfunction toDb(linear) {\n  var log = 10 * Math.log(linear) / Math.LN10\n  return Math.max(0, (log + 20) / 30)\n}\n\nfunction evaluatePixel(sample) {\n  var VV = sample.VV;\n  var iceMask = 0;\n  VVdB = toDb(VV);\n  if (VVdB &gt;-0.001 && VVdB &lt; 0.2) {\n    iceMask = 0;\n    return [0, 0, 255, sample.dataMask, iceMask]; // Water mask\n  } else if (VVdB &gt; 0.2 && VVdB &lt;1) {\n    iceMask = 1;\n    return [0, 255, 255,sample.dataMask, iceMask];\n  } else {\n  iceMask = 0;\n  return [0,0,0,sample.dataMask,iceMask];\n  }\n}\n\"\"\"\n\n\ndef get_ice_mask_request(time_interval):\n    return SentinelHubRequest(\n        evalscript=evalscript_mask,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.SENTINEL1_IW.define_from(\n                    \"s1iw\", service_url=config.sh_base_url\n                ),\n                time_interval=time_interval,\n                other_args={\n                    \"dataFilter\": {\n                        \"resolution\": \"HIGH\",\n                        \"mosaickingOrder\": \"mostRecent\",\n                        \"orbitDirection\": \"ASCENDING\",\n                    },\n                    \"processing\": {\n                        \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                        \"orthorectify\": True,\n                        \"demInstance\": \"COPERNICUS\",\n                        \"speckleFilter\": {\n                            \"type\": \"LEE\",\n                            \"windowSizeX\": 3,\n                            \"windowSizeY\": 3,\n                        },\n                    },\n                },\n            )\n        ],\n        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n        geometry=Geometry(river_gdf.geometry.values[0], crs=river_gdf.crs),\n        resolution=[20, 20],\n        config=config,\n        data_folder=\"./results_mask\",\n    )\n\n\n# create a list of requests\nlist_of_requests = [get_ice_mask_request(slot) for slot in slots]\nlist_of_requests = [request.download_list[0] for request in list_of_requests]\n\n# download data with multiple threads\nmask_data = SentinelHubDownloadClient(config=config).download(\n    list_of_requests, max_threads=5\n)\n\nThe mask_data maps can be plotted as below to visualize the ice pixels and open water pixels.\n\nncols = 4\nnrows = 4\naspect_ratio = 1131 / 1819\nsubplot_kw = {\"xticks\": [], \"yticks\": [], \"frame_on\": False}\nlegend_elements = [\n    Patch(facecolor=\"cyan\", edgecolor=\"c\", label=\"Ice\"),\n    Patch(facecolor=\"blue\", edgecolor=\"b\", label=\"Water\"),\n]\nfig, axs = plt.subplots(\n    ncols=ncols,\n    nrows=nrows,\n    figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n    subplot_kw=subplot_kw,\n)\n\nfor idx, image in enumerate(mask_data):\n    ax = axs[idx // ncols][idx % ncols]\n    ax.imshow(np.clip((image[:, :, :3]), 0, 255))\n    ax.set_title(f\"{slots[idx][0]}  -  {slots[idx][1]}\", fontsize=10)\n    ax.legend(handles=legend_elements, loc=\"lower right\")\n\nplt.tight_layout()\n\n\n\n\n\n\nCreating a Timeseries of the area covered by ice\nNext, we can claculate the area covered by ice by considering the number of pixels classified as ice and multiplying with the initial resolution of the downloaded image, which is 20m x 20m in our case. This is done by counting the number of pixels that have the value 1 in the iceMask band.\n\ndef count_ice_pixels(image):\n    ice_mask = image[:, :, 4]\n\n    # Count the number of blue pixels\n    ice_pixel_count = np.sum(ice_mask)\n\n    # print(ice_pixel_count)\n\n    return ice_pixel_count\n\n\nresolution_s1 = 20 * 20  # meters\narea_covered_ice = []\nfor idx, image in enumerate(mask_data):\n    # Count the number of icy pixels\n    ice_pixels_count = count_ice_pixels(image)\n    area_covered_ice.append(ice_pixels_count * resolution_s1 / 1000000)\n\nThe calculated area can be plotted over time to determine the months with peak ice cover over the river.\n\nxlabels = [\n    \"September\",\n    \"October\",\n    \"November\",\n    \"December\",\n    \"January\",\n    \"February\",\n    \"March\",\n    \"April\",\n]\nx = range(len(slots))\nplt.plot(range(len(slots)), area_covered_ice)\nplt.title(\"Time Series of area covered by ice\")\nplt.xticks(np.arange(0, 16, step=2), xlabels, rotation=30, ha=\"center\")\nplt.xlabel(\"Time slots\")\nplt.ylabel(\"Area covered by ice (in $km^2$)\")\nplt.show()\n\n\n\n\nThis confirms the hypothesis of the ice formation beginning in mid-to-end of November and the amount of ice cover increasing as the winter progressed. We can also notice that once the ice starts breaking up in mid March, the ice clears out very quickly.\n\n\nSummary\n\nThe classification results will provide temporal information about the freeze-thaw cycle in the Nizhnesvirsky lower bay.\nBy analyzing the classified maps, we can observe the progression of ice formation, ice breakup, and the duration of open water periods.\nQuantitative analysis of ice coverage and open water duration can be derived from the classified maps, aiding in the assessment of seasonal changes and long-term trends."
  },
  {
    "objectID": "notebook-samples/sentinelhub/migration_from_scihub_guide.html",
    "href": "notebook-samples/sentinelhub/migration_from_scihub_guide.html",
    "title": "Migrating your workflows from The Copernicus Open Access Hub to the Copernicus Data Space Ecosystem",
    "section": "",
    "text": "The purpose of this notebook is to demonstrate how easy it is to migrate your workflow from accessing the data through the Copernicus Open Access Hub to using APIs to access the data via the Copernicus Data Space Ecosystem. In this notebook, we will show you how to: - setup your credentials - search, discover and download Sentinel-2 L2A Granules using Open Data Protocol (OData) - search, discover and download Sentinel-2 L2A data using Sentinel Hub APIs.\nFirst we need to import some prerequisite libraries:\n# Utilities\nimport os\nimport datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nimport getpass\n\nfrom sentinelhub import (\n    SHConfig,\n    DataCollection,\n    SentinelHubCatalog,\n    SentinelHubRequest,\n    BBox,\n    bbox_to_dimensions,\n    CRS,\n    MimeType,\n    Geometry,\n)\n\nfrom utils import plot_image\n\n/Users/williamray/miniconda3/envs/sentinelhub_base/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm"
  },
  {
    "objectID": "notebook-samples/sentinelhub/migration_from_scihub_guide.html#odata",
    "href": "notebook-samples/sentinelhub/migration_from_scihub_guide.html#odata",
    "title": "Migrating your workflows from The Copernicus Open Access Hub to the Copernicus Data Space Ecosystem",
    "section": "OData",
    "text": "OData\nOData (Open Data Protocol) is a standard that specifies a variety of best practices for creating and using REST APIs. OData makes it possible to build REST-based data services that let Web clients publish and edit resources that are recognized by Uniform Resource Locators (URLs) and described in a data model using straightforward HTTP messages. This is the method you will want to use if your workflow requires the download of full products/granules/tiles from Open Access Hub. In the following cells we will show you how to do the same with Copernicus Data Space Ecosystem. The documentation regarding this can be found here.\nIn this example, we will search the catalogue, generate the required credentials and then download a Sentinel-2 L2A granule using this protocol:\n\nSetting our search parameters\nFirstly, we need to define our start_date and end_date, the data_collection and the area of interest (aoi). We define them in the next cell and will insert them into our request as string variables.\n\nstart_date = \"2022-06-01\"\nend_date = \"2022-06-10\"\ndata_collection = \"SENTINEL-2\"\naoi = \"POLYGON((4.220581 50.958859,4.521264 50.953236,4.545977 50.906064,4.541858 50.802029,4.489685 50.763825,4.23843 50.767734,4.192435 50.806369,4.189689 50.907363,4.220581 50.958859))'\"\n\nTo search the catalogue we use the following code block:\n\njson = requests.get(\n    f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq '{data_collection}' and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}) and ContentDate/Start gt {start_date}T00:00:00.000Z and ContentDate/Start lt {end_date}T00:00:00.000Z\"\n).json()\npd.DataFrame.from_dict(json[\"value\"]).head(5)\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n4b4c6531-ad85-588d-8088-102e7ac30abc\nS2B_MSIL1C_20220604T104619_N0400_R051_T31UES_2...\napplication/octet-stream\n0\n2022-06-04T14:48:01.546Z\n2022-06-04T14:55:02.871Z\n2022-06-04T14:55:02.871Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/06/04/S2B_MSIL...\n[]\n{'Start': '2022-06-04T10:46:19.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((2.9997121758513 ...\n{'type': 'Polygon', 'coordinates': [[[2.999712...\n\n\n1\napplication/octet-stream\nacdd7b9a-a5d4-5d10-9ac8-554623b8a0c9\nS2B_MSIL2A_20220604T104619_N0400_R051_T31UES_2...\napplication/octet-stream\n0\n2022-06-04T19:59:16.441Z\n2022-06-04T20:08:35.955Z\n2022-06-04T20:08:35.955Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/06/04/S2B_MSIL...\n[]\n{'Start': '2022-06-04T10:46:19.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((2.9997121758513 ...\n{'type': 'Polygon', 'coordinates': [[[2.999712...\n\n\n2\napplication/octet-stream\nf2790789-52f5-571a-9a61-17650852d9bd\nS2A_MSIL1C_20220609T104631_N0400_R051_T31UES_2...\napplication/octet-stream\n0\n2022-06-09T17:48:40.156Z\n2022-06-09T17:56:27.164Z\n2022-06-09T17:56:27.164Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/06/09/S2A_MSIL...\n[]\n{'Start': '2022-06-09T10:46:31.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((2.9997121758513 ...\n{'type': 'Polygon', 'coordinates': [[[2.999712...\n\n\n3\napplication/octet-stream\na5f89f85-362d-5bb3-a321-403044ca872e\nS2A_MSIL2A_20220609T104631_N0400_R051_T31UES_2...\napplication/octet-stream\n0\n2022-06-09T19:18:07.672Z\n2022-06-10T06:39:41.624Z\n2022-06-10T06:39:41.624Z\nTrue\n\n/eodata/Sentinel-2/MSI/L2A/2022/06/09/S2A_MSIL...\n[]\n{'Start': '2022-06-09T10:46:31.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((2.9997121758513 ...\n{'type': 'Polygon', 'coordinates': [[[2.999712...\n\n\n4\napplication/octet-stream\nf83b6e00-8669-5f6c-96e1-f8c82dd98909\nS2B_MSIL1C_20220601T103629_N0400_R008_T31UES_2...\napplication/octet-stream\n0\n2022-06-01T15:17:31.386Z\n2022-06-01T15:22:27.713Z\n2022-06-01T15:22:27.713Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2022/06/01/S2B_MSIL...\n[]\n{'Start': '2022-06-01T10:36:29.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((4.0716897587579 ...\n{'type': 'Polygon', 'coordinates': [[[4.071689...\n\n\n\n\n\n\n\n\n\nRetrieving your Access Token\nWhilst no credentials are needed to search the catalogue; in order to download products from Copernicus Data Space Ecosystem catalogue using OData and OpenSearch API users are required to have an Access token. This token can be generated in both Linux and Window OS using either cURL or python script. You can generate this token using the following code block (more information can be found in our documentation).\nTo obtain your token, you are required to provide your Copernicus Data Space Ecosystem username and password. In this example, we import them from a Python file called creds.py and import the credentials as variables into the get_access_token() function (To run the following cell yourself, you will need to create this file yourself).\n\n# Import credentials\n# from creds import *\n\n\ndef get_access_token(username: str, password: str) -&gt; str:\n    data = {\n        \"client_id\": \"cdse-public\",\n        \"username\": username,\n        \"password\": password,\n        \"grant_type\": \"password\",\n    }\n    try:\n        r = requests.post(\n            \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n            data=data,\n        )\n        r.raise_for_status()\n    except Exception as e:\n        raise Exception(\n            f\"Access token creation failed. Reponse from the server was: {r.json()}\"\n        )\n    return r.json()[\"access_token\"]\n\n\naccess_token = get_access_token(\"USERNAME\", \"PASSWORD\")\n\n\naccess_token = get_access_token(\n    getpass.getpass(\"Enter your username\"),\n    getpass.getpass(\"Enter your password\"),\n)\n\nEnter your username ········\nEnter your password ········\n\n\nOnce you have your token, you require a product Id which can be found in the response of the products search: https://catalogue.dataspace.copernicus.eu/odata/v1/Products. This can either be parsed or copied from the json response we have already generated. We insert the product Id into the url parameter in the below cell.\nRunning the cell will download the zipped Sentinel-2 L2A Granule to the same directory as the Jupyter Notebook:\n\nurl = f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products(acdd7b9a-a5d4-5d10-9ac8-554623b8a0c9)/$value\"\n\nheaders = {\"Authorization\": f\"Bearer {access_token}\"}\n\nsession = requests.Session()\nsession.headers.update(headers)\nresponse = session.get(url, headers=headers, stream=True)\n\nwith open(\"product.zip\", \"wb\") as file:\n    for chunk in response.iter_content(chunk_size=8192):\n        if chunk:\n            file.write(chunk)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/migration_from_scihub_guide.html#accessing-data-via-sentinel-hub-apis",
    "href": "notebook-samples/sentinelhub/migration_from_scihub_guide.html#accessing-data-via-sentinel-hub-apis",
    "title": "Migrating your workflows from The Copernicus Open Access Hub to the Copernicus Data Space Ecosystem",
    "section": "Accessing data via Sentinel Hub APIs",
    "text": "Accessing data via Sentinel Hub APIs\nThe Sentinel Hub API is a RESTful API interface that provides access to various satellite imagery archives. It allows you to access raw satellite data, rendered images, statistical analysis, and other features.\nIn these examples, we will be using the sentinelhub python package. The sentinelhub Python package is the official Python interface for Sentinel Hub services. The package provides a collection of basic tools and utilities for working with geospatial and satellite data. It builds on top of well known packages such as numpy, shapely, pyproj.\nTo successfully run this notebook, make sure that you install or upgrade to at least Version 3.9.1.\n\nCredentials\nCredentials for Sentinel Hub services (client_id & client_secret) can be obtained in your Dashboard. In the User Settings you can create a new OAuth Client to generate these credentials. For more detailed instructions, visit the relevant documentation page.\nNow that you have your client_id & client_secret, it is recommended to configure a new profile in your Sentinel Hub Python package. Instructions on how to configure your Sentinel Hub Python package can be found here. Using these instructions you can create a profile specific to using the package for accessing Copernicus Data Space Ecosystem data collections. This is useful as changes to the the config class are usually only temporary in your notebook and by saving the configuration to your profile you won’t need to generate new credentials or overwrite/change the default profile each time you rerun or write a new Jupyter Notebook.\nIf you are a first time user of the Sentinel Hub Python package for Copernicus Data Space Ecosystem, you should create a profile specific to the Copernicus Data Space Ecosystem. You can do this in the following cell:\n\n# Only run this cell if you have not created a configuration.\n\nconfig = SHConfig()\n# config.sh_client_id = getpass.getpass(\"Enter your SentinelHub client id\")\n# config.sh_client_secret = getpass.getpass(\"Enter your SentinelHub client secret\")\nconfig.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\nconfig.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n# config.save(\"cdse\")\n\nHowever, if you have already configured a profile in Sentinel Hub Python for the Copernicus Data Space Ecosystem, then you can run the below cell entering the profile name as a string replacing profile_name.\n\n# config = SHConfig(\"profile_name\")\n\n\n\nSetting an area of interest\nThe bounding box in WGS84 coordinate system is [(longitude and latitude coordinates of lower left and upper right corners)]. You can get the bbox for a different area at the bboxfinder website.\nAll requests require a bounding box to be given as an instance of sentinelhub.geometry.BBox with corresponding Coordinate Reference System (sentinelhub.constants.CRS). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from sentinelhub.constants.CRS.\n\naoi_coords_wgs84 = [4.20762, 50.764694, 4.487708, 50.916455]\n\nWhen the bounding box bounds have been defined, you can initialize the BBox of the area of interest. Using the bbox_to_dimensions utility function, you can provide the desired resolution parameter of the image in meters and obtain the output image shape.\n\nresolution = 10\naoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\naoi_size = bbox_to_dimensions(aoi_bbox, resolution=resolution)\n\nprint(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")\n\nImage shape at 10 m resolution: (1941, 1723) pixels\n\n\n\n\nCatalog API\nTo search and discover data, you can use the Catalog API. Sentinel Hub Catalog API (or shortly “Catalog”) is an API implementing the STAC Specification, providing geospatial information for data available in Sentinel Hub. Firstly, to initialise the SentinelHubCatalog class we will use:\n\ncatalog = SentinelHubCatalog(config=config)\n\nNow we can build the Catalog API request; to do this we use the aoi_bbox we defined earlier as well as time_interval and insert these into the request:\n\naoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\ntime_interval = \"2022-07-01\", \"2022-07-20\"\n\nsearch_iterator = catalog.search(\n    DataCollection.SENTINEL2_L2A,\n    bbox=aoi_bbox,\n    time=time_interval,\n    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []},\n)\n\nresults = list(search_iterator)\nprint(\"Total number of results:\", len(results))\n\nresults\n\nTotal number of results: 16\n\n\n[{'id': 'S2A_MSIL2A_20220719T105041_N0400_R051_T31UES_20220719T170208.SAFE',\n  'properties': {'datetime': '2022-07-19T10:57:07.477Z'}},\n {'id': 'S2A_MSIL2A_20220719T105041_N0400_R051_T31UFS_20220719T170208.SAFE',\n  'properties': {'datetime': '2022-07-19T10:57:03.296Z'}},\n {'id': 'S2A_MSIL2A_20220716T103641_N0400_R008_T31UES_20220716T183414.SAFE',\n  'properties': {'datetime': '2022-07-16T10:47:11.385Z'}},\n {'id': 'S2A_MSIL2A_20220716T103641_N0400_R008_T31UFS_20220716T183414.SAFE',\n  'properties': {'datetime': '2022-07-16T10:47:07.153Z'}},\n {'id': 'S2B_MSIL2A_20220714T104629_N0400_R051_T31UES_20220714T134329.SAFE',\n  'properties': {'datetime': '2022-07-14T10:57:00.047Z'}},\n {'id': 'S2B_MSIL2A_20220714T104629_N0400_R051_T31UFS_20220714T134329.SAFE',\n  'properties': {'datetime': '2022-07-14T10:56:55.872Z'}},\n {'id': 'S2B_MSIL2A_20220711T103629_N0400_R008_T31UES_20220711T121934.SAFE',\n  'properties': {'datetime': '2022-07-11T10:47:03.695Z'}},\n {'id': 'S2B_MSIL2A_20220711T103629_N0400_R008_T31UFS_20220711T121934.SAFE',\n  'properties': {'datetime': '2022-07-11T10:46:59.439Z'}},\n {'id': 'S2A_MSIL2A_20220709T105041_N0509_R051_T31UES_20221214T145059.SAFE',\n  'properties': {'datetime': '2022-07-09T10:57:08.699Z'}},\n {'id': 'S2A_MSIL2A_20220709T105041_N0509_R051_T31UFS_20221214T145059.SAFE',\n  'properties': {'datetime': '2022-07-09T10:57:04.507Z'}},\n {'id': 'S2A_MSIL2A_20220706T103641_N0400_R008_T31UES_20220706T183816.SAFE',\n  'properties': {'datetime': '2022-07-06T10:47:12.125Z'}},\n {'id': 'S2A_MSIL2A_20220706T103641_N0400_R008_T31UFS_20220706T183816.SAFE',\n  'properties': {'datetime': '2022-07-06T10:47:07.92Z'}},\n {'id': 'S2B_MSIL2A_20220704T104629_N0400_R051_T31UES_20220704T123505.SAFE',\n  'properties': {'datetime': '2022-07-04T10:57:00.844Z'}},\n {'id': 'S2B_MSIL2A_20220704T104629_N0400_R051_T31UFS_20220704T123505.SAFE',\n  'properties': {'datetime': '2022-07-04T10:56:56.657Z'}},\n {'id': 'S2B_MSIL2A_20220701T103629_N0400_R008_T31UES_20220701T122344.SAFE',\n  'properties': {'datetime': '2022-07-01T10:47:04.245Z'}},\n {'id': 'S2B_MSIL2A_20220701T103629_N0400_R008_T31UFS_20220701T122344.SAFE',\n  'properties': {'datetime': '2022-07-01T10:47:00.021Z'}}]\n\n\n\n\nProcess API\n\nExample 1: True Color Image\nWe build the request according to the API Reference, using the SentinelHubRequest class. Each Process API request also needs an evalscript.\nThe information that we specify in the SentinelHubRequest object is: - an evalscript, - a list of input data collections with time interval, - a format of the response, - a bounding box and it’s size (size or resolution). - mosaickingOrder (optional): in this example we have used leastCC which will return pixels from the least cloudy acquisition in the specified time period.\nThe evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L2A bands.\nThe least cloudy image from the time period is downloaded. Without any additional parameters in the evalscript, the downloaded data will correspond to reflectance values in UINT8 format (values in 0-255 range).\n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A.define_from(\n                name=\"s2\", service_url=\"https://sh.dataspace.copernicus.eu\"\n            ),\n            time_interval=(\"2022-07-01\", \"2022-07-20\"),\n            other_args={\"dataFilter\": {\"mosaickingOrder\": \"leastCC\"}},\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=aoi_bbox,\n    size=aoi_size,\n    config=config,\n)\n\nThe method get_data() will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays.\n\ntrue_color_imgs = request_true_color.get_data()\n\n\nprint(\n    f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\"\n)\nprint(\n    f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\"\n)\n\nReturned data is of type = &lt;class 'list'&gt; and length 1.\nSingle element in the list is of type &lt;class 'numpy.ndarray'&gt; and has shape (1723, 1941, 3)\n\n\n\nimage = true_color_imgs[0]\nprint(f\"Image type: {image.dtype}\")\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\nplot_image(image, factor=3.5 / 255, clip_range=(0, 1))\n\nImage type: uint8\n\n\n\n\n\n\n\nExample 2: NDVI Image\nSecondly, we will also show you an example of how to calculate and visualise NDVI using the same API. NDVI calculation is a very commonly used spectral vegetation index for vegetation monitoring, for example, monitoring crop growth and yields. As you will notice in the codeblock below, the evalscript has changed substantially: - we are only using Band 4 and Band 8 as an input into our script. - The ColorGradientVisualizer function has also been utilised in this script. More about this can be found in the documentation here.\n\nevalscript_ndvi = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"dataMask\"\n      ]\n    }],\n    output: {\n      bands: 4\n    }\n  }\n}\n  \nlet viz = ColorGradientVisualizer.createWhiteGreen(-1.0, 1.0);\n\nfunction evaluatePixel(samples) {\n    let val = (samples.B08 - samples.B04) / (samples.B08 + samples.B04);\n    val = viz.process(val);\n    val.push(samples.dataMask);\n    return val;\n}\n\"\"\"\n\nrequest_ndvi_img = SentinelHubRequest(\n    evalscript=evalscript_ndvi,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A.define_from(\n                name=\"s2\", service_url=\"https://sh.dataspace.copernicus.eu\"\n            ),\n            time_interval=(\"2022-07-01\", \"2022-07-20\"),\n            other_args={\"dataFilter\": {\"mosaickingOrder\": \"leastCC\"}},\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=aoi_bbox,\n    size=aoi_size,\n    config=config,\n)\n\nThe same method as before is used to request and then visualise the data. In the visualisation, the lighter greens indicate a higher NDVI value (vegetation, forest) and the darker greens (urban areas and water bodies) represent areas with lower NDVI values.\n\nndvi_img = request_ndvi_img.get_data()\n\n\nprint(\n    f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\"\n)\nprint(\n    f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\"\n)\n\nReturned data is of type = &lt;class 'list'&gt; and length 1.\nSingle element in the list is of type &lt;class 'numpy.ndarray'&gt; and has shape (1723, 1941, 3)\n\n\n\nimage = ndvi_img[0]\nprint(f\"Image type: {image.dtype}\")\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\nplot_image(image, factor=1 / 255, clip_range=(-1, 1))\n\nImage type: uint8"
  },
  {
    "objectID": "notebook-samples/sentinelhub/migration_from_scihub_guide.html#summary",
    "href": "notebook-samples/sentinelhub/migration_from_scihub_guide.html#summary",
    "title": "Migrating your workflows from The Copernicus Open Access Hub to the Copernicus Data Space Ecosystem",
    "section": "Summary",
    "text": "Summary\nSo what have we learnt in this notebook?\n\nSetting up credentials to access the Copernicus Data Space Ecosystem through OData and Sentinel Hub APIs.\nSearching and discovering Copernicus data through OData protocols and downloading full Sentinel-2 L2A Granules.\nHow to quickly discover and access satellite imagery using Sentinel Hub APIs.\n\nWith this short guide, we hope to have clarified how the Copernicus Data Space Ecosystem can serve you beyond simply downloading raw images. At this point, you may want to consider which steps of your processing pipeline you prefer to do in house after downloading the data, and which operations you would rather have as part of the pre-processing in the cloud."
  },
  {
    "objectID": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html",
    "href": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html",
    "title": "First Steps in accessing Satellite Imagery on Copernicus Data Space Ecosystem with Sentinel Hub APIs",
    "section": "",
    "text": "The Sentinel Hub API is a RESTful API interface that provides access to various satellite imagery archives. It allows you to access raw satellite data, rendered images, statistical analysis, and other features.\n# Utilities\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport getpass\n\nfrom sentinelhub import (\n    SHConfig,\n    DataCollection,\n    SentinelHubCatalog,\n    SentinelHubRequest,\n    SentinelHubStatistical,\n    BBox,\n    bbox_to_dimensions,\n    CRS,\n    MimeType,\n    Geometry,\n)\n\nfrom utils import plot_image"
  },
  {
    "objectID": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#credentials",
    "href": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#credentials",
    "title": "First Steps in accessing Satellite Imagery on Copernicus Data Space Ecosystem with Sentinel Hub APIs",
    "section": "Credentials",
    "text": "Credentials\nCredentials for Sentinel Hub services (client_id & client_secret) can be obtained in your Dashboard. In the User Settings you can create a new OAuth Client to generate these credentials. For more detailed instructions, visit the relevant documentation page.\nNow that you have your client_id & client_secret, it is recommended to configure a new profile in your Sentinel Hub Python package. Instructions on how to configure your Sentinel Hub Python package can be found here. Using these instructions you can create a profile specific to using the package for accessing Copernicus Data Space Ecosystem data collections. This is useful as changes to the the config class are usually only temporary in your notebook and by saving the configuration to your profile you won’t need to generate new credentials or overwrite/change the default profile each time you rerun or write a new Jupyter Notebook.\nIf you are a first time user of the Sentinel Hub Python package for Copernicus Data Space Ecosystem, you should create a profile specific to the Copernicus Data Space Ecosystem. You can do this in the following cell:\n\n# Only run this cell if you have not created a configuration.\n\nconfig = SHConfig()\n# config.sh_client_id = getpass.getpass(\"Enter your SentinelHub client id\")\n# config.sh_client_secret = getpass.getpass(\"Enter your SentinelHub client secret\")\nconfig.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\nconfig.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n# config.save(\"cdse\")\n\nHowever, if you have already configured a profile in Sentinel Hub Python for the Copernicus Data Space Ecosystem, then you can run the below cell entering the profile name as a string replacing &lt;profile_name&gt;.\n\n# config = SHConfig(\"profile_name\")"
  },
  {
    "objectID": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#setting-an-area-of-interest",
    "href": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#setting-an-area-of-interest",
    "title": "First Steps in accessing Satellite Imagery on Copernicus Data Space Ecosystem with Sentinel Hub APIs",
    "section": "Setting an area of interest",
    "text": "Setting an area of interest\nThe bounding box in WGS84 coordinate system is [(longitude and latitude coordinates of lower left and upper right corners)]. You can get the bbox for a different area at the bboxfinder website.\nAll requests require a bounding box to be given as an instance of sentinelhub.geometry.BBox with corresponding Coordinate Reference System (sentinelhub.constants.CRS). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from sentinelhub.constants.CRS.\n\naoi_coords_wgs84 = [15.461282, 46.757161, 15.574922, 46.851514]\n\nWhen the bounding box bounds have been defined, you can initialize the BBox of the area of interest. Using the bbox_to_dimensions utility function, you can provide the desired resolution parameter of the image in meters and obtain the output image shape.\n\nresolution = 10\naoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\naoi_size = bbox_to_dimensions(aoi_bbox, resolution=resolution)\n\nprint(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")\n\nImage shape at 10 m resolution: (860, 1054) pixels"
  },
  {
    "objectID": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#catalog-api",
    "href": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#catalog-api",
    "title": "First Steps in accessing Satellite Imagery on Copernicus Data Space Ecosystem with Sentinel Hub APIs",
    "section": "Catalog API",
    "text": "Catalog API\nTo search and discover data, you can use the Catalog API. Sentinel Hub Catalog API (or shortly “Catalog”) is an API implementing the STAC Specification, providing geospatial information for data available in Sentinel Hub. Firstly, to initialise the SentinelHubCatalog class we will use:\n\ncatalog = SentinelHubCatalog(config=config)\n\nNow we can build the Catalog API request; to do this we use the aoi_bbox we defined earlier as well as time_interval and insert these into the request:\n\naoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\ntime_interval = \"2022-07-01\", \"2022-07-20\"\n\nsearch_iterator = catalog.search(\n    DataCollection.SENTINEL2_L2A,\n    bbox=aoi_bbox,\n    time=time_interval,\n    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []},\n)\n\nresults = list(search_iterator)\nprint(\"Total number of results:\", len(results))\n\nresults\n\nTotal number of results: 8\n\n\n[{'id': 'S2B_MSIL2A_20220719T095559_N0400_R122_T33TWM_20220719T113943.SAFE',\n  'properties': {'datetime': '2022-07-19T10:07:53.062Z'}},\n {'id': 'S2B_MSIL2A_20220716T094549_N0400_R079_T33TWM_20220716T114017.SAFE',\n  'properties': {'datetime': '2022-07-16T09:57:56.26Z'}},\n {'id': 'S2A_MSIL2A_20220714T100041_N0400_R122_T33TWM_20220714T175057.SAFE',\n  'properties': {'datetime': '2022-07-14T10:08:00.748Z'}},\n {'id': 'S2A_MSIL2A_20220711T095041_N0400_R079_T33TWM_20220711T142927.SAFE',\n  'properties': {'datetime': '2022-07-11T09:58:04.522Z'}},\n {'id': 'S2B_MSIL2A_20220709T100029_N0400_R122_T33TWM_20220709T114004.SAFE',\n  'properties': {'datetime': '2022-07-09T10:07:52.974Z'}},\n {'id': 'S2B_MSIL2A_20220706T095039_N0400_R079_T33TWM_20220706T113052.SAFE',\n  'properties': {'datetime': '2022-07-06T09:57:56.689Z'}},\n {'id': 'S2A_MSIL2A_20220704T100041_N0400_R122_T33TWM_20220704T141618.SAFE',\n  'properties': {'datetime': '2022-07-04T10:08:01.243Z'}},\n {'id': 'S2A_MSIL2A_20220701T095041_N0400_R079_T33TWM_20220701T141709.SAFE',\n  'properties': {'datetime': '2022-07-01T09:58:04.669Z'}}]"
  },
  {
    "objectID": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#process-api",
    "href": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#process-api",
    "title": "First Steps in accessing Satellite Imagery on Copernicus Data Space Ecosystem with Sentinel Hub APIs",
    "section": "Process API",
    "text": "Process API\n\nExample 1: True Color Image\nWe build the request according to the API Reference, using the SentinelHubRequest class. Each Process API request also needs an evalscript. An evalscript (or “custom script”) is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return. It is a required part of any process, batch processing or OGC request.\nThe information that we specify in the SentinelHubRequest object is: - an evalscript, - a list of input data collections with time interval, - a format of the response, - a bounding box and its size (size or resolution). - mosaickingOrder (optional): in this example we have used leastCC which will return pixels from the least cloudy acquisition in the specified time period.\nThe evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L2A bands.\nThe least cloudy image from the time period is downloaded. Without any additional parameters in the evalscript, the downloaded data will correspond to reflectance values in UINT8 format (values in 0-255 range).\n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A.define_from(\n                name=\"s2l2a\", service_url=\"https://sh.dataspace.copernicus.eu\"\n            ),\n            time_interval=(\"2022-05-01\", \"2022-05-20\"),\n            other_args={\"dataFilter\": {\"mosaickingOrder\": \"leastCC\"}},\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=aoi_bbox,\n    size=aoi_size,\n    config=config,\n)\n\nThe method get_data() will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays.\n\ntrue_color_imgs = request_true_color.get_data()\n\n\nprint(\n    f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\"\n)\nprint(\n    f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\"\n)\n\nReturned data is of type = &lt;class 'list'&gt; and length 1.\nSingle element in the list is of type &lt;class 'numpy.ndarray'&gt; and has shape (1054, 860, 3)\n\n\n\nimage = true_color_imgs[0]\nprint(f\"Image type: {image.dtype}\")\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\nplot_image(image, factor=3.5 / 255, clip_range=(0, 1))\n\nImage type: uint8\n\n\n\n\n\n\n\nExample 2: NDVI Image\nSecondly, we will also show you an example of how to calculate and visualise NDVI using the same API. NDVI is a very commonly used spectral vegetation index for vegetation monitoring, for example, monitoring crop growth and yields. As you will notice in the codeblock below, the evalscript has changed substantially: - we are only using Band 4 and Band 8 as an input into our script. - In the evaluatePixel() function, we calculate NDVI and visualise this using the imgVals array.\n\nevalscript_ndvi = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"dataMask\"\n      ]\n    }],\n    output: {\n      bands: 4\n    }\n  }\n}\n  \n\nfunction evaluatePixel(sample) {\n    let val = (sample.B08 - sample.B04) / (sample.B08 + sample.B04);\n    let imgVals = null;\n    \n    if (val&lt;-1.1) imgVals = [0,0,0];\n    else if (val&lt;-0.2) imgVals = [0.75,0.75,0.75];\n    else if (val&lt;-0.1) imgVals = [0.86,0.86,0.86];\n    else if (val&lt;0) imgVals = [1,1,0.88];\n    else if (val&lt;0.025) imgVals = [1,0.98,0.8];\n    else if (val&lt;0.05) imgVals = [0.93,0.91,0.71];\n    else if (val&lt;0.075) imgVals = [0.87,0.85,0.61];\n    else if (val&lt;0.1) imgVals = [0.8,0.78,0.51];\n    else if (val&lt;0.125) imgVals = [0.74,0.72,0.42];\n    else if (val&lt;0.15) imgVals = [0.69,0.76,0.38];\n    else if (val&lt;0.175) imgVals = [0.64,0.8,0.35];\n    else if (val&lt;0.2) imgVals = [0.57,0.75,0.32];\n    else if (val&lt;0.25) imgVals = [0.5,0.7,0.28];\n    else if (val&lt;0.3) imgVals = [0.44,0.64,0.25];\n    else if (val&lt;0.35) imgVals = [0.38,0.59,0.21];\n    else if (val&lt;0.4) imgVals = [0.31,0.54,0.18];\n    else if (val&lt;0.45) imgVals = [0.25,0.49,0.14];\n    else if (val&lt;0.5) imgVals = [0.19,0.43,0.11];\n    else if (val&lt;0.55) imgVals = [0.13,0.38,0.07];\n    else if (val&lt;0.6) imgVals = [0.06,0.33,0.04];\n    else imgVals = [0,0.27,0];\n    \n    \n    imgVals.push(sample.dataMask)\n    \n    return imgVals\n}\n\"\"\"\n\nrequest_ndvi_img = SentinelHubRequest(\n    evalscript=evalscript_ndvi,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A.define_from(\n                name=\"s2l2a\", service_url=\"https://sh.dataspace.copernicus.eu\"\n            ),\n            time_interval=(\"2022-05-01\", \"2022-05-20\"),\n            other_args={\"dataFilter\": {\"mosaickingOrder\": \"leastCC\"}},\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=aoi_bbox,\n    size=aoi_size,\n    config=config,\n)\n\nThe same method as before is used to request and then visualise the data. In the visualisation, the lighter greens indicate a higher NDVI value (vegetation, forest) and the darker greens (urban areas and water bodies) represent areas with lower NDVI values.\n\nndvi_img = request_ndvi_img.get_data()\n\n\nprint(\n    f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\"\n)\nprint(\n    f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\"\n)\n\nReturned data is of type = &lt;class 'list'&gt; and length 1.\nSingle element in the list is of type &lt;class 'numpy.ndarray'&gt; and has shape (1054, 860, 3)\n\n\n\nimage = ndvi_img[0]\nprint(f\"Image type: {image.dtype}\")\n\n# plot function\nplot_image(image, factor=1 / 255)\n\nImage type: uint8"
  },
  {
    "objectID": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#statistical-api",
    "href": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#statistical-api",
    "title": "First Steps in accessing Satellite Imagery on Copernicus Data Space Ecosystem with Sentinel Hub APIs",
    "section": "Statistical API",
    "text": "Statistical API\nIn the Process API examples, we have seen how to obtain satellite imagery. Statistical API can be used in a very similar way. The main difference is that the results of Statistical API are aggregated statistical values of satellite data instead of entire images. In many use cases, such values are all that we need. By using Statistical API we can avoid downloading and processing large amounts of satellite data.\nAll general rules for building evalscripts apply. However, there are some specifics when using evalscripts with the Statistical API:\n\nThe evaluatePixel() function must, in addition to other output, always return a dataMask output. This output defines which pixels are excluded from calculations. For more details and an example, see here.\nThe default value of sampleType is FLOAT32.\nThe output.bands parameter in the setup() function can be an array. This makes it possible to specify custom names for the output bands and different output dataMask for different outputs, see this example.\n\n\nRequesting, and plotting an NDVI time series for a single field\nIn the example here, we will calculate NDVI for a specific field of interest and then plot the mean NDVI and standard deviation over the requested time period. First we define our evalscript:\n\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"ndvi\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  };\n}\n\nfunction evaluatePixel(samples) {\n    let index = (samples.B08 - samples.B04) / (samples.B08+samples.B04);\n    return {\n        ndvi: [index],\n        dataMask: [samples.dataMask],\n    };\n}\n\n\"\"\"\n\nIn this example, we will compare two fields within the area we requested using Process API:\n\nfield1 = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [15.541723001099184, 46.820368115848446],\n            [15.541756949727985, 46.82037740810231],\n            [15.54192669287196, 46.82008470133467],\n            [15.542211861353849, 46.81964331510048],\n            [15.539394125163792, 46.81905789197882],\n            [15.539251540922846, 46.819805931503055],\n            [15.541723001099184, 46.820368115848446],\n        ]\n    ],\n}\n\nfield2 = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [15.507170086710744, 46.83938135202761],\n            [15.508086699688228, 46.83921879483953],\n            [15.50831755036404, 46.839576420004114],\n            [15.508582349668648, 46.83992939835186],\n            [15.508874307876296, 46.840221997066486],\n            [15.50860950857169, 46.840514594187695],\n            [15.50842618597619, 46.84082112279607],\n            [15.508113858591262, 46.840639992466144],\n            [15.50781511065786, 46.84039384001332],\n            [15.50739414766079, 46.83981328730921],\n            [15.507149717533464, 46.83939064099493],\n            [15.507170086710744, 46.83938135202761],\n        ]\n    ],\n}\n\nNow we have defined the evalscript and the two fields of interest, we can build the first Statistical API Request, before returning the response for the first field. In this request, as part of the payload we define some input parameters: - time_interval this defines the time range of our request. - aggregation_interval this defines the length of time each interval is. In this case, the interval is 10 days. he aggregation intervals should be at least one day long (e.g. “P5D”, “P30D”). You can only use period OR time designator not both. - dataFilter: {maxCloudCoverage} this is an additional argument in our request which filters out image acquisitions that have a cloud coverage percentage above 10%.\nNOTE: If a timeRange is not divisible by an aggregationInterval, the last (“not full”) time interval will be dismissed by default (SKIP option). The user can instead set the lastIntervalBehavior to SHORTEN (shortens the last interval so that it ends at the end of the provided time range) or EXTEND (extends the last interval over the end of the provided time range so that all the intervals are of equal duration).\n\ngeometry = Geometry(geometry=field1, crs=CRS.WGS84)\n\nrequest = SentinelHubStatistical(\n    aggregation=SentinelHubStatistical.aggregation(\n        evalscript=evalscript,\n        time_interval=(\"2022-04-01T00:00:00Z\", \"2022-08-30T23:59:59Z\"),\n        aggregation_interval=\"P10D\",\n        size=[368.043, 834.345],\n    ),\n    input_data=[\n        SentinelHubStatistical.input_data(\n            DataCollection.SENTINEL2_L1C.define_from(\n                name=\"s2l1c\", service_url=\"https://sh.dataspace.copernicus.eu\"\n            ),\n            other_args={\"dataFilter\": {\"maxCloudCoverage\": 10}},\n        ),\n    ],\n    geometry=geometry,\n    config=config,\n)\n\nresponse1 = request.get_data()\nresponse1\n\n[{'data': [{'interval': {'from': '2022-04-21T00:00:00Z',\n     'to': '2022-05-01T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.08167635649442673,\n         'max': 0.39603960514068604,\n         'mean': 0.13346635554959452,\n         'stDev': 0.06778421108052068,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-05-11T00:00:00Z', 'to': '2022-05-21T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.07600757479667664,\n         'max': 0.4349462389945984,\n         'mean': 0.11771845381622796,\n         'stDev': 0.06006468950382084,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-05-21T00:00:00Z', 'to': '2022-05-31T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.12070990353822708,\n         'max': 0.22220245003700256,\n         'mean': 0.1623609989287693,\n         'stDev': 0.02119876493505649,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-05-31T00:00:00Z', 'to': '2022-06-10T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.30697834491729736,\n         'max': 0.5585442781448364,\n         'mean': 0.3871644425922805,\n         'stDev': 0.036877585538162914,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-06-10T00:00:00Z', 'to': '2022-06-20T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.4932262897491455,\n         'max': 0.7623130679130554,\n         'mean': 0.7166323115162642,\n         'stDev': 0.03632912872686905,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-06-20T00:00:00Z', 'to': '2022-06-30T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.5235322713851929,\n         'max': 0.8472102880477905,\n         'mean': 0.8134408265822731,\n         'stDev': 0.04334495262826597,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-06-30T00:00:00Z', 'to': '2022-07-10T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.5385261178016663,\n         'max': 0.8165295124053955,\n         'mean': 0.7346462549343704,\n         'stDev': 0.05007425808442363,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-07-10T00:00:00Z', 'to': '2022-07-20T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.48085325956344604,\n         'max': 0.7764950394630432,\n         'mean': 0.6345127327117525,\n         'stDev': 0.037435679050829576,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-07-20T00:00:00Z', 'to': '2022-07-30T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.3827281594276428,\n         'max': 0.7180401086807251,\n         'mean': 0.47361417948967777,\n         'stDev': 0.04486725306919478,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-07-30T00:00:00Z', 'to': '2022-08-09T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.25120440125465393,\n         'max': 0.6704408526420593,\n         'mean': 0.3448654317316632,\n         'stDev': 0.060250767466331526,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}},\n   {'interval': {'from': '2022-08-09T00:00:00Z', 'to': '2022-08-19T00:00:00Z'},\n    'outputs': {'ndvi': {'bands': {'B0': {'stats': {'min': 0.24285714328289032,\n         'max': 0.6134668588638306,\n         'mean': 0.33002391002395726,\n         'stDev': 0.05309494318283593,\n         'sampleCount': 306912,\n         'noDataCount': 137731}}}}}}],\n  'status': 'OK'}]\n\n\nHowever, as it is clear to see, our response is not that useful in json format. It’s difficult to read from a human perspective. So, let’s transform it into a pandas dataframe. To help us achieve this, let’s define some helper functions.\n\n# define functions to extract statistics for all acquisition dates\ndef extract_stats(date, stat_data):\n    d = {}\n    for key, value in stat_data[\"outputs\"].items():\n        stats = value[\"bands\"][\"B0\"][\"stats\"]\n        if stats[\"sampleCount\"] == stats[\"noDataCount\"]:\n            continue\n        else:\n            d[\"date\"] = [date]\n            for stat_name, stat_value in stats.items():\n                if stat_name == \"sampleCount\" or stat_name == \"noDataCount\":\n                    continue\n                else:\n                    d[f\"{key}_{stat_name}\"] = [stat_value]\n    return pd.DataFrame(d)\n\n\ndef read_acquisitions_stats(stat_data):\n    df_li = []\n    for aq in stat_data:\n        date = aq[\"interval\"][\"from\"][:10]\n        df_li.append(extract_stats(date, aq))\n    return pd.concat(df_li)\n\n\nresult_df1 = read_acquisitions_stats(response1[0][\"data\"])\nresult_df1\n\n\n\n\n\n\n\n\ndate\nndvi_min\nndvi_max\nndvi_mean\nndvi_stDev\n\n\n\n\n0\n2022-04-21\n0.081676\n0.396040\n0.133466\n0.067784\n\n\n0\n2022-05-11\n0.076008\n0.434946\n0.117718\n0.060065\n\n\n0\n2022-05-21\n0.120710\n0.222202\n0.162361\n0.021199\n\n\n0\n2022-05-31\n0.306978\n0.558544\n0.387164\n0.036878\n\n\n0\n2022-06-10\n0.493226\n0.762313\n0.716632\n0.036329\n\n\n0\n2022-06-20\n0.523532\n0.847210\n0.813441\n0.043345\n\n\n0\n2022-06-30\n0.538526\n0.816530\n0.734646\n0.050074\n\n\n0\n2022-07-10\n0.480853\n0.776495\n0.634513\n0.037436\n\n\n0\n2022-07-20\n0.382728\n0.718040\n0.473614\n0.044867\n\n\n0\n2022-07-30\n0.251204\n0.670441\n0.344865\n0.060251\n\n\n0\n2022-08-09\n0.242857\n0.613467\n0.330024\n0.053095\n\n\n\n\n\n\n\nWe can take this another step further, and display the data in a time series using the Matplotlib python library:\n\nfig_stat, ax_stat = plt.subplots(1, 1, figsize=(12, 6))\nt1 = result_df1[\"date\"]\nndvi_mean_field1 = result_df1[\"ndvi_mean\"]\nndvi_std_field1 = result_df1[\"ndvi_stDev\"]\nax_stat.plot(t1, ndvi_mean_field1, label=\"field 1 mean\")\nax_stat.fill_between(\n    t1,\n    ndvi_mean_field1 - ndvi_std_field1,\n    ndvi_mean_field1 + ndvi_std_field1,\n    alpha=0.3,\n    label=\"field 1 stDev\",\n)\nax_stat.tick_params(axis=\"x\", labelrotation=30, labelsize=12)\nax_stat.tick_params(axis=\"y\", labelsize=12)\nax_stat.set_xlabel(\"Date\", size=15)\nax_stat.set_ylabel(\"NDVI/unitless\", size=15)\nax_stat.legend(loc=\"lower right\", prop={\"size\": 12})\nax_stat.set_title(\"NDVI time series\", fontsize=20)\nfor label in ax_stat.get_xticklabels()[1::2]:\n    label.set_visible(False)\n\n\n\n\n\n\nComparing different fields\nNow that we have learnt how to plot the data for the first field, let’s take this another step forward and compare the NDVI time series of the first field with the second field. We will now run the same request for our second field and then transform the response into a second Pandas dataframe.\n\ngeometry = Geometry(geometry=field2, crs=CRS.WGS84)\n\nrequest = SentinelHubStatistical(\n    aggregation=SentinelHubStatistical.aggregation(\n        evalscript=evalscript,\n        time_interval=(\"2022-04-01T00:00:00Z\", \"2022-08-30T23:59:59Z\"),\n        aggregation_interval=\"P10D\",\n        size=[368.043, 834.345],\n    ),\n    input_data=[\n        SentinelHubStatistical.input_data(\n            DataCollection.SENTINEL2_L1C.define_from(\n                name=\"s2l1c\", service_url=\"https://sh.dataspace.copernicus.eu\"\n            ),\n            other_args={\"dataFilter\": {\"maxCloudCoverage\": 10}},\n        ),\n    ],\n    geometry=geometry,\n    config=config,\n)\n\nresponse2 = request.get_data()\nresult_df2 = read_acquisitions_stats(response2[0][\"data\"])\n\nNow we have requested the statistics for both fields and transformed them into Pandas dataframes, let’s plot the two time series and visualise this in the same plot:\n\nfig_stat, ax_stat = plt.subplots(1, 1, figsize=(12, 6))\nt1 = result_df1[\"date\"]\nt2 = result_df1[\"date\"]\nndvi_mean_field1 = result_df1[\"ndvi_mean\"]\nndvi_std_field1 = result_df1[\"ndvi_stDev\"]\nndvi_mean_field2 = result_df2[\"ndvi_mean\"]\nndvi_std_field2 = result_df2[\"ndvi_stDev\"]\nax_stat.plot(t1, ndvi_mean_field1, label=\"field 1 mean\")\nax_stat.fill_between(\n    t1,\n    ndvi_mean_field1 - ndvi_std_field1,\n    ndvi_mean_field1 + ndvi_std_field1,\n    alpha=0.3,\n    label=\"field 1 stDev\",\n)\nax_stat.plot(t2, ndvi_mean_field2, label=\"field 2 mean\")\nax_stat.fill_between(\n    t2,\n    ndvi_mean_field2 - ndvi_std_field2,\n    ndvi_mean_field2 + ndvi_std_field2,\n    alpha=0.3,\n    label=\"field 2 stDev\",\n)\nax_stat.tick_params(axis=\"x\", labelrotation=30, labelsize=12)\nax_stat.tick_params(axis=\"y\", labelsize=12)\nax_stat.set_xlabel(\"Date\", size=15)\nax_stat.set_ylabel(\"NDVI/unitless\", size=15)\nax_stat.legend(loc=\"lower right\", prop={\"size\": 12})\nax_stat.set_title(\"NDVI time series\", fontsize=20)\nfor label in ax_stat.get_xticklabels()[1::2]:\n    label.set_visible(False)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#summary",
    "href": "notebook-samples/sentinelhub/introduction_to_SH_APIs.html#summary",
    "title": "First Steps in accessing Satellite Imagery on Copernicus Data Space Ecosystem with Sentinel Hub APIs",
    "section": "Summary",
    "text": "Summary\nSo what have we learnt in this notebook?\n\nHow to quickly access satellite imagery though Sentinel Hub using Process API.\nVisualising NDVI derived from the satellite imagery\nUsing Statistical API to produce NDVI time series for single and multiple fields.\n\nThis concludes this notebook on working with Sentinel Hub APIs to access data from the Copernicus Data Space Ecosystem. For more information you can check out the Sentinel Hub API Documentation and the Sentinel Hub Python package documentation too."
  },
  {
    "objectID": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html",
    "href": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html",
    "title": "Deforestation Monitoring using Sentinel 2 and xarray",
    "section": "",
    "text": "Sentinel 2 data is one of the most popular satellite dataets, but it does come with challenges. Cloud-free mosaics have to be constructed often in order to get analysis-ready data. Accessing a lot of data through tiles takes a long time, and getting the data into a format it can be easily analysed in with common Python tools can be a challenge.\nIn this notebook, we will show how this whole process of getting analysis-ready data into Python can be sped up by using the Copernicus Dataspace Ecosystem and Sentinel Hub APIs. This is being presented by running through a basic deforestation monitoring use-case. The notebook uses the popular xarray Python library to handle the multidimensional data.\nWhat we show in this notebook:"
  },
  {
    "objectID": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#prerequisites",
    "href": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#prerequisites",
    "title": "Deforestation Monitoring using Sentinel 2 and xarray",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nA Copernicus Dataspace Ecosystem account\nBasic understanding of the Sentinel Hub Processing API (Introductory Notebook available here)\n\n\nimport getpass\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport requests\nimport matplotlib.colors as mcolors\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\nfrom ipyleaflet import GeoJSON, Map, basemaps\nfrom sentinelhub import (\n    CRS,\n    BBox,\n    DataCollection,\n    MimeType,\n    SentinelHubDownloadClient,\n    SentinelHubRequest,\n    SHConfig,\n)\nfrom sklearn.metrics import accuracy_score\n\n\nCredentials\nTo obtain your client_id & client_secret, you need to navigate to your Dashboard. In the User Settings, you can create a new OAuth client to generate these credentials. More detailed instructions can be found on the corresponding documentation page.\nNow that you have your client_id & client_secret, it is recommended to configure a new profile in your Sentinel Hub Python package. Instructions on how to configure your Sentinel Hub Python package can be found here. Following these instructions, you can create a profile specifically for using the package to access Copernicus Data Space Ecosystem data collections. This is useful as changes to the config class in your notebook are usually only temporary and by saving the configuration to your profile, you don’t have to generate new credentials or overwrite/change the default profile every time you run or write a new Jupyter Notebook.\nIf you are using the Sentinel Hub Python package for the Copernicus Data Space Ecosystem for the first time, you should create a profile specifically for the Copernicus Data Space Ecosystem. You can do this in the following cell:\n\n# Only run this cell if you have not created a configuration.\n\nconfig = SHConfig()\n# config.sh_client_id = getpass.getpass(\"Enter your SentinelHub client id\")\n# config.sh_client_secret = getpass.getpass(\"Enter your SentinelHub client secret\")\nconfig.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\nconfig.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n# config.save(\"cdse\")\n\nHowever, if you have already configured a profile in Sentinel Hub Python for the Copernicus Data Space Ecosystem, then you can run the below cell entering the profile name as a string replacing profile_name.\n\n# config = SHConfig(\"profile_name\")"
  },
  {
    "objectID": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#area-of-interest",
    "href": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#area-of-interest",
    "title": "Deforestation Monitoring using Sentinel 2 and xarray",
    "section": "Area of Interest",
    "text": "Area of Interest\nFirst, we define an area of interest. In this case the area of interest is in the Harz Mountains in Germany since we are aware of substantial forest dieback in recent years.\nThe resolution is defined in the units of the coordinate reference system. Because we want to define units in meters, we also need to define the bounding box coordinates in a CRS using meters. We use EPSG:3035 in this case. This CRS is only available for Europe, outside of Europe we could use EPSG:3857 or UTM Zones.\nYou can also explore the area of interest in the Copernicus Browser here.\n\n# Desired resolution of our data\nresolution = (100, 100)\nbbox_coords = [10.633501, 51.611195, 10.787234, 51.698098]\nepsg = 3035\n# Convert to 3035 to get crs with meters as units\nbbox = BBox(bbox_coords, CRS(4326)).transform(epsg)\n\n\nx, y = bbox.transform(4326).middle\n\n# Add OSM background\noverview_map = Map(basemap=basemaps.OpenStreetMap.Mapnik, center=(y, x), zoom=10)\n\n# Add geojson data\ngeo_json = GeoJSON(data=bbox.transform(4326).geojson)\noverview_map.add_layer(geo_json)\n\n# Display\noverview_map"
  },
  {
    "objectID": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#data-access",
    "href": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#data-access",
    "title": "Deforestation Monitoring using Sentinel 2 and xarray",
    "section": "Data Access",
    "text": "Data Access\nNext, we define our evalscript. The evalscript is a piece of JavaScript code that tells the Copernicus Dataspace Ecosystem how to process the pixels you request before they are delivered to you.\nThis makes it a very powerful tool to perform pixel-based calculations in the cloud. For inspiration on what can be done in an evalscript, there is an extensive online resource of community-created evalscripts called custom-scripts. In this example, we want to calculate cloud-free mosaics. This is a perfect application for an evalscript, as you do not have to download the data needed to generate the mosaic, but all calculations are done on the server and only the final cloud-free mosaic is delivered.\nSo let’s go over how this is done.\nThe evalscript needs to define two functions, setup() and evaluatePixel(). First, let’s look at the setup function:\nfunction setup() {\n    return {\n        input: [\"B08\", \"B04\", \"B03\", \"B02\", \"SCL\"],\n        output: {\n            bands: 5,\n            sampleType: \"INT16\"\n        },\n        mosaicking: \"ORBIT\"\n    }\n}\nHere we specify which bands we want to request. In this case, we get the bands needed to calculate the NDVI and to display a True Color Image. We also define how our output should be structured, and define the output as a 5-band image with the INT16 data type.\nFinally, we specify the mosaicking parameter. This determines how the pixel values are returned to us. - mosaicking: \"SIMPLE\" returns only a single pixel, either from the most recent, the least recent or the least cloudy Sentinel 2 tile.\n\nmosaicking: \"ORBIT\" returns all pixels of unique orbits for the entire time series as a list. We use this to obtain all possible values from which we can create the cloud-free mosaic.\n\nNext let’s take a look at the evaluatePixel() function. This is the function where the actual calculation is defined:\nfunction evaluatePixel(samples) {\n    var valid = samples.filter(validate);\n    if (valid.length &gt; 0 ) {\n        let cloudless = {\n            b08: getFirstQuartileValue(valid.map(s =&gt; s.B08)),\n            b04: getFirstQuartileValue(valid.map(s =&gt; s.B04)),\n            b03: getFirstQuartileValue(valid.map(s =&gt; s.B03)),\n            b02: getFirstQuartileValue(valid.map(s =&gt; s.B02)),\n        }\n        let ndvi = ((cloudless.b08 - cloudless.b04) / (cloudless.b08 + cloudless.b04))\n        // This applies a scale factor so the data can be saved as an int\n        let scale = [cloudless.b04, cloudless.b03, cloudless.b02, ndvi].map(v =&gt; v*10000);\n        return scale\n    }\n    // If there isn't enough data, return NODATA\n    return [-32768, -32768, -32768, -32768]\n}\nThe way we construct the cloud free mosaic is by first filtering all the available acquisitions to only include the ones which contain clear data with samples.filter(validate);. Then we sort the array and get the value at the first quartile of the array. Getting the first quartile instead of the mean or median further reduces the risk that we select a cloudy pixel.\nFinally, we calculate the NDVI using the cloud-free values and return all the desired values as an array.\n\nevalscript_cloudless = \"\"\"\n//VERSION=3\nfunction setup() {\n    return {\n        input: [\"B08\", \"B04\", \"B03\", \"B02\", \"SCL\"],\n        output: {\n            bands: 4,\n            sampleType: \"INT16\"\n        },\n        mosaicking: \"ORBIT\"\n    }\n}\n\nfunction getFirstQuartileValue(values) {\n    values.sort((a,b) =&gt; a-b);\n    return getFirstQuartile(values);\n}\n\nfunction getFirstQuartile(sortedValues) {\n    var index = Math.floor(sortedValues.length / 4);\n    return sortedValues[index];\n}\n\nfunction validate(sample) {\n    // Define codes as invalid:\n    const invalid = [\n        0, // NO_DATA\n        1, // SATURATED_DEFECTIVE\n        3, // CLOUD_SHADOW\n        7, // CLOUD_LOW_PROBA\n        8, // CLOUD_MEDIUM_PROBA\n        9, // CLOUD_HIGH_PROBA\n        10 // THIN_CIRRUS\n    ]\n    return !invalid.includes(sample.SCL)\n}\n\nfunction evaluatePixel(samples) {\n    var valid = samples.filter(validate);\n    if (valid.length &gt; 0 ) {\n        let cloudless = {\n            b08: getFirstQuartileValue(valid.map(s =&gt; s.B08)),\n            b04: getFirstQuartileValue(valid.map(s =&gt; s.B04)),\n            b03: getFirstQuartileValue(valid.map(s =&gt; s.B03)),\n            b02: getFirstQuartileValue(valid.map(s =&gt; s.B02)),\n        }\n        let ndvi = ((cloudless.b08 - cloudless.b04) / (cloudless.b08 + cloudless.b04))\n        // This applies a scale factor so the data can be saved as an int\n        let scale = [cloudless.b04, cloudless.b03, cloudless.b02, ndvi].map(v =&gt; v*10000);\n        return scale\n    }\n    // If there isn't enough data, return NODATA\n    return [-32768, -32768, -32768, -32768]\n}\n\"\"\"\n\nWe have defined how the pixels should be handled. However, we still need to define some other parameters to get a full request.\nWe need to define which data we want to use and the timeframe of the data.\nThis is what we are doing in the next cell. Here, we also start building our time series. To see changes over the years, we want to get cloud-free mosaics for the same 3 months over the years. We do this by defining the three months (June-August) in the interval_of_interest() function. Then we define a function get_request(), which will build the request to the Sentinel Hub API on the Copernicus Data Space Ecosystem.\nIn this SentinelHubRequest, we define the input data, the timeframe, the output type (TIFF), the bounding box, the resolution and where to save the data.\nWe define this as a function because we want to make several requests with the changing years being the only input.\n\ndef interval_of_interest(year):\n    return (datetime(year, 6, 1), datetime(year, 9, 1))\n\n\ndef get_request(year):\n    time_interval = interval_of_interest(year)\n    return SentinelHubRequest(\n        evalscript=evalscript_cloudless,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.SENTINEL2_L2A.define_from(\n                    \"s2\", service_url=config.sh_base_url\n                ),\n                time_interval=time_interval,\n            )\n        ],\n        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n        bbox=bbox,\n        resolution=resolution,\n        config=config,\n        data_folder=\"./data\",\n    )\n\nThis cell now creates a request for each of the years, from 2018 to 2023.\n\n# create a dictionary of requests\nsh_requests = {}\nfor year in range(2018, 2024):\n    sh_requests[year] = get_request(year)\n\nsh_requests\n\nThe next step is to download the data. This is done with the utility function SentinelHubDownloadClient. It downloads a list of requests in parallel, greatly improving the download speed. Before we can do that, we need to change the format of the requests slightly, which is done in the variable list_of_requests.\n\nlist_of_requests = [request.download_list[0] for request in sh_requests.values()]\n\n# download data with multiple threads\ndata = SentinelHubDownloadClient(config=config).download(\n    list_of_requests, max_threads=5\n)\n\nThe output of the requests do not provide any information about which year the data is from, so we rename the output of each request to the year of the data it represents.\n\ndef request_output_path(request):\n    # Gets the full path to the output from a request\n    return Path(request.data_folder, request.get_filename_list()[0])\n\n\n# Moves and renames the files to the root directory of results\nfor year, request in sh_requests.items():\n    request_output_path(request).rename(f\"./data/{year}.tif\")"
  },
  {
    "objectID": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#read-data-with-xarray",
    "href": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#read-data-with-xarray",
    "title": "Deforestation Monitoring using Sentinel 2 and xarray",
    "section": "Read data with xarray",
    "text": "Read data with xarray\nNow we can load the data into xarray. We use rioxarray, an extension for xarray, to load multiple tiffs into a single xarray dataset. xarray is a scalable tool for analysing multidimensional data in Python. This makes xarray ideal for analysing time series data.\nThe different files correspond to the time dimension, but xarray does not know which file is which time step. Therefore, we add a pre-processing step in which we parse out the year from the filename and add it as the time dimension for that file.\nThe warnings in the output can be safely ignored.\n\ndef add_time_dim(xda):\n    # This pre-processes the file to add the correct\n    # year from the filename as the time dimension\n    year = int(Path(xda.encoding[\"source\"]).stem)\n    return xda.expand_dims(year=[year])\n\n\ntiff_paths = Path(\"./data\").glob(\"*.tif\")\nds_s2 = xr.open_mfdataset(\n    tiff_paths,\n    engine=\"rasterio\",\n    preprocess=add_time_dim,\n    band_as_variable=True,\n)\nds_s2 = ds_s2.rename(\n    {\n        \"band_1\": \"R\",\n        \"band_2\": \"G\",\n        \"band_3\": \"B\",\n        \"band_4\": \"NDVI\",\n    }\n)\nds_s2 = ds_s2 / 10000\n\nThis results in an xarray dataset with 3 coordinates: year, x and y, as well as the data variables returned by the evalscript as data variables in the dataset.\n\nds_s2\n\nWe can use xarray to plot the RGB data as a true color image:\n\n# Get RGB data for a year\nplot_year = 2018\ntrue_color = ds_s2.sel(year=plot_year)[[\"R\", \"G\", \"B\"]].to_array()\n# Divide by scale factor and apply gamma to brighten image\n(true_color * 4).plot.imshow()\nplt.title(f\"True Color {plot_year}\");\n\nWe can also similarly plot the NDVI values:\n\nds_s2.NDVI.plot(cmap=\"PRGn\", x=\"x\", y=\"y\", col=\"year\", col_wrap=3);"
  },
  {
    "objectID": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#analysis",
    "href": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#analysis",
    "title": "Deforestation Monitoring using Sentinel 2 and xarray",
    "section": "Analysis",
    "text": "Analysis\nFor analysis the first step is to classify pixels as forest. In our case we will just do a simple thresholding classification where we classify everything above a certain threshold as forest. This isn’t the best approach for classifying forest, since agricultural areas can also easily reach very high NDVI values. A better approach would be to classify based on the temporal signature of the pixel.\nHowever, for this basic analysis, we stick to the simple thresholding approach.\nIn this case we classify everything above an NDVI of 0.7 as forest. This calculated forest mask is then saved to a new Data Variable in the xarray dataset:\n\nds_s2[\"FOREST\"] = ds_s2.NDVI &gt; 0.7\n\nWith this forest mask we can already do a quick preliminary analysis to plot the total forest area over the years.\nTo do this we sum up the pixels along the x and y coordinate but not along the time coordinate. This will leave us with one value per year representing the number of pixels classified as forest. We can then calculate the forest area by multiplying the number of forest pixels by the resolution.\n\ndef to_km2(dataarray, resolution):\n    # Calculate forest area\n    return dataarray * np.prod(list(resolution)) / 1e6\n\n\nforest_pixels = ds_s2.FOREST.sum([\"x\", \"y\"])\nforest_area_km2 = to_km2(forest_pixels, resolution)\nforest_area_km2.plot()\nplt.title(\"Forest Cover\")\nplt.ylabel(\"Forest Cover [km²]\")\nplt.ylim(0);\n\nWe can see that the total forest area in this AOI decreased from around 80 km² in 2018 to only around 50 km² in 2023.\nThe next step is to make change maps from year to year. To do this we basically take the difference of the forest mask of a year with its previous year.\nThis will result in 0 value where there has been no change, -1 where forest was lost and +1 where forest was gained.\n\n# Make change maps of forest loss and forest gain compared to previous year\n\n# 0 - 0 = No Change: 0\n# 1 - 1 = No Change: 0\n# 1 - 0 = Forest Gain: 1\n# 0 - 1 = Forest Loss: -1\n\n# Define custom colors and labels\ncolors = [\"darkred\", \"white\", \"darkblue\"]\nlabels = [\"Forest Loss\", \"No Change\", \"Forest Gain\"]\n\n# Create a colormap and normalize it\ncmap = mcolors.ListedColormap(colors)\nnorm = plt.Normalize(-1, 1)  # Adjust the range based on your data\n\nplot_year = 2022\nds_s2[\"CHANGE\"] = ds_s2.FOREST.astype(int).diff(\"year\", label=\"upper\")\nds_s2.CHANGE.sel(year=plot_year).plot(cmap=cmap, norm=norm, add_colorbar=False)\n\n# Create a legend with string labels\nlegend_patches = [\n    mpatches.Patch(color=color, label=label) for color, label in zip(colors, labels)\n]\nplt.legend(handles=legend_patches, loc=\"lower left\")\nplt.title(f\"Forest Change Map {plot_year}\");\n\nHere, we can see the spatial distribution of areas affected by forest loss. In the displayed change from 2021 to 2022, most of the forest loss happened in the northern part of the study area, while the southern part lost comparatively less forest.\nTo get a feel for the loss per year, we can cumulatively sum up the lost areas over the years. This should basically follow the same trends as the earlier plot of total forest area.\n\n# Forest Loss per Year\nforest_loss = (ds_s2.CHANGE == -1).sum([\"x\", \"y\"])\nforest_loss_km2 = to_km2(forest_loss, resolution)\nforest_loss_km2.cumsum().plot()\nplt.title(\"Cumulative Forest Loss\")\nplt.ylabel(\"Forest Loss [km²]\");\n\nWe can see that there have been two years with particularly large amounts of lost forest area. From 2019-2020 and with by far the most lost area between 2021 and 2022."
  },
  {
    "objectID": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#validation",
    "href": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#validation",
    "title": "Deforestation Monitoring using Sentinel 2 and xarray",
    "section": "Validation",
    "text": "Validation\nFinally, we want to see how accurate our data is compared to the widely used Hansen Global Forest Change data. In a real scientific scenario, we would use Ground Truth data to assess the accuracy of our classification. In this case we use the Global Forest Change data in place of Ground Truth data, just to show how an accuracy assessment can be done. The assessment we are doing only shows how accurately we replicate the Global Forest Change data, however we will not know if our product is more or less accurate. For a more accurate assessment, actual Ground Truth data is required.\nFirst we download the Global Forest Change Data here and open it using xarray.\n\ndata_path = Path(\"./data/\")\ndata_path.mkdir(parents=True, exist_ok=True)\nhansen_filename = \"Hansen_GFC-2022-v1.10_lossyear_60N_010E.tif\"\ncomp_data = data_path / hansen_filename\n\nwith comp_data.open(\"wb\") as fs:\n    hansen_data = requests.get(\n        f\"https://storage.googleapis.com/earthenginepartners-hansen/GFC-2022-v1.10/{hansen_filename}\"\n    )\n    fs.write(hansen_data.content)\n\n\n# Open the file\nground_truth = (\n    xr.open_dataarray(comp_data, engine=\"rasterio\")\n    .rio.clip_box(*bbox_coords)\n    .rio.reproject(epsg)\n    .sel(band=1)\n    .where(lambda gt: gt &lt; 100, 0)  # fill no-data (values over 100) with 0\n)\nground_truth.plot(levels=range(25), cbar_kwargs={\"label\": \"Year of Forest Loss\"})\nplt.title(\"Global Forest Watch Data\");\n\nThe data shows in which year forest was first lost. To compare with our own data, we need to add the data to our dataset. To do this the data needs to have the same coordinates. This can be achieved with .interp_like(). This function interpolates the data to match up the coordinates of another dataset.\nIn this case we chose the interpolation method nearest since it is categorical data.\n\nds_s2[\"GROUND_TRUTH\"] = ground_truth.interp_like(ds_s2, method=\"nearest\").astype(int)\nds_s2\n\nThe ground truth data saves the year when deforestation was first detected for a pixel in a single raster. To do this, it encodes the year of forest loss as an integer, giving the year. So, an integer 21 means the pixel was first detected as deforested in 2021, whereas a value of 0 means that deforestation was never detected.\nCurrently our classification saves the deforestation detection in multiple rasters, one for each year. To get our data into a format that is similar to our comparison data we need to convert our rasters for each time step into a single one.\nTo do this we first assign all pixels which were detected as deforestation (CHANGE == -1) to the year in which the deforestation was detected (lost_year). Then we compute over our time-series the first occurence of deforestation (equivalent to the first non-zero value) per pixel. This is then saved in a new data variable.\n\n# convert lost forest (-1) into the year it was lost\nlost_year = (ds_s2.CHANGE == -1) * ds_s2.year % 100\nfirst_nonzero = (lost_year != 0).argmax(axis=0).compute()\nds_s2[\"LOST_YEAR\"] = lost_year[first_nonzero]\nds_s2.LOST_YEAR.plot(levels=range(25), cbar_kwargs={\"label\": \"Year of Forest Loss\"})\nplt.title(\"Classification Forest Loss Year\");\n\nComparing this visually to the Global Forest Watch data, allows us to do some initial quality assessment. We can see definite differences between the two datasets. The Global Forest Watch data has much more clearly defined borders. In general, our classification seems to overestimate deforestation. However, the general pattern of forest loss is the same in both. Most of the deforestation is in the north of the study area, with less forest loss in the south.\nThere are a few reasons for those differences. The main difference has to be in our much more simple approach to forest classification and change detection. It is expected that our approach will lead to large amounts of commission errors since changes are only confirmed using a single observation. It however can also lead to a lot of omission errors since the NDVI thresholding might classify highly productive non-forest areas as forest due to their high NDVI values.\nHowever, there are also some systematic differences. Our algorithm looks at differences between the middle of the years, which means that some changes can happen at the end of the growing year which will be detected first in the next year whereas the Global Forest Watch dataset will detect it in the correct (earlier) year.\n\nds_s2.GROUND_TRUTH.plot(levels=range(25), cbar_kwargs={\"label\": \"Year of Forest Loss\"})\nplt.title(\"Global Forest Watch - Interpolated\");\n\nFinally, we can also calculate an accuracy score. This is a score from 0-1, where values close to 0.5 basically mean that the classification is random, and values close to 1 mean that most of the values of our comparison data and classification data match.\nFirst, we look at the overall accuracy of forest loss over the entire period from 2018 to 2023.\n\nscore = accuracy_score(\n    (ds_s2.LOST_YEAR &gt; 18).values.ravel(), (ds_s2.GROUND_TRUTH &gt; 18).values.ravel()\n)\nprint(f\"The overall accuracy of forest loss detection is {score:.2f}.\")\n\nAs expected from the visual interpretation, with an accuracy of 0.77, our product differs quite a lot compared to the Global Forest Watch data. From this we do not know for sure that our product is less accurate compared to the actual forest loss patterns observed on the ground. We only know that it is different to the Global Forest Watch product. It might be more or less accurate.\nHowever, because of the simplicity of our algorithm, it is safe to assume that our output is less accurate."
  },
  {
    "objectID": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#summary",
    "href": "notebook-samples/sentinelhub/deforestation_monitoring_with_xarray.html#summary",
    "title": "Deforestation Monitoring using Sentinel 2 and xarray",
    "section": "Summary",
    "text": "Summary\nThis notebook showed how to efficiently access data stored on the Copernicus Dataspace Ecosystem using the Sentinel Hub APIs. This includes generating cloud-free mosaics and calculating spectral indices in the cloud.\nIt also showed how to import this data using xarray and carry out a basic multi-temporal detection of forest loss.\nThis notebook should serve as a starting point for your own analysis using the powerful Python Data Analysis ecosystem and leveraging the Copernicus Data Space Ecosystem APIs for quick satellite data access."
  },
  {
    "objectID": "notebook-samples/openeo/Sentinel_3.html",
    "href": "notebook-samples/openeo/Sentinel_3.html",
    "title": "Sentinel-3",
    "section": "",
    "text": "This notebook explores working with Sentinel-3 data."
  },
  {
    "objectID": "notebook-samples/openeo/Sentinel_3.html#sentinel-3-olci",
    "href": "notebook-samples/openeo/Sentinel_3.html#sentinel-3-olci",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI",
    "text": "Sentinel-3 OLCI\nhttps://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-3-olci\nThe OLCI dataset provided by Sentinelhub is based on the level-1b products. These products are provided in “instrument” projection rather than being projected into a ground-based reference system. Hence, these products do not come with a ‘native’ reference system. The openEO collections are currently configured to use EPSG:4326 unprojected coordinates, with a resolution set to a fixed value that tries to approximate the native 300m ground resolution.\n\nimport openeo\nimport xarray\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nconn = openeo.connect(\"openeo.dataspace.copernicus.eu\")\nconn.authenticate_oidc()\n\nVisit https://identity.dataspace.copernicus.eu/auth/realms/CDSE/device?user_code=QPMD-IMEL 📋 to authenticate.\n\n\n[####################################-] Authorized successfully\n\n\nAuthenticated using device code flow.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;\n\n\n\nLoad the collection\n\nconn.describe_collection(\"SENTINEL3_OLCI_L1B\")\n\n\n    \n    \n        \n    \n    \n\n\n\nbbox = {\"west\": 27.564697, \"south\": 34.764179, \"east\": 33.002930, \"north\": 37.387617}\nsentinel3 = conn.load_collection(\n    \"SENTINEL3_OLCI_L1B\",\n    spatial_extent=bbox,\n    temporal_extent=[\"2021-07-30\", \"2021-07-30\"],\n    bands=[\"B08\", \"B06\", \"B04\"],\n)\n\nLet’s download this slice of data in netCDF format to give it an initial inspection.\n\nsentinel3.download(\"sentinel3.nc\")\n\nQuick visualisation of the output\n\nds = xarray.load_dataset(\"sentinel3.nc\")\n\n# Convert xarray DataSet to a (bands, t, x, y) DataArray\ndata = ds[[\"B08\", \"B06\", \"B04\"]].to_array(dim=\"bands\")\n\n\nfig, (axrgb, axhist) = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n\n# plot the data\ndata[{\"t\": 0}].plot.imshow(ax=axrgb)\n\n# Plot the data histogram\ndata.plot.hist(bins=50, ax=axhist, histtype=\"stepfilled\")\n\nplt.show()"
  },
  {
    "objectID": "notebook-samples/openeo/Radar_ARD.html",
    "href": "notebook-samples/openeo/Radar_ARD.html",
    "title": "Radar - Sentinel-1: ARD SAR Backscatter",
    "section": "",
    "text": "For certain use cases, the readily available preprocessed data collections in the openEO back-ends are not sufficient or inappropriately preprocessed. openEO supports some processes to address very common preprocessing scenarios:\nThese processes also offer a number of parameters to customize the processing.\nHowever, please note that these operations can be computationally expensive, so they certainly affect the overall processing time and cost of your final algorithm. Hence, make sure to make an informed decision when using these methods.\nIn this notebook has been duplicated from an existing sample processing pipeline for Radar ARD on the openEO platform. In this instance, we aim to showcase it with the Copernicus Data Space Ecosystem backend."
  },
  {
    "objectID": "notebook-samples/openeo/Radar_ARD.html#setup",
    "href": "notebook-samples/openeo/Radar_ARD.html#setup",
    "title": "Radar - Sentinel-1: ARD SAR Backscatter",
    "section": "Setup",
    "text": "Setup\nImport the openeo package and connect to the Copernicus Data Space Ecosystem openEO back-end.\n\nimport openeo\n\n\nbackend = \"openeo.dataspace.copernicus.eu\"\nconn = openeo.connect(backend).authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n\nOn-demand SAR Backscatter\nData from synthetic aperture radar (SAR) sensors requires significant preprocessing to be calibrated and normalized. This is referred to as backscatter computation and is provided in the openEO by the sar_backscatter process.\nThe radiometric correction coefficient used in this example is sigma0-ellipsoid."
  },
  {
    "objectID": "notebook-samples/openeo/Radar_ARD.html#specify-area-of-interest-temporal-extent-polarization",
    "href": "notebook-samples/openeo/Radar_ARD.html#specify-area-of-interest-temporal-extent-polarization",
    "title": "Radar - Sentinel-1: ARD SAR Backscatter",
    "section": "Specify area of interest, temporal extent, polarization",
    "text": "Specify area of interest, temporal extent, polarization\n\nspatial_extent = {\n    \"west\": 11.293602,\n    \"east\": 11.382866,\n    \"south\": 46.460163,\n    \"north\": 46.514768,\n    \"crs\": \"EPSG:4326\",\n}\n\ns1 = conn.load_collection(\n    \"SENTINEL1_GRD\",\n    spatial_extent=spatial_extent,\n    bands=[\"VV\", \"VH\"],\n    temporal_extent=[\"2021-01-01\", \"2021-01-08\"],\n    properties={\"sat:orbit_state\": lambda od: od == \"ASCENDING\"},\n)"
  },
  {
    "objectID": "notebook-samples/openeo/Radar_ARD.html#apply-openeo-processes",
    "href": "notebook-samples/openeo/Radar_ARD.html#apply-openeo-processes",
    "title": "Radar - Sentinel-1: ARD SAR Backscatter",
    "section": "Apply openEO processes",
    "text": "Apply openEO processes\nHere we apply both the SAR backscattering processes on the datacube and then convert it from linear to dB scale.\n\ns1_scatter = s1.sar_backscatter(\n    coefficient=\"sigma0-ellipsoid\", elevation_model=\"COPERNICUS_30\"\n)\ns1bs = s1_scatter.apply(lambda x: 10 * x.log(base=10))"
  },
  {
    "objectID": "notebook-samples/openeo/Radar_ARD.html#execution",
    "href": "notebook-samples/openeo/Radar_ARD.html#execution",
    "title": "Radar - Sentinel-1: ARD SAR Backscatter",
    "section": "Execution",
    "text": "Execution\nSince our area of interest is small, a direct request is preferred. Nevertheless, please note that this approach will not return the JSON metadata. If you want JSON metadata along with the result you can choose the Batch job-based method too.\nNote that this step automatically adds the save_result process at the end based on the output format we choose.\n\n%time s1bs.download(\"sar_bs.nc\")\n\nCPU times: user 13.6 ms, sys: 22.7 ms, total: 36.3 ms\nWall time: 28 s"
  },
  {
    "objectID": "notebook-samples/openeo/Radar_ARD.html#output-visualization",
    "href": "notebook-samples/openeo/Radar_ARD.html#output-visualization",
    "title": "Radar - Sentinel-1: ARD SAR Backscatter",
    "section": "Output visualization",
    "text": "Output visualization\n\nimport xarray as xr\n\nS1_ard = xr.open_dataset(\"sar_bs.nc\")\nS1_ard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (t: 1, x: 704, y: 628)\nCoordinates:\n  * t        (t) datetime64[ns] 2021-01-03\n  * x        (x) float64 6.759e+05 6.76e+05 6.76e+05 ... 6.83e+05 6.83e+05\n  * y        (y) float64 5.154e+06 5.154e+06 5.154e+06 ... 5.148e+06 5.148e+06\nData variables:\n    crs      |S1 ...\n    VV       (t, y, x) float32 ...\n    VH       (t, y, x) float32 ...\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platformxarray.DatasetDimensions:t: 1x: 704y: 628Coordinates: (3)t(t)datetime64[ns]2021-01-03standard_name :tlong_name :taxis :Tarray(['2021-01-03T00:00:00.000000000'], dtype='datetime64[ns]')x(x)float646.759e+05 6.76e+05 ... 6.83e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([675945., 675955., 675965., ..., 682955., 682965., 682975.])y(y)float645.154e+06 5.154e+06 ... 5.148e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5154005., 5153995., 5153985., ..., 5147755., 5147745., 5147735.])Data variables: (3)crs()|S1...crs_wkt :PROJCS[\"WGS 84 / UTM zone 32N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 9.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32632\"]]spatial_ref :PROJCS[\"WGS 84 / UTM zone 32N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 9.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32632\"]][1 values with dtype=|S1]VV(t, y, x)float32...long_name :VVunits :grid_mapping :crs[442112 values with dtype=float32]VH(t, y, x)float32...long_name :VHunits :grid_mapping :crs[442112 values with dtype=float32]Indexes: (3)tPandasIndexPandasIndex(DatetimeIndex(['2021-01-03'], dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Index([675945.0, 675955.0, 675965.0, 675975.0, 675985.0, 675995.0, 676005.0,\n       676015.0, 676025.0, 676035.0,\n       ...\n       682885.0, 682895.0, 682905.0, 682915.0, 682925.0, 682935.0, 682945.0,\n       682955.0, 682965.0, 682975.0],\n      dtype='float64', name='x', length=704))yPandasIndexPandasIndex(Index([5154005.0, 5153995.0, 5153985.0, 5153975.0, 5153965.0, 5153955.0,\n       5153945.0, 5153935.0, 5153925.0, 5153915.0,\n       ...\n       5147825.0, 5147815.0, 5147805.0, 5147795.0, 5147785.0, 5147775.0,\n       5147765.0, 5147755.0, 5147745.0, 5147735.0],\n      dtype='float64', name='y', length=628))Attributes: (2)Conventions :CF-1.9institution :openEO platform\n\n\n\nimport matplotlib.pyplot as plt\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 20))\nax1.imshow(S1_ard.VV[0].values, cmap=\"Greys_r\", vmin=-30, vmax=30)\nax1.set_title(\"VV sigma0\")\nax2.imshow(S1_ard.VH[0].values, cmap=\"Greys_r\", vmin=-30, vmax=30)\nax2.set_title(\"VH sigma0\")\nplt.show()"
  },
  {
    "objectID": "notebook-samples/openeo/basics.html",
    "href": "notebook-samples/openeo/basics.html",
    "title": "openEO Basics: Discovery of Collections and Processes",
    "section": "",
    "text": "Import the openeo package and connect to the Copernicus Data Space Ecosystem openEO back-end.\n\nimport openeo\n\n\nconnection = openeo.connect(\n    url=\"openeo.dataspace.copernicus.eu\",\n)"
  },
  {
    "objectID": "notebook-samples/openeo/basics.html#setup",
    "href": "notebook-samples/openeo/basics.html#setup",
    "title": "openEO Basics: Discovery of Collections and Processes",
    "section": "",
    "text": "Import the openeo package and connect to the Copernicus Data Space Ecosystem openEO back-end.\n\nimport openeo\n\n\nconnection = openeo.connect(\n    url=\"openeo.dataspace.copernicus.eu\",\n)"
  },
  {
    "objectID": "notebook-samples/openeo/basics.html#collections",
    "href": "notebook-samples/openeo/basics.html#collections",
    "title": "openEO Basics: Discovery of Collections and Processes",
    "section": "Collections",
    "text": "Collections\nList all available collection ids:\n\nprint(connection.list_collection_ids())\n\n['SENTINEL3_OLCI_L1B', 'SENTINEL3_SLSTR', 'SENTINEL_5P_L2', 'SENTINEL2_L1C', 'SENTINEL2_L2A', 'SENTINEL1_GRD', 'COPERNICUS_30']\n\n\nGet detailed information about a collection\n\nconnection.describe_collection(\"SENTINEL2_L2A\")"
  },
  {
    "objectID": "notebook-samples/openeo/basics.html#processes",
    "href": "notebook-samples/openeo/basics.html#processes",
    "title": "openEO Basics: Discovery of Collections and Processes",
    "section": "Processes",
    "text": "Processes\nList all available processes:\n\nconnection.list_processes()\n\n\n\n    \n    \n        \n    \n    \n\n\nInspect one process in more detail\n\nconnection.describe_process(\"add\")"
  },
  {
    "objectID": "notebook-samples/openeo/Whittaker.html",
    "href": "notebook-samples/openeo/Whittaker.html",
    "title": "Creating a smoothed dataset using Whittaker",
    "section": "",
    "text": "In this notebook, we use Whittaker algorithm is available in the FuseTS toolbox as a user-defined-function (UDF) to create a smoothed time series. It employs a discrete penalized least squares algorithm that fits a smooth series, denoted as z, to the original data series, denoted as y.\nPlease note that FuseTS library used here is compatible with Python 3.8 - 3.10.\n\nimport itertools\nimport warnings\nfrom datetime import datetime, timedelta\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport openeo\nimport pandas as pd\nimport xarray\nfrom ipyleaflet import GeoJSON, Map, basemaps\nfrom openeo.processes import eq\nfrom openeo.rest.conversions import timeseries_json_to_pandas\n\nfrom fusets.whittaker import whittaker\n\nwarnings.filterwarnings(\"ignore\")\n\nThe first step is to connect to an openEO backend and authenticate with the Copernicus Dataspace Ecosystem’s credentials.\n\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nNext we define the area of interest, in this case an extent, for which we would like to fetch time series data.\n\nyear = 2019\nspat_ext = {\n    \"coordinates\": [\n        [\n            [-4.875091217039325, 41.77290587433312],\n            [-4.872773788450457, 41.77290587433312],\n            [-4.872773788450457, 41.77450614847532],\n            [-4.875091217039325, 41.77450614847532],\n            [-4.875091217039325, 41.77290587433312],\n        ]\n    ],\n    \"type\": \"Polygon\",\n}\ntemp_ext = [f\"{year}-01-01\", f\"{year}-12-30\"]\n\n\ncenter = np.mean(spat_ext[\"coordinates\"][0], axis=0).tolist()[::-1]\nzoom = 16\n\nm = Map(basemap=basemaps.Esri.WorldImagery, center=center, zoom=zoom)\ng = GeoJSON(\n    data=spat_ext,\n    style={\n        \"color\": \"red\",\n        \"opacity\": 1,\n        \"weight\": 1.9,\n        \"dashArray\": \"9\",\n        \"fillOpacity\": 0.5,\n    },\n)\nm.add(g)\nm\n\n\n\n\nWe will be working with with the rapeseed from 2019, located in the Nothern Spain.\nWe will create an openEO process to calculate the NDVI time series for our area of interest. First we begin by using the SENTINEL2_L2A collection, and apply a Sen2Cor cloud masking algorithm to remove any interfering clouds before calculating the NDVI values.\n\ns2 = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    spatial_extent=spat_ext,\n    temporal_extent=temp_ext,\n    bands=[\"B04\", \"B08\", \"SCL\"],\n)\ns2 = s2.process(\"mask_scl_dilation\", data=s2, scl_band_name=\"SCL\")\ns2 = s2.mask_polygon(spat_ext)\nndvi_cube = s2.ndvi(red=\"B04\", nir=\"B08\", target_band=\"NDVI\")\n\nNow that we have calculated the NDVI time series for our area of interest, we can request openEO to download the result to our local storage. This will allow us to access the file and use it for further analysis in this notebook.\n\nndvi_output_file = \"raw_s2_ndvi_field.nc\"\n\n# batch job\n\nndvi_job = ndvi_cube.execute_batch(ndvi_output_file, title=f\"FUSETS-Raw NDVI\")\n\n# load the dataset and check it's structure\nraw_ndvi_ds = xarray.load_dataset(ndvi_output_file)\nraw_ndvi_ds\n\n0:00:00 Job 'j-2310308bb89149cf8106aabb55eba553': send 'start'\n0:00:12 Job 'j-2310308bb89149cf8106aabb55eba553': created (progress N/A)\n0:00:18 Job 'j-2310308bb89149cf8106aabb55eba553': created (progress N/A)\n0:00:24 Job 'j-2310308bb89149cf8106aabb55eba553': created (progress N/A)\n0:00:33 Job 'j-2310308bb89149cf8106aabb55eba553': created (progress N/A)\n0:00:43 Job 'j-2310308bb89149cf8106aabb55eba553': created (progress N/A)\n0:00:56 Job 'j-2310308bb89149cf8106aabb55eba553': created (progress N/A)\n0:01:12 Job 'j-2310308bb89149cf8106aabb55eba553': running (progress N/A)\n0:01:32 Job 'j-2310308bb89149cf8106aabb55eba553': running (progress N/A)\n0:01:56 Job 'j-2310308bb89149cf8106aabb55eba553': running (progress N/A)\n0:02:27 Job 'j-2310308bb89149cf8106aabb55eba553': finished (progress N/A)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (t: 31, x: 21, y: 19)\nCoordinates:\n  * t        (t) datetime64[ns] 2019-01-27 2019-02-11 ... 2019-12-18 2019-12-28\n  * x        (x) float64 3.442e+05 3.442e+05 3.442e+05 ... 3.443e+05 3.444e+05\n  * y        (y) float64 4.626e+06 4.626e+06 4.626e+06 ... 4.626e+06 4.626e+06\nData variables:\n    crs      |S1 b''\n    B04      (t, y, x) float32 nan 1.212e+03 1.226e+03 1.236e+03 ... nan nan nan\n    B08      (t, y, x) float32 nan 1.934e+03 1.964e+03 1.982e+03 ... nan nan nan\n    SCL      (t, y, x) float32 nan 5.0 5.0 5.0 5.0 5.0 ... nan nan nan nan nan\n    NDVI     (t, y, x) float32 nan 0.2295 0.2313 0.2318 ... nan nan nan nan\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platform - Geotrellis backend: 0.18.0a1\n    description:  \n    title:        xarray.DatasetDimensions:t: 31x: 21y: 19Coordinates: (3)t(t)datetime64[ns]2019-01-27 ... 2019-12-28standard_name :tlong_name :taxis :Tarray(['2019-01-27T00:00:00.000000000', '2019-02-11T00:00:00.000000000',\n       '2019-02-21T00:00:00.000000000', '2019-02-26T00:00:00.000000000',\n       '2019-03-03T00:00:00.000000000', '2019-03-13T00:00:00.000000000',\n       '2019-03-23T00:00:00.000000000', '2019-03-28T00:00:00.000000000',\n       '2019-04-07T00:00:00.000000000', '2019-04-12T00:00:00.000000000',\n       '2019-04-27T00:00:00.000000000', '2019-05-02T00:00:00.000000000',\n       '2019-05-27T00:00:00.000000000', '2019-06-01T00:00:00.000000000',\n       '2019-06-26T00:00:00.000000000', '2019-07-01T00:00:00.000000000',\n       '2019-07-11T00:00:00.000000000', '2019-07-16T00:00:00.000000000',\n       '2019-07-21T00:00:00.000000000', '2019-08-05T00:00:00.000000000',\n       '2019-08-15T00:00:00.000000000', '2019-08-20T00:00:00.000000000',\n       '2019-08-30T00:00:00.000000000', '2019-09-04T00:00:00.000000000',\n       '2019-09-19T00:00:00.000000000', '2019-09-29T00:00:00.000000000',\n       '2019-10-09T00:00:00.000000000', '2019-11-18T00:00:00.000000000',\n       '2019-11-23T00:00:00.000000000', '2019-12-18T00:00:00.000000000',\n       '2019-12-28T00:00:00.000000000'], dtype='datetime64[ns]')x(x)float643.442e+05 3.442e+05 ... 3.444e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([344155., 344165., 344175., 344185., 344195., 344205., 344215., 344225.,\n       344235., 344245., 344255., 344265., 344275., 344285., 344295., 344305.,\n       344315., 344325., 344335., 344345., 344355.])y(y)float644.626e+06 4.626e+06 ... 4.626e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([4626435., 4626425., 4626415., 4626405., 4626395., 4626385., 4626375.,\n       4626365., 4626355., 4626345., 4626335., 4626325., 4626315., 4626305.,\n       4626295., 4626285., 4626275., 4626265., 4626255.])Data variables: (5)crs()|S1b''crs_wkt :PROJCS[\"WGS 84 / UTM zone 30N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", -3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32630\"]]spatial_ref :PROJCS[\"WGS 84 / UTM zone 30N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", -3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32630\"]]array(b'', dtype='|S1')B04(t, y, x)float32nan 1.212e+03 1.226e+03 ... nan nanlong_name :B04units :grid_mapping :crsarray([[[  nan, 1212., 1226., ..., 1064., 1040.,   nan],\n        [  nan, 1214., 1224., ..., 1096., 1054.,   nan],\n        [  nan, 1232., 1222., ..., 1082., 1052.,   nan],\n        ...,\n        [  nan, 1230., 1248., ..., 1186., 1142.,   nan],\n        [  nan, 1262., 1262., ..., 1148., 1142.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  nan, 1272., 1258., ..., 1102., 1060.,   nan],\n        [  nan, 1238., 1216., ..., 1094., 1052.,   nan],\n        [  nan, 1266., 1256., ..., 1112., 1096.,   nan],\n        ...,\n        [  nan, 1236., 1202., ..., 1188., 1164.,   nan],\n        [  nan, 1240., 1202., ..., 1162., 1146.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  nan, 1262., 1300., ..., 1130., 1124.,   nan],\n        [  nan, 1288., 1300., ..., 1152., 1118.,   nan],\n        [  nan, 1324., 1294., ..., 1146., 1132.,   nan],\n        ...,\n...\n        ...,\n        [  nan, 1108., 1108., ..., 1112., 1112.,   nan],\n        [  nan, 1100., 1126., ..., 1094., 1104.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  nan, 1352., 1462., ..., 1332., 1304.,   nan],\n        [  nan, 1284., 1388., ..., 1298., 1250.,   nan],\n        [  nan, 1308., 1294., ..., 1266., 1240.,   nan],\n        ...,\n        [  nan, 1324., 1310., ..., 1334., 1384.,   nan],\n        [  nan, 1330., 1348., ..., 1312., 1412.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  nan, 1118., 1102., ..., 1013., 1021.,   nan],\n        [  nan, 1042.,  986., ..., 1030., 1002.,   nan],\n        [  nan, 1066.,  979., ..., 1030., 1015.,   nan],\n        ...,\n        [  nan, 1062., 1106., ..., 1022., 1064.,   nan],\n        [  nan, 1076., 1116., ..., 1030., 1024.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]]], dtype=float32)B08(t, y, x)float32nan 1.934e+03 1.964e+03 ... nan nanlong_name :B08units :grid_mapping :crsarray([[[  nan, 1934., 1964., ..., 1916., 1852.,   nan],\n        [  nan, 1990., 2010., ..., 1846., 1754.,   nan],\n        [  nan, 2050., 2064., ..., 1784., 1680.,   nan],\n        ...,\n        [  nan, 2046., 2032., ..., 1784., 1760.,   nan],\n        [  nan, 2078., 2042., ..., 1796., 1766.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  nan, 1968., 1992., ..., 1838., 1796.,   nan],\n        [  nan, 2028., 2054., ..., 1808., 1748.,   nan],\n        [  nan, 2082., 2110., ..., 1758., 1782.,   nan],\n        ...,\n        [  nan, 1958., 1888., ..., 1786., 1830.,   nan],\n        [  nan, 1926., 1882., ..., 1802., 1816.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  nan, 2120., 2154., ..., 1946., 1898.,   nan],\n        [  nan, 2208., 2214., ..., 1910., 1908.,   nan],\n        [  nan, 2184., 2204., ..., 1908., 1932.,   nan],\n        ...,\n...\n        ...,\n        [  nan, 2008., 2084., ..., 1932., 2020.,   nan],\n        [  nan, 2082., 2080., ..., 1914., 2002.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  nan, 2862., 2850., ..., 2730., 2744.,   nan],\n        [  nan, 2820., 2878., ..., 2714., 2668.,   nan],\n        [  nan, 2890., 2972., ..., 2624., 2608.,   nan],\n        ...,\n        [  nan, 2686., 2742., ..., 2630., 2630.,   nan],\n        [  nan, 2674., 2740., ..., 2618., 2658.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  nan, 2382., 2340., ..., 2248., 2274.,   nan],\n        [  nan, 2252., 2398., ..., 2206., 2222.,   nan],\n        [  nan, 2314., 2424., ..., 2204., 2216.,   nan],\n        ...,\n        [  nan, 2306., 2354., ..., 2152., 2136.,   nan],\n        [  nan, 2302., 2336., ..., 2188., 2132.,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]]], dtype=float32)SCL(t, y, x)float32nan 5.0 5.0 5.0 ... nan nan nan nanlong_name :SCLunits :grid_mapping :crsarray([[[nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        ...,\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        ...,\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        ...,\n...\n        ...,\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        ...,\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        ...,\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan,  5.,  5., ...,  5.,  5., nan],\n        [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)NDVI(t, y, x)float32nan 0.2295 0.2313 ... nan nan nanlong_name :NDVIunits :grid_mapping :crsarray([[[       nan, 0.22949778, 0.23134796, ..., 0.28590605,\n         0.28077456,        nan],\n        [       nan, 0.24219726, 0.24304268, ..., 0.25492862,\n         0.24928775,        nan],\n        [       nan, 0.24923827, 0.25623858, ..., 0.24494068,\n         0.22986823,        nan],\n        ...,\n        [       nan, 0.24908425, 0.23902439, ..., 0.2013468 ,\n         0.21295658,        nan],\n        [       nan, 0.24431138, 0.23607749, ..., 0.2201087 ,\n         0.21458046,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan]],\n\n       [[       nan, 0.21481481, 0.22584616, ..., 0.25034013,\n         0.2577031 ,        nan],\n        [       nan, 0.2418861 , 0.25626913, ..., 0.24603721,\n         0.24857143,        nan],\n        [       nan, 0.2437276 , 0.2537136 , ..., 0.2250871 ,\n         0.23835997,        nan],\n...\n        [       nan, 0.33965087, 0.3534057 , ..., 0.32694247,\n         0.31041354,        nan],\n        [       nan, 0.33566433, 0.34050882, ..., 0.33231553,\n         0.3061425 ,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan]],\n\n       [[       nan, 0.36114284, 0.3596746 , ..., 0.3787182 ,\n         0.38027313,        nan],\n        [       nan, 0.36733454, 0.4172577 , ..., 0.3634116 ,\n         0.37841192,        nan],\n        [       nan, 0.36923078, 0.42462534, ..., 0.36301795,\n         0.37171155,        nan],\n        ...,\n        [       nan, 0.36935866, 0.36069363, ..., 0.35601765,\n         0.335     ,        nan],\n        [       nan, 0.36293665, 0.35341832, ..., 0.35985085,\n         0.35107732,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan]]], dtype=float32)Indexes: (3)tPandasIndexPandasIndex(DatetimeIndex(['2019-01-27', '2019-02-11', '2019-02-21', '2019-02-26',\n               '2019-03-03', '2019-03-13', '2019-03-23', '2019-03-28',\n               '2019-04-07', '2019-04-12', '2019-04-27', '2019-05-02',\n               '2019-05-27', '2019-06-01', '2019-06-26', '2019-07-01',\n               '2019-07-11', '2019-07-16', '2019-07-21', '2019-08-05',\n               '2019-08-15', '2019-08-20', '2019-08-30', '2019-09-04',\n               '2019-09-19', '2019-09-29', '2019-10-09', '2019-11-18',\n               '2019-11-23', '2019-12-18', '2019-12-28'],\n              dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Float64Index([344155.0, 344165.0, 344175.0, 344185.0, 344195.0, 344205.0,\n              344215.0, 344225.0, 344235.0, 344245.0, 344255.0, 344265.0,\n              344275.0, 344285.0, 344295.0, 344305.0, 344315.0, 344325.0,\n              344335.0, 344345.0, 344355.0],\n             dtype='float64', name='x'))yPandasIndexPandasIndex(Float64Index([4626435.0, 4626425.0, 4626415.0, 4626405.0, 4626395.0, 4626385.0,\n              4626375.0, 4626365.0, 4626355.0, 4626345.0, 4626335.0, 4626325.0,\n              4626315.0, 4626305.0, 4626295.0, 4626285.0, 4626275.0, 4626265.0,\n              4626255.0],\n             dtype='float64', name='y'))Attributes: (4)Conventions :CF-1.9institution :openEO platform - Geotrellis backend: 0.18.0a1description :title :\n\n\nPlot the raw NDVI time series, averaged across the parcel\n\nraw_ndvi = raw_ndvi_ds.NDVI.rename({\"t\": \"time\"})\n\nfig, ax = plt.subplots(figsize=(15, 5), dpi=120)\n\nraw_ndvi.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"Raw NDVI\")\nax.legend()\nax.grid()\n\n\n\n\n\n# Make a prediction every 5 days\n# to use the same dates as in the raw time series, just set the `prediction_period` to `None`\nsmoothed = whittaker(raw_ndvi, prediction_period=\"P5D\", smoothing_lambda=10)\n\n\nfig, ax = plt.subplots(figsize=(15, 5), dpi=120)\n\nraw_ndvi.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"Raw NDVI\", color=\"C0\")\nsmoothed.median(dim=[\"x\", \"y\"]).plot(\n    ax=ax, marker=\"x\", label=\"Smoothed NDVI\", color=\"C1\"\n)\nax.legend()\nax.grid()"
  },
  {
    "objectID": "notebook-samples/openeo/Load_Collection.html",
    "href": "notebook-samples/openeo/Load_Collection.html",
    "title": "openEO Basics: How to load a data dube from a data collection?",
    "section": "",
    "text": "This notebook provides a detailed guide on how to load a DataCube from a data collection. Additionally, it will cover how to authenticate in order to process and download data."
  },
  {
    "objectID": "notebook-samples/openeo/Load_Collection.html#setup",
    "href": "notebook-samples/openeo/Load_Collection.html#setup",
    "title": "openEO Basics: How to load a data dube from a data collection?",
    "section": "Setup",
    "text": "Setup\nImport the openeo package and connect to the Copernicus Data Space Ecosystem openEO back-end.\n\nimport openeo\nimport xarray\nimport matplotlib.pyplot as plt\n\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\nconnection\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with NullAuth&gt;\n\n\nNote the NullAuth in the representation of the connection, which indicates that we are not logged in yet.\nThe canonical way to log in is using the authenticate_oidc() method. This might, depending on your situation, trigger an authentication procedure. Follow the instructions, if any.\n\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;\n\n\nNote that the connection is now authenticated now through OidcBearerAuth."
  },
  {
    "objectID": "notebook-samples/openeo/Load_Collection.html#data-loading",
    "href": "notebook-samples/openeo/Load_Collection.html#data-loading",
    "title": "openEO Basics: How to load a data dube from a data collection?",
    "section": "Data Loading",
    "text": "Data Loading\nWith our authenticated connection, we can now start loading a data collection data to build a DataCube, filtered according to specific spatio-temporal constraints:\n\ns2_cube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n    spatial_extent={\n        \"west\": 3.20,\n        \"south\": 51.18,\n        \"east\": 3.25,\n        \"north\": 51.21,\n        \"crs\": \"EPSG:4326\",\n    },\n    bands=[\"B04\", \"B03\", \"B02\", \"SCL\"],\n    max_cloud_cover=50,\n)\n\nLet’s download this slice of data in netCDF format to give it an initial inspection.\n\ns2_cube.download(\"load-raw.nc\")\n\nQuick visualisation of first and last observation in the timeseries.\n\nds = xarray.load_dataset(\"load-raw.nc\")\n# Convert xarray DataSet to a (bands, t, x, y) DataArray\ndata = ds[[\"B04\", \"B03\", \"B02\"]].to_array(dim=\"bands\")\n\nfig, axes = plt.subplots(ncols=2, figsize=(8, 3), dpi=90, sharey=True)\ndata[{\"t\": 0}].plot.imshow(vmin=0, vmax=2000, ax=axes[0])\ndata[{\"t\": -1}].plot.imshow(vmin=0, vmax=2000, ax=axes[1]);\n\n\n\n\nNotice how the observation on the right suffers from clouds and cloud shadows."
  },
  {
    "objectID": "notebook-samples/openeo/Load_Collection.html#data-processing",
    "href": "notebook-samples/openeo/Load_Collection.html#data-processing",
    "title": "openEO Basics: How to load a data dube from a data collection?",
    "section": "Data Processing",
    "text": "Data Processing\nLet’s include a bit of extra data processing. We’ll build a naive composite image by taking the temporal maximum:\n\ncomposite = s2_cube.max_time()\n\nDownload this composite and visualize it:\n\ncomposite.download(\"load-composite.nc\")\n\n\nds = xarray.load_dataset(\"load-composite.nc\")\n# Convert xarray DataSet to a (bands, x, y) DataArray\ndata = ds[[\"B04\", \"B03\", \"B02\"]].to_array(dim=\"bands\")\n\nfig, ax = plt.subplots(ncols=1, figsize=(4, 4), dpi=90)\ndata.plot.imshow(vmin=0, vmax=2000, ax=ax)\n\n&lt;matplotlib.image.AxesImage at 0x7f5288567fd0&gt;\n\n\n\n\n\nNote how the clouds influence this composite: while the cloud shadows are eliminated by the max operation, the bright clouds ruin the composite image."
  },
  {
    "objectID": "notebook-samples/openeo/Load_Collection.html#cloud-masking",
    "href": "notebook-samples/openeo/Load_Collection.html#cloud-masking",
    "title": "openEO Basics: How to load a data dube from a data collection?",
    "section": "Cloud masking",
    "text": "Cloud masking\nIn general, to make the raw data more useful, we typically want remove the cloud pixels and only work with non-cloud data. It is very common for earth observation data to have separate masking layers that for instance indicate whether a pixel is covered by a (type of) cloud or not. For Sentinel-2, one such layer is the “scene classification” layer (band name “SCL”) generated by the Sen2Cor algorithm.\nWith openEO and the openEO Python client library, we can take this “SCL” band (which we already included before in the load_collection call) and apply cloud masking as follows.\nFirst we build a binary cloud mask from the SCL values 3 (cloud shadows), 8 (cloud medium probability) and 9 (cloud high probability):\n\nscl_band = s2_cube.band(\"SCL\")\ncloud_mask = (scl_band == 3) | (scl_band == 8) | (scl_band == 9)\n\n# TODO: TEMP WORKAROUND FOR OFFSET ERROR ON SCL BAND\ncloud_mask = (scl_band == 3 - 1000) | (scl_band == 8 - 1000) | (scl_band == 9 - 1000)\n\nBefore we can apply this mask to the cube we have to resample it, as the “SCL” layer has a “ground sample distance” of 20 meter, while it is 10 meter for the “B02”, “B03” and “B04” bands. We can easily do the resampling by referring directly to the data cube to mask.\n\ncloud_mask = cloud_mask.resample_cube_spatial(s2_cube)\n\nApply the cloud mask, and build the composite again:\n\ncube_masked = s2_cube.mask(cloud_mask)\n\ncomposite_masked = cube_masked.max_time()\n\nDownload the result and visualize it.\n\ncomposite_masked.download(\"load-composite-masked.nc\")\n\n\nds = xarray.load_dataset(\"load-composite-masked.nc\")\n# Convert xarray DataSet to a (bands, x, y) DataArray\ndata = ds[[\"B04\", \"B03\", \"B02\"]].to_array(dim=\"bands\")\n\nfig, ax = plt.subplots(ncols=1, figsize=(4, 4), dpi=90)\ndata.plot.imshow(vmin=0, vmax=2000, ax=ax);\n\n\n\n\nThe cloud masking clearly helped to build a better composte. Note however that there are still some artifacts due to the quality of the SCL band and our simple cloud mask."
  },
  {
    "objectID": "notebook-samples/geo/odata_basics.html",
    "href": "notebook-samples/geo/odata_basics.html",
    "title": "How to query CDSE Catalogue and download products",
    "section": "",
    "text": "The following example shows how to interact with the catalogue and download EO data products for further processing. We will search for cloudless Sentinel-2 L1C products over Warsaw and create an RGB true color image form one of the products found in the catalogue.\n\nImport necessary Python modules\n\n# HTTP requests\nimport requests\n\n# JSON parser\nimport json\n\n# XML parser\nimport xml.etree.ElementTree as ET\n\n# system modules\nimport os\nimport re\nimport sys\nimport random\n\n# data manipulation\nimport pandas as pd\nimport numpy as np\n\n# image manipulation\nimport rasterio\nimport matplotlib.pyplot as plt\nimport matplotlib.image\nfrom rasterio.windows import Window\n\n# file manipulation\nfrom pathlib import Path\n\n\nQuery the catalogue and get a list of products matching the search parameters\nRefer to https://documentation.dataspace.copernicus.eu/APIs/OData.html#query-collection-of-products\n\n# base URL of the product catalogue\ncatalogue_odata_url = \"https://catalogue.dataspace.copernicus.eu/odata/v1\"\n\n# search parameters\ncollection_name = \"SENTINEL-2\"\nproduct_type = \"S2MSI1C\"\nmax_cloud_cover = 1\naoi = \"POLYGON((20.888443 52.169721,21.124649 52.169721,21.124649 52.271099,20.888443 52.271099,20.888443 52.169721))\"\nsearch_period_start = \"2023-06-01T00:00:00.000Z\"\nsearch_period_end = \"2023-06-10T00:00:00.000Z\"\n\n\n\nBuild and check the search query\n\nsearch_query = f\"{catalogue_odata_url}/Products?$filter=Collection/Name eq '{collection_name}' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq '{product_type}') and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}') and ContentDate/Start gt {search_period_start} and ContentDate/Start lt {search_period_end}\"\n\nprint(f\"\"\"\\n{search_query.replace(' ', \"%20\")}\\n\"\"\")\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20'SENTINEL-2'%20and%20Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20'productType'%20and%20att/OData.CSC.StringAttribute/Value%20eq%20'S2MSI1C')%20and%20OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((20.888443%2052.169721,21.124649%2052.169721,21.124649%2052.271099,20.888443%2052.271099,20.888443%2052.169721))')%20and%20ContentDate/Start%20gt%202023-06-01T00:00:00.000Z%20and%20ContentDate/Start%20lt%202023-06-10T00:00:00.000Z\n\n\n\n\n\nRun the query and display the results\n\nresponse = requests.get(search_query).json()\nresult = pd.DataFrame.from_dict(response[\"value\"])\n\n# print first 3 results\nresult.head(3)\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\nadc9ef40-4231-446e-8265-65d85e07d743\nS2A_MSIL1C_20230606T095031_N0509_R079_T34UED_2...\napplication/octet-stream\n628718136\n2023-06-06T14:45:40.192Z\n2023-06-06T14:55:34.488Z\n2023-06-07T01:31:17.153Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2023/06/06/S2A_MSIL...\n[{'Value': '84f6c8ca3a8dfd09b8ebdcfa9b061631',...\n{'Start': '2023-06-06T09:50:31.025Z', 'End': '...\ngeography'SRID=4326;POLYGON ((22.4422542865043...\n{'type': 'Polygon', 'coordinates': [[[22.44225...\n\n\n1\napplication/octet-stream\n7954a18c-5585-4880-a9c4-ef3bc9d8c6c6\nS2B_MSIL1C_20230601T094549_N0509_R079_T34UEC_2...\napplication/octet-stream\n270482371\n2023-06-01T13:42:40.429Z\n2023-06-01T13:48:45.988Z\n2023-06-01T13:55:23.363Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2023/06/01/S2B_MSIL...\n[{'Value': 'de63c6f5614f01cc2b3e3265ab755fc8',...\n{'Start': '2023-06-01T09:45:49.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((21.370763876953 ...\n{'type': 'Polygon', 'coordinates': [[[21.37076...\n\n\n2\napplication/octet-stream\na0e9b43e-0638-4212-aee8-fb5cae2dffdf\nS2B_MSIL1C_20230601T094549_N0509_R079_T34UDC_2...\napplication/octet-stream\n334240926\n2023-06-01T13:50:41.383Z\n2023-06-01T14:00:19.601Z\n2023-06-01T14:02:33.827Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2023/06/01/S2B_MSIL...\n[{'Value': '5a1c9e1f6c40c2f8e13409d209d91581',...\n{'Start': '2023-06-01T09:45:49.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((21.1416714490104...\n{'type': 'Polygon', 'coordinates': [[[21.14167...\n\n\n\n\n\n\n\n\n\nAdd filtering by cloud coverage and repeat the query\n\nsearch_query = f\"{search_query} and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le {max_cloud_cover})\"\nprint(f\"\"\"\\n{search_query.replace(' ', \"%20\")}\\n\"\"\")\n\nresponse = requests.get(search_query).json()\nresult = pd.DataFrame.from_dict(response[\"value\"])\n\n# Print the first 3 results\nresult.head(3)\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name%20eq%20'SENTINEL-2'%20and%20Attributes/OData.CSC.StringAttribute/any(att:att/Name%20eq%20'productType'%20and%20att/OData.CSC.StringAttribute/Value%20eq%20'S2MSI1C')%20and%20OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((20.888443%2052.169721,21.124649%2052.169721,21.124649%2052.271099,20.888443%2052.271099,20.888443%2052.169721))')%20and%20ContentDate/Start%20gt%202023-06-01T00:00:00.000Z%20and%20ContentDate/Start%20lt%202023-06-10T00:00:00.000Z%20and%20Attributes/OData.CSC.DoubleAttribute/any(att:att/Name%20eq%20'cloudCover'%20and%20att/OData.CSC.DoubleAttribute/Value%20le%201)\n\n\n\n\n\n\n\n\n\n\n@odata.mediaContentType\nId\nName\nContentType\nContentLength\nOriginDate\nPublicationDate\nModificationDate\nOnline\nEvictionDate\nS3Path\nChecksum\nContentDate\nFootprint\nGeoFootprint\n\n\n\n\n0\napplication/octet-stream\n7954a18c-5585-4880-a9c4-ef3bc9d8c6c6\nS2B_MSIL1C_20230601T094549_N0509_R079_T34UEC_2...\napplication/octet-stream\n270482371\n2023-06-01T13:42:40.429Z\n2023-06-01T13:48:45.988Z\n2023-06-01T13:55:23.363Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2023/06/01/S2B_MSIL...\n[{'Value': 'de63c6f5614f01cc2b3e3265ab755fc8',...\n{'Start': '2023-06-01T09:45:49.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((21.370763876953 ...\n{'type': 'Polygon', 'coordinates': [[[21.37076...\n\n\n1\napplication/octet-stream\na0e9b43e-0638-4212-aee8-fb5cae2dffdf\nS2B_MSIL1C_20230601T094549_N0509_R079_T34UDC_2...\napplication/octet-stream\n334240926\n2023-06-01T13:50:41.383Z\n2023-06-01T14:00:19.601Z\n2023-06-01T14:02:33.827Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2023/06/01/S2B_MSIL...\n[{'Value': '5a1c9e1f6c40c2f8e13409d209d91581',...\n{'Start': '2023-06-01T09:45:49.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((21.1416714490104...\n{'type': 'Polygon', 'coordinates': [[[21.14167...\n\n\n2\napplication/octet-stream\nbadf9949-313d-464a-869e-4c5add6eab5e\nS2B_MSIL1C_20230601T094549_N0509_R079_T34UED_2...\napplication/octet-stream\n633935426\n2023-06-01T13:54:41.204Z\n2023-06-01T14:05:13.794Z\n2023-06-01T14:05:31.433Z\nTrue\n\n/eodata/Sentinel-2/MSI/L1C/2023/06/01/S2B_MSIL...\n[{'Value': '76289c4e705a458eabbba4be5bb21780',...\n{'Start': '2023-06-01T09:45:49.024Z', 'End': '...\ngeography'SRID=4326;POLYGON ((22.4484108895815...\n{'type': 'Polygon', 'coordinates': [[[22.44841...\n\n\n\n\n\n\n\n\n\nAuthenticate your account to download files\n\n# Provide CDSE account credentials - replace with your own data\nimport os\n\nusername = os.environ[\"CDSE_USERNAME\"]\npassword = os.environ[\"CDSE_PASSWORD\"]\n\n# Get authentication token\nimport certifi\n\nauth_server_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\ndata = {\n    \"client_id\": \"cdse-public\",\n    \"grant_type\": \"password\",\n    \"username\": username,\n    \"password\": password,\n}\n\nresponse = requests.post(auth_server_url, data=data, verify=True, allow_redirects=False)\naccess_token = json.loads(response.text)[\"access_token\"]\n\n\n\nSelect the product and establish authenticated session\n\n# Select identifier of the first product\nproduct_identifier = result.iloc[0, 1]\nproduct_name = result.iloc[0, 2]\n\n# Establish session\nsession = requests.Session()\nsession.headers[\"Authorization\"] = f\"Bearer {access_token}\"\n\n\n\nGet manifest file\n\n# Nodes() method lets us traverse the directory tree and retrieve single file from the product\nurl = f\"{catalogue_odata_url}/Products({product_identifier})/Nodes({product_name})/Nodes(MTD_MSIL1C.xml)/$value\"\nresponse = session.get(url, allow_redirects=False)\nwhile response.status_code in (301, 302, 303, 307):\n    url = response.headers[\"Location\"]\n    response = session.get(url, allow_redirects=False)\n\nfile = session.get(url, verify=False, allow_redirects=True)\n\n# Save the product in home directory\noutfile = Path.home() / \"MTD_MSIL1C.xml\"\noutfile.write_bytes(file.content)\n\n45819\n\n\n\n\nParse manifest file and get bands location\n\n# Pass the path of the xml document\ntree = ET.parse(str(outfile))\n# get the parent tag\nroot = tree.getroot()\n\n# Get the location of individual bands in Sentinel-2 granule\nband_location = []\nband_location.append(f\"{product_name}/{root[0][0][12][0][0][1].text}.jp2\".split(\"/\"))\nband_location.append(f\"{product_name}/{root[0][0][12][0][0][2].text}.jp2\".split(\"/\"))\nband_location.append(f\"{product_name}/{root[0][0][12][0][0][3].text}.jp2\".split(\"/\"))\n\n\n\nDownload bands\n\n# Build the url for each file using Nodes() method\nbands = []\nfor band_file in band_location:\n    url = f\"{catalogue_odata_url}/Products({product_identifier})/Nodes({product_name})/Nodes({band_file[1]})/Nodes({band_file[2]})/Nodes({band_file[3]})/Nodes({band_file[4]})/$value\"\n    response = session.get(url, allow_redirects=False)\n    while response.status_code in (301, 302, 303, 307):\n        url = response.headers[\"Location\"]\n        response = session.get(url, allow_redirects=False)\n    file = session.get(url, verify=False, allow_redirects=True)\n    # Save the product in home directory\n    outfile = Path.home() / band_file[4]\n    outfile.write_bytes(file.content)\n    bands.append(str(outfile))\n    print(\"Saved:\", band_file[4])\n\nSaved: T34UEC_20230601T094549_B02.jp2\nSaved: T34UEC_20230601T094549_B03.jp2\nSaved: T34UEC_20230601T094549_B04.jp2\n\n\n\n\nPrepare cropped patch\n\n%matplotlib inline\n\n# Crop the images to random 1000x1000 patch\nxsize, ysize = 1000, 1000\nxoff, yoff, xmax, ymax = 0, 0, 0, 0\nn = 2\n\nfor band_file in bands:\n    full_band = rasterio.open(band_file, driver=\"JP2OpenJPEG\")\n    if xmax == 0:\n        xmin, xmax = 0, full_band.width - xsize\n    if ymax == 0:\n        ymin, ymax = 0, full_band.height - ysize\n    if xoff == 0:\n        xoff, yoff = random.randint(xmin, xmax), random.randint(ymin, ymax)\n    window = Window(xoff, yoff, xsize, ysize)\n    transform = full_band.window_transform(window)\n    profile = full_band.profile\n    crs = full_band.crs\n    profile.update({\"height\": xsize, \"width\": ysize, \"transform\": transform})\n    with rasterio.open(\n        f\"{Path.home()}/patch_band_{n}.jp2\", \"w\", **profile\n    ) as patch_band:\n        # Read the data from the window and write it to the output raster\n        patch_band.write(full_band.read(window=window))\n    print(f\"Patch for band {n} created\")\n    n += 1\n\nPatch for band 2 created\nPatch for band 3 created\nPatch for band 4 created\n\n\n\n\nGenerate true color image\n\n# Read the patch files\nband2 = rasterio.open(f\"{Path.home()}/patch_band_2.jp2\", driver=\"JP2OpenJPEG\")  # blue\nband3 = rasterio.open(f\"{Path.home()}/patch_band_3.jp2\", driver=\"JP2OpenJPEG\")  # green\nband4 = rasterio.open(f\"{Path.home()}/patch_band_4.jp2\", driver=\"JP2OpenJPEG\")  # red\n\nred = band4.read(1)\ngreen = band3.read(1)\nblue = band2.read(1)\n\n# Normalize the pixel values and apply gain\ngain = 2\nred_n = np.clip(red * gain / 10000, 0, 1)\ngreen_n = np.clip(green * gain / 10000, 0, 1)\nblue_n = np.clip(blue * gain / 10000, 0, 1)\n\n# Create composite image\nrgb_composite_n = np.dstack((red_n, green_n, blue_n))\n\n# Display image\nplt.imshow(rgb_composite_n)\n\n# Save image to file\nmatplotlib.image.imsave(f\"{Path.home()}/Sentinel2_true_color.jpeg\", rgb_composite_n)\nprint(\"Saved as:\", outfile)\n\nSaved as: /home/jovyan/T34UEC_20230601T094549_B04.jp2\n\n\n\n\n\n\n\n\n\n\nExplore the CDSE Documentation to learn more about the available APIs and services:\n\n\nhttps://documentation.dataspace.copernicus.eu/Home.html"
  },
  {
    "objectID": "Roadmap/APITable.html",
    "href": "Roadmap/APITable.html",
    "title": "APIs",
    "section": "",
    "text": "API\nType\nMar-24\nApr-24\nMay-24\nJun-24\n\n\n\n\nProduct search and download\nOData\n\n\n\n\n\n\nSubscriptions API\nPUSH, PULL Available\n\n\n\n\n\nOpenSearch (Resto)\n\n\n\n\n\n\nSTAC API\nPagination, relation links and S3path attribute to items of the results\n\nNew STAC API prototype for Sentinel-2\nNew STAC API prototype for Sentinel-1 and Sentinel-5P\n\n\nSentinel Hub Catalog API\n\n\n\n\n\n\nS3\n\n\n\n\n\n\nS3fs\n\n\n\n\n\n\nData processing\nopenEO API\nRandom forest support\n\nClient-based processing\n\nBest avaiable pixel compisiting\n\nAvailability of Sentinel-3 L2 SLSTR data\n\nHR-VPP collections available\n\n\n\nSentinel Hub data collection support\n\n\n\nSentinel-3 Level 2 support\n\n\nSentinel Hub OGC API\n\n\n\nSentinel-3 Level 2 support\n\n\nSentinel Hub Process API\n\n\n\nSentinel-3 Level 2 support\n\n\nSentinel Hub Asynchronous Process API\n\n\n\nSentinel-3 Level 2 support\n\n\nSentinel Hub Batch Processing API\n\n\n\nSentinel-3 Level 2 support\n\n\nSentinel Hub Statistical API\n\n\n\nSentinel-3 Level 2 support\n\n\nSentinel Hub Batch Statistical API\n\n\n\nSentinel-3 Level 2 support\n\n\nSentinel Hub Bring your own COG API\n\n\n\n\n\n\nSentinel Hub Bring your own Zarr API\n\n\n\n\n\n\nOn Demand Production\nOn Demand Production\n\nAvailable for Sentinel-1, Sentinel-2 and Sentinel-3\n\nAvailable for Sentinel-1 SLC Bursts\n\n\nTraceability\nTraceability\n\nAvailable for Sentinel-1\nAvailable for Sentinel-3\nAvailable for Sentinel-5P"
  },
  {
    "objectID": "Roadmap/DataTable.html",
    "href": "Roadmap/DataTable.html",
    "title": "Data",
    "section": "",
    "text": "Open Data\nType\nMarch-24\nApril-24\nMay-24\nJune-24\n\n\n\n\nSentinel-1\nUser Level Data\nCompressed GRD & SLC & RAW\nGlobal Mosaics 2023\nGlobal Mosaics 2022 and current\n\n\n\nEngineering data\n\n\n\n\n\n\nAuxiliary data\n\n\nAccess to historical AUX data\n\n\n\nSentinel-2\nUser Level Data\nGlobal Quarterly Mosaics for 2022 and 2023\nGlobal Quarterly Mosaics for 2021 and Q1/2024\n\nCollection 1 available up to end-2021\n\n\nEngineering data\n\n\n\n\n\n\nAuxiliary data\n\n\nAccess to historical AUX data\n\n\n\nSentinel-3\nUser Level Data\n\n\n\n\n\n\nEngineering data\n\n\n\n\n\n\nAuxiliary data\n\n\nAccess to historical AUX data\n\n\n\nCopernicus contributing missions (CCM)\nDEM\n\n\n\n\n\n\nOptical VHR\nVHR 2018 & VHR 2021\nVHR 2015 & COP DEM\n\n\n\n\nOptical HR, HR2, MR\n\n\n\n\n\n\nSAR\n\n\nSAR Sea Ice"
  },
  {
    "objectID": "Support.html",
    "href": "Support.html",
    "title": "Support",
    "section": "",
    "text": "If you don’t find answer to your questions in the documentation portal, this page describes how to ask for support.\n\n\nImportant to know is that only users with a Copernicus Data Space Ecosystem account can ask for support. If you don’t have one yet, you can register here. If you have an issue with registering or you want to deregister, please contact us directly.\n\n\n\nNavigate to the following website.\nIn case you’re not logged in, click on LOGIN.\n\nYou will now get the Copernicus Data Space Ecosystems login form.\n\nEnter your credentials and click LOG IN.\n\n\n\nOnce you have logged in you should see this window, click SUBMIT A REQUEST.\n\nThe form used to create tickets should now appear.\n\nFrom the dropdown select what the question is about.\nEnter the subject.\nDescribe your problem in detail in the field Description.\nYou can also upload attachments such as screenshots in the Attachments section.\nOnce you’ve finished, click SUBMIT.\nYour ticket should now be submitted.\n\nYou can see its status here. You can also post additional comments and attachments.\n\n\n\nAfter logging in (as described in Step 1), you can see the status of your requests under your account. Select Requests from the drop-down.\n\nYou will now see all your requests.\n\nIf you can’t see your request here, make sure that Status “Any” is selected from the drop-down.\nYou should now see your request."
  },
  {
    "objectID": "Support.html#prerequisites",
    "href": "Support.html#prerequisites",
    "title": "Support",
    "section": "",
    "text": "Important to know is that only users with a Copernicus Data Space Ecosystem account can ask for support. If you don’t have one yet, you can register here. If you have an issue with registering or you want to deregister, please contact us directly."
  },
  {
    "objectID": "Support.html#step-1-navigate-to-the-help-center",
    "href": "Support.html#step-1-navigate-to-the-help-center",
    "title": "Support",
    "section": "",
    "text": "Navigate to the following website.\nIn case you’re not logged in, click on LOGIN.\n\nYou will now get the Copernicus Data Space Ecosystems login form.\n\nEnter your credentials and click LOG IN."
  },
  {
    "objectID": "Support.html#step-2-submit-a-request",
    "href": "Support.html#step-2-submit-a-request",
    "title": "Support",
    "section": "",
    "text": "Once you have logged in you should see this window, click SUBMIT A REQUEST.\n\nThe form used to create tickets should now appear.\n\nFrom the dropdown select what the question is about.\nEnter the subject.\nDescribe your problem in detail in the field Description.\nYou can also upload attachments such as screenshots in the Attachments section.\nOnce you’ve finished, click SUBMIT.\nYour ticket should now be submitted.\n\nYou can see its status here. You can also post additional comments and attachments."
  },
  {
    "objectID": "Support.html#accessing-your-submitted-requests",
    "href": "Support.html#accessing-your-submitted-requests",
    "title": "Support",
    "section": "",
    "text": "After logging in (as described in Step 1), you can see the status of your requests under your account. Select Requests from the drop-down.\n\nYou will now see all your requests.\n\nIf you can’t see your request here, make sure that Status “Any” is selected from the drop-down.\nYou should now see your request."
  },
  {
    "objectID": "Roadmap/AppTable.html",
    "href": "Roadmap/AppTable.html",
    "title": "Applications",
    "section": "",
    "text": "Open Services\nType\nMar-24\nApr-24\nMay-24\nJun-24\n\n\n\n\nIdentity service\nUser Registration and identity management\n\n\n\n\n\n\nBrowser\nCopernicus Browser\nCCM VHR 2021 and CCM VHR 2018\nCCM VHR 2015 and COP DEM\nCCM SAR Sea Ice Visualization\nSentinel-3 Level 2 support\n\n\nData Workspace\n\n\n\n\n\n\nopenEO Web Editor\n\n\n\n\n\n\nJupyterLab\n\n\n\n\n\n\nWeb Portal\nWeb portal\n\n\n\n\n\n\nPublic dashboard\n\n\n\n\n\n\nHelpdesk\nService desk\n\n\n\n\n\n\nUser forum\n\nNew Forum available\n\n\n\n\nMarketplace\nEO Marketplace\n\n\n\n\n\n\nOthers\nCatalogue CSV\nDownload available"
  },
  {
    "objectID": "Applications.html",
    "href": "Applications.html",
    "title": "Applications",
    "section": "",
    "text": "This section provides an overview of the EO Applications available from Copernicus Data Space Ecosystem.\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\nopenEO Algorithm Plaza\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout the Browser\n\n\n\n\n\n\n\n\n\n\n\n\n\nCatalogue CSV\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopernicus Data Space Ecosystem Dashboard\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout Data Workspace\n\n\n\n\n\n\n\n\n\n\n\n\n\nJupyterLab\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentinel Hub QGIS Plugin\n\n\n\n\n\n\n\n\n\n\n\n\n\nopenEO Web Editor\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebook-samples/openeo/NO2Covid.html",
    "href": "notebook-samples/openeo/NO2Covid.html",
    "title": "NO2 emission and COVID Lockdown effects",
    "section": "",
    "text": "The COVID-19 pandemic has had a significant effect on reducing both human and industrial activities, leading to certain positive outcomes such as a decrease in air pollutants, as discussed in this paper.\nTherefore, in this notebook, we aim to explore the trend in air pollution, focusing on the NO2 product of the Sentinel 5P collection. We will simply, compare the situation during and after the onset of COVID-19 lockdown in the Delhi region of India.\nFurther information on Sentinel-5P can be found the following links:\n\nhttps://documentation.dataspace.copernicus.eu/Data/SentinelMissions/Sentinel5P.html\nhttps://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-5P/Sentinel-5P_brings_air_pollution_into_focus\n\n\nimport openeo\n\n\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n\n1. Create a datacube for period during COVID lockdowns\n\naoi = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [77.11, 28.69],\n            [77.11, 28.56],\n            [77.29, 28.56],\n            [77.29, 28.69],\n            [77.11, 28.69],\n        ]\n    ],\n}\n\n\ns5covid = connection.load_collection(\n    \"SENTINEL_5P_L2\",\n    temporal_extent=[\"2020-06-01\", \"2021-06-30\"],\n    spatial_extent={\"west\": 77.11, \"south\": 28.56, \"east\": 77.29, \"north\": 28.69},\n    bands=[\"NO2\"],\n)\n\n\n# Now aggregate by day to avoid having multiple data per day\ns5covid = s5covid.aggregate_temporal_period(reducer=\"mean\", period=\"day\")\n\n# let's create a spatial aggregation to generate mean timeseries data\ns5covid = s5covid.aggregate_spatial(reducer=\"mean\", geometries=aoi)\n\n\n\n2. Let’s repeat the same process for Post Covid Situation\n\n# Create a datacube for period after COVID lockdowns\n\ns5post = connection.load_collection(\n    \"SENTINEL_5P_L2\",\n    temporal_extent=[\"2022-06-01\", \"2023-06-30\"],\n    spatial_extent={\"west\": 77.11, \"south\": 28.56, \"east\": 77.29, \"north\": 28.69},\n    bands=[\"NO2\"],\n)\n\n# Now aggregate by day to avoid having multiple data per day\ns5post = s5post.aggregate_temporal_period(reducer=\"mean\", period=\"day\")\n\n# Now create a spatial aggregation to generate mean timeseries data\ns5post = s5post.aggregate_spatial(reducer=\"mean\", geometries=aoi)\n\nFinally we execute them as batch jobs and download the results as netCDF. They are further plotted as shown below to study the data.\n\njob = s5covid.execute_batch(title=\"NO2 during Covid\", outputfile=\"during_covid.nc\")\n\n0:00:00 Job 'j-240115e1f4dc4beea1c133d6498ee198': send 'start'\n0:02:06 Job 'j-240115e1f4dc4beea1c133d6498ee198': running (progress N/A)\n0:02:12 Job 'j-240115e1f4dc4beea1c133d6498ee198': running (progress N/A)\n0:02:18 Job 'j-240115e1f4dc4beea1c133d6498ee198': running (progress N/A)\n0:04:08 Job 'j-240115e1f4dc4beea1c133d6498ee198': running (progress N/A)\n0:04:18 Job 'j-240115e1f4dc4beea1c133d6498ee198': running (progress N/A)\n0:06:00 Job 'j-240115e1f4dc4beea1c133d6498ee198': running (progress N/A)\n0:09:46 Job 'j-240115e1f4dc4beea1c133d6498ee198': finished (progress N/A)\n\n\n\njob = s5post.execute_batch(title=\"NO2 Post-Covid\", outputfile=\"post_covid.nc\")\n\n0:00:00 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': send 'start'\n0:01:55 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': created (progress N/A)\n0:02:01 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': created (progress N/A)\n0:03:30 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': running (progress N/A)\n0:03:48 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': running (progress N/A)\n0:03:58 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': running (progress N/A)\n0:04:11 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': running (progress N/A)\n0:04:26 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': running (progress N/A)\n0:04:45 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': running (progress N/A)\n0:05:19 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': running (progress N/A)\n0:05:49 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': running (progress N/A)\n0:07:54 Job 'j-240115fb53df44bea28bb7e8dcc1e4cd': finished (progress N/A)\n\n\n\n\nLet’s plot the result\n\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\n\n# load the results\nduringdata = xr.load_dataset(\"during_covid.nc\")\npostdata = xr.load_dataset(\"post_covid.nc\")\n\nLet’s calculate the mean along-time dimension for the window size of 30days.\n\nduringdata = duringdata.rolling(t=30).mean()\npostdata = postdata.rolling(t=30).mean()\n\n\nfig, ax1 = plt.subplots(dpi=100)\n(line1,) = ax1.plot(\n    duringdata.t, duringdata.NO2.to_numpy().flatten(), color=\"r\", label=\"During COVID\"\n)\nax1.set_xlabel(\"During COVID\")\nax1.set_ylabel(\"NO2 Level\")\nax1.xaxis.label.set_color(\"r\")\nax1.tick_params(axis=\"x\", colors=\"r\")\n\nax2 = ax1.twiny()\n(line2,) = ax2.plot(\n    postdata.t, postdata.NO2.to_numpy().flatten(), color=\"g\", label=\"Post COVID\"\n)\nax2.set_xlabel(\"Post COVID\")\n# Combine legends from both axes\nlines = [line1, line2]\nlabels = [line.get_label() for line in lines]\nax1.legend(lines, labels, loc=\"upper left\")\nax2.xaxis.label.set_color(\"g\")\nax2.tick_params(axis=\"x\", colors=\"g\")\n\n\n\n\nThe red line in the plot shows the NO2 concentration during the COVID lockdown period in a selected area of Delhi, India, and the green line represents the post-COVID period during similar months. There was a minor decline in NO2 levels during the COVID lockdown periods, showing that the air pollution (Specifically NO2) was less during the lockdown, and it increased to higher levels as life went back to normal. It also shows that the months between November and April have higher concentrations of air pollutants in Delhi compared to May and September.\nThus, taking this notebook as a reference case, further scenarios can be investigated using Sentinel 5P data within the Copernicus Data Space Ecosystem, such as PM2.5 concentration, ozone layer depletion, SO2 concentration, etc."
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html",
    "href": "notebook-samples/openeo/Batch_job.html",
    "title": "Using openEO Batch Jobs To Run Large and Heavy Workflows",
    "section": "",
    "text": "Most of the simple, basic openEO usage examples show synchronous execution of process graphs: you submit a process graph with a HTTP request and receive the result as direct response of that same request. This is only feasible if the processing doesn’t take too long (a couple of minutes at most).\nFor the heavier work, covering large regions of interest, long time series, more intensive processing, etc, you have to use batch jobs.\nThis notebook shows how to programmatically create and interact with batch job using the openEO Python client library."
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html#set-up",
    "href": "notebook-samples/openeo/Batch_job.html#set-up",
    "title": "Using openEO Batch Jobs To Run Large and Heavy Workflows",
    "section": "Set up",
    "text": "Set up\nImport openeo package and establish an authenticated connection to Copernicus Data Space Ecosystem openEO back-end.\n\nimport openeo\n\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;"
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html#build-data-cube",
    "href": "notebook-samples/openeo/Batch_job.html#build-data-cube",
    "title": "Using openEO Batch Jobs To Run Large and Heavy Workflows",
    "section": "Build data cube",
    "text": "Build data cube\nStart with a simple data cube: small spatiotemporal slice of SENTINEL2_L2A data:\n\ncube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    bands=[\"B04\", \"B03\", \"B02\"],\n    temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n    spatial_extent={\n        \"west\": 3.202609,\n        \"south\": 51.189474,\n        \"east\": 3.254708,\n        \"north\": 51.204641,\n        \"crs\": \"EPSG:4326\",\n    },\n    max_cloud_cover=50,\n)\n\nSet up output format to be GeoTIFF:\n\ncube = cube.save_result(format=\"GTiff\")"
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html#run-as-batch-job",
    "href": "notebook-samples/openeo/Batch_job.html#run-as-batch-job",
    "title": "Using openEO Batch Jobs To Run Large and Heavy Workflows",
    "section": "Run as Batch Job",
    "text": "Run as Batch Job\nThe easiest way to run our processing as a batch job is using the execute_batch() helper, which takes care of creating a batch job, starting it, and keep polling its status until it’s finished (or failed).\nWhile not necessary, it is recommended to give your batch job a descriptive title so it’s easier to identify in your job listing.\n\njob = cube.execute_batch(title=\"Slice of S2 data\")\n\n0:00:00 Job 'j-cc569e261f4a4dce83e592b0f3425985': send 'start'\n0:00:11 Job 'j-cc569e261f4a4dce83e592b0f3425985': created (progress N/A)\n0:00:16 Job 'j-cc569e261f4a4dce83e592b0f3425985': created (progress N/A)\n0:00:23 Job 'j-cc569e261f4a4dce83e592b0f3425985': created (progress N/A)\n0:00:31 Job 'j-cc569e261f4a4dce83e592b0f3425985': created (progress N/A)\n0:00:45 Job 'j-cc569e261f4a4dce83e592b0f3425985': running (progress N/A)\n0:00:58 Job 'j-cc569e261f4a4dce83e592b0f3425985': running (progress N/A)\n0:01:14 Job 'j-cc569e261f4a4dce83e592b0f3425985': running (progress N/A)\n0:01:33 Job 'j-cc569e261f4a4dce83e592b0f3425985': running (progress N/A)\n0:01:57 Job 'j-cc569e261f4a4dce83e592b0f3425985': finished (progress N/A)\n\n\nIf you need a bit more control over the lifetime of a batch job, you can do each step manually, e.g.  - create a job with job = cube.create_job() - start a job with job.start_job() - wait until job.status() reaches \"finished\""
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html#inspecting-a-job",
    "href": "notebook-samples/openeo/Batch_job.html#inspecting-a-job",
    "title": "Using openEO Batch Jobs To Run Large and Heavy Workflows",
    "section": "Inspecting a Job",
    "text": "Inspecting a Job\nA batch job on a back-end is fully identified by its job id. In case of the job we created above:\n\njob.job_id\n\n'j-cc569e261f4a4dce83e592b0f3425985'\n\n\nIt’s recommended to properly take note of the batch job id. It allows you to “reconnect” to your job (using connection.job(job_id)) on the back-end, even if it was created at another time, by another script/notebook or even with another openEO client.\nA batch job typically takes some time to finish, and you can check its status with the status() method.\n\njob.status()\n\n'finished'\n\n\nBatch job logs can be fetched with job.logs(). If you prefer a graphical, web-based interactive environment to manage and monitor your batch jobs, feel free to switch to an openEO web editor like openeo.dataspace.copernicus.eu at any time.\n\njob.logs()"
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html#fetch-batch-job-results",
    "href": "notebook-samples/openeo/Batch_job.html#fetch-batch-job-results",
    "title": "Using openEO Batch Jobs To Run Large and Heavy Workflows",
    "section": "Fetch Batch Job Results",
    "text": "Fetch Batch Job Results\nThe result of a finished batch job consists of several elements: - a STAC-compatible description (metadata) of the batch job results - one or more output files (e.g. multiple GeoTIFF or netCDF assets)\nYou can get a handle to these results with get_results():\n\nresults = job.get_results()\nresults\n\n\n    \n    \n        \n    \n    \n\n\nIn the general case, when you have one or more result files (also called “assets”), the easiest option to download them is using download_files() (plural) where you just specify a download folder (otherwise the current working directory will be used by default).\n\nresults.download_files(\"output/batch_job\")\n\n[PosixPath('output/batch_job/openEO_2022-05-08Z.tif'),\n PosixPath('output/batch_job/openEO_2022-05-15Z.tif'),\n PosixPath('output/batch_job/openEO_2022-05-18Z.tif'),\n PosixPath('output/batch_job/openEO_2022-05-28Z.tif'),\n PosixPath('output/batch_job/job-results.json')]"
  },
  {
    "objectID": "notebook-samples/openeo/Batch_job.html#visualize-the-result",
    "href": "notebook-samples/openeo/Batch_job.html#visualize-the-result",
    "title": "Using openEO Batch Jobs To Run Large and Heavy Workflows",
    "section": "Visualize the result",
    "text": "Visualize the result\n\nimport pathlib\nimport rasterio\nimport matplotlib.pyplot as plt\n\n\nfig, axes = plt.subplots(figsize=(6, 4), nrows=2, ncols=2, dpi=90)\nfor i, path in enumerate(sorted(pathlib.Path(\"output/batch_job/\").glob(\"*tif\"))[:4]):\n    data = rasterio.open(path).read()\n    ax = axes[i // 2, i % 2]\n    ax.imshow((data.transpose(1, 2, 0) / 3000).clip(0, 1))\n    ax.set_title(path.name)"
  },
  {
    "objectID": "notebook-samples/openeo/NDVI_Timeseries.html",
    "href": "notebook-samples/openeo/NDVI_Timeseries.html",
    "title": "How to create an NDVI Time series using openEO",
    "section": "",
    "text": "This notebook presents an application case, that demonstrates how to display the NDVI (Normalized Difference Vegetation Index) timeseries for specific fields. The case study showcases the process of selecting the fields and generating average NDVI timeseries data for analysis and visualization."
  },
  {
    "objectID": "notebook-samples/openeo/NDVI_Timeseries.html#setup",
    "href": "notebook-samples/openeo/NDVI_Timeseries.html#setup",
    "title": "How to create an NDVI Time series using openEO",
    "section": "Setup",
    "text": "Setup\n\nimport json\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.signal\nimport numpy as np\n\nimport openeo\n\nEstablish an authenticated connection to Copernicus Data Space Ecosystem openEO back-end.\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;"
  },
  {
    "objectID": "notebook-samples/openeo/NDVI_Timeseries.html#basic-ndvi-timeseries",
    "href": "notebook-samples/openeo/NDVI_Timeseries.html#basic-ndvi-timeseries",
    "title": "How to create an NDVI Time series using openEO",
    "section": "Basic NDVI Timeseries",
    "text": "Basic NDVI Timeseries\nWe want to calculate the NDVI values in a couple of fields in a time window of a couple of months.\nFor simplicty, we load the field geometries as an inline GeoJSON feature collection:\n\nfields = json.loads(\n    \"\"\"{\n    \"type\": \"FeatureCollection\",\n    \"features\": [\n        {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.055945487931457, 51.222709834076504], [5.064972484168688, 51.221122565090525], [5.064972484168688, 51.221122565090525], [5.067474954083448, 51.218249806779134], [5.064827929485983, 51.21689628072789], [5.05917785594747, 51.217191909908095], [5.053553857094518, 51.21807492332223], [5.055945487931457, 51.222709834076504]]]}}, \n        {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.063345886679116, 51.23087606640057], [5.06604742694687, 51.22886710731809], [5.070627820472246, 51.22874440121892], [5.068403609708207, 51.22657208381529], [5.064823257492447, 51.22676051738515], [5.064892324615199, 51.2283032878514], [5.063641745941974, 51.2285757299238], [5.062340811262595, 51.227722351687945], [5.06076005158084, 51.228042312276536], [5.063345886679116, 51.23087606640057]]]}},\n        {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.07163184674986, 51.23481147556147], [5.076706025697324, 51.23317590781036], [5.077828303041866, 51.233226237184724], [5.078024733866917, 51.23263978271262], [5.080771081607657, 51.23259097170763], [5.083734842574312, 51.23530464074437], [5.080957826735458, 51.23646091560258], [5.079752631651647, 51.23519531038643], [5.077238400183506, 51.23490534677628], [5.072856439300575, 51.23593546777778], [5.07163184674986, 51.23481147556147]]]}}, \n        {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.083897244679042, 51.23510639883143], [5.081302408741335, 51.232922477780846], [5.082963802194108, 51.233146058575876], [5.084497702305552, 51.232672717580655], [5.085732850338428, 51.2340852086282], [5.083897244679042, 51.23510639883143]]]}}\n    ]}\n\"\"\"\n)\n\nLoad the “B04” (red) and “B08” (NIR) brands from the SENTINEL2_L2A collection for the desired time window:\n\ns2cube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2020-06-01\", \"2020-10-01\"],\n    bands=[\"B04\", \"B08\"],\n)\n\nNote here that it is not necessary to specify a spatial extent in load_collection, because we will provide the field geometries in a later step. The openEO back-end will automatically limit the effective data loading to the necessary bounding box.\nCalculate the NDVI from the red and NIR bands:\n\nred = s2cube.band(\"B04\")\nnir = s2cube.band(\"B08\")\nndvi = (nir - red) / (nir + red)\n\nWith the DataCube.aggregate_spatial() method , we can calculate the mean NDVI for each of the fields.\n\ntimeseries = ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\")\n\nWe now execute this as a batch job and download the timeseries in CSV format.\n\njob = timeseries.execute_batch(out_format=\"CSV\", title=\"NDVI timeseries\")\n\n0:00:00 Job 'j-273d672147ec4603af1bb2b045ff3a3b': send 'start'\n0:00:12 Job 'j-273d672147ec4603af1bb2b045ff3a3b': created (progress N/A)\n0:00:17 Job 'j-273d672147ec4603af1bb2b045ff3a3b': created (progress N/A)\n0:00:23 Job 'j-273d672147ec4603af1bb2b045ff3a3b': created (progress N/A)\n0:00:31 Job 'j-273d672147ec4603af1bb2b045ff3a3b': created (progress N/A)\n0:00:41 Job 'j-273d672147ec4603af1bb2b045ff3a3b': created (progress N/A)\n0:00:53 Job 'j-273d672147ec4603af1bb2b045ff3a3b': created (progress N/A)\n0:01:09 Job 'j-273d672147ec4603af1bb2b045ff3a3b': running (progress N/A)\n0:01:28 Job 'j-273d672147ec4603af1bb2b045ff3a3b': running (progress N/A)\n0:01:52 Job 'j-273d672147ec4603af1bb2b045ff3a3b': running (progress N/A)\n0:02:22 Job 'j-273d672147ec4603af1bb2b045ff3a3b': running (progress N/A)\n0:03:00 Job 'j-273d672147ec4603af1bb2b045ff3a3b': running (progress N/A)\n0:03:46 Job 'j-273d672147ec4603af1bb2b045ff3a3b': finished (progress N/A)\n\n\nDownload the timeseries CSV:\n\njob.get_results().download_file(\"ndvi-results/timeseries-basic.csv\")\npd.read_csv(\"ndvi-results/timeseries-basic.csv\", index_col=0).head()\n\n\n\n\n\n\n\n\nfeature_index\navg(band_0)\n\n\ndate\n\n\n\n\n\n\n2020-07-06T00:00:00.000Z\n1\n-0.035662\n\n\n2020-07-06T00:00:00.000Z\n2\n-0.036050\n\n\n2020-07-06T00:00:00.000Z\n0\n-0.020222\n\n\n2020-07-06T00:00:00.000Z\n3\n-0.035913\n\n\n2020-08-08T00:00:00.000Z\n2\n0.651458\n\n\n\n\n\n\n\nCreate a quick plot helper to visualize the NDVI data:\n\ndef plot_timeseries(filename, figsize=(6, 3)):\n    df = pd.read_csv(filename, index_col=0)\n    df.index = pd.to_datetime(df.index)\n\n    fig, ax = plt.subplots(figsize=figsize, dpi=90)\n    df.groupby(\"feature_index\")[\"avg(band_0)\"].plot(marker=\"o\", ax=ax)\n    ax.set_title(filename.split(\"/\")[-1])\n    ax.set_ylabel(\"NDVI\")\n    ax.set_ylim(0, 1)\n    ax.legend(title=\"parcel id\", loc=\"lower left\", ncol=2)\n\n\nplot_timeseries(\"ndvi-results/timeseries-basic.csv\")"
  },
  {
    "objectID": "notebook-samples/openeo/NDVI_Timeseries.html#cloud-masking-in-ndvi",
    "href": "notebook-samples/openeo/NDVI_Timeseries.html#cloud-masking-in-ndvi",
    "title": "How to create an NDVI Time series using openEO",
    "section": "Cloud Masking in NDVI",
    "text": "Cloud Masking in NDVI\nThe result above is a good start, but there is room for improvement to get smoother NDVI profiles.\nThere are quite some outliers because we didn’t filter out cloudy observations or pixels. We can use the “SCL” (scene classification) band from the “SENTINEL2_L2A” collection to focus on non-cloud pixels. Let’s load an “SENTINEL2_L2A” data cube again, with the additional “SCL” band, and calculate the NDVI like before:\n\ns2cube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2020-06-01\", \"2020-10-01\"],\n    bands=[\"B04\", \"B08\", \"SCL\"],\n)\nred = s2cube.band(\"B04\")\nnir = s2cube.band(\"B08\")\nndvi = (nir - red) / (nir + red)\n\nNow, from the “SCL” band we will build a mask to remove everything that is not class 4 (“vegetation”) or 5 (“not vegetated”). This mask data cube is 1 for pixels which we want to remove (clouds, cloud shadow, …) and 0 for pixels we want to keep.\n\nscl = s2cube.band(\"SCL\")\nmask = ~((scl == 4) | (scl == 5))\n\nThis mask is however a bit noisy (because of imperfect classification) and to be a bit conservative we also want to expand it a bit to exclude extra pixels at cloud edges. We can do this morphological operation by using a convolution with a gaussian kernel and applying a threshold to get a binary mask again.\n\n# 2D gaussian kernel\ng = scipy.signal.windows.gaussian(11, std=1.6)\nkernel = np.outer(g, g)\nkernel = kernel / kernel.sum()\n\n# Morphological dilation of mask: convolution + threshold\nmask = mask.apply_kernel(kernel)\nmask = mask &gt; 0.1\n\nNow, we mask the NDVI data cube and do aggregation again:\n\nndvi_masked = ndvi.mask(mask)\ntimeseries_masked = ndvi_masked.aggregate_spatial(geometries=fields, reducer=\"mean\")\n\n\njob = timeseries_masked.execute_batch(out_format=\"CSV\", title=\"Maked NDVI timeseries\")\n\n0:00:00 Job 'j-7b1b93be7e624a408e7e91691676170b': send 'start'\n0:00:12 Job 'j-7b1b93be7e624a408e7e91691676170b': created (progress N/A)\n0:00:17 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:00:23 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:00:32 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:00:42 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:00:54 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:01:10 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:01:29 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:01:53 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:02:24 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:03:01 Job 'j-7b1b93be7e624a408e7e91691676170b': running (progress N/A)\n0:03:48 Job 'j-7b1b93be7e624a408e7e91691676170b': finished (progress N/A)\n\n\n\njob.get_results().download_file(\"ndvi-results/timeseries-masked.csv\")\n\nPosixPath('ndvi-results/timeseries-masked.csv')\n\n\n\nplot_timeseries(\"ndvi-results/timeseries-masked.csv\")"
  },
  {
    "objectID": "notebook-samples/openeo/NDVI_Timeseries.html#timeseries-smoothing",
    "href": "notebook-samples/openeo/NDVI_Timeseries.html#timeseries-smoothing",
    "title": "How to create an NDVI Time series using openEO",
    "section": "Timeseries Smoothing",
    "text": "Timeseries Smoothing\nAs final step in this demonstration we will add a openEO user-defined function (UDF) to the processing. A UDF allows to submit a snippet of, for example, Python code to be executed on the data at the backend side. In this case we’ll define a UDF to:\n\ninterpolate missing values (due to cloud filtering)\napply a Savitzky-Golay filter for temporal smoothing of the timeseries (using scipy.signal.savgol_filter)\n\nWe can load a UDF from an external file, but here we’ll load it as an inline snippet:\n\nudf = openeo.UDF(\n    \"\"\"\nfrom scipy.signal import savgol_filter\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    filled = array.interpolate_na(dim='t')\n    smoothed_array = savgol_filter(filled.values, 5, 2, axis=0)\n    return DataCube(xarray.DataArray(smoothed_array, dims=array. dims,coords=array.coords))\n\"\"\"\n)\n\nWe apply this UDF along the time dimension of the ndvi_masked cube we created in the previous step:\n\nndvi_smoothed = ndvi_masked.apply_dimension(code=udf, dimension=\"t\")\n\nNow, aggregate this again per field and get the time series.\n\ntimeseries_smoothed = ndvi_smoothed.aggregate_spatial(geometries=fields, reducer=\"mean\")\n\n\njob = timeseries_smoothed.execute_batch(\n    out_format=\"CSV\", title=\"Smoothed NDVI timeseries\"\n)\n\n0:00:00 Job 'j-465abc149b04431cbe9d4ea21a029c90': send 'start'\n0:00:11 Job 'j-465abc149b04431cbe9d4ea21a029c90': created (progress N/A)\n0:00:17 Job 'j-465abc149b04431cbe9d4ea21a029c90': created (progress N/A)\n0:00:23 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:00:31 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:00:41 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:00:53 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:01:09 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:01:28 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:01:52 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:02:22 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:03:00 Job 'j-465abc149b04431cbe9d4ea21a029c90': running (progress N/A)\n0:03:46 Job 'j-465abc149b04431cbe9d4ea21a029c90': finished (progress N/A)\n\n\n\njob.get_results().download_file(\"ndvi-results/timeseries-smoothed.csv\")\n\nPosixPath('ndvi-results/timeseries-smoothed.csv')\n\n\n\nplot_timeseries(\"ndvi-results/timeseries-smoothed.csv\")"
  },
  {
    "objectID": "notebook-samples/openeo/UDP.html",
    "href": "notebook-samples/openeo/UDP.html",
    "title": "User-Defined Processes (UDP) in openEO",
    "section": "",
    "text": "openEO allows processes to be chained together in a process graph to build a particular algorithm. Often, users have specific (sub)graphs that reoccur in the same process graph or even in different process graphs or algorithms. openEO back-ends allows you to store such subgraphs as so-called “User-Defined Process” (often abbreviated as UDP), and build your library of reusable openEO building blocks.\nThis notebook provides a step-by-step guide on how to create and use a User-Defined Process, for with a Normalized Difference Water Index (NDWI) use case."
  },
  {
    "objectID": "notebook-samples/openeo/UDP.html#set-up",
    "href": "notebook-samples/openeo/UDP.html#set-up",
    "title": "User-Defined Processes (UDP) in openEO",
    "section": "Set up",
    "text": "Set up\nImport a couple of packages and establish an authenticated connection\n\nimport json\nimport openeo\nfrom openeo.api.process import Parameter\n\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.dataspace.copernicus.eu/openeo/1.1/' with OidcBearerAuth&gt;"
  },
  {
    "objectID": "notebook-samples/openeo/UDP.html#building-a-parameterized-datacube",
    "href": "notebook-samples/openeo/UDP.html#building-a-parameterized-datacube",
    "title": "User-Defined Processes (UDP) in openEO",
    "section": "Building a parameterized datacube",
    "text": "Building a parameterized datacube\nThe openEO Python client lets you define parameters as Parameter instances (from openeo.api.process subpackage). In general you have to specify at least the parameter name, a description and a schema.\n\ntemporal_extent_param = Parameter(\n    name=\"date_range\",\n    description=\"The date range to load.\",\n    schema={\"type\": \"array\", \"subtype\": \"temporal-interval\"},\n)\n\nspatial_extent_param = Parameter(\n    name=\"bbox\",\n    description=\"The bounding box to load.\",\n    schema={\"type\": \"object\", \"subtype\": \"geojson\"},\n)\n\nUse the parameters directly as arguments to load_collection to build in initial data cube with SENTINEL2_L2A data.\n\nband = [\"B03\", \"B08\"]\ncube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=temporal_extent_param,\n    spatial_extent=spatial_extent_param,\n    bands=band,\n    max_cloud_cover=80,\n)\n\nThe NDWI is a vegetation index sensitive to the water content of vegetation and is complementary to the NDVI. High NDWI values show a high water content of the vegetation. \\[ \\mathrm{NDWI} = \\frac{\\mathrm{Green} - \\mathrm{NIR}}{\\mathrm{Green} + \\mathrm{NIR}} \\]\n\ngreen = cube.band(\"B03\")\nnir = cube.band(\"B08\")\n\nndwi = (green - nir) / (green + nir)\nndwi\n\n\n    \n    \n        \n    \n    \n\n\nNow, let’s produce a temporal aggregation by taking the temporal maximum value.\n\nndwi = ndwi.max_time()"
  },
  {
    "objectID": "notebook-samples/openeo/UDP.html#store-as-user-defined-process-udp",
    "href": "notebook-samples/openeo/UDP.html#store-as-user-defined-process-udp",
    "title": "User-Defined Processes (UDP) in openEO",
    "section": "Store as User-Defined Process (UDP)",
    "text": "Store as User-Defined Process (UDP)\nWe can now store this parametarized data cube representation as a user-defined process called NDWI on the back-end.\n\nconnection.save_user_defined_process(\n    user_defined_process_id=\"NDWI\",\n    process_graph=ndwi,\n    parameters=[temporal_extent_param, spatial_extent_param],\n)"
  },
  {
    "objectID": "notebook-samples/openeo/UDP.html#use-the-udp",
    "href": "notebook-samples/openeo/UDP.html#use-the-udp",
    "title": "User-Defined Processes (UDP) in openEO",
    "section": "Use the UDP",
    "text": "Use the UDP\nNow, let’s evaluate our freshly created user-defined processes “NDWI”. We can using datacube_from_process() to create a DataCube from this process and only have to provide concrete temporal and spatial extents:\n\nndwi2022 = connection.datacube_from_process(\n    process_id=\"NDWI\",\n    date_range=[\"2022-07-19\", \"2022-07-19\"],\n    bbox={\"west\": 5.09, \"south\": 51.18, \"east\": 5.15, \"north\": 51.21},\n)\n\n\nndwi2022.download(\"ndwi2022.tiff\")\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = rasterio.open(\"ndwi2022.tiff\").read()\n\nfig, ax = plt.subplots(figsize=(6, 4), dpi=90)\nimg = ax.imshow(data[0], vmin=np.percentile(data, 1), vmax=np.percentile(data, 99))\nax.set_title(\"NDWI\")\nplt.colorbar(img)\n\n&lt;matplotlib.colorbar.Colorbar at 0x7f21ae661a90&gt;"
  },
  {
    "objectID": "notebook-samples/openeo/UDF.html",
    "href": "notebook-samples/openeo/UDF.html",
    "title": "User-Defined Functions (UDF) in openEO",
    "section": "",
    "text": "While openEO supports a wide range of pre-defined processes and allows to build more complex user-defined processes from them, you sometimes need operations or algorithms that are not (yet) available or standardized as openEO process. User-Defined Functions (UDF) is an openEO feature (through the run_udf process) that aims to fill that gap by allowing a user to express (a part of) an algorithm as a Python/R/… script to be run back-end side.\nThough several types of algorithms can be used as UDF applications, in this notebook, we showcase a simple example of how to work with UDF using the openEO Python Client library.\n\n# estabish connection to the backend and authenticate it\nimport openeo\n\nconnection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n\n# load collection\n\ncube = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    bands=[\"B04\", \"B03\", \"B02\"],\n    temporal_extent=(\"2022-05-01\", \"2022-05-30\"),\n    spatial_extent={\n        \"west\": 5.05,\n        \"south\": 51.21,\n        \"east\": 5.1,\n        \"north\": 51.23,\n        \"crs\": \"EPSG:4326\",\n    },\n    max_cloud_cover=50,\n)\n\ncube = cube.reduce_dimension(dimension=\"t\", reducer=\"max\")\ncube\n\n\n    \n    \n        \n    \n    \n\n\nHere the UDF code shown in the following cell does the actual value rescaling.\n\n# Build a UDF object from an inline string with Python source code.\nudf = openeo.UDF(\n    \"\"\"\nfrom openeo.udf import XarrayDataCube\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    array.values = 0.0001 * array.values\n    return cube\n\"\"\"\n)\n\nUser can also load their UDF from a seperate file using openeo.UDF.from_file('my_udf.py') and apply it.\n\n# Apply the UDF to a cube.\nrescaled_cube = cube.apply(process=udf)\n\n\nrescaled_cube.download(\"rescale_s2.tiff\")\n\n\nVisualize the result\n\nimport rasterio\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import exposure\n\nimg = rasterio.open(\"rescale_s2.tiff\").read()\n\n\ndef normalizeimg(data):\n    data = data.astype(float)\n    for i in range(data.shape[2]):\n        p2, p98 = np.percentile(data[:, :, i], (2, 98))\n        data[:, :, i] = exposure.rescale_intensity(data[:, :, i], in_range=(p2, p98))\n    return data\n\n\nfig, ax = plt.subplots(figsize=(6, 2), dpi=150)\nax.imshow(normalizeimg(np.moveaxis(img, 0, -1)))\n\nax.set_title(\"Rescaled Image\")\n\n# Adjusting the spacing between subplots\nplt.tight_layout()\n\n# Display the figure\nplt.show()"
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html",
    "title": "Sentinel Hub Process API",
    "section": "",
    "text": "In this example notebook we show how to use Sentinel Hub Process API to download satellite imagery. We describe how to use various parameters and configurations to obtain either processed products or raw band data. For more information about the service please check the official service documentation."
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html#example-1-true-color-png-on-a-specific-date",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html#example-1-true-color-png-on-a-specific-date",
    "title": "Sentinel Hub Process API",
    "section": "Example 1: True color (PNG) on a specific date",
    "text": "Example 1: True color (PNG) on a specific date\nWe build the request according to the API Reference, using the SentinelHubRequest class. Each Process API request also needs an evalscript.\nThe information that we specify in the SentinelHubRequest object is:\n\nan evalscript,\na list of input data collections with time interval,\na format of the response,\na bounding box and it’s size (size or resolution).\n\nThe evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L1C bands.\nThe image from Jun 12th 2020 is downloaded. Without any additional parameters in the evalscript, the downloaded data will correspond to reflectance values in UINT8 format (values in 0-255 range).\n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C.define_from(\n                \"s2l1c\", service_url=config.sh_base_url\n            ),\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\ntrue_color_imgs = request_true_color.get_data()\n\nThe method get_data() will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays.\n\nprint(\n    f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\"\n)\nprint(\n    f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\"\n)\n\n\nimage = true_color_imgs[0]\nprint(f\"Image type: {image.dtype}\")\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\nplot_image(image, factor=3.5 / 255, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html#example-2-true-color-mosaic-of-least-cloudy-acquisitions",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html#example-2-true-color-mosaic-of-least-cloudy-acquisitions",
    "title": "Sentinel Hub Process API",
    "section": "Example 2: True color mosaic of least cloudy acquisitions",
    "text": "Example 2: True color mosaic of least cloudy acquisitions\nThe SentinelHubRequest automatically creates a mosaic from all available images in the given time interval. By default, the mostRecent mosaicking order is used. More information available here.\nIn this example we will provide a month long interval, order the images w.r.t. the cloud coverage on the tile level (leastCC parameter), and mosaic them in the specified order.\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C.define_from(\n                \"s2l1c\", service_url=config.sh_base_url\n            ),\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\nplot_image(request_true_color.get_data()[0], factor=3.5 / 255, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html#example-3-all-sentinel-2s-raw-band-values",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html#example-3-all-sentinel-2s-raw-band-values",
    "title": "Sentinel Hub Process API",
    "section": "Example 3: All Sentinel-2’s raw band values",
    "text": "Example 3: All Sentinel-2’s raw band values\nNow let’s define an evalscript which will return all Sentinel-2 spectral bands with raw values.\nIn this example we are downloading already quite a big chunk of data, so optimization of the request is not out of the question. Downloading raw digital numbers in the INT16 format instead of reflectances in the FLOAT32 format means that much less data is downloaded, which results in a faster download and a smaller usage of SH processing units.\nIn order to achieve this, we have to set the input units in the evalscript to DN (digital numbers) and the output sampleType argument to INT16. Additionally, we can’t pack all Sentinel-2’s 13 bands into a PNG image, so we have to set the output image type to the TIFF format via MimeType.TIFF in the request.\nThe digital numbers are in the range from 0-10000, so we have to scale the downloaded data appropriately.\n\nevalscript_all_bands = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"],\n                units: \"DN\"\n            }],\n            output: {\n                bands: 13,\n                sampleType: \"INT16\"\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B01,\n                sample.B02,\n                sample.B03,\n                sample.B04,\n                sample.B05,\n                sample.B06,\n                sample.B07,\n                sample.B08,\n                sample.B8A,\n                sample.B09,\n                sample.B10,\n                sample.B11,\n                sample.B12];\n    }\n\"\"\"\n\nrequest_all_bands = SentinelHubRequest(\n    evalscript=evalscript_all_bands,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C.define_from(\n                \"s2l1c\", service_url=config.sh_base_url\n            ),\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\nall_bands_response = request_all_bands.get_data()\n\n\n# Image showing the SWIR band B12\n# Factor 1/1e4 due to the DN band values in the range 0-10000\n# Factor 3.5 to increase the brightness\nplot_image(all_bands_response[0][:, :, 12], factor=3.5 / 1e4, vmax=1)\n\n\n# From raw bands we can also construct a False-Color image\n# False color image is (B03, B04, B08)\nplot_image(all_bands_response[0][:, :, [2, 3, 7]], factor=3.5 / 1e4, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html#example-4-save-downloaded-data-to-disk-and-read-it-from-disk",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html#example-4-save-downloaded-data-to-disk-and-read-it-from-disk",
    "title": "Sentinel Hub Process API",
    "section": "Example 4: Save downloaded data to disk and read it from disk",
    "text": "Example 4: Save downloaded data to disk and read it from disk\nAll downloaded data can be saved to disk and later read from it. Simply specify the location on disk where data should be saved (or loaded from) via the data_folder argument of the request’s constructor. When executing the request’s get_data method, set the argument save_data to True.\nThis also means that in all the future requests for data, the request will first check the provided location if the data is already there, unless you explicitly demand to redownload the data.\n\nrequest_all_bands = SentinelHubRequest(\n    data_folder=\"test_dir\",\n    evalscript=evalscript_all_bands,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C.define_from(\n                \"s2l1c\", service_url=config.sh_base_url\n            ),\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\n%%time\nall_bands_img = request_all_bands.get_data(save_data=True)\n\n\nprint(\n    \"The output directory has been created and a tiff file with all 13 bands was saved into the following structure:\\n\"\n)\n\nfor folder, _, filenames in os.walk(request_all_bands.data_folder):\n    for filename in filenames:\n        print(os.path.join(folder, filename))\n\n\n%%time\n# try to re-download the data\nall_bands_img_from_disk = request_all_bands.get_data()\n\n\n%%time\n# force the redownload\nall_bands_img_redownload = request_all_bands.get_data(redownload=True)\n\n\nExample 4.1: Save downloaded data directly to disk\nThe get_data method returns a list of numpy arrays and can save the downloaded data to disk, as we have seen in the previous example. Sometimes it is convenient to just save the data directly to disk. You can do that by using save_data method instead.\n\n%%time\nrequest_all_bands.save_data()\n\n\nprint(\n    \"The output directory has been created and a tiff file with all 13 bands was saved into the following structure:\\n\"\n)\n\nfor folder, _, filenames in os.walk(request_all_bands.data_folder):\n    for filename in filenames:\n        print(os.path.join(folder, filename))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html#example-5-other-data-collections",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html#example-5-other-data-collections",
    "title": "Sentinel Hub Process API",
    "section": "Example 5: Other Data Collections",
    "text": "Example 5: Other Data Collections\nThe sentinelhub-py package supports various data collections. The example below is shown for one of them, but the process is the same for all of them.\n\nNote:\nFor more examples and information check the documentation about Sentinel Hub data collections.\n\n\nprint(\"Supported DataCollections:\\n\")\nfor collection in DataCollection.get_available_collections():\n    print(collection)\n\nFor this example let’s download the digital elevation model data (DEM). The process is similar as before, we just provide the evalscript and create the request. More data on the DEM data collection is available here. DEM values are in meters and can be negative for areas which lie below sea level, so it is recommended to set the output format in your evalscript to FLOAT32.\n\nevalscript_dem = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output:{\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32\n    }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM]\n}\n\"\"\"\n\n\ndem_request = SentinelHubRequest(\n    evalscript=evalscript_dem,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.DEM.define_from(\n                \"dem\", service_url=config.sh_base_url\n            ),\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\ndem_data = dem_request.get_data()\n\n\n# Plot DEM map\n# vmin = 0; cutoff at sea level (0 m)\n# vmax = 120; cutoff at high values (120 m)\nplot_image(dem_data[0], factor=1.0, cmap=plt.cm.Greys_r, vmin=0, vmax=120)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html#example-6-multi-response-request-type",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html#example-6-multi-response-request-type",
    "title": "Sentinel Hub Process API",
    "section": "Example 6 : Multi-response request type",
    "text": "Example 6 : Multi-response request type\nProcess API enables downloading multiple files in one response, packed together in a TAR archive.\nWe will get the same image as before, download in the form of digital numbers (DN) as a UINT16 TIFF file. Along with the image we will download the inputMetadata which contains the normalization factor value in a JSON format.\nAfter the download we will be able to convert the INT16 digital numbers to get the FLOAT32 reflectances.\n\nevalscript = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"],\n                units: \"DN\"\n            }],\n            output: {\n                bands: 3,\n                sampleType: \"INT16\"\n            }\n        };\n    }\n\n    function updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n        outputMetadata.userData = { \"norm_factor\":  inputMetadata.normalizationFactor }\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_multitype = SentinelHubRequest(\n    evalscript=evalscript,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C.define_from(\n                \"s2l1c\", service_url=config.sh_base_url\n            ),\n            time_interval=(\"2020-06-01\", \"2020-06-30\"),\n            mosaicking_order=MosaickingOrder.LEAST_CC,\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response(\"default\", MimeType.TIFF),\n        SentinelHubRequest.output_response(\"userdata\", MimeType.JSON),\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config,\n)\n\n\n# print out information\nmulti_data = request_multitype.get_data()[0]\nmulti_data.keys()\n\n\n# normalize image\nimg = multi_data[\"default.tif\"]\nnorm_factor = multi_data[\"userdata.json\"][\"norm_factor\"]\n\nimg_float32 = img * norm_factor\n\n\nplot_image(img_float32, factor=3.5, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html#example-7-raw-dictionary-request",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html#example-7-raw-dictionary-request",
    "title": "Sentinel Hub Process API",
    "section": "Example 7 : Raw dictionary request",
    "text": "Example 7 : Raw dictionary request\nAll requests so far were built with some helper functions. We can also construct a raw dictionary as defined in the API Reference, without these helper functions, so we have full control over building the request body.\n\nrequest_raw_dict = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": betsiboka_bbox.crs.opengis_string},\n            \"bbox\": list(betsiboka_bbox),\n        },\n        \"data\": [\n            {\n                \"type\": \"S2L1C\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-06-01T00:00:00Z\",\n                        \"to\": \"2020-06-30T00:00:00Z\",\n                    },\n                    \"mosaickingOrder\": \"leastCC\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": betsiboka_size[0],\n        \"height\": betsiboka_size[1],\n        \"responses\": [\n            {\"identifier\": \"default\", \"format\": {\"type\": MimeType.TIFF.get_string()}}\n        ],\n    },\n    \"evalscript\": evalscript_true_color,\n}\n\n\n# create request\ndownload_request = DownloadRequest(\n    request_type=\"POST\",\n    url=\"https://sh.dataspace.copernicus.eu/api/v1/process\",\n    post_values=request_raw_dict,\n    data_type=MimeType.TIFF,\n    headers={\"content-type\": \"application/json\"},\n    use_session=True,\n)\n\n# execute request\nclient = SentinelHubDownloadClient(config=config)\nimg = client.download(download_request)\n\n\nplot_image(img, factor=3.5 / 255, clip_range=(0, 1))"
  },
  {
    "objectID": "notebook-samples/sentinelhub/data_download_process_request.html#example-8-multiple-timestamps-data",
    "href": "notebook-samples/sentinelhub/data_download_process_request.html#example-8-multiple-timestamps-data",
    "title": "Sentinel Hub Process API",
    "section": "Example 8 : Multiple timestamps data",
    "text": "Example 8 : Multiple timestamps data\nIt is possible to construct some logic in order to return data for multiple timestamps. By defining the time_interval parameter and some logic of splitting it, it is possible to create an SH reques per each “time slot” and then download the data from all the requests with the SentinelHubDownloadClient in sentinelhub-py. In this example we will create least cloudy monthly images for the year 2019.\nHowever, this is already a functionality built on top of this SH API package. We have extended the support for such usage in our package eo-learn. We recommend to use eo-learn for more complex cases where you need multiple timestamps or high-resolution data for larger areas.\n\nstart = datetime.datetime(2019, 1, 1)\nend = datetime.datetime(2019, 12, 31)\nn_chunks = 13\ntdelta = (end - start) / n_chunks\nedges = [(start + i * tdelta).date().isoformat() for i in range(n_chunks)]\nslots = [(edges[i], edges[i + 1]) for i in range(len(edges) - 1)]\n\nprint(\"Monthly time windows:\\n\")\nfor slot in slots:\n    print(slot)\n\n\ndef get_true_color_request(time_interval):\n    return SentinelHubRequest(\n        evalscript=evalscript_true_color,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.SENTINEL2_L1C.define_from(\n                    \"s2l1c\", service_url=config.sh_base_url\n                ),\n                time_interval=time_interval,\n                mosaicking_order=MosaickingOrder.LEAST_CC,\n            )\n        ],\n        responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n        bbox=betsiboka_bbox,\n        size=betsiboka_size,\n        config=config,\n    )\n\n\n# create a list of requests\nlist_of_requests = [get_true_color_request(slot) for slot in slots]\nlist_of_requests = [request.download_list[0] for request in list_of_requests]\n\n# download data with multiple threads\ndata = SentinelHubDownloadClient(config=config).download(\n    list_of_requests, max_threads=5\n)\n\n\n# some stuff for pretty plots\nncols = 4\nnrows = 3\naspect_ratio = betsiboka_size[0] / betsiboka_size[1]\nsubplot_kw = {\"xticks\": [], \"yticks\": [], \"frame_on\": False}\n\nfig, axs = plt.subplots(\n    ncols=ncols,\n    nrows=nrows,\n    figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n    subplot_kw=subplot_kw,\n)\n\nfor idx, image in enumerate(data):\n    ax = axs[idx // ncols][idx % ncols]\n    ax.imshow(np.clip(image * 2.5 / 255, 0, 1))\n    ax.set_title(f\"{slots[idx][0]}  -  {slots[idx][1]}\", fontsize=10)\n\nplt.tight_layout()"
  },
  {
    "objectID": "notebook-samples/sentinelhub/cloudless_process_api.html",
    "href": "notebook-samples/sentinelhub/cloudless_process_api.html",
    "title": "How to access Sentinel-2 Level 3 Cloudless Quarterly Mosaics using the Process API",
    "section": "",
    "text": "For more details on the individual steps in this notebook, compare with the “Introduction to Sentinel Hub API-s” notebook here: First we import dependencies:\n# Utilities\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport getpass\n\nfrom sentinelhub import (\n    SHConfig,\n    DataCollection,\n    SentinelHubCatalog,\n    SentinelHubRequest,\n    SentinelHubStatistical,\n    BBox,\n    bbox_to_dimensions,\n    CRS,\n    MimeType,\n    Geometry,\n)\n\nfrom utils import plot_image"
  },
  {
    "objectID": "notebook-samples/sentinelhub/cloudless_process_api.html#credentials",
    "href": "notebook-samples/sentinelhub/cloudless_process_api.html#credentials",
    "title": "How to access Sentinel-2 Level 3 Cloudless Quarterly Mosaics using the Process API",
    "section": "Credentials",
    "text": "Credentials\nCredentials for Sentinel Hub services (client_id & client_secret) can be obtained in your Dashboard. In the User Settings you can create a new OAuth Client to generate these credentials. For more detailed instructions, visit the relevant documentation page.\nIf you are a first time user of the Sentinel Hub Python package for Copernicus Data Space Ecosystem, you should create a profile specific to the Copernicus Data Space Ecosystem. You can do this in the following cell:\n\n# Only run this cell if you have not created a configuration.\n\nconfig = SHConfig()\n# config.sh_client_id = getpass.getpass(\"Enter your SentinelHub client id\")\n# config.sh_client_secret = getpass.getpass(\"Enter your SentinelHub client secret\")\nconfig.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\nconfig.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n# config.save(\"cdse\")\n\nHowever, if you have already configured a profile in Sentinel Hub Python for the Copernicus Data Space Ecosystem, then you can run the below cell entering the profile name as a string replacing profile_name.\n\n# config = SHConfig(\"profile_name\")"
  },
  {
    "objectID": "notebook-samples/sentinelhub/cloudless_process_api.html#setting-an-area-of-interest",
    "href": "notebook-samples/sentinelhub/cloudless_process_api.html#setting-an-area-of-interest",
    "title": "How to access Sentinel-2 Level 3 Cloudless Quarterly Mosaics using the Process API",
    "section": "Setting an area of interest",
    "text": "Setting an area of interest\nThe bounding box in WGS84 coordinate system is [(longitude and latitude coordinates of lower left and upper right corners)]. You can get the bbox for a different area at the bboxfinder website.\nAll requests require a bounding box to be given as an instance of sentinelhub.geometry.BBox with corresponding Coordinate Reference System (sentinelhub.constants.CRS). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from sentinelhub.constants.CRS.\n\naoi_coords_wgs84 = [12.292349, 47.810849, 12.569037, 47.967123]\n\nWhen the bounding box bounds have been defined, you can initialize the BBox of the area of interest. Using the bbox_to_dimensions utility function, you can provide the desired resolution parameter of the image in meters and obtain the output image shape. For a Process API request, the limit is 2500*2500 pixels, if the output below has larger values, you have to limit the bouding box or reduce the resolution.\n\nresolution = 100\naoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\naoi_size = bbox_to_dimensions(aoi_bbox, resolution=resolution)\n\nprint(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")\n\nImage shape at 100 m resolution: (213, 167) pixels"
  },
  {
    "objectID": "notebook-samples/sentinelhub/cloudless_process_api.html#process-api-request-for-cloudless-mosaics-as-a-byoc",
    "href": "notebook-samples/sentinelhub/cloudless_process_api.html#process-api-request-for-cloudless-mosaics-as-a-byoc",
    "title": "How to access Sentinel-2 Level 3 Cloudless Quarterly Mosaics using the Process API",
    "section": "Process API request for Cloudless mosaics as a BYOC",
    "text": "Process API request for Cloudless mosaics as a BYOC\n\nExample 1: True Color Image\nWe build the request according to the API Reference, using the SentinelHubRequest class. Each Process API request also needs an evalscript.\nThe information that we specify in the SentinelHubRequest object is: - an evalscript, - a list of input data collections with time interval, - a format of the response, - a bounding box and its size (size or resolution). .\nThe evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L2A bands with some contrast enhancement.\n\nHere the data collection is defined as a BYOC (Bring Your own COG). The collection ID for this collection can be found here:\n\n\nS2l3_cloudless_mosaic = DataCollection.define_byoc(\n    collection_id=\"5460de54-082e-473a-b6ea-d5cbe3c17cca\"\n)\n\nThen, we define the evalscript. The evalscript can be copied directly from the browser, eg. this scene (click on the &lt;/&gt; icon for the selected layer): It is different from the generic true color evalscript for a single Sentinel-2 image, since it has to take care of contrast enhancement to provide a visually pleasing image for a large area.\n\nevalscript_true_color = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B04\",\"B03\",\"B02\", \"dataMask\"],\n    output: { bands: 4 }\n  };\n}\n\n// Contrast enhance / highlight compress\n\nconst maxR = 3.0; // max reflectance\nconst midR = 0.13;\nconst sat = 1.2;\nconst gamma = 1.8;\nconst scalefac = 10000;\n\nfunction evaluatePixel(smp) {\n  const rgbLin = satEnh(sAdj(smp.B04/scalefac), sAdj(smp.B03/scalefac), sAdj(smp.B02/scalefac));\n  return [sRGB(rgbLin[0]), sRGB(rgbLin[1]), sRGB(rgbLin[2]), smp.dataMask];\n}\n\nfunction sAdj(a) {\n  return adjGamma(adj(a, midR, 1, maxR));\n}\n\nconst gOff = 0.01;\nconst gOffPow = Math.pow(gOff, gamma);\nconst gOffRange = Math.pow(1 + gOff, gamma) - gOffPow;\n\nfunction adjGamma(b) {\n  return (Math.pow((b + gOff), gamma) - gOffPow)/gOffRange;\n}\n\n// Saturation enhancement\nfunction satEnh(r, g, b) {\n  const avgS = (r + g + b) / 3.0 * (1 - sat);\n  return [clip(avgS + r * sat), clip(avgS + g * sat), clip(avgS + b * sat)];\n}\n\nfunction clip(s) {\n  return s &lt; 0 ? 0 : s &gt; 1 ? 1 : s;\n}\n\n//contrast enhancement with highlight compression\nfunction adj(a, tx, ty, maxC) {\n  var ar = clip(a / maxC, 0, 1);\n  return ar * (ar * (tx/maxC + ty -1) - ty) / (ar * (2 * tx/maxC - 1) - tx/maxC);\n}\n\nconst sRGB = (c) =&gt; c &lt;= 0.0031308 ? (12.92 * c) : (1.055 * Math.pow(c, 0.41666666666) - 0.055);\"\"\"\n\nNow we run the Process API Request. We set - the evalscript to the script we defined in the cell above, - the input data - collection to the cloudless mosaic BYOC collection we defined in the previous cell, - the time of interest directly in the request parameter - responses of the script - the bounding box and AOI size as defined above - and finally the credentials as defined in the config (the second cell) - optionally, you can also give a location to save data by mentioning the path (data_folder='./data')\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=S2l3_cloudless_mosaic,\n            time_interval=(\"2023-04-01\", \"2023-04-02\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=aoi_bbox,\n    size=aoi_size,\n    config=config,\n    data_folder=\"./data\",\n)\n\nThe method get_data() will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays.If you want to save the data, make sure to set save_data=True\n\ntrue_color_imgs = request_true_color.get_data(save_data=True)\n\n\nprint(\n    f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\"\n)\nprint(\n    f\"Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}\"\n)\n\nReturned data is of type = &lt;class 'list'&gt; and length 1.\nSingle element in the list is of type &lt;class 'numpy.ndarray'&gt; and has shape (167, 213, 4)\n\n\nNow we call the plot function to print the image that we defined above.\n\nimage = true_color_imgs[0]\nprint(f\"Image type: {image.dtype}\")\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 1 to keep brightness scaling that was already handled in the evalscript\nplot_image(image, factor=1 / 255, clip_range=(0, 1))\n\nImage type: uint8"
  },
  {
    "objectID": "notebook-samples/sentinelhub/cloudless_process_api.html#summary",
    "href": "notebook-samples/sentinelhub/cloudless_process_api.html#summary",
    "title": "How to access Sentinel-2 Level 3 Cloudless Quarterly Mosaics using the Process API",
    "section": "Summary",
    "text": "Summary\nSo what have we learnt in this notebook?\n\nHow to modify a Process API request to access a BYOC dataset such as Sentinel-2 Level3 Cloud Free Mosaics.\nVisualising the derived image in a simple way"
  },
  {
    "objectID": "notebook-samples/sentinelhub/soil_erosion_risk.html",
    "href": "notebook-samples/sentinelhub/soil_erosion_risk.html",
    "title": "Estimation of erosion risk based on bare soil periods and digital elevation model slope",
    "section": "",
    "text": "The universal soil loss equation (Wischmeier and Smith 1978) calculates soil loss per unit area based on precipitation and runoff, soil erodibility, slope length, slope steepness, land cover and management and support practices. This notebook shows how to calculate a simplified estimate based on a combination of terrain steepness and the number of days without vegetation cover. It aims to illustrate the accessibility of such datasets in the Copernicus Data Space Ecosystem, which can be complemented by local information on the other factors such as precipitation or soil properties. The notebook uses the Sentinel Hub APIs to access the data and evaluation scripts to perform the calculations on the server side. No downloading of data is needed. For a more detailed introduction to the Sentinel Hub APIs, please refer to this document.\nIn the first step, the dependencies are imported, including getpass for managing credentials, matplotlib for visualization of images, and a number of functions from the Sentinel Hub package.\nimport getpass\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sentinelhub import (\n    CRS,\n    BBox,\n    DataCollection,\n    MimeType,\n    MosaickingOrder,\n    SentinelHubRequest,\n    SentinelHubStatistical,\n    SHConfig,\n)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/soil_erosion_risk.html#get-the-number-of-bare-soil-days-over-a-certain-time-interval",
    "href": "notebook-samples/sentinelhub/soil_erosion_risk.html#get-the-number-of-bare-soil-days-over-a-certain-time-interval",
    "title": "Estimation of erosion risk based on bare soil periods and digital elevation model slope",
    "section": "Get the number of bare soil days over a certain time interval",
    "text": "Get the number of bare soil days over a certain time interval\nEvalscripts are short sections of code that perform a pixel-by-pixel mathematical operation on the spectral bands of an image or series of images. More information on evalscripts functions and features can be found in the documentation here and here respectively.\nThis evalscript combines cloud masking based on scene classification of Level-2 pixels with bare soil detection based on the Barren Soil Custom Script, and outputs counts of days of bare and vegetated soil within the requested time frame.\n\nevalscript_bare_soil = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B04\", \"B08\", \"B11\", \"B12\", \"SCL\", \"dataMask\"],\n    output: { bands: 3, sampleType: \"UINT16\" },\n    mosaicking: \"ORBIT\",\n  };\n}\n\nfunction isCloud(sample) {\n  // Define codes as invalid:\n  const invalid = [\n    0, // NO_DATA\n    1, // SATURATED_DEFECTIVE\n    3, // CLOUD_SHADOW\n    7, // CLOUD_LOW_PROBA\n    8, // CLOUD_MEDIUM_PROBA\n    9, // CLOUD_HIGH_PROBA\n    10, // THIN_CIRRUS\n  ];\n  return !invalid.includes(sample.SCL);\n}\n\nfunction evaluatePixel(samples) {\n  let [nBare, nNonBare, nCloud] = [0, 0, 0];\n  for (let i = 0; i &lt; samples.length; i++) {\n    let s = samples[i];\n    if (s.dataMask === 0) {\n      continue;\n    }\n    if (isCloud(s)) {\n      nCloud++;\n      continue;\n    }\n    // bareness index\n    let mbi =\n      (2.5 * (s.B11 + s.B04 - (s.B08 + s.B02))) /\n      (s.B11 + s.B04 + (s.B08 + s.B02));\n    if (mbi &gt; 0) {\n      nBare++;\n    } else {\n      nNonBare++;\n    }\n  }\n  return [nBare, nNonBare, nCloud];\n}\n\n\"\"\"\n\nIn the next step, we define a Sentinel Hub Process API request. For this request, we use the evalscript defined above for counting bare soil days, together with the bounding box and time range already defined. The authorization for this request is handled via the config.\nFor additional information on the Process API you can find documentation and additional code examples here.\n\nrequest = SentinelHubRequest(\n    evalscript=evalscript_bare_soil,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A.define_from(\n                \"s2l2a\", service_url=config.sh_base_url\n            ),\n            time_interval=time_interval,\n            mosaicking_order=MosaickingOrder.MOST_RECENT,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=bbox,\n    resolution=resolution,\n    config=config,\n    data_folder=\"./data\",\n)\n\n\nbare_soil = request.get_data(save_data=True)[0]\n\nThen we calculate the ratio of bare soil days to total cloud-free days for each pixel: this bare soil ratio is our final output parameter. We use matplotlib pyplot to visualize an image of this index for the study area.\nBlue areas have no bare soil but are covered by vegetation during the whole studied period. Yellow areas have high bare soil ratio, potentially open soil during the whole studied period.\n\ntotal_clear = bare_soil[:, :, 1] + bare_soil[:, :, 0]\nbare_ratio = bare_soil[:, :, 0] / total_clear\n\n# show image of bare soil ratio for the area of interest.\n\nplt.figure(figsize=(12, 12))\nplt.imshow(bare_ratio, cmap=\"cividis\");"
  },
  {
    "objectID": "notebook-samples/sentinelhub/soil_erosion_risk.html#get-terrain-slope-for-the-same-area",
    "href": "notebook-samples/sentinelhub/soil_erosion_risk.html#get-terrain-slope-for-the-same-area",
    "title": "Estimation of erosion risk based on bare soil periods and digital elevation model slope",
    "section": "Get terrain slope for the same area",
    "text": "Get terrain slope for the same area\nCopernicus Data Space Ecosystem allows users to upload their own data in a Cloud Optimized Geotiff (COG) format, ingesting it with the Bring Your Own COG (“BYOC”) API. Once a dataset is ingested, in can be made available privately or publicly, and other Sentinel Hub API requests can access the data collection via its BYOC collection ID (example here)\nTerrain slopes were calculated using the GDALDEM slope function, running on the full global 30 meter Copernicus DEM dataset. The following command was used:\n`gdaldem slope input_dem.tif slope-byoc.tif -of COG -co COMPRESS=DEFLATE -co BLOCKSIZE=1024 -co RESAMPLING=NEAREST -co OVERVIEWS=IGNORE_EXISTING` \nThis dataset of slopes is made available in Copernicus Data Space Ecosystem as a public BYOC collection, making streamlined querying and processing possible.\nHere we also define a simple evalscript that returns slope angle values directly from the dataset\n\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"slope\", \"dataMask\"],\n    output: { bands: 1, sampleType: \"FLOAT32\" },\n  };\n}\n\nfunction evaluatePixel(samples) {\n  return [samples.slope];\n}\n\"\"\"\n\nThen we define a Sentinel Hub Process API request again that calls data from the custom BYOC collection holding the slope data. We use the previously defined bounding box and time interval.\n\nslope_collection = DataCollection.define_byoc(\n    \"f57baa78-b28b-4bf1-b6b1-cc26d292007e\", service_url=config.sh_base_url\n)\nslope_request = SentinelHubRequest(\n    evalscript=evalscript,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=slope_collection,\n            time_interval=time_interval,\n            mosaicking_order=MosaickingOrder.MOST_RECENT,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=bbox,\n    resolution=resolution,\n    config=config,\n    data_folder=\"./data\",\n)\n\nWe collect raster slope data of the area of interest and timeframe from the Process API request into a the variable slope\n\nslope = slope_request.get_data(save_data=True)[0]\n\nWe visualize an image of the slopevariable using pyplot again.\n\nplt.figure(figsize=(12, 12))\nplt.imshow(slope, cmap=\"cividis\");\n\n\n\n\nThis image shows the terrain patterns and drainage network of the area. Forested areas have noisy topography, and forest edges stand out as narrow lines of steeper slopes, due to constraints of the Copernicus 30 DEM terrain dataset."
  },
  {
    "objectID": "notebook-samples/sentinelhub/soil_erosion_risk.html#calculate-relative-erosion-risk",
    "href": "notebook-samples/sentinelhub/soil_erosion_risk.html#calculate-relative-erosion-risk",
    "title": "Estimation of erosion risk based on bare soil periods and digital elevation model slope",
    "section": "Calculate relative erosion risk",
    "text": "Calculate relative erosion risk\nTo estimate erosion risk at a specific location and time, we simply calculate the product of the terrain slope and the ratio of days with bare soil. The respective weighting of these two parameters can be modified by the user.\n\nWEIGHT_BARE_SOIL = 1\nWEIGHT_SLOPE = 1\nrelative_erosion_risk = (slope / 90) * WEIGHT_SLOPE * bare_ratio * WEIGHT_BARE_SOIL\n\nTo optimize the visualization, the minimum and maximum of the erosion risk within the area and timeframe of interest is calculated below. You can set the visualization parameters vmin and vmax according to the minimum and maximum statistics to scale visualization of the result. Finally, an image is created showing the estimated erosion risk for each pixel.\n\nrelative_erosion_risk.min()\n\n0.0\n\n\n\nrelative_erosion_risk.max()\n\n0.02239825470106942\n\n\n\n# First we define a colormap. White for risk of zero, green for low risk, yellow for moderate, red for high.\ncmap = mpl.colors.LinearSegmentedColormap.from_list(\n    \"custom blue\",\n    [\n        (0, (1, 1, 1)),\n        (0.001, (0, 0.5, 0)),\n        (relative_erosion_risk.max(), (1, 1, 0)),\n        (1, (1, 0, 0)),\n    ],\n    N=256,\n)\n\n\nplt.figure(figsize=(12, 12))\n\nplt.imshow(relative_erosion_risk, cmap=cmap)\n\n\n# plt.figure(figsize=(12, 12))\n# plt.imshow(relative_erosion_risk, cmap=\"copper\", vmin=0.0, vmax=0.025);\n\n&lt;matplotlib.image.AxesImage at 0x11159653b90&gt;\n\n\n\n\n\nNow we prepare a side-by-side comparison of a true colour image of the same area and the erosion risk estimation map. The true colour image will be based on the quarterly cloudless Sentinel-2 mosaic of the same area and time - another public BYOC collection. The visualization is done via a Process API request, based on the data source collection and the evalscript for the true colour visualisation.\nFirst we define the data collection - the cloudless mosaic.\n\nS2l3_cloudless_mosaic = DataCollection.define_byoc(\n    collection_id=\"5460de54-082e-473a-b6ea-d5cbe3c17cca\"\n)\n\nThen we define an evalscript for the true color image.\n\nevalscript_true_color = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B04\",\"B03\",\"B02\", \"dataMask\"],\n    output: { bands: 4 }\n  };\n}\n\n// Contrast enhance / highlight compress\n\nconst maxR = 3.0; // max reflectance\nconst midR = 0.13;\nconst sat = 1.2;\nconst gamma = 1.8;\nconst scalefac = 10000;\n\nfunction evaluatePixel(smp) {\n  const rgbLin = satEnh(sAdj(smp.B04/scalefac), sAdj(smp.B03/scalefac), sAdj(smp.B02/scalefac));\n  return [sRGB(rgbLin[0]), sRGB(rgbLin[1]), sRGB(rgbLin[2]), smp.dataMask];\n}\n\nfunction sAdj(a) {\n  return adjGamma(adj(a, midR, 1, maxR));\n}\n\nconst gOff = 0.01;\nconst gOffPow = Math.pow(gOff, gamma);\nconst gOffRange = Math.pow(1 + gOff, gamma) - gOffPow;\n\nfunction adjGamma(b) {\n  return (Math.pow((b + gOff), gamma) - gOffPow)/gOffRange;\n}\n\n// Saturation enhancement\nfunction satEnh(r, g, b) {\n  const avgS = (r + g + b) / 3.0 * (1 - sat);\n  return [clip(avgS + r * sat), clip(avgS + g * sat), clip(avgS + b * sat)];\n}\n\nfunction clip(s) {\n  return s &lt; 0 ? 0 : s &gt; 1 ? 1 : s;\n}\n\n//contrast enhancement with highlight compression\nfunction adj(a, tx, ty, maxC) {\n  var ar = clip(a / maxC, 0, 1);\n  return ar * (ar * (tx/maxC + ty -1) - ty) / (ar * (2 * tx/maxC - 1) - tx/maxC);\n}\n\nconst sRGB = (c) =&gt; c &lt;= 0.0031308 ? (12.92 * c) : (1.055 * Math.pow(c, 0.41666666666) - 0.055);\"\"\"\n\nFinally, we create a Process API request to get a true color image for the study area.\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=S2l3_cloudless_mosaic,\n            time_interval=time_interval,\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=bbox,\n    resolution=(10, 10),\n    config=config,\n    data_folder=\"./data\",\n)\n\nWe load the data from the request into a variable again.\n\ntrue_color_imgs = request_true_color.get_data(save_data=True)\nimage = true_color_imgs[0]\n\nAnd we create a graphic of two subplots, one from the true colour image defined above, and the other from the scaled soil erosion risk map.\n\nplt.figure(figsize=(12, 24))\n\nplt.subplot(121)\nplt.imshow(image)\n\nplt.subplot(122)\nplt.imshow(relative_erosion_risk, cmap=cmap)\n\nplt.show\n\nThe resulting map of estimated erosion risk shows that forested areas have a low erosion risk, although they often occupy the steep slopes unsuitable for cultivation. The agricultural areas with steeper slopes near the valleys sides have the highest erosion risk according to this simple model.\nThis notebook shows how to use the Copernicus Data Space Ecosystem Process API to integrate image and DEM data. The API allows querying a time series of images to quantify the number of days with vegetation and bare soil respectively. Also, DEM slopes from a custom data collection can be queried from the same area. Finally these can be combined in a data product that provides a first estimation of soil erosion risk for the date and location. This workflow can be carried out anywhere in the world as a first check, but for quantitative analysis purposes, must be complemented by local information on precipitation, cultivation and soil type."
  },
  {
    "objectID": "notebook-samples/sentinelhub/soil_erosion_risk.html#adjusting-the-data-fusion-evalscript-for-statistics-api",
    "href": "notebook-samples/sentinelhub/soil_erosion_risk.html#adjusting-the-data-fusion-evalscript-for-statistics-api",
    "title": "Estimation of erosion risk based on bare soil periods and digital elevation model slope",
    "section": "Adjusting the data fusion evalscript for statistics API",
    "text": "Adjusting the data fusion evalscript for statistics API\nStatistics API is an API that allows calculation of statistical parameters of pixels or pixel time series in a streamlined way, directly outputting a table of the requested statistical metrics. These can be calculated both for an area of interest on a single image and a time series of images. For more details on Statistics API, check the documentation and some code examples here.\nIn order to run Statistics API requests with this evalscript, we need to modify it to provide erosion risk as the default output, complemented with a data mask.\n\nstat_evalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        datasource: \"s2\",\n        bands: [\"B02\", \"B04\", \"B08\", \"B11\", \"B12\", \"SCL\", \"dataMask\"],\n        mosaicking: \"ORBIT\",\n      },\n      {\n        datasource: \"slope\",\n        bands: [\"slope\", \"dataMask\"],\n        mosaicking: \"SIMPLE\",\n      },\n    ],\n    output: [\n      {\n        id: \"erosion_risk\",\n        bands: [\"ErosionRisk\"]\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }\n    ]\n  };\n}\n\nconst WEIGHT_BARE_SOIL = 1;\nconst WEIGHT_SLOPE = 1;\n\nfunction isCloud(sample) {\n  // Define codes as invalid:\n  const invalid = [\n    0, // NO_DATA\n    1, // SATURATED_DEFECTIVE\n    3, // CLOUD_SHADOW\n    7, // CLOUD_LOW_PROBA\n    8, // CLOUD_MEDIUM_PROBA\n    9, // CLOUD_HIGH_PROBA\n    10, // THIN_CIRRUS\n  ];\n  return !invalid.includes(sample.SCL);\n}\n\nfunction evaluatePixel(samples) {\n  let [nBare, nNonBare, nCloud] = [0, 0, 0];\n  for (let i = 0; i &lt; samples.s2.length; i++) {\n    let s = samples.s2[i];\n    if (s.dataMask === 0) {\n      continue;\n    }\n    if (isCloud(s)) {\n      nCloud++;\n      continue;\n    }\n    // bareness index\n    let mbi =\n      (2.5 * (s.B11 + s.B04 - (s.B08 + s.B02))) /\n      (s.B11 + s.B04 + (s.B08 + s.B02));\n    if (mbi &gt; 0) {\n      nBare++;\n    } else {\n      nNonBare++;\n    }\n  }\n  const bareRatio = nBare / (nBare + nNonBare);\n  const normalizedSlope = samples.slope[0].slope / 90;\n  const erosionRisk =\n    bareRatio * WEIGHT_BARE_SOIL * normalizedSlope * WEIGHT_SLOPE;\n  return {\n      erosion_risk: [erosionRisk],\n      dataMask: [samples.slope[0].dataMask]\n    };\n}\n\n\"\"\"\n\nNow that we have the modified evalscript, we define a process API request. In order to save data processing capacity, first we define a smaller bounding box of a few parcels. For the Process API request, it is important that we set the aggregation_interval to P1M, which means aggregation for monthly intervals. We then define the two sources of input data: Sentinel-2 L2A and the slope dataset defined from the BYOC collection before.\n\nsmaller_bbox = BBox(\n    (7.485831, 48.563885, 7.491689, 48.566001), crs=CRS.WGS84\n).transform(3035)\n\nerosion_stat = SentinelHubStatistical(\n    aggregation=SentinelHubStatistical.aggregation(\n        evalscript=stat_evalscript,\n        time_interval=time_interval,\n        aggregation_interval=\"P1M\",\n        resolution=(20, 20),\n    ),\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A.define_from(\n                \"s2l2a\", service_url=config.sh_base_url\n            ),\n            time_interval=time_interval,\n            mosaicking_order=MosaickingOrder.MOST_RECENT,\n            identifier=\"s2\",\n        ),\n        SentinelHubRequest.input_data(\n            data_collection=slope_collection,\n            time_interval=time_interval,\n            mosaicking_order=MosaickingOrder.MOST_RECENT,\n            identifier=\"slope\",\n        ),\n    ],\n    bbox=bbox,\n    config=config,\n)\n\n\nerosion_stats = erosion_stat.get_data()\n\nThe raw output of the statistics API is a set of statistics (min, max, mean, stDev, samplecount, and nodatacount), calculated for each month.\n\nerosion_stats\n\n[{'data': [{'interval': {'from': '2023-04-01T00:00:00Z',\n     'to': '2023-05-01T00:00:00Z'},\n    'outputs': {'erosion_risk': {'bands': {'ErosionRisk': {'stats': {'min': 0.0,\n         'max': 0.04839124530553818,\n         'mean': 0.00120173637284527,\n         'stDev': 0.0032264424239037037,\n         'sampleCount': 141512,\n         'noDataCount': 0}}}}}},\n   {'interval': {'from': '2023-05-01T00:00:00Z', 'to': '2023-06-01T00:00:00Z'},\n    'outputs': {'erosion_risk': {'bands': {'ErosionRisk': {'stats': {'min': 0.0,\n         'max': 0.03731662034988403,\n         'mean': 0.0009038782154514808,\n         'stDev': 0.002478568673644408,\n         'sampleCount': 141512,\n         'noDataCount': 0}}}}}},\n   {'interval': {'from': '2023-06-01T00:00:00Z', 'to': '2023-07-01T00:00:00Z'},\n    'outputs': {'erosion_risk': {'bands': {'ErosionRisk': {'stats': {'min': 0.0,\n         'max': 0.08981089293956757,\n         'mean': 0.001446468833208199,\n         'stDev': 0.004060823818060092,\n         'sampleCount': 141512,\n         'noDataCount': 0}}}}}},\n   {'interval': {'from': '2023-07-01T00:00:00Z', 'to': '2023-08-01T00:00:00Z'},\n    'outputs': {'erosion_risk': {'bands': {'ErosionRisk': {'stats': {'min': 0.0,\n         'max': 0.07137357443571091,\n         'mean': 0.0022370956518501695,\n         'stDev': 0.0051342346270820275,\n         'sampleCount': 141512,\n         'noDataCount': 0}}}}}},\n   {'interval': {'from': '2023-08-01T00:00:00Z', 'to': '2023-09-01T00:00:00Z'},\n    'outputs': {'erosion_risk': {'bands': {'ErosionRisk': {'stats': {'min': 0.0,\n         'max': 0.06835917383432388,\n         'mean': 0.0020893739542424536,\n         'stDev': 0.005594925166278125,\n         'sampleCount': 141512,\n         'noDataCount': 0}}}}}}],\n  'status': 'OK'}]\n\n\n\n# define functions to extract statistics for all acquisition dates\n\n\ndef extract_stats(date, stat_data):\n    d = {}\n    for key, value in stat_data[\"outputs\"].items():\n        stats = value[\"bands\"][\"ErosionRisk\"][\"stats\"]\n        if stats[\"sampleCount\"] != stats[\"noDataCount\"]:\n            d[\"date\"] = [date]\n            for stat_name, stat_value in stats.items():\n                if stat_name not in [\"sampleCount\", \"noDataCount\"]:\n                    d[f\"{key}_{stat_name}\"] = [stat_value]\n    return pd.DataFrame(d)\n\n\ndef read_acquisitions_stats(stat_data):\n    df_li = []\n    for aq in stat_data:\n        date = aq[\"interval\"][\"from\"][:10]\n        df_li.append(extract_stats(date, aq))\n    return pd.concat(df_li)\n\n\nresult_df1 = read_acquisitions_stats(erosion_stats[0][\"data\"])\nresult_df1\n\n\n\n\n\n\n\n\ndate\nerosion_risk_min\nerosion_risk_max\nerosion_risk_mean\nerosion_risk_stDev\n\n\n\n\n0\n2023-04-01\n0.0\n0.048391\n0.001202\n0.003226\n\n\n0\n2023-05-01\n0.0\n0.037317\n0.000904\n0.002479\n\n\n0\n2023-06-01\n0.0\n0.089811\n0.001446\n0.004061\n\n\n0\n2023-07-01\n0.0\n0.071374\n0.002237\n0.005134\n\n\n0\n2023-08-01\n0.0\n0.068359\n0.002089\n0.005595\n\n\n\n\n\n\n\n\nfig_stat, ax_stat = plt.subplots(1, 1, figsize=(12, 6))\nt1 = result_df1[\"date\"]\nndvi_mean_field1 = result_df1[\"erosion_risk_mean\"]\nndvi_std_field1 = result_df1[\"erosion_risk_stDev\"]\nax_stat.plot(t1, ndvi_mean_field1, label=\"field 1 mean\")\nax_stat.fill_between(\n    t1,\n    ndvi_mean_field1 - ndvi_std_field1,\n    ndvi_mean_field1 + ndvi_std_field1,\n    alpha=0.3,\n    label=\"field 1 stDev\",\n)\nax_stat.tick_params(axis=\"x\", labelrotation=30, labelsize=12)\nax_stat.tick_params(axis=\"y\", labelsize=12)\nax_stat.set_xlabel(\"Date\", size=15)\nax_stat.set_ylabel(\"Erosion Risk/unitless\", size=15)\nax_stat.legend(loc=\"lower right\", prop={\"size\": 12})\nax_stat.set_title(\"Erosion Risk time series\", fontsize=20)\nfor label in ax_stat.get_xticklabels()[1::2]:\n    label.set_visible(False)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/air_pollution_statistics.html",
    "href": "notebook-samples/sentinelhub/air_pollution_statistics.html",
    "title": "Comparing statistics of NO2 pollution for European cities",
    "section": "",
    "text": "from pathlib import Path\nimport getpass\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport rasterio\nimport rasterio.plot\nfrom rasterio import features\n\nfrom sentinelhub import (\n    SHConfig,\n    CRS,\n    BBox,\n    DataCollection,\n    DownloadRequest,\n    MimeType,\n    MosaickingOrder,\n    SentinelHubDownloadClient,\n    SentinelHubStatisticalDownloadClient,\n    SentinelHubRequest,\n    bbox_to_dimensions,\n    SentinelHubStatistical,\n    Geometry,\n    parse_time,\n)"
  },
  {
    "objectID": "notebook-samples/sentinelhub/air_pollution_statistics.html#outline",
    "href": "notebook-samples/sentinelhub/air_pollution_statistics.html#outline",
    "title": "Comparing statistics of NO2 pollution for European cities",
    "section": "Outline",
    "text": "Outline\nThis notebook analyses air pollution in Europe using the TROPOMI sensor on the Sentinel 5P satellite. This notebook aims to provide data to answer the following questions:\n\nWhat is the spatial distribution of NO2 concentration in Europe\nHow does the NO2 concentration vary over a year\nWhich European capitals are most affected by NO2 emissions"
  },
  {
    "objectID": "notebook-samples/sentinelhub/air_pollution_statistics.html#used-tools-and-features",
    "href": "notebook-samples/sentinelhub/air_pollution_statistics.html#used-tools-and-features",
    "title": "Comparing statistics of NO2 pollution for European cities",
    "section": "Used tools and features",
    "text": "Used tools and features\nTo carry out these analyses we will cover a few different concepts and features available on the Copernicus Dataspace Ecosystem:\n\nDownloading of Raw data using custom resolutions and bounding boxes\nCalculation of monthly mosaics on the fly in the cloud\nDirect access to timeseries data for geometries through the statistical API\n\n\nCredentials\nCredentials for Sentinel Hub services (client_id & client_secret) can be obtained in your Dashboard. In the User Settings you can create a new OAuth Client to generate these credentials. For more detailed instructions, visit the relevant documentation page.\nNow that you have your client_id & client_secret, it is recommended to configure a new profile in your Sentinel Hub Python package. Instructions on how to configure your Sentinel Hub Python package can be found here. Using these instructions you can create a profile specific to using the package for accessing Copernicus Data Space Ecosystem data collections. This is useful as changes to the the config class are usually only temporary in your notebook and by saving the configuration to your profile you won’t need to generate new credentials or overwrite/change the default profile each time you rerun or write a new Jupyter Notebook.\nIf you are a first time user of the Sentinel Hub Python package for Copernicus Data Space Ecosystem, you should create a profile specific to the Copernicus Data Space Ecosystem. You can do this in the following cell:\n\n# Only run this cell if you have not created a configuration.\n\nconfig = SHConfig()\n# config.sh_client_id = getpass.getpass(\"Enter your SentinelHub client id\")\n# config.sh_client_secret = getpass.getpass(\"Enter your SentinelHub client secret\")\nconfig.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\nconfig.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n# config.save(\"cdse\")\n\nHowever, if you have already configured a profile in Sentinel Hub Python for the Copernicus Data Space Ecosystem, then you can run the below cell entering the profile name as a string replacing profile_name.\n\n# config = SHConfig(\"profile_name\")\n\n\n\nAnalysing Spatial Distribution\nLet’s first get an overview of our study area, which is most of mainland Europe. To get this overview we first define an evalscript. An evalscript is a piece of javascript code which specifies how each pixel should be handled. For the first one we just define the input band that we want to look at, which is NO2 and return that band immediately, without carrying out any more calculations before the data is returned to us.\nFor more information on evalscripts have a look at the documentation.\n//VERSION=3\nfunction setup() {\n   return {\n    input: [\"NO2\"], // This specifies the bands that are looked at\n    output: { \n      bands: 1,\n      // This specifies in which data type the values will be returned\n      sampleType: \"FLOAT32\"\n    },\n    // Will make a simple mosaic, taking the most recent tiles to fill the bounding box\n    mosaicking: \"SIMPLE\"\n  };\n}\n\nfunction evaluatePixel(samples) {\n    // Here we could do more calculations which are applied to each pixel, \n    // but for now let's just return the value \n   return [samples.NO2] \n}\n\n# We also need to define the evalscript as a Python variable\nevalscript_raw = \"\"\"\n//VERSION=3\nfunction setup() {\n   return {\n    input: [\"NO2\"], // This specifies the bands that are looked at\n    output: { \n      bands: 1,\n      // This specifies in which data type the values will be returned\n      sampleType: \"FLOAT32\"\n    },\n    // Will make a simple mosaic, taking the most recent tiles to fill the bounding box\n    mosaicking: \"SIMPLE\"\n  };\n}\n\nfunction evaluatePixel(samples) {\n    // Here we could do more calculations which are applied to each pixel, \n    // but for now let's just return the value \n   return [samples.NO2] \n}\n\"\"\"\n\nWith the evalscript we can now make a request for data.\nThe request will take care of a lot of things for us. It will return our the data in our specified resolution and bounding box, for our specified time range and it will automatically mosaic multiple tiles together to fill the entire bounding box.\n\nbbox_europe = BBox([-12.30, 34.59, 32.52, 63.15], crs=CRS.WGS84).transform(CRS(3857))\n# This is defining the data we will use.\n# You can list all available data collections with `DataCollection.get_available_collections()`.\ndata_5p = DataCollection.SENTINEL5P.define_from(\"5p\", service_url=config.sh_base_url)\n\nrequest_raw = SentinelHubRequest(\n    evalscript=evalscript_raw,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=data_5p,\n            time_interval=(\"2023-01-01\", \"2023-05-26\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=bbox_europe,\n    # Resolution is defined in units of the bbox crs! Be careful with WGS84 since this will be in degrees!\n    # Since we have defined our bounding box in Web mercator the resolution is in meters.\n    resolution=(5500, 3500),\n    config=config,\n    data_folder=\"./data\",  # We save the data in a specified folder\n)\n\nAfter we’ve defined the request, we can get the data:\n\nraw_data = request_raw.get_data(save_data=True)\n\nNow we define a function which plots the data of the request together with the borders of the European countries, taken from the natural earth dataset.\n\ncountries = (\n    gpd.read_file(\"./data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp\")\n    .to_crs(3857)\n    .cx[bbox_europe.min_x : bbox_europe.max_x, bbox_europe.min_y : bbox_europe.max_y]\n    .reset_index(drop=True)\n)\ncountries = countries[[\"ADMIN\", \"geometry\"]]\n\n\ndef plot_request(request, bbox):\n    image_path = Path(request.data_folder) / request.get_filename_list()[0]\n    with rasterio.open(image_path) as raster:\n        fig, ax = plt.subplots(figsize=(10, 10))\n        ax.set_xlim([bbox.min_x, bbox.max_x])\n        ax.set_ylim([bbox.min_y, bbox.max_y])\n        rasterio.plot.show(raster, ax=ax)\n        countries.plot(ax=ax, facecolor=\"none\", edgecolor=\"black\")\n\n\nplot_request(request_raw, bbox_europe)\n\n\n\n\nWe can see here that even though the data is already mosaiced together, filling the entire bounding box, we do not have data everywhere since Tropomi does have a bunch of missing data per acquisition depending on atmospheric conditions.\nWith this image we can already see some patterns but let’s try to get a more representative image and take the mean of the NO2 values over an entire month to get a more complete picture.\nTo do this we do not have to download all of the data for an entire month, instead we can extend our evalscript so that the mean value for a month is calculated in the cloud for us. Doing it like this saves us a bunch of time downloading all images. So let’s have a look at the updated evalscript:\nThe most important thing that changed is that we now changed the mosaicking input to ORBIT. This gives us all acquisitions for a time series to calculate values from. In the input we also have added dataMask as a band. This will tell us, if the NO2 band has data or not. We are using this to remove acquisitions without data from our calculation.\nIn our evaluatePixel function we have added two more steps. The first one is to filter out all acquisitions which do not have data with the isClear() function. After we have filtered the time series we can calculate the mean of all values using the sum() function and the length of the clear timeseries.\nIn the end we return the mean value we have calculated.\n//VERSION=3\nfunction setup() {\n    return {\n        input: [\"NO2\", \"dataMask\"],\n        output: {\n            bands: 1,\n            sampleType: \"FLOAT32\",\n        },\n        mosaicking: \"ORBIT\"\n    };\n}\n\nfunction isClear(sample) {\n    return sample.dataMask == 1;\n}\n\nfunction sum(array) {\n    let sum = 0;\n    for (let i = 0; i &lt; array.length; i++) {\n        sum += array[i].NO2;\n    }\n    return sum;\n}\n\nfunction evaluatePixel(samples) {\n    const clearTs = samples.filter(isClear)\n    const mean = sum(clearTs) / clearTs.length\n    return [mean]\n}\n\nevalscript_mean_mosaic = \"\"\"\n//VERSION=3\nfunction setup() {\n    return {\n        input: [\"NO2\", \"dataMask\"],\n        output: {\n            bands: 1,\n            sampleType: \"FLOAT32\",\n        },\n        mosaicking: \"ORBIT\"\n    };\n}\n\nfunction isClear(sample) {\n    return sample.dataMask == 1;\n}\n\nfunction sum(array) {\n    let sum = 0;\n    for (let i = 0; i &lt; array.length; i++) {\n        sum += array[i].NO2;\n    }\n    return sum;\n}\n\nfunction evaluatePixel(samples) {\n    const clearTs = samples.filter(isClear)\n    const mean = sum(clearTs) / clearTs.length\n    return [mean]\n}\n\"\"\"\n\n\nrequest_monthly = SentinelHubRequest(\n    evalscript=evalscript_mean_mosaic,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=data_5p,\n            time_interval=(\"2022-12-01\", \"2023-01-01\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n    bbox=bbox_europe,\n    resolution=(5000, 3500),\n    config=config,\n    data_folder=\"./data\",\n)\n\nWe now made a request for an entire month of data, for December of 2022. Other than that nothing much changed in the request.\n\nmean_data = request_monthly.get_data(save_data=True)\n\n\nplot_request(request_monthly, bbox_europe)\n\n\n\n\nThis looks much better, since it is Winter the northern latitudes and the alps still do not have much data due to snow cover and low sun angles, however most of the rest of Europe is now covered by data.\nWe can clearly see NO2 hot spots around developed areas, like the Po Valley in Italy and the Ruhr area in Germany. You can also clearly make out the effect of some cities, like Istanbul and Madrid.\nIn general the distribution of values is around the lower end though. Only few pixels have much higher values.\n\nplt.stairs(*np.histogram(mean_data[0], range=(0, 0.00015), bins=25), fill=True);\n\n\n\n\n\n\nAnalysing European countries\nNow let’s look at the distribution of values per country to see which countries had the highest average NO2 values in the month.\nTo do this we rasterize all countries in our area of interest. We do this so that we can select all array values which are covered by a certain country.\n\ncountries[\"ID\"] = countries.index\n\nimage_path = Path(request_monthly.data_folder) / request_monthly.get_filename_list()[0]\nwith rasterio.open(image_path) as src:\n    affine = src.transform\n# convert gpd Dataframe to format accepted by rasterize\ngeo_iter = list(countries[[\"geometry\", \"ID\"]].itertuples(index=False, name=None))\n# This call is converting the array into a raster with the same size as our NO2 raster\ncountry_array = features.rasterize(\n    geo_iter, transform=affine, out_shape=mean_data[0].shape, fill=-1\n)\n\nNow we define two helper functions which get all NO2 values in a country and another function which calcuates the mean of those values.\n\ndef get_array(country_id):\n    return mean_data[0][country_array == country_id]\n\n\ndef get_mean(country_id):\n    return np.nanmean(get_array(country_id))\n\nThis function is then applied to the countries dataframe, to fill a new column mean which holds the mean NO2 values per country.\n\ncountries[\"mean\"] = countries.apply(lambda x: get_mean(x[\"ID\"]), axis=1)\n\n/tmp/ipykernel_5069/2776634825.py:5: RuntimeWarning: Mean of empty slice\n  return np.nanmean(get_array(country_id))\n\n\nWe can then sort by that mean value and have a look at the countries with the highest mean.\n\nsorted_df = countries.sort_values(\"mean\", ascending=False)\nsorted_df.head(10)\n\n\n\n\n\n\n\n\nADMIN\ngeometry\nID\nmean\n\n\n\n\n20\nNetherlands\nMULTIPOLYGON (((667242.940 6577267.510, 655945...\n20\n0.000108\n\n\n48\nBelgium\nPOLYGON ((470455.301 6689943.442, 479173.878 6...\n48\n0.000099\n\n\n40\nEstonia\nMULTIPOLYGON (((3044805.494 7868837.787, 30419...\n40\n0.000077\n\n\n36\nGermany\nMULTIPOLYGON (((1060209.439 6028063.653, 10408...\n36\n0.000065\n\n\n27\nLuxembourg\nPOLYGON ((680886.100 6467256.661, 679972.933 6...\n27\n0.000063\n\n\n32\nItaly\nMULTIPOLYGON (((781584.581 5768463.580, 785443...\n32\n0.000054\n\n\n14\nSan Marino\nPOLYGON ((1389852.107 5450198.738, 1383296.868...\n14\n0.000049\n\n\n30\nLatvia\nPOLYGON ((2960380.966 7492512.846, 2954738.894...\n30\n0.000049\n\n\n1\nJersey\nPOLYGON ((-224715.351 6314191.162, -223742.393...\n1\n0.000047\n\n\n24\nMonaco\nPOLYGON ((828069.165 5426902.987, 821285.634 5...\n24\n0.000047\n\n\n\n\n\n\n\nFor the 5 countries with the highest mean we are then plotting a boxplot of NO2 values.\n\n# get the country ids with the 5 highest mean values\nn_countries = 5\ncountry_ids = list(sorted_df[\"ID\"][:n_countries])\ncountry_names = list(sorted_df[\"ADMIN\"][:n_countries])\n\n\nax = sns.boxplot(data=[get_array(country_id) for country_id in country_ids])\nax.set_xticklabels(country_names);\n\n\n\n\nFrom this we can see that even though the mean of values in Germany is the 4th lowest, of the 5 countries it has the absolute highest values. We can also see that Belgium and Germany both have qutie the large variance in NO2 values, with some areas of low NO2 concentration and some areas quite high concentrations.\n\n\nAnalysing EU Capitals\nNow we want to take a look at EU capitals specifically. For this more focused analysis we want to analyse time series data. To do this we are taking advantage of another API capability, the Statistical API.\nEven for the previous analysis of European countries, if we were not interested at all in the spatial distribution of data and only interested in statistics for certain geometries, the statistical API would have been the perfect fit. It removes the need to download a lot of data to calculate statistics for areas. Instead it does all of the calculation of statistics like mean, max, min and standard deviation in the cloud and in the end only sends those values.\nAnother capability of the API is the easy chunking in regular intervals, which we will be using to make the time series.\nBut let’s first import the EU capitals:\n\n# load capitals\ncapitals = gpd.read_file(\"./data/eu_capitals.geojson\")\n\nThe evalscript for the Statistical API is quite similar to the evalscript for the Processing API. However for the statistical API to work we need to add one more output named dataMask. This provides a binary mask for the API, telling it which pixels should be included in the statistical request.\nOther than that not much changed compared to our previous request.\n\nevalscript_stat = \"\"\"\n//VERSION=3\nfunction setup() {\n    return {\n        input: [\"NO2\", \"dataMask\"],\n        output: [{ \n          id: \"default\",\n          bands: [\"NO2\"],\n          sampleType: \"FLOAT32\" \n        },\n        { \n          id: \"dataMask\",\n          bands: 1,\n        }],\n        mosaicking: \"ORBIT\"\n    };\n}\n\nfunction isClear(sample) {\n    return sample.dataMask == 1;\n}\n\nfunction sum(array) {\n    let sum = 0;\n    for (let i = 0; i &lt; array.length; i++) {\n        sum += array[i].NO2;\n    }\n    return sum;\n}\n\nfunction evaluatePixel(samples) {\n    const clearTs = samples.filter(isClear)\n    const mean = sum(clearTs) / clearTs.length\n    return {default: [mean], dataMask: [clearTs.length]}\n}\n\"\"\"\n\nNow we define the Statistical API request, for that we first define an aggregation. Here we define the time range we are interesed in. In this case it is one year of data, all of 2022. We then define the aggregation interval, this defines how many days are aggregated. Since Sentinel 5P has a very high revisit rate we can define a temporal resolution of one day. However we could just as easily make a time series of weekly or monthly values just by changing the aggregation interval to P1W or P1M respectively.\nThe size is set to 1 by 1 pixel since Sentinel 5P pixels are quite large and we are only intersted in point data for the capitals.\n\naggregation = SentinelHubStatistical.aggregation(\n    evalscript=evalscript_stat,\n    time_interval=(\"2022-01-01\", \"2023-01-01\"),\n    aggregation_interval=\"P1D\",\n    size=(1, 1),\n)\n\ninput_data = SentinelHubStatistical.input_data(\n    DataCollection.SENTINEL5P.define_from(\"5p\", service_url=config.sh_base_url)\n)\n\nrequests = []\n\nWe then create one request for each capital city. Instead of doing it like this we could also use the Batch Statistical API which is designed to calculate statistics for many polygons efficiently. Batch Statistical API will also be available on the Copernicus Browser later in 2023.\nThis list of requests is then downloaded in parallel\n\nfor geo_shape in capitals.geometry.values:\n    request = SentinelHubStatistical(\n        aggregation=aggregation,\n        input_data=[input_data],\n        geometry=Geometry(geo_shape, crs=CRS(capitals.crs)),\n        config=config,\n    )\n    requests.append(request)\n\ndownload_requests = [request.download_list[0] for request in requests]\nclient = SentinelHubStatisticalDownloadClient(config=config)\npollution_stats = client.download(download_requests, max_threads=5, show_progress=True)\n\nThis is a helper function to convert the output of the statistical API to a pandas dataframe.\n\ndef stats_to_df(stats_data):\n    \"\"\"Transform Statistical API response into a pandas.DataFrame\"\"\"\n    df_data = []\n\n    for single_data in stats_data[\"data\"]:\n        df_entry = {}\n        is_valid_entry = True\n\n        df_entry[\"interval_from\"] = parse_time(single_data[\"interval\"][\"from\"]).date()\n        df_entry[\"interval_to\"] = parse_time(single_data[\"interval\"][\"to\"]).date()\n\n        for output_name, output_data in single_data[\"outputs\"].items():\n            for band_name, band_values in output_data[\"bands\"].items():\n                band_stats = band_values[\"stats\"]\n                if band_stats[\"sampleCount\"] == band_stats[\"noDataCount\"]:\n                    is_valid_entry = False\n                    break\n\n                for stat_name, value in band_stats.items():\n                    col_name = f\"{output_name}_{band_name}_{stat_name}\"\n                    if stat_name == \"percentiles\":\n                        for perc, perc_val in value.items():\n                            perc_col_name = f\"{col_name}_{perc}\"\n                            df_entry[perc_col_name] = perc_val\n                    else:\n                        df_entry[col_name] = value\n\n        if is_valid_entry:\n            df_data.append(df_entry)\n\n    return pd.DataFrame(df_data)\n\nHere we build the dataframe from the request output.\n\nno2_dfs = [stats_to_df(polygon_stats) for polygon_stats in pollution_stats]\n\nfor df, capital in zip(no2_dfs, capitals[\"name\"].values):\n    df[\"name\"] = capital\n\nno2_df = pd.concat(no2_dfs)\nno2_df[\"month\"] = no2_df[\"interval_from\"].astype(\"datetime64[ns]\").dt.month\nno2_df.to_csv(\"./data/no2_capitals_timeseries.csv\")\nno2_df\n\n\n\n\n\n\n\n\ninterval_from\ninterval_to\ndefault_NO2_min\ndefault_NO2_max\ndefault_NO2_mean\ndefault_NO2_stDev\ndefault_NO2_sampleCount\ndefault_NO2_noDataCount\nname\n\n\n\n\n0\n2022-03-22\n2022-03-23\n0.000047\n0.000047\n0.000047\n0.0\n1\n0\nVilnius\n\n\n1\n2022-04-17\n2022-04-18\n0.000020\n0.000020\n0.000020\n0.0\n1\n0\nVilnius\n\n\n2\n2022-04-18\n2022-04-19\n0.000018\n0.000018\n0.000018\n0.0\n1\n0\nVilnius\n\n\n3\n2022-04-26\n2022-04-27\n0.000039\n0.000039\n0.000039\n0.0\n1\n0\nVilnius\n\n\n4\n2022-04-27\n2022-04-28\n0.000035\n0.000035\n0.000035\n0.0\n1\n0\nVilnius\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n170\n2022-12-25\n2022-12-26\n0.000103\n0.000103\n0.000103\n0.0\n1\n0\nVienna\n\n\n171\n2022-12-27\n2022-12-28\n0.000034\n0.000034\n0.000034\n0.0\n1\n0\nVienna\n\n\n172\n2022-12-28\n2022-12-29\n0.000047\n0.000047\n0.000047\n0.0\n1\n0\nVienna\n\n\n173\n2022-12-30\n2022-12-31\n0.000163\n0.000163\n0.000163\n0.0\n1\n0\nVienna\n\n\n174\n2022-12-31\n2023-01-01\n0.000015\n0.000015\n0.000015\n0.0\n1\n0\nVienna\n\n\n\n\n2870 rows × 9 columns\n\n\n\nWith this dataframe we can now do analysis. To give an example we are looking at the time series for a few different capital cities.\n\nsel_capitals = [\"Tallinn\", \"Berlin\", \"Rome\", \"Madrid\"]\nsns.lineplot(\n    data=no2_df.loc[no2_df[\"name\"].isin(sel_capitals)],\n    x=\"month\",\n    y=\"default_NO2_mean\",\n    hue=\"name\",\n);\n\n\n\n\nThis shows us that for most cities the NO2 concentration is seasonal, with higher values in winter than in Summer. Madrid, Berlin and Rome all share quite similar temporal patterns. Tallinn on the other hand has much lower NO2 concentration throughout.\nWith this data now acquired many different types of analysis can be carried out. This showed the advantage of statistical API, since you don’t have to download entire tiles even if you are only interested in the value of a single pixel. This makes data access much more efficient, allowing you to get started with analysis much quicker."
  },
  {
    "objectID": "Roadmap.html",
    "href": "Roadmap.html",
    "title": "Service description and evolution roadmap",
    "section": "",
    "text": "The Service description and evolution document provides a comprehensive view of all data products and services available in the frame of the Copernicus Data Space Ecosystem, both the “Copernicus Free Services” as well as the services operated by third parties.\n\n\n\n\n\n\n\nMore detailed information on the timelines for Copernicus Data Space Ecosystem data, APIs and Application updates can be found here:\n\nData timeline overview\nAPIs timeline overview\nApplications timeline overview"
  },
  {
    "objectID": "Roadmap.html#details",
    "href": "Roadmap.html#details",
    "title": "Service description and evolution roadmap",
    "section": "",
    "text": "More detailed information on the timelines for Copernicus Data Space Ecosystem data, APIs and Application updates can be found here:\n\nData timeline overview\nAPIs timeline overview\nApplications timeline overview"
  },
  {
    "objectID": "404-not-found.html",
    "href": "404-not-found.html",
    "title": "Page not found",
    "section": "",
    "text": "Page not found"
  },
  {
    "objectID": "ResearchNetwork.html",
    "href": "ResearchNetwork.html",
    "title": "Access through Research Network",
    "section": "",
    "text": "This section provides the most important information for users intending to access the Copernicus Data Space Ecosystem data repository through the GEANT network."
  },
  {
    "objectID": "ResearchNetwork.html#introduction",
    "href": "ResearchNetwork.html#introduction",
    "title": "Access through Research Network",
    "section": "Introduction",
    "text": "Introduction\nTo ease your first steps in the new Copernicus Data Space Ecosystem environment, we prepared a Step-by-Step guide for your reference. It is addressed to users who want to use data retrieval services for downloading products using the research networks (GEANT connectivity).\nWe would like to inform that the current setup for downloading Copernicus Data utilising research network connectivity (via NREN+GEANT) is still in a process of optimisation to achieve best possible performance. This primarily concerns the load balancing mechanism which is based on a Global Service Load Balancer (GSLB) using the requesting party’s DNS resolver as a criterion where to direct the request."
  },
  {
    "objectID": "ResearchNetwork.html#instructions",
    "href": "ResearchNetwork.html#instructions",
    "title": "Access through Research Network",
    "section": "Instructions",
    "text": "Instructions\n\n1. Introduction to Copernicus Data Space environment\nDiscover the new services on the Copernicus Data Space Ecosystem portal.\nUse the documentation portal.\n\n\n2. Become a registered user\nIf you don’t have an account, you need to register as a new user. Follow the steps on User registration and authentication.\n\n\n3. Request a KeyCloak token\nThis is required to access to OData catalogue API.\nTo get the token you can follow the steps on Access token.\n\n\n4. Use OData catalogue API to search the products\nAs a default configuration you can use the general URL https://catalogue.dataspace.copernicus.eu/odata/v1/Products.\nThe prerequisite for using this URL is the correct set up of the DNS resolver as described below in Verification of data download via the research network. This is the recommended setup as it will take advantage of the Global Service Load Balancer (GSLB) mechanism.\nAlternatively, you can also use https://catalogue.ams.dataspace.copernicus.eu/odata/v1/Products.\nThis URL directs you to the designated endpoint utilizing GEANT connectivity.\n\n\n5. Use script for data download\nOnce you have your token and product Id, you can download the product using a script:\n\ncURL\n\n\ncurl -O -J -k --header \"Authorization: Bearer ${KEYCLOAK_TOKEN}\" 'https://catalogue.ams.dataspace.copernicus.eu/odata/v1/Products(d7e6cd54-7d53-5569-8a9e-d148bcb8917e)/$value' \n\n\n\nalternative download is possible\n\ncURL\n\n\ncurl -O -J -k --header \"Authorization: Bearer ${KEYCLOAK_TOKEN}\" 'https://download.ams.dataspace.copernicus.eu/odata/v1/Products(d7e6cd54-7d53-5569-8a9e-d148bcb8917e)/$value' \n\n\n\n\n\n6. S3 access (optional)\nTo access EO data via S3, please refer to S3 Access."
  },
  {
    "objectID": "ResearchNetwork.html#verification-of-data-download-via-the-research-network",
    "href": "ResearchNetwork.html#verification-of-data-download-via-the-research-network",
    "title": "Access through Research Network",
    "section": "Verification of data download via the research network",
    "text": "Verification of data download via the research network\nTo verify that your service has been set up correctly, please perform following steps:\n\ncommand\n\n\nhost catalogue.ams.dataspace.copernicus.eu\n\n\n\nShould resolve IP addresses to\n\ndownload.ams.dataspace.copernicus.eu has address 80.158.97.159\n\n\ndownload.ams.dataspace.copernicus.eu has address 80.158.97.12\n\n\ndownload.ams.dataspace.copernicus.eu has address 80.158.97.1\n\n\ndownload.ams.dataspace.copernicus.eu has address 80.158.97.169\n\nIf your DNS resolver is utilizing an IPv4 assigned to the Geant network, you should expect to receive an identical set of IP addresses. However, if this is not the case, it indicates that the resolver needs to be added to our service configuration."
  },
  {
    "objectID": "ResearchNetwork.html#global-service-load-balancer",
    "href": "ResearchNetwork.html#global-service-load-balancer",
    "title": "Access through Research Network",
    "section": "Global Service Load Balancer",
    "text": "Global Service Load Balancer\nTo ensure proper routing of user traffic through the Geant network to the designated endpoint, it is essential for the DNS resolver to be operational within the Geant network. Alternatively, we kindly request you to provide us with the public address of your resolver to enhance our configuration. It is essential to emphasize that it is not recommended to utilize widely known resolvers such as Google’s 8.8.8.8 or CloudFlare’s 1.1.1.1 in this particular context. In such cases, traffic directed to those resolvers will be routed to public endpoints via the Internet rather than through the Geant connectivity.\nOnce the DNS set up has been configured in line with above requirements the following general URL should be used to access the OData catalogue.\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products\nThe GSLB automatically routes users to the foreseen endpoint. The mechanism will also be used for failover in case of outages on one of the cloud platforms (Open Telekom Cloud or Cloud Ferro Cloud)."
  },
  {
    "objectID": "ResearchNetwork.html#relevant-ip-addresses",
    "href": "ResearchNetwork.html#relevant-ip-addresses",
    "title": "Access through Research Network",
    "section": "Relevant IP Addresses",
    "text": "Relevant IP Addresses\nIn case your firewall setting blocks IP addresses relevant for the data download function please find following IP Address ranges which are relevant. You may have to change your firewall rules to allow traffic from those Addresses.\n❯ host catalogue.ams.dataspace.copernicus.eu\n\ncatalogue.ams.dataspace.copernicus.eu has address 80.158.97.1\n\n\ncatalogue.ams.dataspace.copernicus.eu has address 80.158.97.159\n\n\ncatalogue.ams.dataspace.copernicus.eu has address 80.158.97.12\n\n\ncatalogue.ams.dataspace.copernicus.eu has address 80.158.97.169\n\n❯ host download.ams.dataspace.copernicus.eu\n\ncatalogue.ams.dataspace.copernicus.eu has address 80.158.97.1\n\n\ncatalogue.ams.dataspace.copernicus.eu has address 80.158.97.159\n\n\ncatalogue.ams.dataspace.copernicus.eu has address 80.158.97.12\n\n\ncatalogue.ams.dataspace.copernicus.eu has address 80.158.97.169\n\n❯ host eodata.ams.dataspace.copernicus.eu\n\neodata.ams.dataspace.copernicus.eu has address 80.158.97.24\n\n\neodata.ams.dataspace.copernicus.eu has address 80.158.97.202"
  },
  {
    "objectID": "Usecase.html",
    "href": "Usecase.html",
    "title": "Jupyter Notebook Samples",
    "section": "",
    "text": "In this page, we present a compilation of Jupyter Notebooks showcasing the utilization of available data analyzed through the openEO API and the Sentinel Hub API across various use cases. These notebooks are categorized and will expand over time. Written in Python, they are designed to be executed in a Jupyter environment.\nThe notebooks serve as a foundational resource for users, offering a starting point to acquaint themselves with the openEO API and the Sentinel Hub API. Users are encouraged to explore these notebooks when developing their workflow."
  },
  {
    "objectID": "Usecase.html#land-monitoring-related-examples",
    "href": "Usecase.html#land-monitoring-related-examples",
    "title": "Jupyter Notebook Samples",
    "section": "Land monitoring related examples",
    "text": "Land monitoring related examples\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\nBest available pixel composite\n\n\n\n\n\n\n\n\n\n\n\nClassification of Ice and Open Water in Nizhnesvirsky Lower Bay using Sentinel-1 IW Product\n\n\n\n\n\n\n\n\n\n\n\nDeforestation Monitoring using Sentinel 2 and xarray\n\n\n\n\n\n\n\n\n\n\n\nEstimation of erosion risk based on bare soil periods and digital elevation model slope\n\n\n\n\n\n\n\n\n\n\n\nParcel delineation using Sentinel-2\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Usecase.html#atmospheric-monitoring-related-examples",
    "href": "Usecase.html#atmospheric-monitoring-related-examples",
    "title": "Jupyter Notebook Samples",
    "section": "Atmospheric monitoring related examples",
    "text": "Atmospheric monitoring related examples\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\nComparing statistics of NO2 pollution for European cities\n\n\n\n\n\n\n\n\n\n\n\nNO2 emission and COVID Lockdown effects\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Usecase.html#agriculture-related-examples",
    "href": "Usecase.html#agriculture-related-examples",
    "title": "Jupyter Notebook Samples",
    "section": "Agriculture related examples",
    "text": "Agriculture related examples\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\nCalculate Radar Vegetation Index(RVI) using Sentinel-1 GRD collection\n\n\n\n\n\n\n\n\n\n\n\nHow to create an NDVI Time series using openEO\n\n\n\n\n\n\n\n\n\n\n\nRank composites\n\n\n\n\n\n\n\n\n\n\n\nSurface Soil Moisture (SSM)\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Usecase.html#disaster-monitoring-examples",
    "href": "Usecase.html#disaster-monitoring-examples",
    "title": "Jupyter Notebook Samples",
    "section": "Disaster monitoring examples",
    "text": "Disaster monitoring examples\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\nHeatwave in the Netherlands\n\n\n\n\n\n\n\n\n\n\n\nNDVI-based approach to study Landslide areas\n\n\n\n\n\n\n\n\n\n\n\nWildfire mapping using Sentinel-2\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Usecase.html#additional-examples",
    "href": "Usecase.html#additional-examples",
    "title": "Jupyter Notebook Samples",
    "section": "Additional examples",
    "text": "Additional examples\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\nCreating a smoothed dataset using Whittaker\n\n\n\n\n\n\n\n\n\n\n\nCreating multi-mission, multi-temporal datacube\n\n\n\n\n\n\n\n\n\n\n\nFirst Steps in accessing Satellite Imagery on Copernicus Data Space Ecosystem with Sentinel Hub APIs\n\n\n\n\n\n\n\n\n\n\n\nHow to access Sentinel-2 Level 3 Cloudless Quarterly Mosaics using the Process API\n\n\n\n\n\n\n\n\n\n\n\nMigrating your workflows from The Copernicus Open Access Hub to the Copernicus Data Space Ecosystem\n\n\n\n\n\n\n\n\n\n\n\nUser-Defined Functions (UDF) in openEO\n\n\n\n\n\n\n\n\n\n\n\nUser-Defined Processes (UDP) in openEO\n\n\n\n\n\n\n\n\n\n\n\nopenEO Basics: How to load a data dube from a data collection?\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html",
    "href": "Applications/PlazaDetails/ServiceMaturity.html",
    "title": "Service Maturity",
    "section": "",
    "text": "All the services on the openEO algorithm plaza are assigned a maturity level that indicates what users can expect from the service in regard to its performance and metadata. Currently, we have five different maturity levels for each service, namely Prototype being the primary and default level, followed by Incubating, Verified, Validated and Operational as advanced services. These levels are determined solely based on software readiness and user documentation criteria. These criteria are generally designed to ensure that the service meets specific standards and provides customers with a certain level of quality."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-1-prototype",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-1-prototype",
    "title": "Service Maturity",
    "section": "Level 1: Prototype",
    "text": "Level 1: Prototype\nBy default, every published service will have a prototype level. It is expected that users consider the following points when publishing a service:\n\nThe service is executable, and basic logging information is supported.\nA possible reference or a general overview of what it tries to implement is provided as service metadata.\n\n\nIf your service satisfies the criteria for a higher level, you can request an upgrade anytime once your service is published. Nevertheless, please note that every criterion must be satisfied for an upgrade."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-2-incubating",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-2-incubating",
    "title": "Service Maturity",
    "section": "Level 2: Incubating",
    "text": "Level 2: Incubating\nIn addition to the criteria for prototype level, a few additional criteria, as mentioned below, need to be satisfied to be upgraded to incubating service.\n\nService metadata should also include an example of executing the service along with the expected output format.\nAn approximate assumption on how much user credit is required to execute a service should be provided.\n\n\nNote that no added value will be associated with services with a prototype or incubating levels. In other words, approximate credit will include added value cost only on services that are either verified, validated or operational."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-3-verified-or-validated",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-3-verified-or-validated",
    "title": "Service Maturity",
    "section": "Level 3: Verified or Validated",
    "text": "Level 3: Verified or Validated\nWhen a service is labelled as either verified or validated, they mark the same level of maturity. Users can expect the same level of performance from them, but the naming difference is due to its irrelevance/relevance to software validation reports as a part of user documentation.\n\nLevel 3a: Verified\n\nA comprehensive functional and integration test should be possible.\nThere should be advanced logging that could help while debugging.\nService metadata should include information on detailed descriptions of the services, their parameters and a link to a publication that supports the methodology adopted. An example of executing service expected outcome should be provided in a similar manner to that of incubating service.\nApproximate cost estimation on a larger scale should be presented.\n\n\nPlease mention or provide a report to the support team if there exist any constraints/limitations with the services that should be considered.\n\n\n\nLevel 3b: Validated\n\nAll the criteria mentioned for the verified level are applicable to this level, along with the additional criteria that the validation report should be provided either as a separate document to the support team or a non-expiring link.\n\n\nAlthough services can be either of verified or validated type, i.e. if a service satisfies all the criteria mentioned under verified but does not provide a validation report despite being relevant to them will be labelled as incubating."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#level-4-operational",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#level-4-operational",
    "title": "Service Maturity",
    "section": "Level 4: Operational",
    "text": "Level 4: Operational\nA highly improved service can only be marked with the highest level of maturity i.e. operational, when it fully satisfies the following criteria:\n\nAll the conditions to be either verified or validated should be satisfied.\nThe service has been shown to fit large-scale production and integration in an operating system.\nRules and constraints for estimating resource usage should be provided as a document to the support team.\nService lifecycle management policy should be available for the end users.\nAn article summarising the process used for the service should be available on a peer-reviewed website or journal or a conference article (There is no limitation to a specific journal, but proof that the article was peer-reviewed should be provided to the openEO algorithm plaza support service)."
  },
  {
    "objectID": "Applications/PlazaDetails/ServiceMaturity.html#requesting-a-change-of-the-maturity-level",
    "href": "Applications/PlazaDetails/ServiceMaturity.html#requesting-a-change-of-the-maturity-level",
    "title": "Service Maturity",
    "section": "Requesting a change of the maturity level",
    "text": "Requesting a change of the maturity level\nBased on the fulfilment of the above criteria, users can request an upgrade of the service by submitting a ticket at our help center."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html",
    "href": "Applications/PlazaDetails/ManageOrg.html",
    "title": "Manage your organization",
    "section": "",
    "text": "Organisations are core elements of the openEO algorithm plaza Portal, as they are the entities that relate users, accesses, services, data, etc. One can think of an organisation as a company in most cases, although an individual can be a one-man organisation. This organisational concept allows users to manage shared services and allocate credits accordingly. Users can design their organisation to specific needs, whether for project collaborators, a particular team, or at the organisational level.\n\n\nWhen you register in the Copernicus Data Space Ecosystem, a personal organisation is already created for you. On your profile page within the openEO Algorithm Plaza, you’ll find your organisation shown under the linked organisation section. Additionally, you can access the Organisation page by selecting the “Organisation” option in the sub-navigation. Here, you can both view and edit your organisation’s details, which may include:\n\nOrganisation name (mandatory)\nOrganisation Identity registration (optional)\nOrganisation Avatar / logo URL (optional)\nOrganisation description (optional)\nOrganisation website (optional)\nTerms of use URL (optional) and other “useful links” e.g., Terms of Service, Privacy, YouTube, and Support URLs\nUpdate button, disabled by default\n\n\n\n\nA key aspect of this platform is the capability to invite colleagues, friends, or co-workers to join a shared organisation. You can invite new members to your organisation by clicking on the INVITE MEMBER button available within the Team sub-menu of your profile. This will prompt a form where you will have to provide some more information for adding a new user to your organization. This block contains the following fields:\n\nEmail address (Mandatory)\nRole dropdown (Organisation owner or Developer).\nSEND button\n\nThe form should also disappear after successful submission.\n\n\n\nInvite member\n\n\nOnce you click on the SEND button, a message that the invitation was send will pop up at the top of the page. The invitee will receive an email with a link to accept the invitation.\n\n\n\nOnce the invitation is accepted, the new member will be added to the organisation and will be able to access the organisation’s resources.\n\n\n\nTo be a part of an existing organisation, you need to be invited by the organisation owner or admin. As mentioned above, an invitation can be sent to any user within the platform. You will receive an email with the invitation link. We recommend you sign in first and then accept the invitation by simply confirming the link. When you click on the confirm invitation, you will see the following screen:\n\n\n\nOnce you click on the ACCEPT INVITATION button, you will be see a message that you have successfully accepted the invitation appearing at the top of the screen.\n\n\n\nYou can now close the invitation from the top right corner.\n\n\n\nOnce you have accepted the invitation to join the organisation, upon returing to your profile, you’ll find the organisation you have joined listed under the Linked organisation dropdown menu. To switch to the new organisation, simply select it from the dropdown menu and click on the SWITCH button.\n\n\n\nOnce you switch the organisation, you’ll be able to see all the team members and their roles. However, please note that if you have a Developer role, you won’t be able to invite new members to your organisation. Only the Organisation owner will be able to invite new members to the organisation."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html#provide-your-organisation-details",
    "href": "Applications/PlazaDetails/ManageOrg.html#provide-your-organisation-details",
    "title": "Manage your organization",
    "section": "",
    "text": "When you register in the Copernicus Data Space Ecosystem, a personal organisation is already created for you. On your profile page within the openEO Algorithm Plaza, you’ll find your organisation shown under the linked organisation section. Additionally, you can access the Organisation page by selecting the “Organisation” option in the sub-navigation. Here, you can both view and edit your organisation’s details, which may include:\n\nOrganisation name (mandatory)\nOrganisation Identity registration (optional)\nOrganisation Avatar / logo URL (optional)\nOrganisation description (optional)\nOrganisation website (optional)\nTerms of use URL (optional) and other “useful links” e.g., Terms of Service, Privacy, YouTube, and Support URLs\nUpdate button, disabled by default"
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html#invite-team-members",
    "href": "Applications/PlazaDetails/ManageOrg.html#invite-team-members",
    "title": "Manage your organization",
    "section": "",
    "text": "A key aspect of this platform is the capability to invite colleagues, friends, or co-workers to join a shared organisation. You can invite new members to your organisation by clicking on the INVITE MEMBER button available within the Team sub-menu of your profile. This will prompt a form where you will have to provide some more information for adding a new user to your organization. This block contains the following fields:\n\nEmail address (Mandatory)\nRole dropdown (Organisation owner or Developer).\nSEND button\n\nThe form should also disappear after successful submission.\n\n\n\nInvite member\n\n\nOnce you click on the SEND button, a message that the invitation was send will pop up at the top of the page. The invitee will receive an email with a link to accept the invitation.\n\n\n\nOnce the invitation is accepted, the new member will be added to the organisation and will be able to access the organisation’s resources."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html#accept-the-invitation",
    "href": "Applications/PlazaDetails/ManageOrg.html#accept-the-invitation",
    "title": "Manage your organization",
    "section": "",
    "text": "To be a part of an existing organisation, you need to be invited by the organisation owner or admin. As mentioned above, an invitation can be sent to any user within the platform. You will receive an email with the invitation link. We recommend you sign in first and then accept the invitation by simply confirming the link. When you click on the confirm invitation, you will see the following screen:\n\n\n\nOnce you click on the ACCEPT INVITATION button, you will be see a message that you have successfully accepted the invitation appearing at the top of the screen.\n\n\n\nYou can now close the invitation from the top right corner."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageOrg.html#switch-between-organisation",
    "href": "Applications/PlazaDetails/ManageOrg.html#switch-between-organisation",
    "title": "Manage your organization",
    "section": "",
    "text": "Once you have accepted the invitation to join the organisation, upon returing to your profile, you’ll find the organisation you have joined listed under the Linked organisation dropdown menu. To switch to the new organisation, simply select it from the dropdown menu and click on the SWITCH button.\n\n\n\nOnce you switch the organisation, you’ll be able to see all the team members and their roles. However, please note that if you have a Developer role, you won’t be able to invite new members to your organisation. Only the Organisation owner will be able to invite new members to the organisation."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html",
    "href": "Applications/PlazaDetails/ManageService.html",
    "title": "Manage your services",
    "section": "",
    "text": "In this section, we aim to address the key aspects of managing your services on the openEO Algorithm Plaza.\n\n\nEach service is given a maturity level based on the quality of the service. In order to upgrade the level of service, responsible user should improve their services and documentation in such a way that it meets the criteria for the desired levels. Then a request can be made at our help center for upgrading the service.\n\n\n\nChanging the visibility of a service to private ensures that the service is not visible in the openEO algorithm plaza. This can be useful for fixing bugs, developing, and testing before publishing it to the marketplace.\nChanging a service’s visibility can be done by selecting the specific service card from the Services. This will open the service details. Scroll down to the section to set the service’s visibility to private.\n\nIt is important to note that setting the visibility to private only hides the service in openEO algorithm plaza.\n\n\n\nSimilar to making a service private, a user can remove it. You can simply click on the REMOVE button at the bottom of the service details page. A popup window will request your confirmation of deleting the service. Clicking YES will remove it from the openEO algorithm plaza service catalogue and delete all of its related data.\n\nIt is important to note that removing the service from the openEO algorithm plaza does not remove it from the orchestrators. Users are still able to execute the service through the orchestrators. If you want to remove the service from the orchestrators, please follow the instructions below.\n\n\nRemoving a service from the orchestrators will disable its execution by any of the orchestrator’s users. openEO provides two ways to remove a service (also known as a user-defined process in openEO):\n\nUsing the OpenEO APIThe process_graphs endpoint allows users to remove a service based on its ID. More information is available in the official API documentation.\nUsing the openEO Python ClientThe openEO Python Client supplies a delete function that can be executed for any user defined process that is managed by the authenticated user. More information is available in the official Python Client documentation."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#upgrade-your-service",
    "href": "Applications/PlazaDetails/ManageService.html#upgrade-your-service",
    "title": "Manage your services",
    "section": "",
    "text": "Each service is given a maturity level based on the quality of the service. In order to upgrade the level of service, responsible user should improve their services and documentation in such a way that it meets the criteria for the desired levels. Then a request can be made at our help center for upgrading the service."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#changing-a-service-visibility-to-private",
    "href": "Applications/PlazaDetails/ManageService.html#changing-a-service-visibility-to-private",
    "title": "Manage your services",
    "section": "",
    "text": "Changing the visibility of a service to private ensures that the service is not visible in the openEO algorithm plaza. This can be useful for fixing bugs, developing, and testing before publishing it to the marketplace.\nChanging a service’s visibility can be done by selecting the specific service card from the Services. This will open the service details. Scroll down to the section to set the service’s visibility to private.\n\nIt is important to note that setting the visibility to private only hides the service in openEO algorithm plaza."
  },
  {
    "objectID": "Applications/PlazaDetails/ManageService.html#remove-a-service",
    "href": "Applications/PlazaDetails/ManageService.html#remove-a-service",
    "title": "Manage your services",
    "section": "",
    "text": "Similar to making a service private, a user can remove it. You can simply click on the REMOVE button at the bottom of the service details page. A popup window will request your confirmation of deleting the service. Clicking YES will remove it from the openEO algorithm plaza service catalogue and delete all of its related data.\n\nIt is important to note that removing the service from the openEO algorithm plaza does not remove it from the orchestrators. Users are still able to execute the service through the orchestrators. If you want to remove the service from the orchestrators, please follow the instructions below.\n\n\nRemoving a service from the orchestrators will disable its execution by any of the orchestrator’s users. openEO provides two ways to remove a service (also known as a user-defined process in openEO):\n\nUsing the OpenEO APIThe process_graphs endpoint allows users to remove a service based on its ID. More information is available in the official API documentation.\nUsing the openEO Python ClientThe openEO Python Client supplies a delete function that can be executed for any user defined process that is managed by the authenticated user. More information is available in the official Python Client documentation."
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html",
    "href": "Applications/PlazaDetails/ExecuteService.html",
    "title": "Execute a service",
    "section": "",
    "text": "Services can be executed using the tools provided by openEO. The table below provides a brief summary of the different tools available:\n\n\n\n\n\n\n\nTool\nDescription\n\n\n\n\nopenEO Web Editor\nA web-based interface for executing openEO processes.\n\n\nCommand Line Interface (CLI)\nAllows execution of openEO processes through the command line.\n\n\nPython Client\nA Python library facilitating interaction with openEO services programmatically.\n\n\nR Client\nAn R library for integrating openEO services into R scripts.\n\n\n\nWhen publishing a service on the openEO algorithm plaza, a user can choose to provide the following information in the service details:\n\nAn executable link which redirects the user to the online orchestrator’s user interface. If this is the case, an ACCESS SERVICE button will appear when opening an openEO algorithm plaza service.\nSample code in the service description on how to execute a service programmatically.\n\n\n\n\n\n\n\nImportant\n\n\n\nThere is a limitation when executing a service (User Defined Processes) in Copernicus Dataspace Ecosystem, that it only works collection from 2017 or so onwards. Moreover, it is recommended to test it for multiple consecutive years.\n\n\n\n\nopenEO provide an online user interface where users can execute services directly in a web-editor. Through these graphical user interfaces, users can execute, link, and configure different services. More information on the usage of the online applications is presented in the table below.\n\n\n\nopenEO\n\n\n\n\nAccess\n\n\nDocumentation\n\n\n\n\n\n\nopenEO provides client libraries to support the creation and execution of JavaScript, Python and R services. The full client libraries documentation is available on the official openEO support pages:\n\nJavaScript\nPython\nR\n\nThe following example shows a code sample on how to execute a service through the openEO Python Client.\nimport openeo\n\n# Setup parameters\naoi = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [\n                5.179324150085449,\n                51.2498689148547\n            ],\n            [\n                5.178744792938232,\n                51.24672597710759\n            ],\n            [\n                5.185289382934569,\n                51.24504696935156\n            ],\n            [\n                5.18676996231079,\n                51.245342479161295\n            ],\n            [\n                5.187370777130127,\n                51.24918393390799\n            ],\n            [\n                5.179324150085449,\n                51.2498689148547\n            ]\n        ]\n    ]\n}\ndate = '2020-06-01'\n\n# Setup connection with OpenEO\neoconn = openeo.connect(\"https://openeo.dataspace.copernicus.eu\").authenticate_oidc(\"egi\")\n\n# Create a processing graph from the BIOMASS process using an active openEO connection\ntaskmap = eoconn.datacube_from_process(\"taskmap_generate\", namespace=\"https://openeo.dataspace.copernicus.eu/openeo/1.0/processes/u:123456/taskmap_generate\", aoi=aoi,\n                                       date=date)\n\n# Execute the openEO request as a batch job\ntaskmap_job = taskmap.download('task.nc')\nTo execute a service from the openEO algorithm plaza through one of the OpenEO client libraries, it is important to use the datacube_from_process function. It accepts the ID and namespace of the service. Both are made available in the service description on the openEO algorithm plaza. The full documentation on using the function is available on the official openEO documentation."
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html#online-user-interface",
    "href": "Applications/PlazaDetails/ExecuteService.html#online-user-interface",
    "title": "Execute a service",
    "section": "",
    "text": "openEO provide an online user interface where users can execute services directly in a web-editor. Through these graphical user interfaces, users can execute, link, and configure different services. More information on the usage of the online applications is presented in the table below.\n\n\n\nopenEO\n\n\n\n\nAccess\n\n\nDocumentation"
  },
  {
    "objectID": "Applications/PlazaDetails/ExecuteService.html#client-libraries",
    "href": "Applications/PlazaDetails/ExecuteService.html#client-libraries",
    "title": "Execute a service",
    "section": "",
    "text": "openEO provides client libraries to support the creation and execution of JavaScript, Python and R services. The full client libraries documentation is available on the official openEO support pages:\n\nJavaScript\nPython\nR\n\nThe following example shows a code sample on how to execute a service through the openEO Python Client.\nimport openeo\n\n# Setup parameters\naoi = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [\n                5.179324150085449,\n                51.2498689148547\n            ],\n            [\n                5.178744792938232,\n                51.24672597710759\n            ],\n            [\n                5.185289382934569,\n                51.24504696935156\n            ],\n            [\n                5.18676996231079,\n                51.245342479161295\n            ],\n            [\n                5.187370777130127,\n                51.24918393390799\n            ],\n            [\n                5.179324150085449,\n                51.2498689148547\n            ]\n        ]\n    ]\n}\ndate = '2020-06-01'\n\n# Setup connection with OpenEO\neoconn = openeo.connect(\"https://openeo.dataspace.copernicus.eu\").authenticate_oidc(\"egi\")\n\n# Create a processing graph from the BIOMASS process using an active openEO connection\ntaskmap = eoconn.datacube_from_process(\"taskmap_generate\", namespace=\"https://openeo.dataspace.copernicus.eu/openeo/1.0/processes/u:123456/taskmap_generate\", aoi=aoi,\n                                       date=date)\n\n# Execute the openEO request as a batch job\ntaskmap_job = taskmap.download('task.nc')\nTo execute a service from the openEO algorithm plaza through one of the OpenEO client libraries, it is important to use the datacube_from_process function. It accepts the ID and namespace of the service. Both are made available in the service description on the openEO algorithm plaza. The full documentation on using the function is available on the official openEO documentation."
  },
  {
    "objectID": "Applications/WebEditor.html",
    "href": "Applications/WebEditor.html",
    "title": "openEO Web Editor",
    "section": "",
    "text": "The openEO Web Editor is a web-based graphical user interface (GUI) that allows users to interact with the openEO API and perform various tasks related to Earth observation data processing. It provides a user-friendly interface for users who are not familiar with a programming language to carry out several Earth Observation data processing tasks, such as querying available data, defining processing workflows, executing processes, and visualising the results. It allows users to build complex processing chains by connecting different processing steps as building blocks and provides options to specify parameters and input data for each step.\nIn short, the openEO Web Editor can act as a simple interface for:\nThe openEO Web Editor can be accessed via https://openeo.dataspace.copernicus.eu/. Even without logging in, users have the ability to retrieve information on available collections, processes, User Defined Functions(UDF) Runtimes, and the options for exporting files. Additionally, users can create openEO process graphs, however, log in is necessary to execute them."
  },
  {
    "objectID": "Applications/WebEditor.html#getting-started",
    "href": "Applications/WebEditor.html#getting-started",
    "title": "openEO Web Editor",
    "section": "Getting Started",
    "text": "Getting Started\nUpon initial access to the provided link, users are presented with the following screen which is further explained below in refernce to the given numbering:\n\n\nService Offering\nThe sidebar offers users the ability to navigate through the available collections, processes, UDF Runtimes and Export file formats. At the top of the sidebar, there is a search feature that allows for direct searching.\nWithin the Collections section, users can access a comprehensive list of data collections available in the backend through openEO. Clicking on any of these collections will bring up a detailed metadata window.\nUnder the Processes section, users can find a comprehensive list of openEO processes specifically designed for Earth Observation processing. These processes operate on individual values within an array, accepting and returning a single value.\nThe UDF Runtimes section provides information on the available environments or platforms where User Defined Functions (UDFs) can be executed. Currently, the python runtime is available during this stage of development.\nIn the Export File Formats section, users are guided on the supported output formats within openEO. Clicking on each format provides a detailed summary of its associated parameters.\nHelp\nThe Help icon at the top of the screen will provide you with a short tour of the main section of the editor.\nWizard\nThe Wizard is an experimental feature that will help you to create openEO processes in a simple way for some common use cases.\nServer\nThe Server icon will pop up a window giving the user detailed information on the server used for processing the created processes.\nGuest\nThe Guest naming will be replaced with your username when logged in. The dropdown will provide with an option to Log in.\nFeatures\nThe basic functionalities that can be handy when creating the processes in openEO Web Editor is available in this row. These functionalities includes creating a new script, importing processes from external sources, exporting in another programming language, validating processes on the server side, editing process metadata, adding parameters, etc.\nProcess Editor\nThis is the editor for the processes. We recommend to work in “Visual Model” mode, where you can create processing chains simply by adding collections and processes and connecting them with each other. The “Code” mode allows to see the generated JSON process, which is usually only needed if you want to run the process using another client library such as Python or R.\nThe area on it’s right will later be used for previewing collections or inspecting the results of batch jobs, web services or other computations. It will also be used to display log messages, if available.\nLog in\nAs previously mentioned, it is necessary to log in to interact with the server. A new window will appear when attempting to log in, as demonstrated below. While other options are sometimes available, the recommended authentication choice is the “Copernicus Data Space Ecosystem”. For further information regarding various authentication methods or to seek assistance, you can always click on the “help” option at the top or contact us."
  },
  {
    "objectID": "Applications/WebEditor.html#create-a-workflow",
    "href": "Applications/WebEditor.html#create-a-workflow",
    "title": "openEO Web Editor",
    "section": "Create a workflow",
    "text": "Create a workflow\nBased on their applications user can build their model by simple drag and drop method. Some processes may necessitate input parameters, which must be carefully considered. As an illustration, we present a simple case of creating a workflow to calculate NDVI using the Sentinel 2 L2A collection. Three main steps involved in using openEO for Earth Observation data processing is shown below.\n\nLoad Collection\n\nTo start a task within the openEO web editor, your first step is to search the necessary collections for the analysis. Thus, you must check the required collections exists within the openEO database, you can do this by exploring/searching the list of available collections from the sidebar of the interface. In our example, we want to calculate the Normalized Difference Vegetation Index (NDVI), so the Sentinel 2 L2A collection will be used. So the next step is to drag and drop it into the Process Editor for further operations.\n\n\n\nNow, once you load collection, there are several parameters you need to specify, including the area of interest, the temporal extent, and the selection of bands. By clicking on load_collection, a window pops up, where you can define the necessary parameters for subsequent processing.\nTo specify the area of interest, you can choose between generating a bounding box or importing your spatial extent by dragging and dropping GeoJSON or KML files onto the map view. While this example demonstrates the use of a bounding box, we suggest experimenting with a suitably compact area for testing purposes. There is also an option to “No filter”, that will include all the data in the datacube.\n\n\n Another parameter to consider is the temporal extent, allowing you to restrict the loaded data to a specified time window. We encourage you to choose a timeframe of 1-2 weeks for testing purposes. \n\n In our case, for NDVI calculation, we have specifically chosen the Red band (B04) and the Near-Infrared (NIR) band (B08). \n\nApply Processes\nThe next step involves applying essential openEO processes, ranging from straightforward mathematical operations to more complex tasks such spatial or temporal aggregations.\nIn this task, we’ll using a specific openEO process called reduce_dimension two times to simplify our data cube. First we deal with the various bands and then reduce the temporal dimension.\n\nIn the initial process, the reduce_dimension algorithm is utilised to reduce the band dimension after executing a series of addition, subtraction, and division operations necessary for the NDVI calculation.\n\nFollowing this, with the same reduce_dimension algorithm we eliminate the temporal dimension by selecting the maximum value using the max function.\n\nSelect a format\nAs a final step in the workflow creation is to select the output format.\n\nSince our workflow eliminated the temporal dimension, we can keep things simple and just save the result as a GeoTiff."
  },
  {
    "objectID": "Applications/WebEditor.html#execute-the-workflow",
    "href": "Applications/WebEditor.html#execute-the-workflow",
    "title": "openEO Web Editor",
    "section": "Execute the workflow",
    "text": "Execute the workflow\nTo complete the data analysis process, the final step involves executing the created workflow. This can be done in two ways: synchronously or through batch job-based method. Synchronous method allows the user to download the data directly, whereas batch job-based method enables the user to execute process as a batch. The choice of method depends on the user’s preference and the size of the dataset.\n\nIn the above figure, the red box includes the two methods possible for executing the process. In this example, I used the synchronus method by directly clicking on Run now, which popped up a box in the bottom right corner.\nOnce the execution process is completed, the result is automatically saved locally. It can also be visualised in the parallel window as shown in the image below:\n\nFurthermore, if you have created Batch Job, you can monitor its action from the same window."
  },
  {
    "objectID": "Applications/WebEditor.html#data-download-using-wizard",
    "href": "Applications/WebEditor.html#data-download-using-wizard",
    "title": "openEO Web Editor",
    "section": "Data Download using Wizard",
    "text": "Data Download using Wizard\nThe Wizard feature at the top navigation bar allows easy creation of process graphs for common, basic use cases without having to drag and drop processes as done earlier.\n\nThis feature is experimental and it’s not guaranteed that the generated process graphs are fully functional.\n\nAt the time of this documentation release, two cases are currently available through the Wizard feature: direct downloading of data for a selected area and downloading computed spectral indices as shown in the figure below:\n\nYou have the option to choose any one of them and enter the necessary parameters as instructed. This method makes the task considerably more straightforward than the previously mentioned workflow creation approach, as the structure is already established and you only need to input the essential parameters."
  },
  {
    "objectID": "Applications/WebEditor.html#monitor-the-workflow",
    "href": "Applications/WebEditor.html#monitor-the-workflow",
    "title": "openEO Web Editor",
    "section": "Monitor the workflow",
    "text": "Monitor the workflow\nWhen a batch job is created, openEO’s logs feature can help with monitoring and debugging of workflows. The back-end typically uses this to dump information during data processing that may be relevant for the user (e.g. warnings, resource stats, …). Like many other processes, job logs can be visualized programmatically as well as in the web editor.\nAs shown in the following image, you have the option to access the job logs by clicking on the icon located next to the job ID at the bottom of the interface.\n\nWhen clicking on it, a pane emerges on the right, as shown below:\n\nMoreover, users can use openEO processes like inspect, this will allow you to log your own information to be displayed in the job logs."
  },
  {
    "objectID": "Applications/QGIS.html",
    "href": "Applications/QGIS.html",
    "title": "Sentinel Hub QGIS Plugin",
    "section": "",
    "text": "The Sentinel Hub QGIS Plugin allows you to view satellite image data from the Copernicus Data Space Ecosystem or from Sentinel Hub directly within a QGIS workspace. All datasets are available that are part of collections associated with your user, including commercial data within Sentinel Hub subscriptions and Bring Your Own COG datasets in Sentinel Hub and Copernicus Data Space. The current functionality of the QGIS Plugin is for visualization; it does not allow you to perform operations or access properties of the dataset. For individual downloads, we recommend the Copernicus Browser; for downloading multiple datasets for an area and time period of interest in a graphical interface, Request Builder is the optimal tool."
  },
  {
    "objectID": "Applications/QGIS.html#first-step-authentication",
    "href": "Applications/QGIS.html#first-step-authentication",
    "title": "Sentinel Hub QGIS Plugin",
    "section": "First step: authentication",
    "text": "First step: authentication\nBefore starting, you should have an OAuth client prepared in your Copernicus Data Space Sentinel Hub Services Dashboard (or commercial Sentinel Hub Dashboard). This serves as your authentication to these services when you log in.\n\nRegistering OAuth client\nTo register an OAuth client, open the \"User Settings\" tab in your dashboard, then click the Create new button (1) in the \"OAuth client\" section. Give your OAuth client a name (2), set the Client grant type to Client Credentials, and click the Create client button (3). Your client secret will be displayed. Copy the secret value (4) and paste it locally, as it will not be visible after the pop-up window closes! When you are finished, click Close (5). You should now see the newly created OAuth client name and ID (6) in the list of your OAuth clients. With client ID and client secret, you are now ready to request tokens.\n\nYou can install the plugin from the QGIS plugin repository. Select Plugins/Manage and Install Plugins from the main menu in QGIS and use the search box to find the Sentinel Hub plugin, click Install Plugin and you are done. Paste the client ID and secret to the respective fields in the Login tab of the plugin to authenticate - these will be remembered next time you launch QGIS."
  },
  {
    "objectID": "Applications/QGIS.html#creating-a-configuration",
    "href": "Applications/QGIS.html#creating-a-configuration",
    "title": "Sentinel Hub QGIS Plugin",
    "section": "Creating a configuration",
    "text": "Creating a configuration\nOn the left panel of the Copernicus Data Space Ecosystem Sentinel Hub Services dashboard, select Configuration Utility. Here, you will see a list of all configurations you created earlier. You can create a new one with the New Configuration button (1). For a new configuration, you first have to create a name (2), then the option is offered to create the configuration based on one of the existing instances by changing the settings (3). Clicking Create Configuration (4) takes you to the settings of the configuration.\n\nThe Warnings switch decides whether you will see a warning message if you want to show or download an area larger than the limit. Show logo does not affect your QGIS plugin, there is a switch for this on the download panel of the plugin where you can decide.\n\n\n\n\n\n\nWarning\n\n\n\nDon’t switch on Disable OGC requests if you are creating a configuration you want to access in QGIS – the plugin is based on OGC requests!\n\n\nImage quality for visualization can be set using the slider or numerically, and the boundaries of the dataset can be selected in a small map window (Map bounds). Under Advanced Settings, a window opens where you can edit a JSON configuration.\n\nThe New Layer button takes you to the form for setting the data layers in your configuration. Here, you can prepare the dataset you want to view in QGIS. First, add a Name for your layer. Choose an imagery data Source from the Collections available and add a Data Processing evalscript – the pencil icon opens a panel where you can select from predefined evalscripts or edit your own, optionally based on the Custom script repository. By defining a Time range and a Cloud coverage threshold, you can filter the imagery to include, additionally setting the Mosaic order (most recent, first, least cloudy) to your preferences. For one configuration, you can create several layers that will be available as options in QGIS."
  },
  {
    "objectID": "Applications/QGIS.html#use-the-plugin-for-creating-and-updating-a-data-layer",
    "href": "Applications/QGIS.html#use-the-plugin-for-creating-and-updating-a-data-layer",
    "title": "Sentinel Hub QGIS Plugin",
    "section": "Use the Plugin for Creating and updating a data layer",
    "text": "Use the Plugin for Creating and updating a data layer\nOn the Create tab, you can select a Configuration. The configurations available in your dashboard are listed here. These can be used to choose between configurations of different data sources (eg. Sentinel-2 and Sentinel-3) or different evalscript settings.\nSelect Service type based on the data you want to use. You typically will need WMS for this case, since the images are in raster format, but WMTS and WFS services are also available if you want to perform more advanced queries or bring your own areas of interest.\nThe Layer menu allows you to select between the different visualization layers included in your configuration. For the default Sentinel-2 configuration, this menu includes a wide range of visualization options similar to the Copernicus Browser.\n\n\n\n\n\n\nNote\n\n\n\nCRS refers to Coordinate Reference System; this is where you can set the coordinate system of the dataset. For Copernicus Data Space or Sentinel Hub imagery data layers, this should keep the default value of EPSG:3857 .\n\n\n\nIn the Time range bar and the calendar panel, you can choose the start and end date of the period of interest and set an Image Priority order for mosaicking the data layers for this period. Alternatively, if you are interested in images for specific dates, tick Use exact date to disable mosaicking. Calendar dates where an image is available within the selected Cloud Cover ratio for the onscreen area will be highlighted. You can set the Cloud Cover threshold using the slider below the calendar.\nIf you are using mosaicking within a time range, the Image Priority can be set using the dropdown menu to include the most recent, the first or the least cloudy image of the time range in the mosaic for each pixel.\nOnce this is set, you can decide whether to Create a new WMS layer in your QGIS workspace or update an existing one. Take care – the “update existing layer” dropdown is set by default to the selected layer. If you want to look at a different date, click on the date in the calendar and update the layer. If you want to compare, create a new layer for the new date, and you can use QGIS visualization tools such as transparency."
  },
  {
    "objectID": "Applications/QGIS.html#downloading-imagery",
    "href": "Applications/QGIS.html#downloading-imagery",
    "title": "Sentinel Hub QGIS Plugin",
    "section": "Downloading imagery",
    "text": "Downloading imagery\nOn the Download panel, you can download a three-channel RGB rendering of the image on your map window. File format and image resolution can be selected, and optionally a custom bounding box can be added with coordinates."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html",
    "href": "Applications/AlgorithmPlaza.html",
    "title": "openEO Algorithm Plaza",
    "section": "",
    "text": "The openEO Algorithm Plaza is a marketplace within Copernicus Data Space Ecosystem that allows user to discover and share different Earth Observation(EO) algorithms expressed as openEO process graphs. It’s a one-stop-shop where they can either share their algorithm or use existing ones as a service.\nThis platform relies on standardized web interfaces, making it easy for users to access services. Within the platform, the hosted algorithms can be used through user interfaces or APIs. Furthermore, it simplifies the IT aspects of service publishing, allowing users to concentrate solely on algorithm development. As a result, users can seamlessly onboard their algorithms on the openEO Algorithm Plaza for further exposure to a large audience."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#overview",
    "href": "Applications/AlgorithmPlaza.html#overview",
    "title": "openEO Algorithm Plaza",
    "section": "Overview",
    "text": "Overview\nA captivating feature of the marketplace is the growing and diverse catalogue of EO services from different providers. To enhance user experience when searching a service, a text filter bar is available at the top of the page in addition to attribute filtering.\n\nEach service, represented as a placard in the above image, has its dedicated page providing detailed information. This page briefly describes the methodology, expected results, and instructions for executing the service."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#what-is-a-service",
    "href": "Applications/AlgorithmPlaza.html#what-is-a-service",
    "title": "openEO Algorithm Plaza",
    "section": "What is a service?",
    "text": "What is a service?\nopenEO Algorithm Plaza offers a wide range of services in Earth Observation. These services support algorithms ranging from simple computations like the Normalized Difference Vegetation Index (NDVI) to more complex algorithms that utilize machine learning and multiple parameters.\nIn addition to providing existing services, the marketplace also supports users in showcasing their algorithms as services in its catalogue. To advertise your service on the marketplace, the algorithm must be built using openEO. It’s important to consider your target audience, especially if reaching a non-scientific audience; you may want to hold back on hard-to-interpret options.\nOnce your algorithm is exposed as a service, users can ‘invoke’ it with a given set of parameters."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#service-maturity-levels",
    "href": "Applications/AlgorithmPlaza.html#service-maturity-levels",
    "title": "openEO Algorithm Plaza",
    "section": "Service maturity levels",
    "text": "Service maturity levels\nTo ensure quality control across the various services offered in the openEO algorithm plaza, the platform assigns a maturity level to them. This level indicates what end users can expect from the services with in terms of:\n\nValidation of the results\nStability\nScalability\nDocumentation\n\nThe table below provides an overview of the different maturity levels that are applied within the openEO algorithm plaza.\n\n\n\n\n\n\n\nLevel\nDescription\n\n\n\n\nPrototype\nService is provided ‘as-is’, with a short description and possibly a reference to what it tries to implement.\n\n\nIncubating\nQuality of the service is documented with example requests (sets of parameters) and the corresponding output, as well as the resources required to generate that output. Allowing interested users to self-assess whether this service is suitable for usage.\n\n\nVerified\nThe service is labelled verified based on its software readiness and irrelevance to the scientific validation report.\n\n\nValidated\nThe service is validated, and validation reports are available in addition to being verified.\n\n\nOperational\nThe service has been shown to be fit for larger scale production and integration in operational systems. Rules for estimating resource usage are available, or a unit cost is established. (€ per hectare, € per request, etc.)\n\n\n\n\nDetailed descriptions of the criteria for each maturity level are explained here.\n\nFor more information on dealing with the services, please refer to the Manage your services guide."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#interested-in-using-or-publishing-services",
    "href": "Applications/AlgorithmPlaza.html#interested-in-using-or-publishing-services",
    "title": "openEO Algorithm Plaza",
    "section": "Interested in using or publishing services?",
    "text": "Interested in using or publishing services?\nAs a user, you have the option to either use an existing service or publish your own algorithms. Here, we have provided a list of important steps to consider when using or sharing a service. It’s worth noting that this list is not exhaustive and additional steps may be required based on your specific needs.\n\nManaging your account\nYou can explore the available services and features within the openEO Algorithm Plaza. However, to use them, you must be logged in. Nevertheless, if you still need to register, you can follow the registration process mentioned here.\n\nStep 1: Manage your Profile\nYou can find more information on updating your profile settings once you click on your avatar in the top right corner of the openEO Algorithm Plaza portal. This takes you to a page with options like Overview, Team, and Organisation in a sub-navigation menu.\n\nThe Overview section presents your profile details, such as your name, email, and affiliated organisation which you can update by clicking the MANAGE button. Whereas, the Team sub-menu will show you a list of all the members of your organisation. You can also reach this list by clicking the VIEW TEAM button at the left-bottom of the overview sub-menu. You can find more information team management in the here. From the Organisation sub-menu, you can view and modify your organisation’s information, including its name, email address, website, VAT number, and more.\n\n\nStep 2: Manage your Organisation\nEach registered user acts as a personal organisation; you can modify its details as discussed in Step 1. However, this step is helpful when working with multiple individuals or being part of multiple organisations. Organisations allow collaboration with other users, facilitating the sharing of billing and service accounts. For more information on managing your organisation, please refer to the organisation’s documentation of the openEO Algorithm Plaza.\n\n\nStep 3: Check your Credits\nUsing any openEO processes, including those offered as services in this marketplace, consumes a certain amount of credits. Credits are crucial in executing openEO processes, serving as the main currency for accessing services and processing resources. Notably, these credits are shared among organisations. Whenever a service or a supported processing platform is executed, credits from the shared pool cover the resource consumption.\nThis marketplace simplifies credit management, allowing users to monitor their account’s credits easily. You can check your openEO credit under the Billing section. Moreover, every user is provided with 4000 credits each month, with which they can execute multiple services.\n\nCredits are deducted based on the chosen services and spatial extent.The amount will vary depending on the processing complexity and time required for each type of service. Detailed examples of some well-known services and how they fit into the 4000 free credits can further be found here.\nIf you think your available credits are insufficient or you run out of credits, you can create a ticket with your username, email for further support and guidance.\n\n\n\nExecuting a services\nAs you have sufficient credits, you can start using the services available in the catalogue page. You can chose any service you want by simply clicking on the service card.\nWhen you click on any of these services, you will be redirected to the service details page. Here, you can find information about the service such as a general description and instructions on how to execute the service. For more information on how to execute a service, please refer to the Execute a service page.\n\n\n\nPublishing a services\nEvery user have the choice to onboard their services as an individual or as part of a group organisation.\n\nPublish your algorithm\nTo publish your service on marketplace, the algorithm must be built using one of the supported processing platforms(currently we only support openEO as orchestrator). This ensures that users can take full advantage of plaza’s features, such as accounting and reporting, as well as the ability to execute services directly through the web editor.\nFor more information on how to publish a service, please refer to the Publish a service page.\n\n\nManage your service\nManaging your services in this marketplace is a simple process. You can edit or delete services, as well as hide or show them in the plaza’s catalogue. For detailed instructions on how to manage a service, please refer to the manage your service page."
  },
  {
    "objectID": "Applications/AlgorithmPlaza.html#support",
    "href": "Applications/AlgorithmPlaza.html#support",
    "title": "openEO Algorithm Plaza",
    "section": "Support",
    "text": "Support\nIf you are experiencing issues with executing your service or with publishing your service onto the openEO Algorithm Plaza?, feel free to contact our support team by creating a ticket."
  },
  {
    "objectID": "Applications/DataSpaceDashboard.html",
    "href": "Applications/DataSpaceDashboard.html",
    "title": "Copernicus Data Space Ecosystem Dashboard",
    "section": "",
    "text": "The Copernicus Data Space Ecosystem Dashboard (hereinafter the Dashboard) is your go-to tool for checking out the Copernicus Data Space Ecosystem in action. It’s a free, user-friendly platform where you can easily see what’s going on with the data space.\nYou can access the Copernicus Data Space Ecosystem Dashboard at: https://dashboard.dataspace.copernicus.eu/"
  },
  {
    "objectID": "Applications/DataSpaceDashboard.html#what-youll-find",
    "href": "Applications/DataSpaceDashboard.html#what-youll-find",
    "title": "Copernicus Data Space Ecosystem Dashboard",
    "section": "What You’ll Find",
    "text": "What You’ll Find\n1. Highlights\nThe Dashboard greets users with a snapshot of overall statistics, highlighting key metrics with overall statistics to provide a quick glance at the system’s vital signs.\n2. Main Content\nIn the middle of the screen you will find the main content. The main content changes based on the selected page from the application navigation, so you always get the specific info you need.\n3. Application Navigation and Personalization\nOn the left side, you’ll find easy navigation to explore different parts of the Dashboard. Plus, there are settings to tailor the Dashboard to fit your preferences."
  },
  {
    "objectID": "Applications/DataSpaceDashboard.html#interactive-use",
    "href": "Applications/DataSpaceDashboard.html#interactive-use",
    "title": "Copernicus Data Space Ecosystem Dashboard",
    "section": "Interactive Use",
    "text": "Interactive Use\nUsing the Dashboard is easy and interactive, letting you explore more details for each statistic.\n1. Hover for Quick Info\nHover your mouse over any number or chart to get quick descriptions and the last updated info.\n\nFigure 1 Mouse hover on the Total volume of published products – Sentinels\n\nFigure 2 Mouse hover on chart Total volume of published products - Sentinels\n2. Detailed Data\nFor an even closer look, click directly on the chart to explore details. Let’s walk through visualizing the “Total number of published products - Sentinels” per product type as an example:\n\nLocate the pie chart displaying Sentinels missions: Total number of published products - Sentinels\nFocus on the segment corresponding to Sentinel-2.\nClick on the Sentinel-2 segment to reveal detailed data per product type\n\n\n\nPop-up opens with details per product type for the selected mission."
  },
  {
    "objectID": "Applications/DataSpaceDashboard.html#explore-historical-data",
    "href": "Applications/DataSpaceDashboard.html#explore-historical-data",
    "title": "Copernicus Data Space Ecosystem Dashboard",
    "section": "Explore Historical Data",
    "text": "Explore Historical Data\nTo view trends over time are available by clicking on the icon  . The chart transforms into a line chart, giving you a historical data overview.\n\nFigure 3 Historical data for Number of Streamlined Data Access requests with time period last 30 days\nIf you want to dive deeper, modify the view with your mouse or chart tools to focus on what matters to you.\n\nFigure 4 Tools for modifying the line chart with historical data\nService Health Exception\nThere is something special on the Service Health page. Each service has its own “Availability Timeline”. Simply click on the icon  next to any service. You will see the availability of that service over time.\n\nFigure 5 Copernicus Browser availability over time"
  },
  {
    "objectID": "Applications/DataSpaceDashboard.html#share-widget",
    "href": "Applications/DataSpaceDashboard.html#share-widget",
    "title": "Copernicus Data Space Ecosystem Dashboard",
    "section": "Share Widget",
    "text": "Share Widget\nIf you want to share a statistic within a widget, follow these simple steps:\n\nClick on the widget with the statistic you want to share. This opens a dialog with a URL.\nHover your mouse over the URL, and a pop-up appears with the text “CLICK TO COPY LINK”.\n\n\nFigure 6 Share selected statistic with others\n\nClick on the pop-up and the URL to the selected widget is now copied to your clipboard."
  },
  {
    "objectID": "Applications/DataSpaceDashboard.html#news",
    "href": "Applications/DataSpaceDashboard.html#news",
    "title": "Copernicus Data Space Ecosystem Dashboard",
    "section": "News",
    "text": "News\nNews is available by clicking on the icon on the bottom right corner  to open an overview. A quick look reveals the most recent news with an option to read more: “Show all news”."
  },
  {
    "objectID": "Applications/DataSpaceDashboard.html#settings",
    "href": "Applications/DataSpaceDashboard.html#settings",
    "title": "Copernicus Data Space Ecosystem Dashboard",
    "section": "Settings",
    "text": "Settings\nSettings are available next to the News by clicking on the icon on the bottom right corner:\n\nAuto Refresh\nThe statistics on the Dashboard are by default automatically updated without manually refreshing the Dashboard page. If you prefer to keep the current statistics unchanged, simply go to Settings → Auto refresh → toggle the switch.\nShow overview on the page load\nThis setting enables you to turn off the highlights visualization on the Dashboard.\n\nFigure 7 Settings"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html",
    "href": "Data/SentinelMissions/Sentinel1.html",
    "title": "Sentinel-1",
    "section": "",
    "text": "The Sentinel-1 radar imaging mission is composed of a constellation of two polar-orbiting satellites providing continuous all-weather, day and night imagery for Land and Maritime Monitoring. C-band synthetic aperture radar imaging has the advantage of operating at wavelengths that are not obstructed by clouds or lack of illumination and therefore can acquire data during day or night under all weather conditions.\nThe end of mission of the Sentinel-1B satellite has been declared in July 2022 On 23 December 2021, Copernicus Sentinel-1B experienced an anomaly related to the instrument electronics power supply provided by the satellite platform, leaving it unable to deliver radar data. Despite all investigations and recovery attempts, ESA and the European Commission had to announce that it is the end of the mission for Sentinel-1B. Copernicus Sentinel-1A remains fully operational. More information about the end of the mission for the Sentinel-1B satellite can be found on the webpage Mission ends for Copernicus Sentinel-1B satellite. In response to the loss of Sentinel-1B, the mission observation scenario of Sentinel-1A was adjusted, affecting the nominal global coverage frequency. An up-to-date overview of the observation scenario in place can be consulted on the webpage Sentinel-1 Observation Scenario. Some regions are currently not observed by Sentinel-1. Nevertheless, the regions that are still observed, now have a repeat cycle of 12 days under a one-satellite constellation scenario, which affects possible interferometric analyses.\nSentinel data products are made available systematically and free of charge to all data users including the general public, scientific and commercial users. These data products are available in single polarisation for Wave mode and dual polarisation or single polarisation for SM, IW and EW modes.\nLevel-0 Level-1 Level-2"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#sentinel-1-level-1-ground-range-detected-grd",
    "href": "Data/SentinelMissions/Sentinel1.html#sentinel-1-level-1-ground-range-detected-grd",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 1 Ground Range Detected (GRD)",
    "text": "Sentinel-1 Level 1 Ground Range Detected (GRD)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel 1 Level 1 GRD products in this Collection consist of focused SAR data that has been detected, multi-looked and projected to ground range using the Earth ellipsoid model WGS84. The ellipsoid projection of the GRD products is corrected using the terrain height specified in the product general annotation. The terrain height used varies in azimuth but is constant in range (but can be different for each IW/EW sub-swath). Ground range coordinates are the slant range coordinates projected onto the ellipsoid of the Earth. Pixel values represent detected amplitude. Phase information is lost. The resulting product has approximately square resolution pixels and square pixel spacing with reduced speckle at a cost of reduced spatial resolution.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\n(*) Packed or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJan 2023\n\n\n\n\n(**) Packed or Unpacked, SAFE with Cloud optimized GeoTIFF\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\n(***) Packed, original SAFE\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJul 2023\n\n\n\n\n\n(*) Packed means data are available in the original bundling (e.g. compressed zipping) (**) Conversion of Sentinel-1 GRD products to the SAFE with Cloud Optimized GeoTIFF (COG_SAFE) format was performed in June 2023. The newest products are converted and available first, and older products will be added gradually until the entire archive is converted. Please refer to Handling Sentinel-1 COG_SAFE products for more information regarding how COG_SAFE is created and how to search for such products. (***) COG_SAFE products will be available immediately (IAD). In case original Sentinel-1 GRD products would be needed with immediate access, users can convert COG_SAFE products to the original SAFE products using COG2GRD tool.\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2014-10-03T00:00:00Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\n\n\n\n\nVH\n\n\n\n\nVV\n\n\n\n\nHH\n\n\n\n\nHV\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#sentinel-1-level-1-single-look-complex-slc",
    "href": "Data/SentinelMissions/Sentinel1.html#sentinel-1-level-1-single-look-complex-slc",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 1 Single Look Complex (SLC)",
    "text": "Sentinel-1 Level 1 Single Look Complex (SLC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel 1 Level 1 SLC products are images in the slant range by azimuth imaging plane, in the image plane of satellite data acquisition. Each image pixel is represented by a complex (I and Q) magnitude value and therefore contains both amplitude and phase information. Each I and Q value is 16 bits per pixel. The processing for all SLC products results in a single look in each dimension using the full available signal bandwidth. The imagery is geo-referenced using orbit and attitude data from the satellite.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nOct 2014 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nExcept Europe (RoW)\n\n\nFeb 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2014-10-03T00:00:00Z’, None]\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSTAC: https://stac-extensions.github.io/datacube/v2.2.0/schema.json"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#sentinel-1-level-2-ocean-ocn",
    "href": "Data/SentinelMissions/Sentinel1.html#sentinel-1-level-2-ocean-ocn",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 2 Ocean (OCN)",
    "text": "Sentinel-1 Level 2 Ocean (OCN)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-1 Level 2 OCN (Ocean) products are specifically processed radar data products for oceanographic applications. These products are derived from Sentinel-1 SAR data. They are tailored to meet the needs of oceanographic studies, such as monitoring sea surface conditions, detecting oil spills, tracking marine vessels, and studying ocean currents. The OCN products typically involve specialized processing techniques to extract relevant oceanographic information from the radar data. This can include surface wave analysis, wind speed and direction estimation, ocean surface current mapping, and identifying features such as oil slicks or marine traffic.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nDec 2014 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nDec 2014 - Present\n\n\nJul 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#sentinel-1-level-0",
    "href": "Data/SentinelMissions/Sentinel1.html#sentinel-1-level-0",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Level 0",
    "text": "Sentinel-1 Level 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-1 Level 0 products are unprocessed radar measurements obtained by the satellite’s SAR system, containing amplitude and phase information. They serve as the initial input for generating higher-level radar products with calibrated and corrected data.\n\nOffered Data\n\n\n\n\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nJan 2021 - Present\n\n\nJan 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nOct 2014 - Present\n\n\nJul 2023\n\n\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nExcept Europe (RoW)\n\n\nLast one year\n\n\nJul 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#sentinel-1-precise-orbit-determination-pod-products",
    "href": "Data/SentinelMissions/Sentinel1.html#sentinel-1-precise-orbit-determination-pod-products",
    "title": "Sentinel-1",
    "section": "Sentinel-1 Precise Orbit Determination (POD) products",
    "text": "Sentinel-1 Precise Orbit Determination (POD) products\n\nOverview\nThe Precise Orbital products and auxiliary data from Copernicus POD for Sentinel-1 fall into three categories based on timeliness. Near Real-Time (NRT) products are created immediately using GPS L0 data and EGP’s near real-time GPS orbits and clocks. Near Real-Time Predicted (PRE) products are computed in advance of astronomical events, like ascending node crossings. Non Time Critical (NTC) products are generated after several days, incorporating highly accurate inputs like GPS orbits and clocks from IGS.\n\nOffered Data\n\n\n\n\n\n\nProduct ID\n\n\nContent\n\n\nEOF\n\n\nTGZ\n\n\nRolling Policy\n\n\nCatalog API\n\n\nS3 Path\n\n\n\n\n\n\nAUX_RESORB\n\n\nOrbit\n\n\nX\n\n\n\n\n3 months\n\n\nOData\n\n\n/eodata/Sentinel-1/AUX/AUX_RESORB/\n\n\n\n\nAUX_POEORB\n\n\nOrbit\n\n\nX\n\n\n\n\n\n\nOData\n\n\n/eodata/Sentinel-1/AUX/AUX_POEORB/\n\n\n\n\nAUX_PREORB\n\n\nOrbit\n\n\nX\n\n\n\n\n3 months\n\n\nOData\n\n\n/eodata/Sentinel-1/AUX/AUX_PREORB/\n\n\n\n\nAUX_GNSSRD\n\n\nRINEX\n\n\n\n\nX\n\n\n\n\nOData\n\n\n/eodata/Sentinel-1/AUX/AUX_GNSSRD/\n\n\n\n\nAUX_PROQUA\n\n\nQuaternions\n\n\n\n\nX\n\n\n\n\nOData\n\n\n/eodata/Sentinel-1/AUX/AUX_PROQUA/"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#sentinel-1-rtc",
    "href": "Data/SentinelMissions/Sentinel1.html#sentinel-1-rtc",
    "title": "Sentinel-1",
    "section": "Sentinel-1 RTC",
    "text": "Sentinel-1 RTC\nSentinel-1 RTC (Radiometric Terrain Correction) SAR Backscatter is a product processed from Sentinel-1 GRD data and compliant with CEOS Analysis Ready Data for Land (CARD4L) specifications for Normalised Radar Backscatter (NRB) products. Orthorectification is based on Copernicus DEM and no speckle filtering is applied. (Additional product information)"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#copernicus-sentinel-1-mosaics",
    "href": "Data/SentinelMissions/Sentinel1.html#copernicus-sentinel-1-mosaics",
    "title": "Sentinel-1",
    "section": "Copernicus Sentinel-1 Mosaics",
    "text": "Copernicus Sentinel-1 Mosaics\nSentinel-1 GRD monthly and yearly mosaics (available soon).\nIt is planned that the mosaics will be processed with the following Sentinel Hub processing options:\n\nOrthorectification with Copernicus 10m/30m DEM\nRadiometric Terrain Correction with Copernicus 10m/30m DEM\nNo speckle filtering applied"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#sentinel-hub-processing-options",
    "href": "Data/SentinelMissions/Sentinel1.html#sentinel-hub-processing-options",
    "title": "Sentinel-1",
    "section": "Sentinel Hub processing options",
    "text": "Sentinel Hub processing options\nSentinel Hub offers the following processing options in the Sentinel-1 GRD processing chain:\n\nBackscatter coefficients:\n\nbeta0 (ellipsoid)\nsigma0 (ellipsoid)\ngamma0 (ellipsoid)\ngamma0 (terrain) → this gamma0 RTC option can only be performed if orthorectification is enabled\n\nLee Speckle Filtering applied on source data after calibration and noise removal\nRadiometric Terrain Correction (RTC) can be enabled by setting the backscatter coefficient to gamma0 (terrain) and enabling orthorectification\nOrthorectification with Range-Doppler terrain correction using one of the following DEMs:\n\nCopernicus 10m/30m DEM (10m resolution inside 39 European states including islands and 30m elsewhere.)\nCopernicus 30m DEM\nCopernicus 90m DEM"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#openeo-processing-options",
    "href": "Data/SentinelMissions/Sentinel1.html#openeo-processing-options",
    "title": "Sentinel-1",
    "section": "openEO processing options",
    "text": "openEO processing options\nWhen working with the SENTINEL1_GRD data collection through openEO, SAR backscatter computation is automatically applied. Unfortunately, the default backscatter coefficient “gamma0-terrain” is not yet supported in the openEO backend implementation of Copernicus Data Space Ecosystem, typically resulting in an error like “Backscatter coefficient ‘gamma0-terrain’ is not supported.”\nAs a workaround, it is currently recommended to explicitly specify the sar_backscatter() process with the supported coefficient “sigma0-ellipsoid”.\n\nsigma0-ellipsoid: ground area computed with ellipsoid earth model\n\nFor example:\n\nsentinel1 = connection.load_collection(\n    \"SENTINEL1_GRD\",\n    temporal_extent = [\"2022-06-04\", \"2022-08-04\"],\n    bands = [\"VV\",\"VH\"]\n)\n\n  sentinel1 = sentinel1.sar_backscatter(\n      coefficient='sigma0-ellipsoid')\nThe product is orthorectified using the Copernicus 30m DEM. No RTC or speckle filtering is applied to this product."
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel1.html#on-demand-processing-options",
    "href": "Data/SentinelMissions/Sentinel1.html#on-demand-processing-options",
    "title": "Sentinel-1",
    "section": "On-demand processing options",
    "text": "On-demand processing options\nProcessing of CARD-BS and COH6/COH12 products can be requested on demand:\n\nSentinel-1 (CARD-BS) BackScatter\n\nThis processing option contains gamma0 geometric terrain correction (orthorectification) using Copernicus 30m DEM (identical to the gamma0 (ellipsoid) backscatter coefficient with enabled orthorectification option in Sentinel Hub processing options.) No RTC or speckle filtering is applied to this product.\nAdditional information\n\nSentinel-1 (CARD-COH) Coherence\n\nThe Sentinel-1 CARD COH (Copernicus Analysis Ready Data Coherence) processor generates a Sentinel-1 Level 2 product describing the coherence of a pair of images - 12 days apart. The product is orthorectified using Copernicus 30m DEM but no RTC or speckle filtering is applied.\nAdditional information."
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel6.html",
    "href": "Data/SentinelMissions/Sentinel6.html",
    "title": "Sentinel-6",
    "section": "",
    "text": "Copernicus Sentinel-6 Michael Freilich includes two satellites that will fly sequentially, launched in 2020 and 2025, carrying a state-of-the art optimized payload.\nCopernicus Sentinel-6 Michael Freilich is an Earth Observation satellite mission developed to provide enhanced continuity to the very stable time series of mean sea level measurements and ocean sea state that started in 1992, with the TOPEX/Poseidon mission, then continued by the Jason-1, Jason-2 and Jason-3 satellite missions."
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel6.html#sentinel-6-precise-orbit-determination-pod-products",
    "href": "Data/SentinelMissions/Sentinel6.html#sentinel-6-precise-orbit-determination-pod-products",
    "title": "Sentinel-6",
    "section": "Sentinel-6 Precise Orbit Determination (POD) products",
    "text": "Sentinel-6 Precise Orbit Determination (POD) products\n\nOverview\nThe Copernicus Sentinel-6 satellites feature three main scientific instruments: a Ku/C-band Synthetic Aperture Radar (SAR) altimeter known as Poseidon-4, a multi-frequency Advanced Microwave Radiometer for Climate (AMR-C) with an experimental High-Resolution Microwave Radiometer (HRMR), and a suite for Precise Orbit Determination (POD) incorporating Global Navigation Satellite System (GNSS) receivers, a Laser Retroreflector Array (LRA), and a Doppler Orbitography Radio-positioning Integrated by Satellite (DORIS) system. Additionally, there are secondary instruments: a Global Navigation Satellite System Radio Occultation (GNSS-RO) device for atmospheric vertical profile data, and a Radiation Environment Monitor (REM) sensor for in-situ measurement of proton and electron fluxes in the challenging space radiation environment of low-earth orbit.\n\nOffered Data\n\n\n\n\n\n\nProduct ID\n\n\nContent\n\n\nTGZ\n\n\ntar\n\n\nRolling Policy\n\n\nCatalog API\n\n\nS3 Path\n\n\n\n\n\n\nAX____ROE__AX\n\n\nOrbit\n\n\n\n\nX\n\n\n1 month\n\n\nOData\n\n\n/eodata/Sentinel-6/AUX/AX____ROE__AX/\n\n\n\n\nAUX_GNSSRD\n\n\nRINEX\n\n\nX\n\n\n\n\n\n\nOData\n\n\n/eodata/Sentinel-6/AUX/AUX_GNSSRD/\n\n\n\n\nAUX_PROQUA\n\n\nQuaternions\n\n\nX\n\n\n\n\n\n\nOData\n\n\n/eodata/Sentinel-6/AUX/AUX_PROQUA/\n\n\n\n\nAX____MOED_AX\n\n\nOrbit\n\n\n\n\nX\n\n\n1 month\n\n\nOData\n\n\n/eodata/Sentinel-6/AUX/AX____MOED_AX/\n\n\n\n\nAX____POE__AX\n\n\nOrbit\n\n\n\n\nX\n\n\n\n\nOData\n\n\n/eodata/Sentinel-6/AUX/AX____POE__AX/"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html",
    "href": "Data/SentinelMissions/Sentinel3.html",
    "title": "Sentinel-3",
    "section": "",
    "text": "The main objective of the Copernicus Sentinel-3 mission is to measure ocean and land surface colour, sea and land surface temperature, and sea surface topography with high accuracy and reliability to support ocean forecasting systems, environmental monitoring and climate monitoring. The mission definition is driven by the need for continuity in provision of ERS, ENVISAT and SPOT vegetation data, with improvements in instrument performance and coverage.\nLevel-1 Level-2"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html#sentinel-3-olci-level-1",
    "href": "Data/SentinelMissions/Sentinel3.html#sentinel-3-olci-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI Level 1",
    "text": "Sentinel-3 OLCI Level 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level 1 products provides calibrated, geolocated, and orthorectified data from the Ocean and Land Colour Instrument (OLCI). These products are delivered not later than 1 month (commitment) after acquisition or from long-term archives.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nOa01\n\n\nAerosol correction\n\n\n300\n\n\n0.4000\n\n\n\n\nOa02\n\n\nYellow substance and detrital pigments (turbidity)\n\n\n300\n\n\n0.4125\n\n\n\n\nOa03\n\n\nChlorophyll absorption maximum\n\n\n300\n\n\n0.4425\n\n\n\n\nOa04\n\n\nChlorophyll\n\n\n300\n\n\n0.4900\n\n\n\n\nOa05\n\n\nChlorophyll\n\n\n300\n\n\n0.5100\n\n\n\n\nOa06\n\n\nChlorophyll reference (minimum)\n\n\n300\n\n\n0.5600\n\n\n\n\nOa07\n\n\nSediment loading\n\n\n300\n\n\n0.6200\n\n\n\n\nOa08\n\n\n2nd Chlorophyll absorption maximum\n\n\n300\n\n\n0.6650\n\n\n\n\nOa09\n\n\nImproved fluorescence retrieval\n\n\n300\n\n\n0.6737\n\n\n\n\nOa010\n\n\nChlorophyll fluorescence peak\n\n\n300\n\n\n0.6813\n\n\n\n\nOa11\n\n\nChlorophyll fluorescence baseline\n\n\n300\n\n\n0.7087\n\n\n\n\nOa12\n\n\nO2 absorption / clouds\n\n\n300\n\n\n0.7538\n\n\n\n\nOa16\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.7788\n\n\n\n\nOa17\n\n\nAtmospheric / aerosol correction\n\n\n300\n\n\n0.8650\n\n\n\n\nOa18\n\n\nWater vapour absorption\n\n\n300\n\n\n0.8850\n\n\n\n\nOa19\n\n\nWater vapour absorption\n\n\n300\n\n\n0.9000\n\n\n\n\nOa21\n\n\nWater vapour absorption\n\n\n300\n\n\n1.0200"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html#sentinel-3-olci-level-2",
    "href": "Data/SentinelMissions/Sentinel3.html#sentinel-3-olci-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 OLCI Level 2",
    "text": "Sentinel-3 OLCI Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 OLCI Level-2 product provides geophysical data that is derived from the Level-1 product. The level-2 land product provides land and atmospheric geophysical parameters computed for full and Reduced Resolution. The Level-2 product also includes data quality flags that provide information on the reliability of the geophysical parameters, as well as information on the atmospheric correction applied to the data. These flags can be used to filter out data that is not of sufficient quality for a particular application.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html#sentinel-3-slstr-level-1",
    "href": "Data/SentinelMissions/Sentinel3.html#sentinel-3-slstr-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SLSTR Level 1",
    "text": "Sentinel-3 SLSTR Level 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView in browser\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level-1 product provides a valuable source of processed and calibrated data that is suitable for a wide range of applications. The product includes key parameters and data quality flags that provide important information on the reliability and accuracy of the data, and the product is generated offline with a delay of a few days after the acquisition of the Level-0 data.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543\n\n\n\n\nS2\n\n\nVegetation monitoring\n\n\n500\n\n\n0.6595\n\n\n\n\nS3\n\n\nNDVI, cloud flagging\n\n\n500\n\n\n0.8680\n\n\n\n\nS4\n\n\nCirrus detection over land\n\n\n500\n\n\n1.3748\n\n\n\n\nS5\n\n\nCloud clearing\n\n\n500\n\n\n1.6134\n\n\n\n\nS6\n\n\nVegetation state and cloud clearing\n\n\n500\n\n\n2.2557\n\n\n\n\nS7\n\n\nSST, LST, Active fire\n\n\n500\n\n\n3.7420\n\n\n\n\nS8\n\n\nSST, LST, Active fire\n\n\n500\n\n\n10.8540\n\n\n\n\nS9\n\n\nSST, LST\n\n\n1000\n\n\n12.0225\n\n\n\n\nF1\n\n\nActive fire\n\n\n500\n\n\n3.7420\n\n\n\n\nF2\n\n\nActive fire\n\n\n1000\n\n\n3.9400\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSTAC: https://stac-extensions.github.io/datacube/v1.0.0/schema.json"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html#sentinel-3-slstr-level-2",
    "href": "Data/SentinelMissions/Sentinel3.html#sentinel-3-slstr-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SLSTR Level 2",
    "text": "Sentinel-3 SLSTR Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SLSTR Level-2 product provides higher-level geophysical parameters, but with a longer processing time and coarser spatial resolution compared to the Level-1 product. The product also includes additional data quality flags to provide more information on the reliability and accuracy of the data.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html#sentinel-3-syn-level-2",
    "href": "Data/SentinelMissions/Sentinel3.html#sentinel-3-syn-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SYN Level 2",
    "text": "Sentinel-3 SYN Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SYN Level 2 product is a higher-level processed product that contains information about the Earth’s atmosphere and its constituents. It is derived from the Level-1 and Level-2 products of the OLCI and SLSTR instruments on board the Sentinel-3 satellite.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\nCopernicus Sentinel data 2023  \n\n\n\n\n\nSpatial Extent\n\n[-180, -90, 180, 90]\n\n\n\nTemporal Interval\n\n[‘2016-04-17T11:33:13Z’, None]\n\n\n\n\nSpectral Bands\n\n\n\n\n\n\nBand Name\n\n\nCommon Name\n\n\nGSD(m)\n\n\nCenter Wavelength(μm)\n\n\n\n\n\n\nS1\n\n\nCloud screening\n\n\n500\n\n\n0.5543"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html#sentinel-3-sral-level-1",
    "href": "Data/SentinelMissions/Sentinel3.html#sentinel-3-sral-level-1",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SRAL Level 1",
    "text": "Sentinel-3 SRAL Level 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SRAL Level-1 product provides corrected and validated geophysical parameters derived from the raw SRAL Level-0 data, along with metadata and data quality flags that enable the user to assess the reliability and suitability of the data for specific applications.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html#sentinel-3-sral-level-2",
    "href": "Data/SentinelMissions/Sentinel3.html#sentinel-3-sral-level-2",
    "title": "Sentinel-3",
    "section": "Sentinel-3 SRAL Level 2",
    "text": "Sentinel-3 SRAL Level 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Sentinel-3 SRAL Level-2 product is a higher-level processed product that contains more detailed and refined geophysical parameters suitable for scientific and research applications. It contains advanced geophysical parameters such as sea surface height, significant wave height, and wind speed, that are derived from the SRAL Level-1 products using advanced processing algorithms and quality control procedures.\n\nOffered Data\n\n\n\n\n\n\nTimeliness\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\nAvailable in Ecosystem from\n\n\n\n\n\n\nNon Time Critical (NTC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nMar 2016 - Present\n\n\nJan 2023\n\n\n\n\nNear Real Time (NRT)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one year\n\n\nJan 2023\n\n\n\n\nShort Time Critical (STC)\n\n\nPacked or Unpacked\n\n\nImmediately available data (IAD)\n\n\nWorld\n\n\nLast one month\n\n\nJan 2023"
  },
  {
    "objectID": "Data/SentinelMissions/Sentinel3.html#sentinel-3-precise-orbit-determination-pod-products",
    "href": "Data/SentinelMissions/Sentinel3.html#sentinel-3-precise-orbit-determination-pod-products",
    "title": "Sentinel-3",
    "section": "Sentinel-3 Precise Orbit Determination (POD) products",
    "text": "Sentinel-3 Precise Orbit Determination (POD) products\n\nOverview\nThe Copernicus POD Service for the Sentinel-3 mission categorizes Precise Orbital products into three types based on timeliness. Near Real-Time (NRT) products are generated immediately using real-time GPS data. Short Time Critical (STC) products use data delivered by EGP with a 1-day timeliness. Non Time Critical (NTC) products are computed after several days, incorporating precise inputs like GPS data from CODE, with current ambiguity resolution.\n\nOffered Data\n\n\n\n\n\n\nProduct ID\n\n\nContent\n\n\nEOF\n\n\nTGZ\n\n\nzip\n\n\nRolling Policy\n\n\nCatalog API\n\n\nS3 Path\n\n\n\n\n\n\nSR___ROE_AX\n\n\nOrbit\n\n\n\n\n\n\nX\n\n\n1 month\n\n\nOData\n\n\n/eodata/Sentinel-3/AUX/SR___ROE_AX/\n\n\n\n\nAUX_MOEORB\n\n\nOrbit\n\n\nX\n\n\n\n\n\n\n1 month\n\n\nOData\n\n\n/eodata/Sentinel-3/AUX/AUX_MOEORB/\n\n\n\n\nAUX_POEORB\n\n\nOrbit\n\n\nX\n\n\n\n\n\n\n\n\nOData\n\n\n/eodata/Sentinel-3/AUX/AUX_POEORB/\n\n\n\n\nAUX_PRCPTF\n\n\nPlatform\n\n\nX\n\n\n\n\n\n\n\n\nOData\n\n\n/eodata/Sentinel-3/AUX/AUX_PRCPTF/\n\n\n\n\nAUX_GNSSRD\n\n\nRINEX\n\n\n\n\nX\n\n\n\n\n\n\nOData\n\n\n/eodata/Sentinel-3/AUX/AUX_GNSSRD/\n\n\n\n\nAUX_PROQUA\n\n\nQuaternions\n\n\n\n\nX\n\n\n\n\n\n\nOData\n\n\n/eodata/Sentinel-3/AUX/AUX_PROQUA/\n\n\n\n\nSR___MDO_AX\n\n\nOrbit\n\n\n\n\nX\n\n\n\n\n1 month\n\n\nOData\n\n\n/eodata/Sentinel-3/AUX/SR___MDO_AX/\n\n\n\n\nSR___POE_AX\n\n\nOrbit\n\n\nX\n\n\n\n\n\n\n\n\nOData\n\n\n/eodata/Sentinel-3/AUX/SR___POE_AX/"
  },
  {
    "objectID": "Data/Others/Dashboard.html",
    "href": "Data/Others/Dashboard.html",
    "title": "Copernicus Operations Dashboard",
    "section": "",
    "text": "This dashboard keeps users and stakeholders up to date with the latest information about available satellite data.\nAccess Link : https://operations.dashboard.copernicus.eu/index\nIt aims at providing details on the status of the Copernicus operations, covering Sentinel-1, 2, 3 (Land) and Sentinel-5P.\nThe Homepage includes a high-level overview of the Copernicus Sentinel missions over the past 24 h, including the number of missions, time spent gathering data, data volumes, and the number of products delivered.\nThe Events tab provides details of events over the past three months that have impact on the completeness of the data production, such as planned calibration activities, manoeuvrers, or anomalies. The information of which data is affected is included.\n\n\n\n\n\n\n\n\n\n\nThe Data Takes tab hosts a real-time list of available collections delivered by the missions, enabling users to scan through these products to find data that meet their research and development requirements, and to assess their availability.\n\n\n\n\n\nThe Publication Statistics tab provides detailed information on Copernicus Sentinel data – such as number of products delivered – covering anywhere between the past 24h and the past three months. These insights are represented visually, with one graphical representation per mission that is subdivided by sensor.\n\n\n\n\n\nIn the coming year the Dashboard is planned to improve the emerging requirements.\nFor any inquiries on the Copernicus Operations Dashboard contact us."
  },
  {
    "objectID": "Data/Others/Sentinel2_Mosaic_Algorithm.html",
    "href": "Data/Others/Sentinel2_Mosaic_Algorithm.html",
    "title": "Algorithm",
    "section": "",
    "text": "The following algorithm was run independently for each pixel:\n(1) For each pixel: Take the three-month stack of Sentinel-2 L2A observations. Only bands B02, B03, B04, B08 and SCL are used to create the mosaic. For bands B02-B08 transform the values to reflectance.\n(2) For each observation: Mark an observation as invalid if the value of the Sentinel-2 L2A scene classification band (SCL) has one of the following values:\n\n1-SATURATED_DEFECTIVE,\n3-CLOUD_SHADOW,\n7-CLOUD_LOW_PROBA / UNCLASSIFIED,\n8-CLOUD_MEDIUM_PROBA,\n9-CLOUD_HIGH_PROBA,\n10-THIN_CIRRUS\n\n(3) For each pixel: Discard all invalid observations, what remains is called valid observations. The number of valid observations is generally different for each pixel and is output as a positive integer in the observations output band.\n(4) For each pixel, for each band (B02, B03, B04, B08): Sort all valid observations for each band separately.\n(5) For each pixel, for each band (B02, B03, B04, B08): Take the value of the first quartile and multiply it by 10000 (to get a ‘digital number’). This is an output value.\n(6) For each pixel, for each band (B02, B03, B04, B08): If there are no valid observations, output the value -32768, which represents no data. For the observations band, output the value 0, which also represents no data.\n\n\n\n\n\n\nNote\n\n\n\n\nIf multiple Sentinel-2 observations from the same day are available, only the most recent observation on that day is used.\nNo pre-filtering (e.g. based on cloud coverage) was performed to preserve as many non-cloudy pixels as possible.\n\n\n\nAccess Sentinel-2 Level 3 Quarterly Mosaics with Sentinel Hub\n\n\nAccess Sentinel-2 Level 3 Quarterly Mosaics with Sentinel Hub\nSentinel-2 Level 3 Quarterly Mosaics are onboarded to Sentinel Hub as a BYOC data collection. To access the data, you will need the specific pieces of information listed below, for general information about how to access BYOC collections visit our Data BYOC page.\n\nData collection id: byoc-5460de54-082e-473a-b6ea-d5cbe3c17cca\nAvailable Bands and Data:\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nResolution\n\n\n\n\n\n\nB02\n\n\nBlue\n\n\n10 m\n\n\n\n\nB03\n\n\nGreen\n\n\n10 m\n\n\n\n\nB04\n\n\nRed\n\n\n10 m\n\n\n\n\nB08\n\n\nNear Infrared (NIR)\n\n\n10 m\n\n\n\n\nobservations\n\n\nNumber of valid observations\n\n\n10 m\n\n\n\n\ndataMask\n\n\nThe mask of data/no data pixels (more).\n\n\nN/A*\n\n\n\n\n\n*dataMask has no source resolution as it is calculated for each output pixel.\n\nExample of requesting mosaic over Rome with Processing API request\nThe request below is written in python. To execute it, you need to create an OAuth client as is explained here. It is named oauth in this example.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 }\n  };\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04/10000, 2.5 * sample.B03/10000, 2.5 * sample.B02/10000];\n}\n\"\"\"\n\nrequest = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [\n        12.44693,\n        41.870072,\n        12.541001,\n        41.917096\n      ]\n    },\n    \"data\": [\n      {\n        \"dataFilter\": {\n          \"timeRange\": {\n            \"from\": \"2023-01-01T00:00:00Z\",\n            \"to\": \"2023-01-02T23:59:59Z\"\n          }\n        },\n        \"type\": \"byoc-5460de54-082e-473a-b6ea-d5cbe3c17cca\"\n      }\n    ]\n  },\n  \"output\": {\n    \"width\": 780,\n    \"height\": 523,\n    \"responses\": [\n      {\n        \"identifier\": \"default\",\n        \"format\": {\n          \"type\": \"image/jpeg\"\n        }\n      }\n    ]\n  },\n  \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "Data/Others/Sentinel2_Mosaic_access.html",
    "href": "Data/Others/Sentinel2_Mosaic_access.html",
    "title": "Access Sentinel-2 Level 3 Quarterly Mosaics with Sentinel Hub",
    "section": "",
    "text": "Sentinel-2 Level 3 Quarterly Mosaics are onboarded to Sentinel Hub as a BYOC data collection. To access the data, you will need the specific pieces of information listed below, for general information about how to access BYOC collection visit our Data BYOC page.\n\nData collection id: byoc-5460de54-082e-473a-b6ea-d5cbe3c17cca\nAvailable Bands and Data:\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nResolution\n\n\n\n\n\n\nB02\n\n\nBlue\n\n\n10 m\n\n\n\n\nB03\n\n\nGreen\n\n\n10 m\n\n\n\n\nB04\n\n\nRed\n\n\n10 m\n\n\n\n\nB08\n\n\nNear Infrared (NIR)\n\n\n10 m\n\n\n\n\nobservations\n\n\nNumber of valid observations\n\n\n10 m\n\n\n\n\ndataMask\n\n\nThe mask of data/no data pixels (more).\n\n\nN/A*\n\n\n\n\n\n*dataMask has no source resolution as it is calculated for each output pixel.\n\nExample of requesting mosaic over Rome with Processing API request\nThe request below is written in python. To execute it, you need to create an OAuth client as is explained here. It is named oauth in this example.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 }\n  };\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04/10000, 2.5 * sample.B03/10000, 2.5 * sample.B02/10000];\n}\n\"\"\"\n\nrequest = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [\n        12.44693,\n        41.870072,\n        12.541001,\n        41.917096\n      ]\n    },\n    \"data\": [\n      {\n        \"dataFilter\": {\n          \"timeRange\": {\n            \"from\": \"2023-01-01T00:00:00Z\",\n            \"to\": \"2023-01-02T23:59:59Z\"\n          }\n        },\n        \"type\": \"byoc-5460de54-082e-473a-b6ea-d5cbe3c17cca\"\n      }\n    ]\n  },\n  \"output\": {\n    \"width\": 780,\n    \"height\": 523,\n    \"responses\": [\n      {\n        \"identifier\": \"default\",\n        \"format\": {\n          \"type\": \"image/jpeg\"\n        }\n      }\n    ]\n  },\n  \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat7.html",
    "href": "Data/ComplementaryData/Landsat7.html",
    "title": "Landsat-7",
    "section": "",
    "text": "The Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters.\nLandsat products in the Copernicus Data Space Ecosystem originate from the ESA processing. For more information please visit here.\nLandsat-7 has continued the goal of the Landsat programme to repeatedly image Earth’s land and coastal areas in order to monitor changes to these areas over time. The satellite has continued to provide data continuity for the Thematic Mapper aboard Landsat-4 and 5, utilising an enhanced version of the instrument.\nThe Enhanced Thematic Mapper Plus (ETM+) is the main instrument on board Landsat-7 and has been operational since 1999. It provides 30 m resolution for visible (VIS), near-infrared (NIR) and shortwave infrared (SWIR) as well as 60 m resolution for thermal infrared. Moreover, it adds a 15 m resolution panchromatic band (PAN).\nAccess to Landsat-7 data is possible via API\nIn order to get access to data at specific processing level as well as specific product types, you are advised to use queries provided in each section below.\nIf it is required to customize query in respect to spatial and time coverage, satellite features etc. please, follow instructions on:\n• OpenSearch\n• OData\nLevel-1"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat7.html#landsat-7-etmgtc-1p",
    "href": "Data/ComplementaryData/Landsat7.html#landsat-7-etmgtc-1p",
    "title": "Landsat-7",
    "section": "Landsat-7 ETM+GTC-1P",
    "text": "Landsat-7 ETM+GTC-1P\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-7 ETM+ GTC (Global Land Survey) 1-arc second Panchromatic (1P) product is particularly useful for applications such as detailed land-cover mapping, change detection, and mapping of urban areas, as it enables the ability to discriminate between objects with higher detail. However, the Landsat-7 satellite experienced a hardware malfunction that caused a loss of data in every image acquired after May 2003. Therefore, the Landsat-7 ETM+ GTC 1-arc second Panchromatic (1P) product is limited to images acquired before the malfunction occurred.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\n(*)ETM-GTC-1P\n\n\n(*) Unpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nSep 1999 - Dec 2003\n\n\n\n\n\n(*) Landsat ETM+ ESA archive\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatETM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-etm-esa-archive"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat7.html#landsat-7-etml1g",
    "href": "Data/ComplementaryData/Landsat7.html#landsat-7-etml1g",
    "title": "Landsat-7",
    "section": "Landsat-7 ETM+L1G",
    "text": "Landsat-7 ETM+L1G\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-7 ETM+ Level-1 Georeferenced (L1G) product is suitable for applications such as land-use mapping, change detection, and ecological monitoring, where the spatial accuracy may not be critical. The data is provided in an unprocessed, uncalibrated format. However, it also includes georeferencing information, allowing for easy integration into geospatial analysis systems.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nETM-L1G\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nSep 1999 - Nov 2015\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatETM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-etm-esa-archive"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat7.html#landsat-7-etml1gt",
    "href": "Data/ComplementaryData/Landsat7.html#landsat-7-etml1gt",
    "title": "Landsat-7",
    "section": "Landsat-7 ETM+L1GT",
    "text": "Landsat-7 ETM+L1GT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-7 ETM+ L1GT refers to the Level-1 Geocorrected and Terrain corrected product acquired by the Enhanced Thematic Mapper Plus (ETM+) instrument on board Landsat 7 satellite. This product is corrected for geometric distortions caused by the satellite’s altitude, position, and attitude, as well as to correct for variations in terrain height. The corrected images are orthorectified to a cartographic projection, with radiometric and atmospheric corrections applied to produce accurate and calibrated reflectance values. This product is widely used for various applications including crop management, forest management, geological studies, land-use planning, and environmental monitoring.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nETM-L1GT\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nSep 1999 - Jan 2017\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatETM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-etm-esa-archive"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat7.html#landsat-7-etml1t",
    "href": "Data/ComplementaryData/Landsat7.html#landsat-7-etml1t",
    "title": "Landsat-7",
    "section": "Landsat-7 ETM+L1T",
    "text": "Landsat-7 ETM+L1T\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-7 ETM+ L1T refers to the Level-1 Precision Terrain corrected product acquired by the Enhanced Thematic Mapper Plus (ETM+) instrument on board Landsat 7 satellite. This product is corrected for geometric distortions caused by the satellite’s altitude, position, and attitude, as well as to correct for variations in terrain height. The corrected images are orthorectified to a cartographic projection, with radiometric and atmospheric corrections applied to produce accurate and calibrated reflectance values. In addition to the correction for terrain effects, this product also has geometric accuracy maintained to 1/3 of a Landsat pixel. The Landsat-7 ETM+ L1T product is mostly used for precision mapping and monitoring of natural resources, such as land cover classification, vegetation change detection, and urban growth analysis.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nETM-L1T\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nSep 1999 - Jan 2017\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LandsatETM\n\n\nMore Information: https://earth.esa.int/eogateway/catalog/landsat-etm-esa-archive"
  },
  {
    "objectID": "Data/ComplementaryData/CAMS.html",
    "href": "Data/ComplementaryData/CAMS.html",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "",
    "text": "The Copernicus Atmosphere Monitoring Service (CAMS) is a service implemented by the European Centre for Medium-Range Weather Forecasts (ECMWF) which provides continuous, open, free, regular data and information on atmospheric composition. CAMS describes the current situation, forecasts, reanalysis and analyses consistently retrospective data records for recent years.\nCopernius Data Space Ecosystem provides data from Global Fire Assimilation System (GFAS), Global Atmospheric Composition Forecasts (GLOBAL) including analysis and forecast data on vertical level, Global Additional (GLOBAL_ADDITIOANL) and WMO Essential including data on cyclones."
  },
  {
    "objectID": "Data/ComplementaryData/CAMS.html#global-fire-assimilation-system-gfas",
    "href": "Data/ComplementaryData/CAMS.html#global-fire-assimilation-system-gfas",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "Global Fire Assimilation System (GFAS)",
    "text": "Global Fire Assimilation System (GFAS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe Global Fire Assimilation System (GFAS) uses data from satellite observations, such as fire detection and radiative power measurements, to estimate global wildfire emissions. This data is then assimilated into a global atmospheric chemistry transport model to provide tailored information on wildfire emissions to CAMS users.\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nAN (Analysis)\n\n\nWorld\n\n\n(*) Nov 2022 - Apr 2023\n\n\n/eodata/CAMS/GFAS/\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition."
  },
  {
    "objectID": "Data/ComplementaryData/CAMS.html#global-atmospheric-composition-forecasts-global",
    "href": "Data/ComplementaryData/CAMS.html#global-atmospheric-composition-forecasts-global",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "Global Atmospheric Composition Forecasts (GLOBAL)",
    "text": "Global Atmospheric Composition Forecasts (GLOBAL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nThe CAMS Global Atmospheric Composition Forecasts (GLOBAL) service provides short-term forecasts of atmospheric composition up to five days in advance. The GLOBAL service utilizes state-of-the-art satellite observations, measurement networks, and models to provide forecasts of a variety of atmospheric constituents, including ozone, nitrogen dioxide, carbon monoxide, and dust.\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nAN (Analysis)\nFC (Forecasts)\n\n\nWorld\n\n\n(*) Nov 2022 - Apr 2023\n\n\n/eodata/CAMS/GLOBAL/\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition"
  },
  {
    "objectID": "Data/ComplementaryData/CAMS.html#global-additional",
    "href": "Data/ComplementaryData/CAMS.html#global-additional",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "GLOBAL ADDITIONAL",
    "text": "GLOBAL ADDITIONAL\n\nOverview\nIn addition to the services provided by the CAMS Global Atmospheric Composition Forecasts (GLOBAL), the CAMS program offers several other services aimed at monitoring and forecasting air quality, greenhouse gas concentrations, and other atmospheric constituents.\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nAN (Analysis)\nFC (Forecasts)\n\n\nWorld\n\n\n(*) Nov 2022 - Apr 2023\n\n\n/eodata/CAMS/GLOBAL_ADDITIONAL/\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition"
  },
  {
    "objectID": "Data/ComplementaryData/CAMS.html#wmo-essentials",
    "href": "Data/ComplementaryData/CAMS.html#wmo-essentials",
    "title": "Copernicus Atmosphere Monitoring Service (CAMS)",
    "section": "WMO ESSENTIALS",
    "text": "WMO ESSENTIALS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nWorld Meteorological Organization (WMO) Essential Climate Variables (ECVs). These ECVs are parameters that are used to monitor and understand climate change, and are recognized by the WMO as essential indicators of the Earth’s climate system. They related to atmospheric composition, including the concentration of aerosols and greenhouse gases, as well as the distribution of ozone, nitrogen dioxide, and sulfur dioxide.\n\nOffered Data\n\n\n\n\n\n\nSpecific Products\n\n\nSpatial Extext\n\n\nTemporal Extent\n\n\nCatalogue\n\n\n\n\n\n\nGH (Geopotential Height),\nT (Temperature),\nMSL (Mean sea level pressure),\nU (U component of wind),\nV (V component of wind),\nTCT (Tropical Cyclone Trajectory)\n\n\nWorld\n\n\n(*) Mar 2018 - Oct 2022\n\n\n/eodata/CAMS/WMO_ESSENTIAL/\n\n\n\n\n\n(*) Available ~7-14 days after product’s acquisition"
  },
  {
    "objectID": "Data/ComplementaryData/CEMS.html",
    "href": "Data/ComplementaryData/CEMS.html",
    "title": "Copernicus Emergency Management Service (CEMS)",
    "section": "",
    "text": "The Copernicus Emergency Management Service (CEMS) provides geospatial data and images for informed decision making in order to support all involved in the management of natural or manmade disasters. CEMS constantly monitors Europe and the globe for signals of an impending disaster or evidence of one happening in real time. Products of CEMS are generated using remote sensing, satellite, in-situ (non-space) and modelled data.\nOne of the products offered by CEMS is Rapid Mapping which provides geospatial information within hours or days of a service request in order to support emergency management activities in the immediate aftermath of a disaster.\nThe Rapid Mapping datasets are provided categorised by emergency type, be it floods, fires, earthquakes, epidemic, humanitarian crisis, industrial accidents, mass movements, storms, volcanic activity etc. For each emergency activation, Rapid Mapping data is available as shapefiles of the event itself (flood extent, fire scar, etc.), transportation systems, hydrography, land use, etc.\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMore Information: https://emergency.copernicus.eu/mapping/list-of-activations-risk-and-recovery"
  },
  {
    "objectID": "Data/ComplementaryData/CEMS.html#copernicus-emergency-management-service---cems",
    "href": "Data/ComplementaryData/CEMS.html#copernicus-emergency-management-service---cems",
    "title": "Copernicus Emergency Management Service (CEMS)",
    "section": "",
    "text": "The Copernicus Emergency Management Service (CEMS) provides geospatial data and images for informed decision making in order to support all involved in the management of natural or manmade disasters. CEMS constantly monitors Europe and the globe for signals of an impending disaster or evidence of one happening in real time. Products of CEMS are generated using remote sensing, satellite, in-situ (non-space) and modelled data.\nOne of the products offered by CEMS is Rapid Mapping which provides geospatial information within hours or days of a service request in order to support emergency management activities in the immediate aftermath of a disaster.\nThe Rapid Mapping datasets are provided categorised by emergency type, be it floods, fires, earthquakes, epidemic, humanitarian crisis, industrial accidents, mass movements, storms, volcanic activity etc. For each emergency activation, Rapid Mapping data is available as shapefiles of the event itself (flood extent, fire scar, etc.), transportation systems, hydrography, land use, etc.\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMore Information: https://emergency.copernicus.eu/mapping/list-of-activations-risk-and-recovery"
  },
  {
    "objectID": "Data/ComplementaryData/CEMS_Events/Events2.html",
    "href": "Data/ComplementaryData/CEMS_Events/Events2.html",
    "title": "Events",
    "section": "",
    "text": "Mass Movement\n        Storm\n        Volcano\n        Wild fire\n        Forest fire\n        Flood\n        Wind storm\n        Earthquake\n        Industrial\n        Humanitarian\n        Epidemic\n        Others"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat8.html",
    "href": "Data/ComplementaryData/Landsat8.html",
    "title": "Landsat-8",
    "section": "",
    "text": "The Landsat programme is a joint USGS and NASA-led enterprise for Earth observation that represents the world’s longest running system of satellites for moderate-resolution optical remote sensing for land, coastal areas and shallow waters.\nLandsat products in the Copernicus Data Space Ecosystem originate from the ESA processing. For more information please visit here.\nLandsat-8 carries the Operational Land Imager (OLI) and the Thermal Infrared Sensor (TIRS). OLI provides imagery in the VIS, NIR and SWIR spectral ranges. It acquires images with 15 m panchromatic and 30 m multi-spectral spatial resolutions, covering a wide 185 km swath. This allows it to capture extensive areas of the Earth’s landscape while maintaining enough resolution to identify features like urban centers, farms, forests, and other land uses. The entire Earth falls within view once every 16 days due to Landsat-8’s near-polar orbit. The TIRS instrument is a thermal imager operating in a pushbroom mode with two Infra-Red channels: 10.8 µm and 12 µm with 100 m spatial resolution.\nAccess to Landsat-8 data is possible via API\nIn order to get access to data at specific processing level as well as specific product types, you are advised to use queries provided in each section below.\nIf it is required to customize query in respect to spatial and time coverage, satellite features etc. please, follow instructions on:\n• OpenSearch\n• OData\nLevel-1 Level-2"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat8.html#landsat-8-olitirs_l1gt",
    "href": "Data/ComplementaryData/Landsat8.html#landsat-8-olitirs_l1gt",
    "title": "Landsat-8",
    "section": "Landsat-8 OLI/TIRS_L1GT",
    "text": "Landsat-8 OLI/TIRS_L1GT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-8 OLI/TIRS L1GT refers to the Level-1 Geocorrected and Terrain corrected product acquired by the Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS) instrument on board Landsat 8 satellite. This product is corrected for geometric distortions caused by satellite altitude, position, and attitude, as well as to correct for variations in terrain height. The corrected images are orthorectified to a cartographic projection, with radiometric and atmospheric corrections applied to produce accurate and calibrated reflectance values. The Landsat-8 OLI/TIRS L1GT product also includes a level of geolocation accuracy and precision that corresponds to 3-meters.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nOLI/TIRS_L1GT\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nMar 2013 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LANDSAT-8_L1\n\n\nMore Information: https://earth.esa.int/eogateway/missions/landsat-8"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat8.html#landsat-8-olitirs_l1t",
    "href": "Data/ComplementaryData/Landsat8.html#landsat-8-olitirs_l1t",
    "title": "Landsat-8",
    "section": "Landsat-8 OLI/TIRS_L1T",
    "text": "Landsat-8 OLI/TIRS_L1T\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-8 OLI/TIRS L1T refers to the Level-1 Precision Terrain corrected product acquired by the Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS) instrument on board Landsat 8 satellite. This product is corrected for geometric distortions caused by the satellite’s altitude, position, and attitude, as well as to correct for variations in terrain height. The corrected images are orthorectified to a cartographic projection, with radiometric and atmospheric corrections applied to produce accurate and calibrated reflectance values. The Landsat-8 OLI/TIRS L1T product also includes a level of radiometric accuracy and precision that corresponds to 1/3 of a Landsat pixel.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\n(*) OLI/TIRS_L1T\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nMar 2013 - Aug 2020\n\n\n\n\n\n(*) not accessible by landsat-diss.eo.esa.int\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LANDSAT-8_L1\n\n\nMore Information: https://earth.esa.int/eogateway/missions/landsat-8"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat8.html#landsat-8-olitirs_l1tp",
    "href": "Data/ComplementaryData/Landsat8.html#landsat-8-olitirs_l1tp",
    "title": "Landsat-8",
    "section": "Landsat-8 OLI/TIRS_L1TP",
    "text": "Landsat-8 OLI/TIRS_L1TP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-8 OLI/TIRS L1TP refers to the Level-1 Precision Terrain corrected product acquired by the Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS) instrument on board Landsat 8 satellite. This product is similar to the Landsat-8 OLI/TIRS L1T product, but with the addition of a Landsat Quality Assessment (QA) band. This QA band flags areas of the image affected by clouds, cloud shadow, haze, or other factors that may affect the overall quality of the image. The Landsat-8 OLI/TIRS L1TP product also includes the same level of radiometric and geometric accuracy and precision as the Landsat-8 OLI/TIRS L1T product.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nOLI/TIRS_L1TP\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nMar 2013 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LANDSAT-8_L1\n\n\nMore Information: https://earth.esa.int/eogateway/missions/landsat-8"
  },
  {
    "objectID": "Data/ComplementaryData/Landsat8.html#landsat-8-olitirs_l2sp",
    "href": "Data/ComplementaryData/Landsat8.html#landsat-8-olitirs_l2sp",
    "title": "Landsat-8",
    "section": "Landsat-8 OLI/TIRS_L2SP",
    "text": "Landsat-8 OLI/TIRS_L2SP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\nLandsat-8 OLI/TIRS L2SP refers to the Level-2 Surface Reflectance product acquired by the Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS) instrument on board Landsat 8 satellite. This product is derived from the Landsat-8 OLI/TIRS L1T or L1TP product and is generated using atmospheric correction algorithms to remove atmospheric effects and convert the top-of-atmosphere reflectance to surface reflectance values.\n\nOffered Data\n\n\n\n\n\n\nProduct\n\n\nArchive Status\n\n\nAccess Type\n\n\nSpatial Extent\n\n\nTemporal Extent\n\n\n\n\n\n\nOLI/TIRS_L2SP\n\n\nUnpacked\n\n\nImmediately available data (IAD)\n\n\nEurope\n\n\nJan 2015 - Present\n\n\n\n\n\n\nFurther details about the data collection\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Links\n\n\n\nSource: https://landsat-diss.eo.esa.int/socat/LANDSAT-8_L1\n\n\nMore Information: https://earth.esa.int/eogateway/missions/landsat-8"
  },
  {
    "objectID": "APIs.html",
    "href": "APIs.html",
    "title": "APIs",
    "section": "",
    "text": "This section gives an overview on the APIs provided by Copernicus Data Space Ecosystem."
  },
  {
    "objectID": "APIs.html#catalog-apis",
    "href": "APIs.html#catalog-apis",
    "title": "APIs",
    "section": "Catalog APIs",
    "text": "Catalog APIs\nThere are various interfaces providing capability to search the catalog, to serve various users’ needs and to ensure continuity over the existing Copernicus Hubs. All interfaces are connected to the same database to guarantee consistency.\n\n\n\n\n\n\n\nOData\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenSearch Catalog web service\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTAC product catalogue\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\nCatalog APIs news\nThis section provides detailed information about upcoming changes and the changelog of the implemented updates. The releases include all Catalog APIs interfaces. To avoid disruption to your scripts or apps, we recommend reviewing the upcoming changes and the latest release notes described below:\n\n1.Upcoming Changes\nWe’ve put together a list of potential updates related to Catalog APIs as of September 2023. You can find a detailed comparison of these changes here.\n\n\n2. Release notes\nThe release notes document provides you with a comprehensive list of modifications made to the Catalog APIs for every release."
  },
  {
    "objectID": "APIs.html#streamlined-data-access",
    "href": "APIs.html#streamlined-data-access",
    "title": "APIs",
    "section": "Streamlined data access",
    "text": "Streamlined data access\nThe Streamlined Data Access APIs (SDA) enables users to access and retrieve Earth observation (EO) data from the Copernicus Data Space Ecosystem catalogue. These APIs also provide you with a set of tools and services to support data processing and analysiss.\n\n\n\n\n\n\n\nSentinel Hub\n\n\n\n\n\n\n\n\n\n\n\n\n\nopenEO\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "APIs.html#additionally",
    "href": "APIs.html#additionally",
    "title": "APIs",
    "section": "Additionally",
    "text": "Additionally\nAdditional in Copernicus Data Space Ecosystem, we provide you with the S3 API, Traceability API and On-Demand Production API. The S3 API is one of the main access methods for EO data. Whereas, the Traceability API allows you to verify and register traces for user level data available in the Copernicus Data Space. Similarly, the On-Demand Production API provides you with on-demand processing capability for CARD-BS, CARD-COH6/12.\n\n\n\n\n\n\n\nAccess to EO data via S3\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn-Demand Production API\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraceability Service\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "APIs/Token.html",
    "href": "APIs/Token.html",
    "title": "Copernicus Data Space Ecosystem Token Generation",
    "section": "",
    "text": "Users must have an access token to download products from the CDSE catalogue using OData and OpenSearch API. This token can be generated in Linux and Windows OS using cURL or Python script."
  },
  {
    "objectID": "APIs/Token.html#by-query-with-curl",
    "href": "APIs/Token.html#by-query-with-curl",
    "title": "Copernicus Data Space Ecosystem Token Generation",
    "section": "By query with cURL",
    "text": "By query with cURL\nCURL is a tool to send data to the server using several protocols, such as HTTPS.\nOn Linux:\nIn this example, the output is filtered by grep and awk commands to obtain a token. In the Linux operating system, it’s seen as an environmental variable ACCESS_TOKEN.\n\ncURLcURL with 2FA\n\n\nexport ACCESS_TOKEN=$(curl -d 'client_id=cdse-public' \\\n                    -d \"username=&lt;username&gt;\" \\\n                    -d \"password=&lt;password&gt;\" \\\n                    -d 'grant_type=password' \\\n                    'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | \\\n                    python3 -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}')\n\n\nexport ACCESS_TOKEN=$(curl -d 'client_id=cdse-public' \\\n                    -d \"username=&lt;username&gt;\" \\\n                    -d \"password=&lt;password&gt;\" \\\n                    -d 'grant_type=password' \\\n                    -d 'totp=&lt;2FA_token&gt;' \\\n                    'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | \\\n                    python3 -m json.tool | grep \"access_token\" | awk -F\\\" '{print $4}')\n\n\n\nYou can use following command to print the token:\nprintenv ACCESS_TOKEN\nOn Windows:\n\ncURLcURL with 2FA\n\n\ncurl -s -X POST https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token -H \"Content-Type: application/x-www-form-urlencoded\" -d \"username=&lt;username&gt;\" -d \"password=&lt;password&gt;\" -d \"grant_type=password\" -d \"client_id=cdse-public\"\n\n\n\ncurl -s -X POST https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token -H \"Content-Type: application/x-www-form-urlencoded\" -d \"username=&lt;username&gt;\" -d \"password=&lt;password&gt;\" -d \"totp=&lt;2FA_token&gt;\" -d \"grant_type=password\" -d \"client_id=cdse-public\"\n\n\n\nFor commands to work you need to replace “&lt;username&gt;” and “&lt;password&gt;” with your Copernicus Data Space Ecosystem login credentials \nIf you have any questions, please contact our support."
  },
  {
    "objectID": "APIs/Traceability.html",
    "href": "APIs/Traceability.html",
    "title": "Traceability Service",
    "section": "",
    "text": "Traceability Service allows the user to track a data product’s lifecycle. It acts as a historian of the product’s lifecycle, collecting the traces of all related events. These traces then can be used to check the integrity of the product, its current whereabouts, its impact on other products or, ultimately, its inadequacy for continued use in case of obsolescence. Digital signatures on the traces provide users with the ability to verify the authenticity and integrity of the traces themselves – this also enables users to detect any alterations of the product during its lifecycle.\nUsers may interact directly with Traceability API, e.g., curl, or through the open-source Traceability command line utility.\nTraceability Service API OpenAPI endpoint documentation: https://trace.dataspace.copernicus.eu/api/docs\nTraceability Service command line utility: https://github.com/eu-cdse/trace-cli"
  },
  {
    "objectID": "APIs/Traceability.html#example",
    "href": "APIs/Traceability.html#example",
    "title": "Traceability Service",
    "section": "Example",
    "text": "Example\nInteraction with Traceability Service by using the curl command on Linux:\ncurl -X 'GET' 'https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip' -H 'accept: application/json'\nPlease be aware that curl command might have a different syntax on Windows. Please refer to the curl official documentation if you have any questions (https://curl.se/docs/manual.html)."
  },
  {
    "objectID": "APIs/Traceability.html#direct-access",
    "href": "APIs/Traceability.html#direct-access",
    "title": "Traceability Service",
    "section": "Direct access",
    "text": "Direct access\nInteraction with Traceability Service directly via the Traceability Service API: https://trace.dataspace.copernicus.eu/api/v1/traces/name/S2A_MSIL1C_20230420T100021_N0509_R122_T33UVP_20230420T120027.SAFE.zip"
  },
  {
    "objectID": "APIs/Traceability.html#digital-certificates",
    "href": "APIs/Traceability.html#digital-certificates",
    "title": "Traceability Service",
    "section": "Digital Certificates",
    "text": "Digital Certificates\nThe Traceability service uses X.509 Certificates to sign information sent to the API. This allows verification of the identity of the user who created the trace.\nUse of certificates with the trace-cli tool:\nhttps://github.com/eu-cdse/trace-cli#digital-signatures\nUsers may use certificates from a trusted public authority or the Copernicus Data Space Ecosystem Certificate Authority.\n\nAbout Our Certificate Authority (CA)\nCopernicus Data Space Ecosystem operates its own Certificate Authority (CA). A CA is a trusted entity that issues digital certificates, which are data files used to link an entity with a public key cryptographically. The role of our CA is to guarantee that the individual granted the unique certificate is, who they claim to be. This is crucial for secure digital identification and trust.\n\n\nWhy Do You Need Our Root Certificates?\nCertificates are used to sign information sent to our Traceability service. By installing our root certificates, your system will trust the information signed with our certificates generated by the Copernicus Data Space Ecosystem CA. This is crucial for ensuring the integrity and the authenticity of the messages you receive.\n\n\nHow to Install Our Root Certificates?\nUsers can download the root certificates by using the links below. Once downloaded, you can install them into your operating system certificate store. The process varies depending on your operating system and browser, so please refer to their respective documentation for detailed instructions.\n\nLink to certificate: https://ca.cloudferro.com/certs/ca.crt\n\nLink to certificate revocation list: https://ca.cloudferro.com/certs/cdse-ca.crl"
  },
  {
    "objectID": "APIs/Others/UpcomingChanges.html",
    "href": "APIs/Others/UpcomingChanges.html",
    "title": "Upcoming changes",
    "section": "",
    "text": "This page includes the list of upcoming changes to Catalog APIs."
  },
  {
    "objectID": "APIs/Others/UpcomingChanges.html#default-timezone-change-for-odata-and-opensearch-apis",
    "href": "APIs/Others/UpcomingChanges.html#default-timezone-change-for-odata-and-opensearch-apis",
    "title": "Upcoming changes",
    "section": "Default Timezone Change for OData and OpenSearch APIs",
    "text": "Default Timezone Change for OData and OpenSearch APIs\nWe would like to inform you about an upcoming change to our OData and OpenSearch API interfaces, effective 27th May 2024.\nStarting from 27th May 2024, all API requests without a specified timezone will be treated by default as datetime provided in UTC format.\nCurrently, if a client does not specify a timezone in their date request, it defaults to Warsaw local time. However, as of 27th May 2024, all API requests without a specified timezone will default to datetime provided in UTC format.\nThis change is aimed at standardizing our API responses and ensuring uniformity. Please review your systems and update your requests with datetime accordingly to accommodate this change.\nTo specify a timezone within the request:\nOData API (e.g. UTC-4)\n\nOData Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and ContentDate/Start gt 2022-05-03T00:00:00.000-04:00 and ContentDate/Start lt 2022-05-04T00:00:00.000-04:00&$top=2\n\n\n\nOpenSearch API (e.g. UTC+1)\n\nOpenSearch Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/search.json?startDate=2022-05-03T00:00:00%2b01:00&maxRecords=2\n\n\n\nExamples of API requests without the timezone and API responses before and after the change:\nOData API Example\n\nHTTP RequestCurrent responseNew response\n\n\nhttps://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-1' and ContentDate/Start gt 2022-05-03T00:00:00.000 and ContentDate/Start lt 2022-05-04T00:00:00.000&$top=2\n\n\n{\n  \"@odata.context\": \"$metadata#Products\",\n  \"value\": [\n    {\n      \"@odata.mediaContentType\": \"application/octet-stream\",\n      \"Id\": \"896aeef0-eee1-5e28-acaa-7f420bb23e8c\",\n      \"Name\": \"S1A_IW_SLC__1SDV_20220502T220617_20220502T220647_043037_052392_1E9A.SAFE\",\n      \"ContentType\": \"application/octet-stream\",\n      \"ContentLength\": 8231197123,\n      \"OriginDate\": \"2022-05-02T23:30:02.126Z\",\n      \"PublicationDate\": \"2022-05-02T23:40:02.825Z\",\n      \"ModificationDate\": \"2024-03-16T03:19:06.436Z\",\n      \"Online\": true,\n      \"EvictionDate\": \"\",\n      \"S3Path\": \"/eodata/Sentinel-1/SAR/SLC/2022/05/02/S1A_IW_SLC__1SDV_20220502T220617_20220502T220647_043037_052392_1E9A.SAFE\",\n      \"Checksum\": [\n        {\n          \"Value\": \"65940707f71f444b0fa05141657cc387\",\n          \"Algorithm\": \"MD5\",\n          \"ChecksumDate\": \"2024-03-16T03:18:49.857391Z\"\n        },\n        {\n          \"Value\": \"3d2d07a95aad14f1fb77ea5ba49485b6efee667578a74257d07b9edbd9d4912a\",\n          \"Algorithm\": \"BLAKE3\",\n          \"ChecksumDate\": \"2024-03-16T03:19:07.058832Z\"\n        }\n      ],\n      \"ContentDate\": {\n        \"Start\": \"2022-05-02T22:06:17.548Z\",\n        \"End\": \"2022-05-02T22:06:47.359Z\"\n      },\n      \"Footprint\": \"geography'SRID=4326;POLYGON ((-57.750202 -2.026322, -57.366844 -3.828814, -55.15321 -3.341953, -55.540607 -1.545508, -57.750202 -2.026322))'\",\n      \"GeoFootprint\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [\n              -57.750202,\n              -2.026322\n            ],\n            [\n              -57.366844,\n              -3.828814\n            ],\n            [\n              -55.15321,\n              -3.341953\n            ],\n            [\n              -55.540607,\n              -1.545508\n            ],\n            [\n              -57.750202,\n              -2.026322\n            ]\n          ]\n        ]\n      }\n    },\n    {...\n    }\n  ],\n  \"@odata.nextLink\": \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?%24filter=Collection%2FName+eq+%27SENTINEL-1%27+and+ContentDate%2FStart+gt+2022-05-03T00%3A00%3A00.000+and+ContentDate%2FStart+lt+2022-05-04T00%3A00%3A00.000&%24top=2&%24skip=2\"\n}\n\n\n{\n  \"@odata.context\": \"$metadata#Products\",\n  \"value\": [\n    {\n      \"@odata.mediaContentType\": \"application/octet-stream\",\n      \"Id\": \"1d42f2d3-2456-485f-a93e-92f08bdd5c51\",\n      \"Name\": \"S1A_OPER_AUX_GNSSRD_POD__20220510T020122_V20220502T235946_20220503T235936\",\n      \"ContentType\": \"application/octet-stream\",\n      \"ContentLength\": 2663000,\n      \"OriginDate\": \"2022-05-10T02:30:11.130Z\",\n      \"PublicationDate\": \"2023-10-25T13:45:19.736Z\",\n      \"ModificationDate\": \"2023-11-14T22:50:17.708Z\",\n      \"Online\": true,\n      \"EvictionDate\": \"\",\n      \"S3Path\": \"/eodata/Sentinel-1/AUX/AUX_GNSSRD/2022/05/03/S1A_OPER_AUX_GNSSRD_POD__20220510T020122_V20220502T235946_20220503T235936\",\n      \"Checksum\": [\n        {\n          \"Value\": \"6a99572d2baaa3c9a83bd851ba3ba70f\",\n          \"Algorithm\": \"MD5\",\n          \"ChecksumDate\": \"2023-11-14T22:50:17.595702Z\"\n        },\n        {\n          \"Value\": \"d42f79c1ab8840db09d7596dea4ee40b175df7795dd186f812eafe4a5fa21aab\",\n          \"Algorithm\": \"BLAKE3\",\n          \"ChecksumDate\": \"2023-11-14T22:50:17.616477Z\"\n        }\n      ],\n      \"ContentDate\": {\n        \"Start\": \"2022-05-03T00:00:04.000Z\",\n        \"End\": \"2022-05-03T23:59:54.000Z\"\n      },\n      \"Footprint\": null,\n      \"GeoFootprint\": null\n    },\n    {...\n    }\n  ],\n  \"@odata.nextLink\": \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?%24filter=Collection%2FName+eq+%27SENTINEL-1%27+and+ContentDate%2FStart+gt+2022-05-03T00%3A00%3A00.000Z+and+ContentDate%2FStart+lt+2022-05-04T00%3A00%3A00.000Z&%24top=2&%24skip=2\"\n}\n\n\n\nOpenSearch API Example\n\nHTTP RequestCurrent responseNew response\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/search.json?startDate=2022-05-03T00:00:00&maxRecords=2\n\n\n{\n  \"type\": \"FeatureCollection\",\n  \"properties\": {\n    \"id\": \"04139de2-34f6-56d0-b36f-122f1a3c290a\",\n    \"totalResults\": null,\n    \"exactCount\": 0,\n    \"startIndex\": 1,\n    \"itemsPerPage\": 2,\n    \"query\": {\n      \"originalFilters\": {\n        \"startDate\": \"2022-05-03T00:00:00\",\n        \"collection\": \"SENTINEL-1\"\n      },\n      \"appliedFilters\": {\n        \"startDate\": \"2022-05-03T00:00:00\",\n        \"collection\": \"SENTINEL-1\"\n      },\n      \"processingTime\": 0.163432102\n    },\n    \"links\": [\n      {\n        \"rel\": \"self\",\n        \"type\": \"application/json\",\n        \"title\": \"self\",\n        \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/search.json?startDate=2022-05-03T00:00:00&maxRecords=2\"\n      },\n      {\n        \"rel\": \"search\",\n        \"type\": \"application/opensearchdescription+xml\",\n        \"title\": \"OpenSearch Description Document\",\n        \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/describe.xml\"\n      },\n      {\n        \"rel\": \"next\",\n        \"type\": \"application/json\",\n        \"title\": \"next\",\n        \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/search.json?startDate=2022-05-03T00%3A00%3A00&maxRecords=2&page=2\"\n      }\n    ]\n  },\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"id\": \"896aeef0-eee1-5e28-acaa-7f420bb23e8c\",\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [...\n        ]\n      },\n      \"properties\": {\n        \"collection\": \"SENTINEL-1\",\n        \"status\": \"ONLINE\",\n        \"license\": {\n          \"licenseId\": \"unlicensed\",\n          \"hasToBeSigned\": \"never\",\n          \"grantedCountries\": null,\n          \"grantedOrganizationCountries\": null,\n          \"grantedFlags\": null,\n          \"viewService\": \"public\",\n          \"signatureQuota\": -1,\n          \"description\": {\n            \"shortName\": \"No license\"\n          }\n        },\n        \"productIdentifier\": \"/eodata/Sentinel-1/SAR/SLC/2022/05/02/S1A_IW_SLC__1SDV_20220502T220617_20220502T220647_043037_052392_1E9A.SAFE\",\n        \"parentIdentifier\": null,\n        \"title\": \"S1A_IW_SLC__1SDV_20220502T220617_20220502T220647_043037_052392_1E9A.SAFE\",\n        \"description\": \"The Sentinel-1 mission is the European Radar Observatory for the Copernicus joint initiative of the European Commission (EC) and the European Space Agency (ESA). The Sentinel-1 mission includes C-band imaging operating in four exclusive imaging modes with different resolution (down to 5 m) and coverage (up to 400 km). It provides dual polarization capability, short revisit times and rapid product delivery. Additionally, precise measurements of spacecraft position and attitude are available for every observation [https://dataspace.copernicus.eu/explore-data/data-collections/sentinel-data/sentinel-1].\",\n        \"organisationName\": \"ESA\",\n        \"startDate\": \"2022-05-02T22:06:17.548Z\",\n        \"completionDate\": \"2022-05-02T22:06:47.359Z\",\n        \"productType\": \"IW_SLC__1S\",\n        \"processingLevel\": \"LEVEL1\",\n        \"platform\": \"S1A\",\n        \"instrument\": \"SAR\",\n        \"resolution\": 2.3,\n        \"sensorMode\": \"IW\",\n        \"orbitNumber\": 43037,\n        \"quicklook\": null,\n        \"thumbnail\": \"https://catalogue.dataspace.copernicus.eu/get-object?path=/Sentinel-1/SAR/SLC/2022/05/02/S1A_IW_SLC__1SDV_20220502T220617_20220502T220647_043037_052392_1E9A.SAFE/preview/thumbnail.png\",\n        \"updated\": \"2024-03-16T03:19:06.436Z\",\n        \"published\": \"2022-05-02T23:40:02.825Z\",\n        \"snowCover\": 0,\n        \"cloudCover\": 0,\n        \"gmlgeometry\": \"&lt;gml:Polygon srsName=\\\"EPSG:4326\\\"&gt;&lt;gml:outerBoundaryIs&gt;&lt;gml:LinearRing&gt;&lt;gml:coordinates&gt;-57.750202,-2.026322 -57.366844,-3.828814 -55.15321,-3.341953 -55.540607,-1.545508 -57.750202,-2.026322&lt;/gml:coordinates&gt;&lt;/gml:LinearRing&gt;&lt;/gml:outerBoundaryIs&gt;&lt;/gml:Polygon&gt;\",\n        \"centroid\": {\n          \"type\": \"Point\",\n          \"coordinates\": [\n            -56.45314692566288,\n            -2.68610524638\n          ]\n        },\n        \"orbitDirection\": \"ASCENDING\",\n        \"timeliness\": \"Fast-24h\",\n        \"relativeOrbitNumber\": 90,\n        \"processingBaseline\": 0,\n        \"polarisation\": \"VV&VH\",\n        \"swath\": \"IW1 IW2 IW3\",\n        \"services\": {\n          \"download\": {\n            \"url\": \"https://catalogue.dataspace.copernicus.eu/download/896aeef0-eee1-5e28-acaa-7f420bb23e8c\",\n            \"mimeType\": \"application/octet-stream\",\n            \"size\": 8231197123\n          }\n        },\n        \"links\": [\n          {\n            \"rel\": \"self\",\n            \"type\": \"application/json\",\n            \"title\": \"GeoJSON link for 896aeef0-eee1-5e28-acaa-7f420bb23e8c\",\n            \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/collections/SENTINEL-1/896aeef0-eee1-5e28-acaa-7f420bb23e8c.json\"\n          }\n        ]\n      }\n    },\n    {...\n    }\n  ]\n}\n\n\n{\n  \"type\": \"FeatureCollection\",\n  \"properties\": {\n    \"id\": \"1f7387ef-7456-5a77-ba63-fa036a7659cd\",\n    \"totalResults\": null,\n    \"exactCount\": 0,\n    \"startIndex\": 1,\n    \"itemsPerPage\": 2,\n    \"query\": {\n      \"originalFilters\": {\n        \"startDate\": \"2022-05-03T00:00:00Z\",\n        \"collection\": \"SENTINEL-1\"\n      },\n      \"appliedFilters\": {\n        \"startDate\": \"2022-05-03T00:00:00Z\",\n        \"collection\": \"SENTINEL-1\"\n      },\n      \"processingTime\": 0.032169373\n    },\n    \"links\": [\n      {\n        \"rel\": \"self\",\n        \"type\": \"application/json\",\n        \"title\": \"self\",\n        \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/search.json?startDate=2022-05-03T00:00:00Z&maxRecords=2\"\n      },\n      {\n        \"rel\": \"search\",\n        \"type\": \"application/opensearchdescription+xml\",\n        \"title\": \"OpenSearch Description Document\",\n        \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/describe.xml\"\n      },\n      {\n        \"rel\": \"next\",\n        \"type\": \"application/json\",\n        \"title\": \"next\",\n        \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/search.json?startDate=2022-05-03T00%3A00%3A00Z&maxRecords=2&page=2\"\n      }\n    ]\n  },\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"id\": \"1d42f2d3-2456-485f-a93e-92f08bdd5c51\",\n      \"geometry\": [\n         \n      ],\n      \"properties\": {\n        \"collection\": \"SENTINEL-1\",\n        \"status\": \"ONLINE\",\n        \"license\": {\n          \"licenseId\": \"unlicensed\",\n          \"hasToBeSigned\": \"never\",\n          \"grantedCountries\": null,\n          \"grantedOrganizationCountries\": null,\n          \"grantedFlags\": null,\n          \"viewService\": \"public\",\n          \"signatureQuota\": -1,\n          \"description\": {\n            \"shortName\": \"No license\"\n          }\n        },\n        \"productIdentifier\": \"/eodata/Sentinel-1/AUX/AUX_GNSSRD/2022/05/03/S1A_OPER_AUX_GNSSRD_POD__20220510T020122_V20220502T235946_20220503T235936\",\n        \"parentIdentifier\": null,\n        \"title\": \"S1A_OPER_AUX_GNSSRD_POD__20220510T020122_V20220502T235946_20220503T235936\",\n        \"description\": \"The Sentinel-1 mission is the European Radar Observatory for the Copernicus joint initiative of the European Commission (EC) and the European Space Agency (ESA). The Sentinel-1 mission includes C-band imaging operating in four exclusive imaging modes with different resolution (down to 5 m) and coverage (up to 400 km). It provides dual polarization capability, short revisit times and rapid product delivery. Additionally, precise measurements of spacecraft position and attitude are available for every observation [https://dataspace.copernicus.eu/explore-data/data-collections/sentinel-data/sentinel-1].\",\n        \"organisationName\": null,\n        \"startDate\": \"2022-05-03T00:00:04.000Z\",\n        \"completionDate\": \"2022-05-03T23:59:54.000Z\",\n        \"productType\": \"AUX_GNSSRD\",\n        \"processingLevel\": null,\n        \"platform\": \"SENTINEL-1\",\n        \"instrument\": \"SAR\",\n        \"resolution\": 0,\n        \"sensorMode\": null,\n        \"orbitNumber\": 0,\n        \"quicklook\": null,\n        \"thumbnail\": null,\n        \"updated\": \"2023-11-14T22:50:17.708Z\",\n        \"published\": \"2023-10-25T13:45:19.736Z\",\n        \"snowCover\": 0,\n        \"cloudCover\": 0,\n        \"gmlgeometry\": null,\n        \"centroid\": {\n          \"type\": null,\n          \"coordinates\": null\n        },\n        \"orbitDirection\": null,\n        \"timeliness\": null,\n        \"relativeOrbitNumber\": 0,\n        \"processingBaseline\": 0,\n        \"polarisation\": null,\n        \"swath\": null,\n        \"services\": {\n          \"download\": {\n            \"url\": \"https://catalogue.dataspace.copernicus.eu/download/1d42f2d3-2456-485f-a93e-92f08bdd5c51\",\n            \"mimeType\": \"application/octet-stream\",\n            \"size\": 2663000\n          }\n        },\n        \"links\": [\n          {\n            \"rel\": \"self\",\n            \"type\": \"application/json\",\n            \"title\": \"GeoJSON link for 1d42f2d3-2456-485f-a93e-92f08bdd5c51\",\n            \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/collections/SENTINEL-1/1d42f2d3-2456-485f-a93e-92f08bdd5c51.json\"\n          }\n        ]\n      }\n    },\n    {...\n    }\n  ]\n}\n\n\n\nWe kindly ask that you ensure your date requests include the appropriate timezone information to prevent any disruptions to your services."
  },
  {
    "objectID": "APIs/Others/UpcomingChanges.html#opensearch-api-new-error-handling-release",
    "href": "APIs/Others/UpcomingChanges.html#opensearch-api-new-error-handling-release",
    "title": "Upcoming changes",
    "section": "OpenSearch API new error handling release",
    "text": "OpenSearch API new error handling release\nPlease be informed that the OpenSearch API error handling update was successfully implemented on 24th October 2023. The details of the change are explained here."
  },
  {
    "objectID": "APIs/Others/UpcomingChanges.html#opensearch-api-error-handling-update-new-date",
    "href": "APIs/Others/UpcomingChanges.html#opensearch-api-error-handling-update-new-date",
    "title": "Upcoming changes",
    "section": "OpenSearch API error handling update new date",
    "text": "OpenSearch API error handling update new date\nPlease be informed that the OpenSearch API error handling update has been rescheduled for 24th October 2023. The details of the change are explained here."
  },
  {
    "objectID": "APIs/Others/UpcomingChanges.html#opensearch-api-error-handling-update-date",
    "href": "APIs/Others/UpcomingChanges.html#opensearch-api-error-handling-update-date",
    "title": "Upcoming changes",
    "section": "OpenSearch API error handling update date",
    "text": "OpenSearch API error handling update date\nPlease be informed that the OpenSearch API error handling update is planned for 17th of October 2023. The details of the change are explained here."
  },
  {
    "objectID": "APIs/Others/UpcomingChanges.html#opensearch-api-error-handling-update",
    "href": "APIs/Others/UpcomingChanges.html#opensearch-api-error-handling-update",
    "title": "Upcoming changes",
    "section": "OpenSearch API error handling update",
    "text": "OpenSearch API error handling update\nPlease be informed that the OpenSearch API error handling will be updated soon.\nPlease also note that new responses with errors will provide the RequestId, which is intended to help identify the requests with errors. It is strongly recommended to include the RequestId in the issues you submitted to the support team in case of Catalog API problems.\nThe new error handling is described below.\n\nIncorrect collection name\n\nCurrent responseNew response\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"loadFromStore - Not Found\",\n        \"ErrorCode\": 404\n    }\n}\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown collection.\",\n        \"ErrorCode\": 404,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [\n                    \"collection\"\n                ],\n                \"msg\": \"Collection '&lt;collection name presented in query&gt;' does not exist.\",\n            },\n        ],\n        \"RequestId\": &lt;request_id&gt;,\n    }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinl2/search.json\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown collection.\",\n        \"ErrorCode\": 404,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [\n                    \"collection\"\n                ],\n                \"msg\": \"Collection 'Sentinl2' does not exist.\"\n            },\n        ],\n        \"RequestID\": \"70970f42-e374-4e26-8778-41a1463e700d\"\n    }\n}\n\n\n\n\n\nIncorrect name of the query parameter\n(when the collection is not specified)\n\nCurrent responseNew response\n\n\nNo error is returned. The incorrect query parameter is ignored and not reflected in appliedFilters.\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown query parameter(s).\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [&lt;list of unexisting parameters&gt;],\n                \"msg\": \"Query parameters do not exist.\",\n            },\n        ],\n        \"RequestId\": &lt;request_id&gt;,\n    }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?productsType=S2MSI1C\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown query parameter(s).\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": {\n            \"loc\": [\n                \"productsType\"\n            ],\n            \"msg\": \"Query parameters do not exist.\"\n        },\n        \"RequestID\": \"d9f22173-4d56-44fd-ab18-35d6018c49d7\"\n    }\n}\n\n\n\n\n\nIncorrect name of the query parameter\n(when the collection is specified)\n\nCurrent responseNew response\n\n\nNo error is returned. The incorrect query parameter is ignored and not reflected in appliedFilters.\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown query parameter(s).\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [&lt;list of unexisting parameters&gt;],\n                \"msg\": \"Query parameters do not exist or are not available for specified collection.\",\n            },\n        ],\n        \"RequestId\": &lt;request_id&gt;,\n  }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?productType=S2MSI1C&startDat=2023-06-11&completionDte=2023-06-22\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Unknown query parameter(s).\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": {\n            \"loc\": [\n                \"startDat\",\n                \"completionDte\",\n                        ],\n            \"msg\": \"Query parameters do not exist or are not available for specified collection.\"\n        },\n        \"RequestID\": \"25d522af-ba4e-4152-a368-9635d560e649\"\n    }\n}\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nPlease note that the dataset parameter will not be supported anymore. Any query with the dataset parameter will result in an error.\n\n\n\n\nIncorrect value of the query parameter\n(maxRecords, index, page, sortParam, sortOrder, exactCount, geometry, box, lon, lat, radius, startDate, completionDate, updated, published, publishedAfter, publishedBefore, status)\n\nCurrent responseNew response\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": &lt;error message&gt;,\n        \"ErrorCode\": 400\n    }\n}\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Validation error.\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [&lt;list of parameters that error \"msg\" field relate to&gt;],\n                \"msg”: &lt;error message&gt;}&gt;,\n            },\n        ]\n        \"RequestId\": &lt;request_id&gt;,\n  }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&maxRecords=2001\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Validation error.\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [\n                    \"maxRecords\"\n                ],\n                \"msg\": \"Input should be less than or equal to 2000.\"\n            }\n        ],\n        \"RequestID\": \"b3b4c0bb-9697-4ff8-b90c-4eb1b97a9914\"\n    }\n}\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe kindly remind you that for the status parameter, the only acceptable values will be:\n\nONLINE\nOFFLINE\nALL\n\nAny other value will result in an error.\n\n\n\n\nIncorrect value type of the query parameter\n\nCurrent responseNew response\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": &lt;error message&gt;,\n        \"ErrorCode\": 400\n    }\n}\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Validation error.\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [&lt;list of parameters that error \"msg\" field relate to&gt;],\n                \"msg”: &lt;error message&gt;}&gt;,\n            },\n        ]\n        \"RequestId\": &lt;request_id&gt;,\n  }\n}\n\n\n\nExample\n\nHTTP RequestNew response example\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?orbitNumber=ascending\n\n\n{\n    \"detail\": {\n        \"ErrorMessage\": \"Validation error.\",\n        \"ErrorCode\": 400,\n        \"ErrorDetail\": [\n            {\n                \"loc\": [\n                    \"orbitNumber\"\n                ],\n                \"msg\": \"Proper value types for specified attribute query parameters are: 'orbitNumber'-integer\"\n            }\n        ],\n        \"RequestID\": \"33e3ebb0-7d44-4dcd-8cb2-f60216c11cef\"\n    }\n}\n\n\n\nPlease also note about the following change:\n\nupdate of the last link\n\nThe last link will be provided only when exactCount is used in the request.\n\nLink last example\n\n\n{\n    \"rel\": \"last\",\n    \"type\": \"application/json\",\n    \"title\": \"last\",\n    \"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?page=19168&processingLevel=S2MSI1C&startDate=2023-07-01&completionDate=2023-07-31&sortParam=startDate&exactCount=1\"\n}\n\n\n\nWe recommend reviewing the upcoming changes to Catalog OpenSearch API described above to avoid disruption to your current scripts or apps."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html",
    "title": "Processing Unit definition",
    "section": "",
    "text": "⚠ Costs marked with ** are not yet applied, they will come into effect in the future."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#general-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#general-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "title": "Processing Unit definition",
    "section": "General data processing - applicable to Process API, OGC API, Statistical API",
    "text": "General data processing - applicable to Process API, OGC API, Statistical API\nEach request costs a proportional amount of processing unit(s), depending on what data and processing is requested. One processing unit (PU) is defined as a request for:\n\nan output (image) size of 512 x 512 pixels,\n3 collection input bands,\none data sample per pixel (see sample),\nan output (image) format not exceeding 16 bits per pixel,\nwithout additional processing (e.g. orthorectification) applied,\n\nIn addition to this:\n\nMinimal cost of a request is\n\n0.005 PU for Process API and OGC API,\n0.01 PU for Statistical API.\n\nThe number of remaining processing units is reduced only when a request successfully executes, i.e. when the response code is 2XX.\n\n\"Multiplication factors\" are used to calculate how many processing units are required for each request. The definition of 1 processing unit and the calculation rules are summarized in the following tables:\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\nArea of interest\n512 x 512 px\nThe multiplication factor is calculated by dividing requested input size (BBOX) by 512 x 512 (pixel size depends on the user-defined resolution of the request execution).  The minimum value of this multiplication factor is 0.01. This corresponds to an area of 0.25 km^2 for Sentinel-2 data at 10 m spatial resolution.\n\n\nNumber of input bands\n3\nThe multiplication factor is calculated by dividing the requested number of input bands by 3. An exception is requesting dataMask which is not counted, unless it is the only band included.\n\n\nOutput format\n8 bit or 16 bit TIFF/JPG/PNG\nRequesting 32 bit float TIFF will result in a multiplication factor of 2 due to larger memory consumption and data traffic.  Requesting application/octet-stream will result in a multiplication factor of 1.4 due to additional integration costs (This is used for integration with external tools such as xcube.).\n\n\nNumber of data samples\n1\nThe multiplication factor equals the number of data samples per pixel.\n\n\nData fusion\nN/A\nThe multiplication is only applied when data fusion is used. Multiplication factor is calculated as a sum of all collections within the same endpoint location and twice the sum of all remote collections, i.e. count(local_collections) + 2x count(remote_collections). Example: data fusion request executed on services.sentinel-hub.com endpoint, which includes Sentinel-2 L1C, Sentinel-2 L2A and Landsat-9 would have a multiplication factor of 4 (1 + 1 + 2).\n\n\n\nSurcharges\n'Surcharges' are used for non-standard requests, which impact on the execution costs.\n\n\n\nSurcharge\nRules for calculation\n\n\n\n\n** Evalscript execution time\nExecution of evalscript with duration shorter than 200ms, is covered within the base request. Execution of complex evalscripts (i.e. neural networks, large decision trees, etc.) with duration longer than 200m there is a surcharge of 0.5 PU per each additional started 100ms interval."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#sentinel-1-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#sentinel-1-data-processing---applicable-to-process-api-ogc-api-statistical-api",
    "title": "Processing Unit definition",
    "section": "Sentinel-1 data processing - applicable to Process API, OGC API, Statistical API",
    "text": "Sentinel-1 data processing - applicable to Process API, OGC API, Statistical API\nIn addition to General data processing rules defined above, the following optional multiplicators apply as well:\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\nOrthorectification\nN/A\nRequesting orthorectification will result in a multiplication factor of 2 due to additional processing requirements .\n\n\nRadiometric Terrain Correction\nN/A\nRequesting radiometric terrain correction will result in a multiplication factor of 2.5 due to additional processing requirements. The orthorectification factor is not additionally applied as it is a prerequisite.\n\n\nSpeckle Filtering\nN/A\nRequesting speckle filtering will result in a multiplication factor of 2 due to additional processing requirements."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-querying---applicable-to-catalog-api-ogc-wfs",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-querying---applicable-to-catalog-api-ogc-wfs",
    "title": "Processing Unit definition",
    "section": "Data querying - applicable to Catalog API, OGC WFS",
    "text": "Data querying - applicable to Catalog API, OGC WFS\nEach request costs a proportional amount of processing unit(s) depending on what data and processing is requested. One processing unit (PU) is defined as a request for:\n\narea of 1000 x 1000 km\ntime period up to one month\n\nIn addition to this:\n\nMinimal cost of a request is 0.01 PU.\nMaximal cost of a request is 1 PU.\nThe number of remaining processing units is reduced only when a request successfully executes, i.e. when the response code is 2XX.\n\n\n\n\nParameter/API\nQuantity for 1 PU\nRules for multiplication factors\n\n\n\n\nArea of interest\n1 000 000 km2\nThe multiplication factor is calculated by dividing requested input area of interest (BBOX) by 1 000 000.The minimum value of this multiplication factor is 0.01. This corresponds to an area of 10 000 km2\n\n\nTime period\n1 month\nThe multiplication factor is calculated by ceiling requested time period in months."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-processing-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-processing-api",
    "title": "Processing Unit definition",
    "section": "Batch Processing API",
    "text": "Batch Processing API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\nMinimal cost of a request is 100 PU.\nProcessing with batch processing API will result in a multiplication factor of 1/3. Thus, three times more data can be processed comparing to process API for the same amount of PUs.\n** When data is delivered to a bucket in other region within the same system (i.e. Copernicus Data Space Ecosystem, AWS) there is additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#asynchronous-processing-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#asynchronous-processing-api",
    "title": "Processing Unit definition",
    "section": "Asynchronous Processing API",
    "text": "Asynchronous Processing API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\nMinimal cost of a request is 10 PU.\nWhen data is delivered to a bucket in other region within the same system (i.e. Copernicus Data Space Ecosystem, AWS) there is an additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-statistical-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#batch-statistical-api",
    "title": "Processing Unit definition",
    "section": "Batch Statistical API",
    "text": "Batch Statistical API\n\"General data processing\" and \"Sentinel-1 data processing\" rules apply with the following exceptions:\n\nMinimal cost of a request is 100 PU.\n** When data is delivered to a bucket in other region within the same system (i.e. Copernicus Data Space Ecosystem, AWS) there is an additional cost of 0.03 PU per MB of data."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#third-party-data-order---applicable-to-third-party-data-import-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#third-party-data-order---applicable-to-third-party-data-import-api",
    "title": "Processing Unit definition",
    "section": "Third party data order - applicable to Third Party Data Import API",
    "text": "Third party data order - applicable to Third Party Data Import API\n\n** Each search request costs 1 PU.\n** Each thumbnail request costs 1 PU.\n** Each created order/subscription costs 5 PU.\n** Each processed order delivery costs 5 PU.\n** Each processed subscription delivery costs 2 PU."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-ingestion---applicable-to-bring-your-own-cog-api-and-zarr-api",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#data-ingestion---applicable-to-bring-your-own-cog-api-and-zarr-api",
    "title": "Processing Unit definition",
    "section": "Data ingestion - applicable to Bring your own COG API and Zarr API",
    "text": "Data ingestion - applicable to Bring your own COG API and Zarr API\n\nEach non-GET request to BYOC or Zarr API costs 1 PU.\nUsage of your BYOC and Zarr collections is billed the same as usage of public collections."
  },
  {
    "objectID": "APIs/SentinelHub/Overview/ProcessingUnit.html#request-cost-calculation-examples",
    "href": "APIs/SentinelHub/Overview/ProcessingUnit.html#request-cost-calculation-examples",
    "title": "Processing Unit definition",
    "section": "Request cost calculation examples",
    "text": "Request cost calculation examples\n\nSentinel-1 change detection\nAn example of calculation of processing units for a Sentinel-1 change detection request (e.g. comparison of two time slices) is presented in the table below.\n\n\n\nParameter\nQuantity\nMultiplication factor\nDetails\n\n\n\n\nOutput size (width x height)\n1024 x 1024 px\nx 4\nThe requested output size is 1024 x 1024 px which is 4 times larger than the output size for one PU (512 x 512 px). Hence the multiplication factor is 4.\n\n\nNumber of input bands\n4\nx 4/3\n4 input bands are requested, which is 4/3 times more than 3 input bands, which are included in one PU. The multiplication factor is thus 4/3.\n\n\nOutput format\n32-bit float\nx 2\nThe requested 32 bit float TIFF has a multiplication factor of 2.\n\n\nNumber of data samples\n2\nx 2\n2 data samples (one for each time slice) were requested for each pixel. Thus the multiplication factor is 2.\n\n\nOrthorectification\nYes\nx 2\nOrtorectification is requested, which results in a multiplication factor of 2.\n\n\n\nTotal\n42.667 processing units\nTo calculate the number of processing units for this request multiply all the individual multiplication factors: 4 x 4/3 x 2 x 2 x 2 = 42.667\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nStatistical API is also a multi-temporal request. The same rules for calculating multiplication factors apply.\n\n\n\n\nNDVI calculation for a parcel\nAn example of calculation of processing units of NDVI value over a 4 hectare large parcel at 10 m spatial resolution is presented in the table below.\n\n\n\nParameter\nQuantity\nMultiplication factor\nDetails\n\n\n\n\nOutput size (width x height)\n20 x 20 px\nx 0.01\nThe requested output size is 20 x 20 px which is smaller than the minimum area, thus the multiplication factor is 0.01.\n\n\nNumber of input bands\n2\nx 2/3\n2 input bands are requested, thus the multiplication factor is 2/3.\n\n\nOutput format\n16-bit tiff\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\nNumber of data samples\n1\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\nOrthorectification\nNo\nx 1\nThe same as in the definition of one processing unit, thus the multiplication factor is 1.\n\n\n\nTotal\n0.0067 processing units\nTo calculate the number of processing units for this request multiply all the individual multiplication factors:  0.01 x 2/3 x 1 x 1 = 0.0067"
  },
  {
    "objectID": "APIs/SentinelHub/Overview/Authentication.html",
    "href": "APIs/SentinelHub/Overview/Authentication.html",
    "title": "Authentication",
    "section": "",
    "text": "The Sentinel Hub API uses OAuth2 Authentication and requires that you have an access token. In essence, this is a piece of information you add to your requests so the server knows it's you. These tokens do not last forever for a multitude of reasons, but you can get new ones and when they expire from the Sentinel-Hub OAuth2 server at the token endpoint listed below. But first, if you do not have one already, you need to register an OAuth Client in your account settings. This is so the server can expect you to make such token requests.\n\nHow to use tokens\nOnce you have a token, do use it for authenticating all your requests within its validity period. While tokens do not last forever, they do last a reasonable amount of time, and sufficiently long that they can be reused. The information of how long each token lasts is embedded in the token itself in the exp claim, and can be read from there.\nDo not fetch a new token for each API request you make. Token requests are rate limited, so if you are getting an HTTP 429 error, that means you are requesting too many tokens.\nTokens are JSON Web Tokens (JWT), more information about them here or here.\n\n\nRegistering OAuth client\nTo register an OAuth client, open the \"User Settings\" tab in your dashboard, then click the Create new button (1) in the \"OAuth client\" section. Give your OAuth client a name (2), set the Client grant type to Client Credentials, and click the Create client button (3). Your client secret will be displayed. Copy the secret value (4) and paste it locally, as it will not be visible after the pop-up window closes! When you are finished, click Close (5). You should now see the newly created OAuth client name and ID (6) in the list of your OAuth clients. With client ID and client secret, you are now ready to request tokens.\n\nTo request tokens the easiest way is to have some software which understands OAuth2 and can make the proper request. For example, REST clients like Postman and Insomnia have support for OAuth2 Client credentials already included. See the Token Request Examples section below.\n\n\nOAuth2 Endpoints\nToken Endpoint - for requesting tokens\nhttps://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\n\n\nToken Request Examples\n\ncURL\nThe following cURL request will return an access token, just make sure to replace &lt;your client id&gt; with your client ID and &lt;your client secret&gt; with your client secret:\ncurl --request POST --url https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token --header 'content-type: application/x-www-form-urlencoded' --data 'grant_type=client_credentials&client_id=&lt;your client id&gt;' --data-urlencode 'client_secret=&lt;your client secret&gt;'\n\n\nPostman\nIn the Postman request Authorization tab set the Type to OAuth 2.0 and Add auth data to to Request Headers. Set the Grant Type to Client Credentials, the access token URL to the token endpoint, then set the Client ID and Client Secret to the values of your OAuth Client. Scope can be blank. Set Client Authentication to Send client credentials in body. Click Get New Access Token button. You should get a new one immediately. To use this token to authorize your request, click Use Token. For more information see the Postman authorization documentation\n\n\nPython\nIn python the requests-oauthlib library can handle the retrieval of access tokens using your OAuth Client configuration.\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Your client credentials\nclient_id = '&lt;client_id&gt;'\nclient_secret = '&lt;secret&gt;'\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token',\n                          client_secret=client_secret, include_client_id=True)\n\n# All requests using this session will have an access token automatically added\nresp = oauth.get(\"https://sh.dataspace.copernicus.eu/configuration/v1/wms/instances\")\nprint(resp.content)\nrequests-oauthlib doesn't check for status before checking if the response is ok. In case there's a server error, the user can receive an incorrect error, which falsely makes it seem as if the issue is on client side. Library's compliance hooks will prevent the invalid status response from being ignored, returning the correct error. To use them, add the following code:\ndef sentinelhub_compliance_hook(response):\n    response.raise_for_status()\n    return response\n\noauth.register_compliance_hook(\"access_token_response\", sentinelhub_compliance_hook)\n\n\nJavascript\nExample using axios.\nimport axios from \"axios\"\nimport qs from \"qs\"\n\nconst client_id = \"&lt;client_id&gt;\"\nconst client_secret = \"&lt;secret&gt;\"\n\nconst instance = axios.create({\n  baseURL: \"https://sh.dataspace.copernicus.eu\"\n})\n\nconst config = {\n  headers: {\n    'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8'\n  }\n}\n\nconst body = qs.stringify({\n  client_id,\n  client_secret,\n  grant_type: \"client_credentials\"\n})\n\n\n// All requests using this instance will have an access token automatically added\ninstance.post(\"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\", body, config).then(resp =&gt; {\n  Object.assign(instance.defaults, {headers: {authorization: `Bearer ${resp.data.access_token}`}})\n})"
  },
  {
    "objectID": "APIs/SentinelHub/Overview.html",
    "href": "APIs/SentinelHub/Overview.html",
    "title": "API Overview",
    "section": "",
    "text": "The Sentinel Hub API is a RESTful API interface to various satellite imagery archives. It provides access to raw satellite data, rendered images, statistical analysis and much more.\nThe Sentinel Hub API is annotated via OpenAPI. You can browse reference docs here:\n\nWeb preview\nYAML"
  },
  {
    "objectID": "APIs/SentinelHub/Overview.html#about-sentinel-hub-api",
    "href": "APIs/SentinelHub/Overview.html#about-sentinel-hub-api",
    "title": "API Overview",
    "section": "",
    "text": "The Sentinel Hub API is a RESTful API interface to various satellite imagery archives. It provides access to raw satellite data, rendered images, statistical analysis and much more.\nThe Sentinel Hub API is annotated via OpenAPI. You can browse reference docs here:\n\nWeb preview\nYAML"
  },
  {
    "objectID": "APIs/SentinelHub/Zarr/Examples.html",
    "href": "APIs/SentinelHub/Zarr/Examples.html",
    "title": "Zarr Import API examples",
    "section": "",
    "text": "The following API requests are written in Python. To execute them, you need to create an OAuth client as is explained here. The client is named oauth in these examples. The examples are structured in a way to be as separable as possible, however in many cases doing all the steps in each chapter makes sense.\n\nCreating a collection\nTo create a collection with the name My Collection and S3 bucket my-bucket using Zarr data that resides inside s3://my-bucket/path-to-zarr.zarr/:\n\ncollection = {\n  'name': 'My Collection',\n  's3Bucket': 'my-bucket',\n  'path': 'path-to-zarr.zarr/',\n  \"crs\":\"http://www.opengis.net/def/crs/EPSG/0/4326\"\n}\n\nresponse = oauth.post('https://sh.dataspace.copernicus.eu/api/v1/zarr/collections', json=collection)\nresponse.raise_for_status()\nExtracting the collection id and status from the response:\ncollection = response.json()['data']\ncollection_id = collection['id']\ncollection_status = collection['status']\n\n# if the ingestion failed, you can access the error as follows:\n# collection_errors = collection['ingestionErrors']\nTo update the name of your Zarr collection:\n# Update name of the collection\nnew_col_name = {\n  name: 'My modified collection name'\n}\nresponse = oauth.put(f'https://sh.dataspace.copernicus.eu/api/v1/zarr/collections/{collection_id}', json=new_col_name)\nresponse.raise_for_status()\nTo delete the collection:\n# Delete the collection\nresponse = oauth.delete(f'https://sh.dataspace.copernicus.eu/api/v1/zarr/collections/{collection_id}')\nresponse.raise_for_status()\n\n\nListing arrays\nIf the ingestion was successful, you can query all ingested arrays and their properties. Arrays are paginated, that is, if there are more than 100 arrays you will only get the first 100 by default. All pages can be traversed in the same way as with other paged Sentinel Hub endpoints (see e.g. the example under listing tiles on BYOC). Retrieving the first page is shown in the following snippet:\nresponse = oauth.get(f'https://sh.dataspace.copernicus.eu/api/v1/zarr/collections/{collection_id}/arrays')\nresponse.raise_for_status()\n\narrays = response.json()['data']\nYou can also get a single array by adding the array name to the URL path. For example, to get the array named B1 of the above collection:\n\nb1_array_response = oauth.get(f'https://sh.dataspace.copernicus.eu/api/v1/zarr/collections/{collection_id}/arrays/B1')\nb1_array_response.raise_for_status()\n\nb1_array = b1_array_response.json()['data']"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S2L2A.html",
    "href": "APIs/SentinelHub/Process/Examples/S2L2A.html",
    "title": "Examples for S2L2A",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32633)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n            \"bbox\": [\n                408553.58,\n                5078145.48,\n                466081.02,\n                5126576.61,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 100,\n        \"resy\": 100,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTIff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue Color, cloudy pixels masked out\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"SCL\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if ([8, 9, 10].includes(sample.SCL)) {\n    return [1, 0, 0]\n  } else {\n    return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02]\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],\n    mosaicking: Mosaicking.ORBIT,\n    output: { id: \"default\", bands: 3 },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.orbits }\n}\n\nfunction evaluatePixel(samples) {\n  return [2.5 * samples[1].B04, 2.5 * samples[1].B03, 2.5 * samples[1].B02]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ]\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 200,\n        \"height\": 100,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nTrue color multi-part-reponse (different formats and SampleType)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B03\", \"B02\"],\n        units: \"REFLECTANCE\", // default units\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 3,\n        sampleType: \"AUTO\", // default  - scales the output values from input values [0,1] to [0,255].\n      },\n      {\n        id: \"true_color_8bit\",\n        bands: 3,\n        sampleType: \"UINT8\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_16bit\",\n        bands: 3,\n        sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n      },\n      {\n        id: \"true_color_32float\",\n        bands: 3,\n        sampleType: \"FLOAT32\",\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return {\n    // output band values are scaled from [0,1] to [0,255]. Multiply by 2.5 to increase brightness\n    default: [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02],\n\n    // Multiply input reflectance values by 2.5 to increase brighness and by 255 to return the band values clamped to [0, 255] unsigned 8 bit range.\n    true_color_8bit: [\n      2.5 * sample.B04 * 255,\n      2.5 * sample.B03 * 255,\n      2.5 * sample.B02 * 255,\n    ],\n\n    // Multiply input reflectance values by 2.5 to increase brightness and by 65535 to return the band values clamped to [0, 65535] unsigned 16 bit range.\n    true_color_16bit: [\n      2.5 * sample.B04 * 65535,\n      2.5 * sample.B03 * 65535,\n      2.5 * sample.B02 * 65535,\n    ],\n\n    // Returns band reflectance.\n    true_color_32float: [sample.B04, sample.B03, sample.B02],\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                12.206251,\n                41.627351,\n                12.594042,\n                41.856879,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/jpeg\"},\n            },\n            {\n                \"identifier\": \"true_color_8bit\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"true_color_16bit\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"true_color_32float\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nNDVI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) return [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) return [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) return [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) return [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) return [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) return [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) return [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) return [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) return [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) return [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) return [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) return [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) return [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) return [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) return [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) return [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) return [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) return [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) return [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) return [0.06, 0.33, 0.04]\n  else return [0, 0.27, 0]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 80,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nExact NDVI values using a floating point GeoTIFF\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  return [ndvi]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI values as INT16 raster\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.INT16, //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n  // Return NDVI multiplied by 10000 as integers to save processing units. To obtain NDVI values, simply divide the resulting pixel values by 10000.\n  return [ndvi * 10000]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nNDVI image and value (multi-part response png and GeoTIFF)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B08\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: SampleType.FLOAT32,\n      },\n      {\n        id: \"ndvi_image\",\n        bands: 3,\n        sampleType: SampleType.AUTO,\n      },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04)\n\n  if (ndvi &lt; -0.5) image = [0.05, 0.05, 0.05]\n  else if (ndvi &lt; -0.2) image = [0.75, 0.75, 0.75]\n  else if (ndvi &lt; -0.1) image = [0.86, 0.86, 0.86]\n  else if (ndvi &lt; 0) image = [0.92, 0.92, 0.92]\n  else if (ndvi &lt; 0.025) image = [1, 0.98, 0.8]\n  else if (ndvi &lt; 0.05) image = [0.93, 0.91, 0.71]\n  else if (ndvi &lt; 0.075) image = [0.87, 0.85, 0.61]\n  else if (ndvi &lt; 0.1) image = [0.8, 0.78, 0.51]\n  else if (ndvi &lt; 0.125) image = [0.74, 0.72, 0.42]\n  else if (ndvi &lt; 0.15) image = [0.69, 0.76, 0.38]\n  else if (ndvi &lt; 0.175) image = [0.64, 0.8, 0.35]\n  else if (ndvi &lt; 0.2) image = [0.57, 0.75, 0.32]\n  else if (ndvi &lt; 0.25) image = [0.5, 0.7, 0.28]\n  else if (ndvi &lt; 0.3) image = [0.44, 0.64, 0.25]\n  else if (ndvi &lt; 0.35) image = [0.38, 0.59, 0.21]\n  else if (ndvi &lt; 0.4) image = [0.31, 0.54, 0.18]\n  else if (ndvi &lt; 0.45) image = [0.25, 0.49, 0.14]\n  else if (ndvi &lt; 0.5) image = [0.19, 0.43, 0.11]\n  else if (ndvi &lt; 0.55) image = [0.13, 0.38, 0.07]\n  else if (ndvi &lt; 0.6) image = [0.06, 0.33, 0.04]\n  else image = [0, 0.27, 0]\n\n  return {\n    default: [ndvi],\n    ndvi_image: image,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"ndvi_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S2L2A raw bands, original data (no harmonization)\nLearn about harmonization here.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B8A\",\n          \"B09\",\n          \"B11\",\n          \"B12\",\n        ],\n        units: \"DN\",\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 12,\n      sampleType: SampleType.UINT16,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [\n    sample.B01,\n    sample.B02,\n    sample.B03,\n    sample.B04,\n    sample.B05,\n    sample.B06,\n    sample.B07,\n    sample.B08,\n    sample.B8A,\n    sample.B09,\n    sample.B11,\n    sample.B12,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04803276062012,\n                            41.805773608962866,\n                        ],\n                        [\n                            -94.06738758087158,\n                            41.805901566741305,\n                        ],\n                        [\n                            -94.06734466552734,\n                            41.7967199475024,\n                        ],\n                        [\n                            -94.06223773956299,\n                            41.79144072064381,\n                        ],\n                        [\n                            -94.0504789352417,\n                            41.791376727347966,\n                        ],\n                        [\n                            -94.05039310455322,\n                            41.7930725281021,\n                        ],\n                        [\n                            -94.04798984527588,\n                            41.7930725281021,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n                \"processing\": {\"harmonizeValues\": \"false\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nOther S2L2A specific data (Aerosol Optical Thickness, Scene Classification, Snow and Cloud probabilities, Sun and View angles)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"AOT\",\n          \"SCL\",\n          \"SNW\",\n          \"CLD\",\n          \"sunAzimuthAngles\",\n          \"sunZenithAngles\",\n          \"viewAzimuthMean\",\n          \"viewZenithMean\",\n        ],\n      },\n    ],\n    output: [\n      { id: \"TrueColor\", bands: 3, sampleType: SampleType.FLOAT32 },\n      { id: \"AOT\", bands: 1, sampleType: SampleType.UINT16 },\n      { id: \"SCL\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"SNW\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"CLD\", bands: 1, sampleType: SampleType.UINT8 },\n      { id: \"SAA\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"SZA\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"VAM\", bands: 1, sampleType: SampleType.FLOAT32 },\n      { id: \"VZM\", bands: 1, sampleType: SampleType.FLOAT32 },\n    ],\n  }\n}\n\nfunction evaluatePixel(sample) {\n  var truecolor = [sample.B04, sample.B03, sample.B02]\n  var aot = [sample.AOT]\n  var scl = [sample.SCL]\n  var snw = [sample.SNW]\n  var cld = [sample.CLD]\n  var saa = [sample.sunAzimuthAngles]\n  var sza = [sample.sunZenithAngles]\n  var vam = [sample.viewAzimuthMean]\n  var vzm = [sample.viewZenithMean]\n\n  return {\n    TrueColor: truecolor,\n    AOT: aot,\n    SCL: scl,\n    SNW: snw,\n    CLD: cld,\n    SAA: saa,\n    SZA: sza,\n    VAM: vam,\n    VZM: vzm,\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-2-l2a\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2022-10-01T00:00:00Z\",\n                        \"to\": \"2022-10-31T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"TrueColor\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"AOT\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SCL\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SNW\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"CLD\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SAA\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"SZA\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"VAM\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"VZM\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/DEM.html",
    "href": "APIs/SentinelHub/Process/Examples/DEM.html",
    "title": "Examples for DEM",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCopernicus DEM 30 image (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output: { bands: 1 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM / 1000]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"dem\",\n                \"dataFilter\": {\"demInstance\": \"COPERNICUS_30\"},\n                \"processing\": {\n                    \"upsampling\": \"BILINEAR\",\n                    \"downsampling\": \"BILINEAR\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCopernicus DEM 30, 0.0003° (~33m) resolution (tiff)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output: { bands: 1 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM / 1000]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"dem\",\n                \"dataFilter\": {\"demInstance\": \"COPERNICUS_30\"},\n                \"processing\": {\n                    \"upsampling\": \"BILINEAR\",\n                    \"downsampling\": \"BILINEAR\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 0.0003,\n        \"resy\": 0.0003,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCopernicus DEM 90 values, orthometric heights (tif)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"dem\",\n                \"dataFilter\": {\"demInstance\": \"COPERNICUS_90\"},\n                \"processing\": {\n                    \"upsampling\": \"BILINEAR\",\n                    \"downsampling\": \"BILINEAR\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCopernicus DEM 90 values, ellipsoidal heights (tif)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output: {\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32,\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                13.822174072265625,\n                45.85080395917834,\n                14.55963134765625,\n                46.29191774991382,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"dem\",\n                \"dataFilter\": {\"demInstance\": \"COPERNICUS_90\"},\n                \"processing\": {\n                    \"egm\": True,\n                    \"upsampling\": \"BILINEAR\",\n                    \"downsampling\": \"BILINEAR\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nCopernicus DEM 90 image at sea level (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output: { bands: 3 },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.DEM &gt; 0) {\n    return [0, sample.DEM / 1000, 0]\n  } else {\n    return [0, 0, -sample.DEM / 100]\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                10.082016,\n                42.625876,\n                10.496063,\n                42.927268,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"dem\",\n                \"dataFilter\": {\"demInstance\": \"COPERNICUS_90\"},\n                \"processing\": {\n                    \"upsampling\": \"BILINEAR\",\n                    \"downsampling\": \"BILINEAR\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S3OLCI.html",
    "href": "APIs/SentinelHub/Process/Examples/S3OLCI.html",
    "title": "Examples for S3OLCI",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nTrue Color\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the data from 0-255.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, resolution (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\", \"B06\", \"B04\"],\n    output: {\n      bands: 3,\n      sampleType: \"AUTO\", // default value - scales the output values from [0,1] to [0,255].\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [2.5 * sample.B08, 2.5 * sample.B06, 2.5 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    },\n                    \"processing\": {\"upsampling\": \"BILINEAR\"},\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 150,\n        \"resy\": 150,\n        \"responses\": [{\"format\": {\"type\": \"image/png\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nTrue Color, multi-band GeoTiff\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B06\", \"B08\"],\n        units: \"REFLECTANCE\", // default value\n      },\n    ],\n    output: {\n      bands: 3,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [10000 * sample.B08, 10000 * sample.B06, 10000 * sample.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nTrue color and metadata (multi-part response GeoTIFF and json)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B04\", \"B06\", \"B08\"],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    mosaicking: Mosaicking.SIMPLE,\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n  outputMetadata.userData = { scenes: scenes.tiles }\n}\n\nfunction evaluatePixel(samples) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [10000 * samples.B08, 10000 * samples.B06, 10000 * samples.B04]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"bbox\": [\n                8.3333,\n                41.3149,\n                9.7009,\n                43.0568,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"userdata\",\n                \"format\": {\"type\": \"application/json\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nOTCI as jpeg image with bounds given as polygon\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B10\", \"B11\", \"B12\"],\n      },\n    ],\n    output: {\n      id: \"default\",\n      bands: 3,\n      sampleType: \"AUTO\",\n    },\n  }\n}\n\n// Create a new visualiser to represent data\nvar cm = new ColorMapVisualizer([\n  [0, [0, 0, 0.5]],\n  [1, [0, 0.3, 0.8]],\n  [1.8, [1, 0.2, 0.2]],\n  [2.5, [1, 0.9, 0]],\n  [4, [0, 0.8, 0.1]],\n  [4.5, [0, 0.6, 0.2]],\n  [5, [1, 1, 1]],\n])\n\nfunction evaluatePixel(sample) {\n  let OTCI = (sample.B12 - sample.B11) / (sample.B11 - sample.B10)\n  return cm.process(OTCI)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                        [\n                            8.6956787109375,\n                            42.370720143531976,\n                        ],\n                        [\n                            8.7890625,\n                            42.238685347536496,\n                        ],\n                        [\n                            8.60504150390625,\n                            42.20614200929954,\n                        ],\n                        [\n                            8.70391845703125,\n                            42.15322331239858,\n                        ],\n                        [\n                            8.83575439453125,\n                            41.97991089691236,\n                        ],\n                        [\n                            8.81378173828125,\n                            41.797935707842974,\n                        ],\n                        [\n                            8.9208984375,\n                            41.777456667491066,\n                        ],\n                        [\n                            8.94012451171875,\n                            41.68316883525891,\n                        ],\n                        [\n                            9.0472412109375,\n                            41.52297326747377,\n                        ],\n                        [\n                            9.35760498046875,\n                            41.70777900286713,\n                        ],\n                        [\n                            9.33013916015625,\n                            42.06764572379527,\n                        ],\n                        [\n                            9.48394775390625,\n                            42.261049162113856,\n                        ],\n                        [\n                            9.47021484375,\n                            42.51462626746592,\n                        ],\n                        [\n                            9.33837890625,\n                            42.62385465855651,\n                        ],\n                        [\n                            9.1900634765625,\n                            42.6844544397102,\n                        ],\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    \"type\": \"image/jpeg\",\n                    \"quality\": 90,\n                },\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nOTCI image and value (multi-part response png and GeoTIFF containing floats)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\"B10\", \"B11\", \"B12\"],\n      },\n    ],\n    output: [\n      {\n        id: \"default\",\n        bands: 1,\n        sampleType: \"FLOAT32\",\n      },\n      {\n        id: \"otci_image\",\n        bands: 3,\n        sampleType: \"AUTO\",\n      },\n    ],\n  }\n}\n\n// Create a new visualiser to represent data\nvar cm = new ColorMapVisualizer([\n  [0, [0, 0, 0.5]],\n  [1, [0, 0.3, 0.8]],\n  [1.8, [1, 0.2, 0.2]],\n  [2.5, [1, 0.9, 0]],\n  [4, [0, 0.8, 0.1]],\n  [4.5, [0, 0.6, 0.2]],\n  [5, [1, 1, 1]],\n])\n\nfunction evaluatePixel(sample) {\n  let OTCI = (sample.B12 - sample.B11) / (sample.B11 - sample.B10)\n  return {\n    default: [OTCI],\n    otci_image: cm.process(OTCI),\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"},\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                        [\n                            8.6956787109375,\n                            42.370720143531976,\n                        ],\n                        [\n                            8.7890625,\n                            42.238685347536496,\n                        ],\n                        [\n                            8.60504150390625,\n                            42.20614200929954,\n                        ],\n                        [\n                            8.70391845703125,\n                            42.15322331239858,\n                        ],\n                        [\n                            8.83575439453125,\n                            41.97991089691236,\n                        ],\n                        [\n                            8.81378173828125,\n                            41.797935707842974,\n                        ],\n                        [\n                            8.9208984375,\n                            41.777456667491066,\n                        ],\n                        [\n                            8.94012451171875,\n                            41.68316883525891,\n                        ],\n                        [\n                            9.0472412109375,\n                            41.52297326747377,\n                        ],\n                        [\n                            9.35760498046875,\n                            41.70777900286713,\n                        ],\n                        [\n                            9.33013916015625,\n                            42.06764572379527,\n                        ],\n                        [\n                            9.48394775390625,\n                            42.261049162113856,\n                        ],\n                        [\n                            9.47021484375,\n                            42.51462626746592,\n                        ],\n                        [\n                            9.33837890625,\n                            42.62385465855651,\n                        ],\n                        [\n                            9.1900634765625,\n                            42.6844544397102,\n                        ],\n                        [\n                            8.80279541015625,\n                            42.494377798972465,\n                        ],\n                    ]\n                ],\n            },\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"otci_image\",\n                \"format\": {\"type\": \"image/png\"},\n            },\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})\n\n\nAll S3OLCI reflectance bands as a GeoTIFF (EPSG 32632)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\n      {\n        bands: [\n          \"B01\",\n          \"B02\",\n          \"B03\",\n          \"B04\",\n          \"B05\",\n          \"B06\",\n          \"B07\",\n          \"B08\",\n          \"B09\",\n          \"B10\",\n          \"B11\",\n          \"B12\",\n          \"B13\",\n          \"B14\",\n          \"B15\",\n          \"B16\",\n          \"B17\",\n          \"B18\",\n          \"B19\",\n          \"B20\",\n          \"B21\",\n        ],\n        units: \"REFLECTANCE\",\n      },\n    ],\n    output: {\n      bands: 21,\n      sampleType: \"UINT16\", //floating point values are automatically rounded to the nearest integer by the service.\n    },\n  }\n}\n\nfunction evaluatePixel(sample) {\n  // Return reflectance multiplied by 10000 as integers to save processing units.\n  // To obtain reflectance values, simply divide the result pixel values by 10000.\n  return [\n    10000 * sample.B01,\n    10000 * sample.B02,\n    10000 * sample.B03,\n    10000 * sample.B04,\n    10000 * sample.B05,\n    10000 * sample.B06,\n    10000 * sample.B07,\n    10000 * sample.B08,\n    10000 * sample.B09,\n    10000 * sample.B10,\n    10000 * sample.B11,\n    10000 * sample.B12,\n    10000 * sample.B13,\n    10000 * sample.B14,\n    10000 * sample.B15,\n    10000 * sample.B16,\n    10000 * sample.B17,\n    10000 * sample.B18,\n    10000 * sample.B19,\n    10000 * sample.B20,\n    10000 * sample.B21,\n  ]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n            \"bbox\": [\n                444170,\n                4574059,\n                557052,\n                4767386,\n            ],\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-3-olci\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2020-04-04T00:00:00Z\",\n                        \"to\": \"2020-04-05T00:00:00Z\",\n                    }\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 300,\n        \"resy\": 300,\n        \"responses\": [{\"format\": {\"type\": \"image/tiff\"}}],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})"
  },
  {
    "objectID": "APIs/SentinelHub/Process/Examples/S1GRD.html",
    "href": "APIs/SentinelHub/Process/Examples/S1GRD.html",
    "title": "Examples for S1GRD",
    "section": "",
    "text": "The requests below are written in python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nS1GRD orthorectified linear gamma0 VV between 0 and 0.5 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\"orthorectify\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified linear gamma0 VV between 0 and 0.5 in approximate real-world 10 m resolution (IW) (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                268574.43,\n                4624494.84,\n                276045.41,\n                4631696.16,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"},\n        },\n        \"data\": [\n            {\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    },\n                    \"resolution\": \"HIGH\",\n                    \"acquisitionMode\": \"IW\",\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"demInstance\": \"COPERNICUS_30\",\n                },\n                \"type\": \"sentinel-1-grd\",\n            }\n        ],\n    },\n    \"output\": {\n        \"resx\": 10,\n        \"resy\": 10,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified with Copernicus DEM 30 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"demInstance\": \"COPERNICUS_30\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified linear gamma0 VV, ascending orbit direction, GeoTIFF in EPSG:32648 (UTM zone 48N)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1, sampleType: SampleType.FLOAT32 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                699800,\n                1190220,\n                709800,\n                1200220,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32648\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2017-11-15T00:00:00Z\",\n                        \"to\": \"2017-11-15T23:00:00Z\",\n                    },\n                    \"acquisitionMode\": \"IW\",\n                    \"polarization\": \"DV\",\n                    \"orbitDirection \": \"ASCENDING\",\n                },\n                \"processing\": {\n                    \"backCoeff\": \"GAMMA0_ELLIPSOID\",\n                    \"orthorectify\": \"true\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 1000,\n        \"height\": 1000,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/tiff\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"image/tiff\"})\n\n\nS1GRD orthorectified decibel gamma0 VH between -20 dB and 0 dB (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VH\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [toDb(samples.VH)]\n}\n\n// visualizes decibels from -20 to 0\n\nfunction toDb(linear) {\n  // the following commented out lines are simplified below\n  // var log = 10 * Math.log(linear) / Math.LN10\n  // var val = Math.max(0, (log + 20) / 20)\n  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\"orthorectify\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified decibel gamma0 RGB composite of VV, VH, VV/VH/10 between -20 dB and 0 dB (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\", \"VH\"],\n    output: { id: \"default\", bands: 3 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  var vvdB = toDb(samples.VV)\n  var vhdB = toDb(samples.VH)\n  return [vvdB, vhdB, vvdB / vhdB / 10]\n}\n\n// displays VV in decibels from -20 to 0\n\nfunction toDb(linear) {\n  // the following commented out lines are simplified below\n  // var log = 10 * Math.log(linear) / Math.LN10\n  // var val = Math.max(0, (log + 20) / 20)\n  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\"orthorectify\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD non-orthorectified linear sigma0 VH between 0 and 0.5 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VH\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VH]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"false\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD non-orthorectified Lee speckle filtered decibel gamma0 HH between -20 dB and +10 dB (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"HH\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [toDb(samples.HH)]\n}\n\n// visualizes decibels from -20 to +10\n\nfunction toDb(linear) {\n  var log = (10 * Math.log(linear)) / Math.LN10\n  return Math.max(0, (log + 20) / 30)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                18400000,\n                -11330000,\n                18500000,\n                -11430000,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"acquisitionMode\": \"EW\",\n                    \"timeRange\": {\n                        \"from\": \"2020-09-29T00:00:00Z\",\n                        \"to\": \"2020-09-29T23:59:59Z\",\n                    },\n                },\n                \"processing\": {\n                    \"orthorectify\": \"false\",\n                    \"backCoeff\": \"GAMMA0_ELLIPSOID\",\n                    \"speckleFilter\": {\n                        \"type\": \"LEE\",\n                        \"windowSizeX\": 5,\n                        \"windowSizeY\": 5,\n                    },\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 1000,\n        \"height\": 1000,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD orthorectified gamma0 two month temporal averaged decibel VV between -20 dB and 0 dB (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\", \"dataMask\"],\n    output: { id: \"default\", bands: 1 },\n    mosaicking: Mosaicking.ORBIT,\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [calculateAverage(samples)]\n}\n\nfunction calculateAverage(samples) {\n  var sum = 0\n  var nValid = 0\n  for (let sample of samples) {\n    if (sample.dataMask != 0) {\n      nValid++\n      sum += toDb(sample.VV)\n    }\n  }\n  return sum / nValid\n}\n\n// visualizes decibels from -20 to 0\n\nfunction toDb(linear) {\n  // the following commented out lines are simplified below\n  // var log = 10 * Math.log(linear) / Math.LN10\n  // var val = Math.max(0, (log + 20) / 20)\n  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1360000,\n                5121900,\n                1370000,\n                5131900,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-01T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    },\n                    \"orbitDirection\": \"ASCENDING\",\n                },\n                \"processing\": {\"orthorectify\": \"true\"},\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD radiometrically terrain corrected linear gamma0 VV between 0 and 0.5 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1095431,\n                5714610,\n                1146158,\n                5754129,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"GAMMA0_TERRAIN\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD radiometrically terrain corrected using Copernicus DEM 30 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1095431,\n                5714610,\n                1146158,\n                5754129,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"GAMMA0_TERRAIN\",\n                    \"demInstance\": \"COPERNICUS_30\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD radiometrically terrain corrected with custom DEM oversampling of 3 (png)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\"],\n    output: { id: \"default\", bands: 1 },\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return [2 * samples.VV]\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                1095431,\n                5714610,\n                1146158,\n                5754129,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/3857\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"GAMMA0_TERRAIN\",\n                    \"radiometricTerrainOversampling\": 3,\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 512,\n        \"height\": 512,\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\"type\": \"image/png\"},\n            }\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request)\n\n\nS1GRD radiometrically terrain corrected gamma0 VV and auxiliary data: local incidence angle, scattering area, and shadow mask\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"VV\", \"localIncidenceAngle\", \"scatteringArea\", \"shadowMask\"],\n    output: [\n      { id: \"s1_rtc_VV_area\", bands: 2, sampleType: \"FLOAT32\" },\n      { id: \"s1_rtc_angle_mask\", bands: 2, sampleType: \"UINT8\" },\n    ],\n  }\n}\n\nfunction evaluatePixel(samples) {\n  return {\n    s1_rtc_VV_area: [samples.VV, samples.scatteringArea],\n    s1_rtc_angle_mask: [samples.localIncidenceAngle, samples.shadowMask],\n  }\n}\n\"\"\"\n\nrequest = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [\n                565556.94,\n                5048644.47,\n                600656.56,\n                5076658.33,\n            ],\n            \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32632\"},\n        },\n        \"data\": [\n            {\n                \"type\": \"sentinel-1-grd\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-02-02T00:00:00Z\",\n                        \"to\": \"2019-04-02T23:59:59Z\",\n                    }\n                },\n                \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"GAMMA0_TERRAIN\",\n                },\n            }\n        ],\n    },\n    \"output\": {\n        \"width\": 1024,\n        \"height\": 796,\n        \"responses\": [\n            {\n                \"identifier\": \"s1_rtc_VV_area\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n            {\n                \"identifier\": \"s1_rtc_angle_mask\",\n                \"format\": {\"type\": \"image/tiff\"},\n            },\n        ],\n    },\n    \"evalscript\": evalscript,\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\nresponse = oauth.post(url, json=request, headers={\"Accept\": \"application/tar\"})"
  },
  {
    "objectID": "APIs/SentinelHub/Byoc/Examples.html",
    "href": "APIs/SentinelHub/Byoc/Examples.html",
    "title": "BYOC API examples",
    "section": "",
    "text": "The following API requests are written in Python. To execute them, you need to create an OAuth client as is explained here. The client is named oauth in these examples. The examples are structured in a way to be as separable as possible, however in many cases doing all the steps in each chapter makes sense.\n\nCreating a collection\nTo create a collection with the name &lt;MyCollection&gt; and S3 bucket &lt;MyBucket&gt;:\ncollection = {\n  'name': '&lt;MyCollection&gt;',\n  's3Bucket': '&lt;MyBucket&gt;'\n}\n\nresponse = oauth.post('https://sh.dataspace.copernicus.eu/api/v1/byoc/collections', json=collection)\nresponse.raise_for_status()\nExtracting the collection id from the response:\nimport json\n\ncollection = json.loads(response.text)['data']\ncollection_id = collection['id']\n\n\nCreating a tile\nTo create a tile with the path &lt;MyTile&gt;:\ntile = {\n  'path': '&lt;MyTile&gt;',\n}\n\nresponse = oauth.post(f'https://sh.dataspace.copernicus.eu/api/v1/byoc/collections/{collection_id}/tiles', json=tile)\nresponse.raise_for_status()\nIf your tile has a known sensing time, e.g. October 21, 2019 at 14:51 by UTC time, add this information by using the following payload:\ntile = {\n  'path': '&lt;MyTile&gt;',\n  'sensingTime': '2019-10-21T14:51:00Z'\n}\nIf you want to provide a cover geometry, set it as the value of the coverGeometry field:\ntile = {\n  'path': '&lt;MyTile&gt;',\n  'coverGeometry': &lt;MyCoverGeometry&gt;\n}\nFor information on how to prepare a cover geometry, see Preparing a cover geometry.\nTo extract the tile id from the response:\nimport json\n\ntile = json.loads(response.text)['data']\ntile_id = tile['id']\n\n\nPreparing a cover geometry\nTo obtain a cover geometry automatically, you can use the gdal_trace_outline script which gives you a cover geometry in the WKT format:\nimport subprocess\n\ncommand = f'gdal_trace_outline &lt;MyCOG&gt; -out-cs en -wkt-out wkt.txt'\nsubprocess.run(command, shell=True, check=True)\nOnce complete, transform the geometry into the GeoJSON format:\nfrom osgeo import ogr\nimport json\n\nf = open('wkt.txt')\ngeom = ogr.CreateGeometryFromWkt(f.read())\ncover_geometry = json.loads(geom.ExportToJson())\nIf the CRS is something other than WGS84, make sure to set its URN &lt;CrsUrn&gt; under crs.properties.name. For example urn:ogc:def:crs:EPSG::32633 for EPSG:32633.\ncover_geometry['crs'] = {\n  'properties': {\n    'name': '&lt;CrsUrn&gt;'\n  }\n}\nTo obtain the URN automatically from a raster file you can use the following Python scriptget_crn_urn.py.\n\n\nChecking the tile ingestion status\nTo check the ingestion status of the tile, first get the tile:\nresponse = oauth.get(f'https://sh.dataspace.copernicus.eu/api/v1/byoc/collections/{collection_id}/tiles/{tile_id}')\nresponse.raise_for_status()\nThen extract its status from the response:\nimport json\n\ntile = json.loads(response.text)['data']\nstatus = tile['status']\n\nif status == 'INGESTED':\n  print('Tile ingested')\nelif status == 'FAILED':\n  print('Tile failed to ingest')\nelse:\n  print(status)\nTo check why a tile failed to ingest:\nprint(tile['additionalData']['failedIngestionCause'])\n\n\nListing tiles\nTiles are paginated and to traverse all pages use the link from response that points to the next page, which is located at links.next. By default, you get back 100 tiles per page, but you can change this using the query parameter count, however it cannot be more than 100.\nimport time\n\nurl = f'https://sh.dataspace.copernicus.eu/api/v1/byoc/collections/{collection_id}/tiles'\n\nwhile url is not None:\n  response = oauth.get(url)\n  response.raise_for_status()\n\n  output = response.json()\n  tiles = output['data']\n  links = output['links']\n\n  for tile in tiles:\n    print(tile['path'])\n\n  # sets url to None if there's no link to the next set of tiles\n  url = links.get('next', None)\n\n  # waits a bit before fetching the next set\n  time.sleep(0.1)"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html",
    "href": "APIs/SentinelHub/Evalscript/Functions.html",
    "title": "Utility Functions",
    "section": "",
    "text": "Visualizers are JavaScript classes with a method process which evaluates the representation value for a pixel from pixel’s band values.\n\n\nSets the color from a discrete color map.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\n\n\n\n\nconst map = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorMapVisualizer(map);\nvisualizer.process(199); // returns [ 1, 0, 0 ]\nvisualizer.process(200); // returns [ 1, 0, 0 ]\nvisualizer.process(250); // returns [ 1, 0, 0 ]\nvisualizer.process(299); // returns [ 1, 0, 0 ]\nvisualizer.process(300); // returns [ 0, 0, 1 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorMapVisualizer with following valColPairs\n[\n  [-1.0, 0x000000],\n  [-0.2, 0xff0000],\n  [-0.1, 0x9a0000],\n  [0.0, 0x660000],\n  [0.1, 0xffff33],\n  [0.2, 0xcccc33],\n  [0.3, 0x666600],\n  [0.4, 0x33ffff],\n  [0.5, 0x33cccc],\n  [0.6, 0x006666],\n  [0.7, 0x33ff33],\n  [0.8, 0x33cc33],\n  [0.9, 0x006600]\n]\n\n\n\n\nInterpolates a color based on interval.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\nminVal number (optional, default 0.0)\nmaxVal number (optional, default 1.0)\n\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs redTemperature\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createRedTemperature(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0.43137254901960786, 0, 0 ]\nvisualizer.process(0.5); // returns [ 0.7176470588235294, 0.047058823529411764, 0 ]\nvisualizer.process(0.8); // returns [ 1, 0.6196078431372549, 0.2 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs greenWhite\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createWhiteGreen(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0, 0.2980392156862745, 0 ]\nvisualizer.process(0.5); // returns [ 0.16862745098039217, 0.5019607843137255, 0 ]\nvisualizer.process(0.8); // returns [ 0.6666666666666666, 0.8, 0.3333333333333333 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs blueRed\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createBlueRed(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0.5019607843137255 ]\nvisualizer.process(0.3); // returns [ 0, 0.7019607843137254, 1 ]\nvisualizer.process(0.5); // returns [ 0.5019607843137255, 1, 0.5019607843137255 ]\nvisualizer.process(0.8); // returns [ 1, 0.2980392156862745, 0 ]\nvisualizer.process(1.0); // returns [ 0.5019607843137255, 0, 0 ]\nReturns ColorGradientVisualizer\n\n\n\n\n\nInterpolates a color based on the given color ramps.\n\n\n\nramps Array&lt;[number, number]&gt; Array of color ramps, which are defined as a pair of numbers - the ramp start and the ramp starting color.\n\n\n\n\nconst ramps = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorRampVisualizer(ramps);\nvisualizer.process(199); // [ 1, 0, 0 ]\nvisualizer.process(200); // [ 1, 0, 0 ]\nvisualizer.process(250); // [ 0.5019607843137255, 0, 0.5019607843137255 ]\nvisualizer.process(299); // [ 0.011764705882352941, 0, 0.9882352941176471 ]\nvisualizer.process(300); // [ 0, 1, 0 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nvalue number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\n\nThis is a piecewise linear function which compresses highlights. The minValue and maxValue will be mapped inside the interval [ 0, 1 ]. However, if maxValue lies in (0, 1) a second function which increases much more slowly will be used to further map the values which are mapped to 0.92 and above (see the figure below). This increases the visualized dynamic range while keeping most of the interval of interest linear. Useful, for example, for true color, with a maxValue of 0.4 to still keep some detail in clouds.\n\n\n\nPiecewise linear function which compresses highlights\n\n\n\n\n\nminValue number the value which will be mapped to 0. All values smaller than minValue will also be mapped to 0. (optional, default 0.0)\nmaxValue number the value which controls the position of the boundary point between both linear functions. It will be mapped to approx. 0.9259, while values greater than or equal to (2*maxValue - minValue) will be mapped to 1 (see the figure above). (optional, default 1.0)\ngain (optional, default 1.0)\noffset (optional, default 0.0)\ngamma (optional, default 1.0)\n\n\n\n\nconst visualizer = new HighlightCompressVisualizer(0.1, 0.4)\n\nvisualizer.process(0); // will return 0\nvisualizer.process(0.1); // will return 0\nvisualizer.process(0.25); // will return 0.5\nvisualizer.process(0.376); // will return 0.92. Note: 0.376 = minValue + 0.92*(maxValue - minValue)\nvisualizer.process(0.4); // will return 0.9259\nvisualizer.process(0.7); // will return 1 Note: 0.7 is the smallest value mapped to 1.\nvisualizer.process(1.1); // will return 1\n\n\n\nReturns mapped value.\n\n\n\nval number the input value to be mapped.\ni number the index of val. This is EO Browser specific.\n\nReturns [number] mapped value."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#visualizers",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#visualizers",
    "title": "Utility Functions",
    "section": "",
    "text": "Visualizers are JavaScript classes with a method process which evaluates the representation value for a pixel from pixel’s band values.\n\n\nSets the color from a discrete color map.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\n\n\n\n\nconst map = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorMapVisualizer(map);\nvisualizer.process(199); // returns [ 1, 0, 0 ]\nvisualizer.process(200); // returns [ 1, 0, 0 ]\nvisualizer.process(250); // returns [ 1, 0, 0 ]\nvisualizer.process(299); // returns [ 1, 0, 0 ]\nvisualizer.process(300); // returns [ 0, 0, 1 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorMapVisualizer with following valColPairs\n[\n  [-1.0, 0x000000],\n  [-0.2, 0xff0000],\n  [-0.1, 0x9a0000],\n  [0.0, 0x660000],\n  [0.1, 0xffff33],\n  [0.2, 0xcccc33],\n  [0.3, 0x666600],\n  [0.4, 0x33ffff],\n  [0.5, 0x33cccc],\n  [0.6, 0x006666],\n  [0.7, 0x33ff33],\n  [0.8, 0x33cc33],\n  [0.9, 0x006600]\n]\n\n\n\n\nInterpolates a color based on interval.\n\n\n\nvalColPairs Array&lt;[number, number]&gt;\nminVal number (optional, default 0.0)\nmaxVal number (optional, default 1.0)\n\n\n\n\nReturns interpolated color for value.\n\n\n\nval number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs redTemperature\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createRedTemperature(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0.43137254901960786, 0, 0 ]\nvisualizer.process(0.5); // returns [ 0.7176470588235294, 0.047058823529411764, 0 ]\nvisualizer.process(0.8); // returns [ 1, 0.6196078431372549, 0.2 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs greenWhite\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createWhiteGreen(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0 ]\nvisualizer.process(0.3); // returns [ 0, 0.2980392156862745, 0 ]\nvisualizer.process(0.5); // returns [ 0.16862745098039217, 0.5019607843137255, 0 ]\nvisualizer.process(0.8); // returns [ 0.6666666666666666, 0.8, 0.3333333333333333 ]\nvisualizer.process(1.0); // returns [ 1, 1, 1 ]\nReturns ColorGradientVisualizer\n\n\n\n\nCreates ColorGradientVisualizer with valColPairs blueRed\n\n\n\nminVal number min value of interval\nmaxVal number max value of interval\n\n\n\n\nconst visualizer = ColorGradientVisualizer.createBlueRed(0.0, 1.0);\nvisualizer.process(0.0); // returns [ 0, 0, 0.5019607843137255 ]\nvisualizer.process(0.3); // returns [ 0, 0.7019607843137254, 1 ]\nvisualizer.process(0.5); // returns [ 0.5019607843137255, 1, 0.5019607843137255 ]\nvisualizer.process(0.8); // returns [ 1, 0.2980392156862745, 0 ]\nvisualizer.process(1.0); // returns [ 0.5019607843137255, 0, 0 ]\nReturns ColorGradientVisualizer\n\n\n\n\n\nInterpolates a color based on the given color ramps.\n\n\n\nramps Array&lt;[number, number]&gt; Array of color ramps, which are defined as a pair of numbers - the ramp start and the ramp starting color.\n\n\n\n\nconst ramps = [\n  [200, 0xff0000],\n  [300, 0x0000ff ],\n];\n\nconst visualizer = new ColorRampVisualizer(ramps);\nvisualizer.process(199); // [ 1, 0, 0 ]\nvisualizer.process(200); // [ 1, 0, 0 ]\nvisualizer.process(250); // [ 0.5019607843137255, 0, 0.5019607843137255 ]\nvisualizer.process(299); // [ 0.011764705882352941, 0, 0.9882352941176471 ]\nvisualizer.process(300); // [ 0, 1, 0 ]\n\n\n\nReturns interpolated color for value.\n\n\n\nvalue number\n\nReturns [number, number, number] normalized RGB triplet.\n\n\n\n\n\nThis is a piecewise linear function which compresses highlights. The minValue and maxValue will be mapped inside the interval [ 0, 1 ]. However, if maxValue lies in (0, 1) a second function which increases much more slowly will be used to further map the values which are mapped to 0.92 and above (see the figure below). This increases the visualized dynamic range while keeping most of the interval of interest linear. Useful, for example, for true color, with a maxValue of 0.4 to still keep some detail in clouds.\n\n\n\nPiecewise linear function which compresses highlights\n\n\n\n\n\nminValue number the value which will be mapped to 0. All values smaller than minValue will also be mapped to 0. (optional, default 0.0)\nmaxValue number the value which controls the position of the boundary point between both linear functions. It will be mapped to approx. 0.9259, while values greater than or equal to (2*maxValue - minValue) will be mapped to 1 (see the figure above). (optional, default 1.0)\ngain (optional, default 1.0)\noffset (optional, default 0.0)\ngamma (optional, default 1.0)\n\n\n\n\nconst visualizer = new HighlightCompressVisualizer(0.1, 0.4)\n\nvisualizer.process(0); // will return 0\nvisualizer.process(0.1); // will return 0\nvisualizer.process(0.25); // will return 0.5\nvisualizer.process(0.376); // will return 0.92. Note: 0.376 = minValue + 0.92*(maxValue - minValue)\nvisualizer.process(0.4); // will return 0.9259\nvisualizer.process(0.7); // will return 1 Note: 0.7 is the smallest value mapped to 1.\nvisualizer.process(1.1); // will return 1\n\n\n\nReturns mapped value.\n\n\n\nval number the input value to be mapped.\ni number the index of val. This is EO Browser specific.\n\nReturns [number] mapped value."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#helper-functions",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#helper-functions",
    "title": "Utility Functions",
    "section": "Helper functions",
    "text": "Helper functions\nHelper functions that can be used in custom scripts.\n\nint2rgb\nTransforms a color as integer into RGB triplet.\n\nParameters\n\ncolor number as integer\n\n\n\nExamples\nint2rgb(255);    // returns [ 0, 0, 255 ]\nint2rgb(256);    // returns [ 0, 1, 0 ]\nint2rgb(65537);  // returns [ 1, 0, 1 ]\nReturns [number, number, number]\n\n\n\nrgb2int\nInverse of the int2rgb function. Transforms a RGB triplet into integer.\n\nParameters\n\ncolor [number, number, number] as RGB triplet\n\n\n\nExamples\nrgb2int([0, 0, 255]);  // returns 255\nrgb2int([0, 1, 0]);    // returns 256\nrgb2int([1, 0, 1]);    // returns 65537\nReturns number\n\n\n\ncombine\nCombines two colors.\n\nParameters\n\ncolor1 number The first color defined as an array of values.\ncolor2 number The second color defined as an array of values.\nalpha number A share of the first color defined as a floating point between 0 and\n\n\n\n\n\n\nExamples\ncombine([100, 0, 0], [0, 100, 0], 1);   // returns [ 100, 0, 0 ]\ncombine([100, 0, 0], [0, 100, 0], 0);   // returns [ 0, 100, 0 ]\ncombine([100, 0, 0], [0, 100, 0], 0.5); // returns [ 50, 50, 0 ]\nReturns number The combined color defined as an array of values.\n\n\n\nindex\nCalculate difference divided by sum\n\nParameters\n\nx number first value\ny number second value\n\n\n\nExamples\nindex(0.6, 0.4); // returns 0.2\nindex(0.5, -0.5); //returns 0.0\nReturns number (x - y) / (x + y), if sum is 0 returns 0\n\n\n\ninverse\nCalculate inverse value\n\nParameters\n\nx number value\n\n\n\nExamples\ninverse(2.0); // returns 0.5\ninverse(5.0); // returns 0.2\ninverse(0); // returns 1.7976931348623157E308\nReturns number inverse of value of x (1 / x), if x is 0 returns JAVA_DOUBLE_MAX_VAL\n\n\n\nvalueMap\nMaps a value to another value bound by an interval (from,to].\nintervals = [-10, -5, 0, 5, 10], values = [-100,-50, 0, 50, 100]\ndefines the following mapping:\n(-inf, -10]  =&gt; -100\n(-10, -5] =&gt; -50\n(-5,0] =&gt; 0\n(0, 5] =&gt; 50\n(5, +inf) =&gt; 100\n\nParameters\n\nvalue number input value\nintervals [number] array of numbers in ascending order defining intervals\nvalues [number] output value for the given interval\n\n\n\nExamples\nvalueMap(5, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 500\nvalueMap(1, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 100\nvalueMap(2, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 300\nvalueMap(12, [1, 3, 5, 7, 10], [100, 300, 500, 700, 900]); // returns 900\nvalueMap(50); // returns 50\nReturns number\n\n\n\nvalueInterpolate\nInterpolates a value to another value bound by an interval (from,to]. Values at far ends of defined intervals are clamped to min/max value. This function is a replacement for the deprecated colorBlend function.\nintervals = [-10, -5, 0, 5, 10], values = [-1000,-50, 0, 50, 1000]\ndefines the following mapping:\n(-inf, -10]  =&gt; -1000\n(-10, -5] =&gt; (-1000, -50]\n(-5,0] =&gt; (-50,0]\n(0, 5] =&gt; (0,50]\n(5, 10] =&gt; (50,1000]\n(10, +inf) =&gt; 1000\n\nParameters\n\nvalue number input value\nintervals Array&lt;number&gt; array of numbers in ascending order defining intervals\nvalues (Array&lt;number&gt; | Array&lt;Array&lt;number&gt;&gt;) output interval for the given value/interval of the intervals array\n\n\n\nExamples\nvalueInterpolate(0, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns 0\nvalueInterpolate(-10, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns -1000\nvalueInterpolate(9, [-10, -5, 0, 5, 10], [-1000,-50, 0, 50, 1000]); // returns 810\nvalueInterpolate(50); // returns 50\nvalueInterpolate(0.1, [0, 0.2, 0.4, 0.6, 0.8, 1], [\n  [0, 0, 0],\n  [0.1, 0.2, 0.5],\n  [0.25, 0.4, 0.5],\n  [0.4, 0.6, 0.5],\n  [0.75, 0.8, 0.5],\n  [1, 1, 0.5]\n]); // return [0.05, 0.1, 0.25]\nReturns (number | Array&lt;number&gt;)"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#constants",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#constants",
    "title": "Utility Functions",
    "section": "Constants",
    "text": "Constants\n\nJAVA_DOUBLE_MAX_VAL\n const JAVA_DOUBLE_MAX_VAL = 1.7976931348623157E308;\nType: number\n\n\nblueRed\nconst blueRed = [\n  [1.000, 0x000080],\n  [0.875, 0x0000FF],\n  [0.625, 0x00FFFF],\n  [0.375, 0xFFFF00],\n  [0.125, 0xFF0000],\n  [0.000, 0x800000]\n]\nType: Array&lt;[number, number]&gt;\n\n\nredTemperature\nconst redTemperature = [\n  [1.000, 0x000000],\n  [0.525, 0xAE0000],\n  [0.300, 0xFF6E00],\n  [0.250, 0xFF8600],\n  [0.000, 0xFFFFFF]\n]\nType: Array&lt;[number, number]&gt;\n\n\ngreenWhite\nconst greenWhite = [\n  [1.000, 0x000000],\n  [0.600, 0x006600],\n  [0.300, 0x80B300],\n  [0.000, 0xFFFFFF]\n]\nType: Array&lt;[number, number]&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#colorblend",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#colorblend",
    "title": "Utility Functions",
    "section": "colorBlend",
    "text": "colorBlend\n\nParameters\n\nvalue number input value\nlimits Array&lt;number&gt; array of numbers in ascending order defining intervals\ncolors (Array&lt;number&gt; | Array&lt;Array&lt;number&gt;&gt;) output interval for the given value/interval of the intervals array\n\nReturns (number | Array&lt;number&gt;)\nMeta\n\ndeprecated: See valueInterpolate"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#landsat8c2qabandconditions",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#landsat8c2qabandconditions",
    "title": "Utility Functions",
    "section": "Landsat8C2QaBandConditions",
    "text": "Landsat8C2QaBandConditions\nCloud confidence, cloud shadow confidence, snow ice confidence and cirrus confidence represent levels of confidence that a condition exists:\n\n0 = “Not Determined”\n1 = “Low” = Low confidence.\n2 = “Medium / Reserved” = Medium only for cloud confidence.\n3 = “High” = High confidence.\n\nType: Object\n\nProperties\n\nfill number 0 for image data, 1 for fill data\ndilatedCloud number 0 for cloud is not dilated or no cloud, 1 for cloud dilation\ncirrus number 0 for no confidence level or low confidence, 1 for high confidence cirrus\ncloud number 0 for cloud confidence is not high, 1 for high confidence cloud\ncloudShadow number 0 for cloud shadow confidence is not high, 1 for high confidence cloud shadow\nsnow number 0 for snow/ice confidence is not high, 1 for high confidence snow cover\nclear number 0 if cloud or dilated cloud, or else 1\nwater number 0 for land or cloud, 1 for water\ncloudConfidence number\ncloudShadowConfidence number\nsnowIceConfidence number\ncirrusConfidence number"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#decodel8c2qa",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#decodel8c2qa",
    "title": "Utility Functions",
    "section": "decodeL8C2Qa",
    "text": "decodeL8C2Qa\nDecodes Landsat 8 Collection 2 Quality Assessment band conditions.\n\nParameters\n\nvalue integer band pixel (16-bit value)\n\n\n\nExamples\ndecodeL8C2Qa(55052);\n// returns {\n//   cirrus: 1, cirrusConfidence: 3,\n//   clear: 0,\n//   cloud: 1,\n//   cloudConfidence: 3,\n//   cloudShadow: 0,\n//   cloudShadowConfidence: 1,\n//   dilatedCloud: 0,\n//   fill: 0,\n//   snow: 0,\n//   snowIceConfidence: 1,\n//   water: 0\n// }\nReturns Landsat8C2QaBandConditions"
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript/Functions.html#decodes3olciqualityflags",
    "href": "APIs/SentinelHub/Evalscript/Functions.html#decodes3olciqualityflags",
    "title": "Utility Functions",
    "section": "decodeS3OLCIQualityFlags",
    "text": "decodeS3OLCIQualityFlags\nUnpacks bit-packed Sentinel 3 OLCI Quality Flags values.\n\nParameters\n\nvalue integer QUALITY_FLAGS band DN value (32-bit value)\n\nReturns object An object containing the following keys with either 0 or 1 values: land, coastline, fresh_inland_water, tidal_region, bright, straylight_risk, invalid, cosmetic, duplicated, sun_glint_risk, dubious, saturatedBxy (where xy is the band number, e.g. saturatedB01)."
  },
  {
    "objectID": "APIs/SentinelHub/Batch/Crs.html",
    "href": "APIs/SentinelHub/Batch/Crs.html",
    "title": "CRS",
    "section": "",
    "text": "Find the list of supported CRSs here.\nThe area of interest can be defined in any of these CRSs but the CRS of the output of batch API is defined with selected tiling grid."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical/Examples.html",
    "href": "APIs/SentinelHub/Statistical/Examples.html",
    "title": "Examples of Statistical API",
    "section": "",
    "text": "The requests below are written in Python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nStatistics for one single-band output on a given day\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        },\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-04T00:00:00Z\",\n            \"to\": \"2020-07-05T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-04T00:00:00Z',\n    'to': '2020-07-05T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nStatistics, histogram and percentiles for one single-band output\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        },\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-04T00:00:00Z\",\n            \"to\": \"2020-07-05T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  },\n  \"calculations\": {\n    \"default\": {\n      \"histograms\": {\n        \"default\": {\n          \"nBins\": 5,\n          \"lowEdge\": 0.0,\n          \"highEdge\": 0.3\n        }\n      },\n      \"statistics\": {\n        \"default\": {\n          \"percentiles\": {\n            \"k\": [ 33, 50, 75, 90 ]\n          }\n        }\n      }\n    }\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-04T00:00:00Z',\n    'to': '2020-07-05T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.09709999710321426,\n         '50.0': 0.10360000282526016,\n         '75.0': 0.11940000206232071,\n         '90.0': 0.16040000319480896}},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.06, 'count': 0},\n         {'lowEdge': 0.06, 'highEdge': 0.12, 'count': 2458},\n         {'lowEdge': 0.12, 'highEdge': 0.18, 'count': 558},\n         {'lowEdge': 0.18, 'highEdge': 0.24, 'count': 177},\n         {'lowEdge': 0.24, 'highEdge': 0.3, 'count': 44}],\n        'overflowCount': 3,\n        'underflowCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nStatistics for one single-band output for two months with 10 days aggregation period\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-06-01T00:00:00Z\",\n            \"to\": \"2020-07-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P10D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-06-01T00:00:00Z',\n    'to': '2020-06-11T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.7892000079154968,\n        'max': 0.8303999900817871,\n        'mean': 0.804223583473102,\n        'stDev': 0.0067066009561434865,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-06-11T00:00:00Z', 'to': '2020-06-21T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.016300000250339508,\n        'max': 0.5956000089645386,\n        'mean': 0.06240126554233315,\n        'stDev': 0.06266500670629409,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-06-21T00:00:00Z', 'to': '2020-07-01T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.026000000536441803,\n        'max': 0.43799999356269836,\n        'mean': 0.06872379640174772,\n        'stDev': 0.056520330692016944,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-01T00:00:00Z', 'to': '2020-07-11T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.07970000058412552,\n        'max': 0.30959999561309814,\n        'mean': 0.11471141986778864,\n        'stDev': 0.034298170449733226,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-11T00:00:00Z', 'to': '2020-07-21T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.017400000244379044,\n        'max': 0.4187999963760376,\n        'mean': 0.062194598779473156,\n        'stDev': 0.06317700445712106,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}},\n  {'interval': {'from': '2020-07-21T00:00:00Z', 'to': '2020-07-31T00:00:00Z'},\n   'outputs': {'output_B04': {'bands': {'B0': {'stats': {'min': 0.13920000195503235,\n        'max': 0.4927999973297119,\n        'mean': 0.3146395680115182,\n        'stDev': 0.054700527707146035,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}\n\n\nBasic statistics of NDVI with water pixels excluded (custom output dataMask)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"data\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\n\nfunction evaluatePixel(samples) {\n    let ndvi = (samples.B08 - samples.B04)/(samples.B08 + samples.B04)\n\n    var validNDVIMask = 1\n    if (samples.B08 + samples.B04 == 0 ){\n        validNDVIMask = 0\n    }\n\n    var noWaterMask = 1\n    if (samples.SCL == 6 ){\n        noWaterMask = 0\n    }\n\n    return {\n        data: [ndvi],\n        // Exclude nodata pixels, pixels where ndvi is not defined and water pixels from statistics:\n        dataMask: [samples.dataMask * validNDVIMask * noWaterMask]\n    }\n}\n\"\"\"\n\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"geometry\": {\n          \"type\": \"Polygon\",\n          \"coordinates\": [\n            [\n              [\n                458085.878866,\n                5097236.833044\n              ],\n              [\n                457813.834156,\n                5096808.351383\n              ],\n              [\n                457979.897062,\n                5096313.767184\n              ],\n              [\n                458146.639373,\n                5096405.411294\n              ],\n              [\n                458085.878866,\n                5097236.833044\n              ]\n            ]\n          ]\n        },\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastCC\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n        \"from\": \"2020-01-01T00:00:00Z\",\n        \"to\": \"2020-12-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P30D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-01-01T00:00:00Z',\n    'to': '2020-01-31T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.24306687712669373,\n        'max': 0.6244725584983826,\n        'mean': 0.4123224201824293,\n        'stDev': 0.055874589607421886,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-01-31T00:00:00Z', 'to': '2020-03-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.2451941967010498,\n        'max': 0.4233206510543823,\n        'mean': 0.3160828609431641,\n        'stDev': 0.0280772593636271,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-01T00:00:00Z', 'to': '2020-03-31T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.4236144721508026,\n        'max': 0.8021259307861328,\n        'mean': 0.5844831434836089,\n        'stDev': 0.05766820795482124,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-31T00:00:00Z', 'to': '2020-04-30T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.4647541046142578,\n        'max': 0.8266128897666931,\n        'mean': 0.6615912824901472,\n        'stDev': 0.05539347152437238,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-04-30T00:00:00Z', 'to': '2020-05-30T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.1761743128299713,\n        'max': 0.870899498462677,\n        'mean': 0.6880682412526884,\n        'stDev': 0.18833356676740057,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-05-30T00:00:00Z', 'to': '2020-06-29T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.6883189082145691,\n        'max': 0.8775584697723389,\n        'mean': 0.8230951517303176,\n        'stDev': 0.026851310273968688,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-06-29T00:00:00Z', 'to': '2020-07-29T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.8124191164970398,\n        'max': 0.9270430207252502,\n        'mean': 0.8977047195274247,\n        'stDev': 0.01321883825220214,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-07-29T00:00:00Z', 'to': '2020-08-28T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.750795304775238,\n        'max': 0.8925060033798218,\n        'mean': 0.8437445996058478,\n        'stDev': 0.017705930134783242,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-08-28T00:00:00Z', 'to': '2020-09-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.7094070315361023,\n        'max': 0.8823529481887817,\n        'mean': 0.8138526516467535,\n        'stDev': 0.020639924263070358,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-09-27T00:00:00Z', 'to': '2020-10-27T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.6416097283363342,\n        'max': 0.8256189227104187,\n        'mean': 0.7368144742384923,\n        'stDev': 0.02884084473079313,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-10-27T00:00:00Z', 'to': '2020-11-26T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': 0.5131579041481018,\n        'max': 0.9108409285545349,\n        'mean': 0.6912739742345253,\n        'stDev': 0.06273793790576106,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-11-26T00:00:00Z', 'to': '2020-12-26T00:00:00Z'},\n   'outputs': {'data': {'bands': {'B0': {'stats': {'min': -0.01446416787803173,\n        'max': 0.015364916995167732,\n        'mean': 0.0018048733875211391,\n        'stDev': 0.004322122712106793,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}}],\n 'status': 'OK'}\n\n\nStatistics of maximum monthly NDVI for a parcel in 2020\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    mosaicking: \"ORBIT\",\n    output: [\n      {\n        id: \"data\",\n        bands: [\"monthly_max_ndvi\"]\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\n\nfunction evaluatePixel(samples) {\n    var max = 0;\n    var hasData = 0;\n    for (var i=0;i&lt;samples.length;i++) {\n      if (samples[i].dataMask == 1 && samples[i].SCL != 6 && samples[i].B04+samples[i].B08 != 0 ){\n        hasData = 1\n        var ndvi = (samples[i].B08 - samples[i].B04)/(samples[i].B08 + samples[i].B04);\n        max = ndvi &gt; max ? ndvi:max;\n      }\n    }\n\n    return {\n        data: [max],\n        dataMask: [hasData]\n    }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"geometry\": {\n          \"type\": \"Polygon\",\n          \"coordinates\": [\n            [\n              [\n                458085.878866,\n                5097236.833044\n              ],\n              [\n                457813.834156,\n                5096808.351383\n              ],\n              [\n                457979.897062,\n                5096313.767184\n              ],\n              [\n                458146.639373,\n                5096405.411294\n              ],\n              [\n                458085.878866,\n                5097236.833044\n              ]\n            ]\n          ]\n        },\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastCC\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-01-01T00:00:00Z\",\n            \"to\": \"2021-01-01T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P1M\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n   'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-01-01T00:00:00Z',\n    'to': '2020-02-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.4755639135837555,\n        'max': 0.881286084651947,\n        'mean': 0.6396090604381046,\n        'stDev': 0.06844923487502963,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-02-01T00:00:00Z', 'to': '2020-03-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.3580246865749359,\n        'max': 0.8721038103103638,\n        'mean': 0.5956351390500386,\n        'stDev': 0.07367438999713516,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-03-01T00:00:00Z', 'to': '2020-04-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.4486735761165619,\n        'max': 0.8021259307861328,\n        'mean': 0.5871563556072766,\n        'stDev': 0.057052289003643133,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-04-01T00:00:00Z', 'to': '2020-05-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7103235721588135,\n        'max': 0.9151291251182556,\n        'mean': 0.8202670164519443,\n        'stDev': 0.029936259510749567,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-05-01T00:00:00Z', 'to': '2020-06-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7955418825149536,\n        'max': 0.9187881350517273,\n        'mean': 0.8889340774162204,\n        'stDev': 0.013139359632348635,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-06-01T00:00:00Z', 'to': '2020-07-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.6883189082145691,\n        'max': 0.8775584697723389,\n        'mean': 0.8258738168990016,\n        'stDev': 0.025802682912912194,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-07-01T00:00:00Z', 'to': '2020-08-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.8329545259475708,\n        'max': 0.9370484948158264,\n        'mean': 0.9037947789513383,\n        'stDev': 0.01278601507445675,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-08-01T00:00:00Z', 'to': '2020-09-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.750795304775238,\n        'max': 0.8925060033798218,\n        'mean': 0.843880225772972,\n        'stDev': 0.017580399946741675,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-09-01T00:00:00Z', 'to': '2020-10-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.7121148109436035,\n        'max': 0.8823529481887817,\n        'mean': 0.8138710224835326,\n        'stDev': 0.02056652680651673,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-10-01T00:00:00Z', 'to': '2020-11-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.6416097283363342,\n        'max': 0.8256189227104187,\n        'mean': 0.7368144742384923,\n        'stDev': 0.02884084473079313,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-11-01T00:00:00Z', 'to': '2020-12-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.5424679517745972,\n        'max': 0.9108409285545349,\n        'mean': 0.7069293897671695,\n        'stDev': 0.05380689467103403,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}},\n  {'interval': {'from': '2020-12-01T00:00:00Z', 'to': '2021-01-01T00:00:00Z'},\n   'outputs': {'data': {'bands': {'monthly_max_ndvi': {'stats': {'min': 0.0683102235198021,\n        'max': 0.23551543056964874,\n        'mean': 0.1444664227123698,\n        'stDev': 0.027443079533455306,\n        'sampleCount': 3036,\n        'noDataCount': 1192}}}}}}],\n 'status': 'OK'}\n\n\nMultiple outputs with different dataMasks, multi-band output with custom bands' names and different histogram types\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\",\n        \"SCL\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_my_bands\",\n        bands: [\"only_band_B04\", \"only_band_B08\"],\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"output_my_indices\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"output_scl\",\n        bands: 1,\n        sampleType: \"UINT8\"\n      },\n      {\n        id: \"dataMask\",\n        bands: [\"output_my_bands\", \"output_my_indices\"]\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    let ndvi = (samples.B08 - samples.B04)/(samples.B08 + samples.B04)\n\n    var validNDVIMask = 1\n    if (samples.B08 + samples.B04 == 0 ){\n        validNDVIMask = 0\n    }\n\n    var noWaterMask = 1\n    if (samples.SCL == 6 ){\n        noWaterMask = 0\n    }\n\n    return {\n        output_my_bands: [samples.B04, samples.B08],\n        output_my_indices: [ndvi],\n        output_scl: [samples.SCL],\n        dataMask: [samples.dataMask, samples.dataMask * noWaterMask * validNDVIMask]\n    }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n   \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n      \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n      }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastRecent\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-01T00:00:00Z\",\n            \"to\": \"2020-07-15T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P5D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 20,\n    \"resy\": 20\n  },\n  \"calculations\": {\n    \"output_my_bands\": {\n      \"histograms\": {\n        \"only_band_B08\": {\n          \"nBins\": 3,\n          \"lowEdge\": 0.0,\n          \"highEdge\": 0.3\n        }\n      },\n      \"statistics\": {\n        \"only_band_B04\": {\n          \"percentiles\": {\n            \"k\": [33, 66,100],\n          }\n        }\n      }\n    },\n    \"output_scl\": {\n      \"histograms\": {\n        \"default\": {\n          \"bins\": [0,1,2,3,4,5,6,7,8,9,10,11]\n        }\n      }\n    },\n    \"default\": {\n      \"histograms\": {\n        \"default\": {\n          \"binWidth\": 0.05,\n          \"lowEdge\": 0.0\n        }\n      }\n    }\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\n\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-01T00:00:00Z',\n    'to': '2020-07-06T00:00:00Z'},\n   'outputs': {'output_my_bands': {'bands': {'only_band_B04': {'stats': {'min': 0.0803999975323677,\n        'max': 0.2939999997615814,\n        'mean': 0.11451061716602186,\n        'stDev': 0.032769790113614555,\n        'sampleCount': 810,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.09719999879598618,\n         '66.0': 0.11169999837875366,\n         '100.0': 0.2939999997615814}}},\n      'only_band_B08': {'stats': {'min': 0.0860000029206276,\n        'max': 0.34290000796318054,\n        'mean': 0.16518679009175594,\n        'stDev': 0.07128630441809644,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0,\n          'highEdge': 0.09999999999999999,\n          'count': 199},\n         {'lowEdge': 0.09999999999999999,\n          'highEdge': 0.19999999999999998,\n          'count': 270},\n         {'lowEdge': 0.19999999999999998, 'highEdge': 0.3, 'count': 332}],\n        'overflowCount': 9,\n        'underflowCount': 0}}}},\n    'output_scl': {'bands': {'B0': {'stats': {'min': 8.0,\n        'max': 10.0,\n        'mean': 9.75432098765432,\n        'stDev': 0.6555648554361158,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0, 'highEdge': 1, 'count': 0},\n         {'lowEdge': 1, 'highEdge': 2, 'count': 0},\n         {'lowEdge': 2, 'highEdge': 3, 'count': 0},\n         {'lowEdge': 3, 'highEdge': 4, 'count': 0},\n         {'lowEdge': 4, 'highEdge': 5, 'count': 0},\n         {'lowEdge': 5, 'highEdge': 6, 'count': 0},\n         {'lowEdge': 6, 'highEdge': 7, 'count': 0},\n         {'lowEdge': 7, 'highEdge': 8, 'count': 0},\n         {'lowEdge': 8, 'highEdge': 9, 'count': 99},\n         {'lowEdge': 9, 'highEdge': 10, 'count': 1},\n         {'lowEdge': 10, 'highEdge': 11, 'count': 710}],\n        'overflowCount': 0,\n        'underflowCount': 0}}}},\n    'output_my_indices': {'bands': {'B0': {'stats': {'min': -0.04050104320049286,\n        'max': 0.5338308215141296,\n        'mean': 0.14599402473584097,\n        'stDev': 0.15671216615792566,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.05, 'count': 340},\n         {'lowEdge': 0.05, 'highEdge': 0.1, 'count': 71},\n         {'lowEdge': 0.1, 'highEdge': 0.15000000000000002, 'count': 50},\n         {'lowEdge': 0.15000000000000002, 'highEdge': 0.2, 'count': 26},\n         {'lowEdge': 0.2, 'highEdge': 0.25, 'count': 23},\n         {'lowEdge': 0.25, 'highEdge': 0.30000000000000004, 'count': 33},\n         {'lowEdge': 0.30000000000000004,\n          'highEdge': 0.35000000000000003,\n          'count': 64},\n         {'lowEdge': 0.35000000000000003, 'highEdge': 0.4, 'count': 81},\n         {'lowEdge': 0.4, 'highEdge': 0.45, 'count': 53},\n         {'lowEdge': 0.45, 'highEdge': 0.5, 'count': 6},\n         {'lowEdge': 0.5, 'highEdge': 0.55, 'count': 9}],\n        'overflowCount': 0,\n        'underflowCount': 54}}}}}},\n  {'interval': {'from': '2020-07-06T00:00:00Z', 'to': '2020-07-11T00:00:00Z'},\n   'outputs': {'output_my_bands': {'bands': {'only_band_B04': {'stats': {'min': 0.007499999832361937,\n        'max': 0.3788999915122986,\n        'mean': 0.05566148159990979,\n        'stDev': 0.060176196853468686,\n        'sampleCount': 810,\n        'noDataCount': 0,\n        'percentiles': {'33.0': 0.022700000554323196,\n         '66.0': 0.04439999908208847,\n         '100.0': 0.3788999915122986}}},\n      'only_band_B08': {'stats': {'min': 0.006500000134110451,\n        'max': 0.46369999647140503,\n        'mean': 0.12869839533864502,\n        'stDev': 0.1266643048401008,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0.0,\n          'highEdge': 0.09999999999999999,\n          'count': 450},\n         {'lowEdge': 0.09999999999999999,\n          'highEdge': 0.19999999999999998,\n          'count': 27},\n         {'lowEdge': 0.19999999999999998, 'highEdge': 0.3, 'count': 254}],\n        'overflowCount': 79,\n        'underflowCount': 0}}}},\n    'output_scl': {'bands': {'B0': {'stats': {'min': 2.0,\n        'max': 9.0,\n        'mean': 5.1716049382715985,\n        'stDev': 1.09834157450977,\n        'sampleCount': 810,\n        'noDataCount': 0},\n       'histogram': {'bins': [{'lowEdge': 0, 'highEdge': 1, 'count': 0},\n         {'lowEdge': 1, 'highEdge': 2, 'count': 0},\n         {'lowEdge': 2, 'highEdge': 3, 'count': 29},\n         {'lowEdge': 3, 'highEdge': 4, 'count': 0},\n         {'lowEdge': 4, 'highEdge': 5, 'count': 235},\n         {'lowEdge': 5, 'highEdge': 6, 'count': 103},\n         {'lowEdge': 6, 'highEdge': 7, 'count': 428},\n         {'lowEdge': 7, 'highEdge': 8, 'count': 13},\n         {'lowEdge': 8, 'highEdge': 9, 'count': 1},\n         {'lowEdge': 9, 'highEdge': 10, 'count': 1},\n         {'lowEdge': 10, 'highEdge': 11, 'count': 0}],\n        'overflowCount': 0,\n        'underflowCount': 0}}}},\n    'output_my_indices': {'bands': {'B0': {'stats': {'min': -0.18976545333862305,\n        'max': 0.858506441116333,\n        'mean': 0.47965881587323095,\n        'stDev': 0.25189343011256504,\n        'sampleCount': 810,\n        'noDataCount': 428},\n       'histogram': {'bins': [{'lowEdge': 0.0, 'highEdge': 0.05, 'count': 3},\n         {'lowEdge': 0.05, 'highEdge': 0.1, 'count': 3},\n         {'lowEdge': 0.1, 'highEdge': 0.15000000000000002, 'count': 15},\n         {'lowEdge': 0.15000000000000002, 'highEdge': 0.2, 'count': 36},\n         {'lowEdge': 0.2, 'highEdge': 0.25, 'count': 28},\n         {'lowEdge': 0.25, 'highEdge': 0.30000000000000004, 'count': 20},\n         {'lowEdge': 0.30000000000000004,\n          'highEdge': 0.35000000000000003,\n          'count': 17},\n         {'lowEdge': 0.35000000000000003, 'highEdge': 0.4, 'count': 6},\n         {'lowEdge': 0.4, 'highEdge': 0.45, 'count': 9},\n         {'lowEdge': 0.45, 'highEdge': 0.5, 'count': 24},\n         {'lowEdge': 0.5, 'highEdge': 0.55, 'count': 22},\n         {'lowEdge': 0.55, 'highEdge': 0.6000000000000001, 'count': 18},\n         {'lowEdge': 0.6000000000000001, 'highEdge': 0.65, 'count': 32},\n         {'lowEdge': 0.65, 'highEdge': 0.7000000000000001, 'count': 46},\n         {'lowEdge': 0.7000000000000001, 'highEdge': 0.75, 'count': 37},\n         {'lowEdge': 0.75, 'highEdge': 0.8, 'count': 29},\n         {'lowEdge': 0.8, 'highEdge': 0.8500000000000001, 'count': 21},\n         {'lowEdge': 0.8500000000000001, 'highEdge': 0.9, 'count': 2}],\n        'overflowCount': 0,\n        'underflowCount': 14}}}}}}],\n 'status': 'OK'}\n\n\nStatistics for Sentinel-1\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"VV\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_VV\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_VV: [samples.VV],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nstats_request = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": [414315, 4958219, 414859, 4958819],\n    \"properties\": {\n        \"crs\": \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n        }\n    },\n    \"data\": [\n      {\n        \"type\": \"sentinel-1-grd\",\n        \"dataFilter\": {\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-07-01T00:00:00Z\",\n            \"to\": \"2020-07-10T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P5D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  }\n}\nheaders = {\n  'Content-Type': 'application/json',\n  'Accept': 'application/json'\n}\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics\"\nresponse = oauth.request(\"POST\", url=url , headers=headers, json=stats_request)\nsh_statistics = response.json()\nsh_statistics\n{'data': [{'interval': {'from': '2020-07-01T00:00:00Z',\n    'to': '2020-07-06T00:00:00Z'},\n   'outputs': {'output_VV': {'bands': {'B0': {'stats': {'min': 0.0,\n        'max': 0.4447733759880066,\n        'mean': 0.046840328479290934,\n        'stDev': 0.05487441687888816,\n        'sampleCount': 3240,\n        'noDataCount': 0}}}}}}],\n 'status': 'OK'}"
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html",
    "href": "APIs/SentinelHub/BatchStatistical.html",
    "title": "Batch Statistical API",
    "section": "",
    "text": "The Batch Statistical API is only available for users with Copernicus Service accounts. Please refer to our FAQ on account typology change and Submit an account change request to our Copernicus Data Space Ecosystem Support Team to request your Copernicus Service account accordingly.\nThe Batch Statistical API (or shortly \"Batch Stats API\") enables you to request statistics similarly as with the Statistical API but for multiple polygons at once and/or for longer aggregations. A typical use case would be calculating statistics for all parcels in a country.\nSimilarly to the Batch Processing API, this is an asynchronous REST service. This means that data will not be immediately returned in the response of the request but delivered to your object storage, which needs to be specified in the request (e.g. bucket, see bucket settings below).\nYou can find more details about the API in the API Reference or in the examples of the workflow."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#workflow",
    "href": "APIs/SentinelHub/BatchStatistical.html#workflow",
    "title": "Batch Statistical API",
    "section": "Workflow",
    "text": "Workflow\nThe Batch statistical API workflow in many ways resembles the Batch Processing API workflow. Available actions and statuses are:\n\nuser's actions ANALYSE, START and STOP.\nrequest's statuses CREATED, ANALYSING, ANALYSIS_DONE, STOPPED, PROCESSING, DONE, and FAILED.\n\nThe Batch statistical API comes with a set of REST actions that support the execution of various steps in the workflow. The diagram below shows all possible statuses of the batch statistical request and users' actions which trigger transitions among them.\n\n\n\n\nstateDiagram\n    [*]--&gt;CREATED\n    CREATED--&gt;ANALYSING: #128100; START/ANALYSE\n    state fork_state_analysis &lt;&lt;fork&gt;&gt;\n    ANALYSING --&gt; fork_state_analysis\n    fork_state_analysis --&gt; FAILED\n    fork_state_analysis --&gt; ANALYSIS_DONE\n    state fork_state_analysis_done &lt;&lt;fork&gt;&gt;\n    ANALYSIS_DONE--&gt;fork_state_analysis_done\n    fork_state_analysis_done--&gt;PROCESSING: #128100; START\n    PROCESSING--&gt; STOPPED: #128100; STOP\n    fork_state_analysis_done--&gt; STOPPED: #128100; STOP\n    PROCESSING--&gt; DONE\n    STOPPED --&gt; ANALYSIS_DONE: #128100; START\n    DONE--&gt;[*]\n    FAILED--&gt;[*]\n\n\n\n\n\nThe workflow starts when a user posts a new batch statistical request. In this step the system:\n\ncreates a new batch statistical request with status CREATED,\nvalidates the user's input (not the evalscript),\nreturns the overview of the created request.\n\nThe user can then decide to either request an additional analysis of the request or start the processing. When an additional analysis is requested:\n\nthe status of the request changes to ANALYSING,\nthe evalscript is validated,\nAfter the analysis is finished the status of the request changes to ANALYSIS_DONE.\n\nIf the user chooses to directly start processing, the system still executes the analysis but when the analysis is done it automatically starts with processing. This is not explicitly shown in the diagram in order to keep it simple.\nWhen the user starts the processing:\n\nthe status of the request changes to PROCESSING (this may take a while),\nthe processing starts,\nspent processing units are billed periodically.\n\nWhen the processing finishes, the status of the request changes to DONE.\n\nStopping the request\nA request might be stopped for following reasons:\n\nit's requested by a user (user action)\nuser is out of processing units (see chapter below)\nsomething is wrong with the processing of the request\n\nA user may stop the request in following states: ANALYSING, ANALYSIS_DONE and PROCESSING. However:\n\nif the status is ANALYSING, the analysis will complete,\nif the status is PROCESSING, all features (polygons) that have been processed or are being processed at that moment are charged for,\nuser is not allowed to restart the request in the next 30 minutes.\n\nThe service itself may also stop the request when processing of a lot of features is repeatedly failing. stoppedStatusReason of such requests will be UNHEALTHY. This can happen if the service is unstable or something is wrong with the request. If former, the request should eventually be restarted by Sentinel Hub team.\n\n\nProcessing unit costs\nTo be able to create, analyse or start a request the user has to have at least 1000 processing units available in their account. If available processing units of a user drop below 1000 while request is being processed the request is automatically stopped and cannot be restarted in the next 60 minutes. Therefore it is highly recommended to start a request with a sufficient reserve.\nMore information about batch statistical costs is available here.\n\n\nAutomatic deletion of stale data\nStale (inactive) requests will be deleted after a certain period of inactivity, depending on their status:\n\nrequests with status CREATED are deleted after 7 days of inactivity\nrequests with status FAILED are deleted after 15 days of inactivity\nall other requests are deleted after 30 days of inactivity.\n\nNote that only such requests themselves will be deleted, while the requests' result (created statistics) will remain under your control in your bucket."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#input-polygons-as-geopackage-file",
    "href": "APIs/SentinelHub/BatchStatistical.html#input-polygons-as-geopackage-file",
    "title": "Batch Statistical API",
    "section": "Input polygons as GeoPackage file",
    "text": "Input polygons as GeoPackage file\nThe Batch Statistical API accepts a GeoPackage file containing features (polygons) as an input. The GeoPackage must be stored in your object storage (e.g. AWS bucket) and Sentinel Hub must be able to read from the storage (find more details about this in the bucket settings section below). In a batch statistical request, the input GeoPackage is specified by setting the path to the .gpkg file in the input.features.s3 parameter.\nAll features (polygons) in an input GeoPackage must be in the same CRS supported by Sentinel Hub. An example of a GeoPackage file can be downloaded here."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#evalscript-and-batch-statistical-api",
    "href": "APIs/SentinelHub/BatchStatistical.html#evalscript-and-batch-statistical-api",
    "title": "Batch Statistical API",
    "section": "Evalscript and Batch statistical API",
    "text": "Evalscript and Batch statistical API\nThe same specifics as described for evalscript and Statistical API apply also for Batch statistical API.\nEvalscripts smaller than 32KB in size can be provided directly in a batch statistical request under evalscript parameter. If your evalsript exceeds this limit, you can store it to your bucket and provide a reference to it in a batch statistical request under evalscriptReference parameter."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#processing-results",
    "href": "APIs/SentinelHub/BatchStatistical.html#processing-results",
    "title": "Batch Statistical API",
    "section": "Processing results",
    "text": "Processing results\nOutputs of a Batch Statistical API request are json files stored in your object storage. Each .json file will contain requested statistics for one feature (polygon) in the provided GeoPackage. You can connect statistics in a json file with corresponding feature (polygon) in the GeoPackge based on:\n\nid of a feature from GeoPackage is used as name of json file (e.g. 1.json, 2.json) and available in the json file as id property OR\na custom column identifier of type string can be added to GeoPackage and its value will be available in json file as identifier property.\n\nThe outputs will be stored in the bucket and the folder specified by output.s3.path parameter of the batch statistical request. The outputs will be available in a sub-folder named after the ID of your request (e.g. s3://&lt;my-bucket&gt;/&lt;my-folder&gt;/db7de265-dfd4-4dc0-bc82-74866078a5ce)."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#bucket-settings",
    "href": "APIs/SentinelHub/BatchStatistical.html#bucket-settings",
    "title": "Batch Statistical API",
    "section": "Bucket settings",
    "text": "Bucket settings\nAs noted above, the Batch Statistical API uses buckets to:\n\nread GeoPackage file with input features (polygons) from a bucket,\nread evalscript from a bucket (this is optional because an evalscript can also be provided directly in a request),\nwrite results of processing to a bucket.\n\nOne bucket or different buckets can be used for all three purposes.\nIf you do not yet have a bucket at Copernicus Data Space Ecosystem, please follow these steps to get one.\nYou will have to configure your bucket to allow full access to Sentinel Hub. To do this, update your bucket policy to include the following statement (don’t forget to replace &lt;bucket_name&gt; with your actual bucket name):\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::ddf4c98b5e6647f0a246f0624c8341d9:root\"\n            },\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;\",\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}\nA python script to set a bucket policy can be downloaded here."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical.html#examples",
    "href": "APIs/SentinelHub/BatchStatistical.html#examples",
    "title": "Batch Statistical API",
    "section": "Examples",
    "text": "Examples\nExample of a Batch Statistical Workflow"
  },
  {
    "objectID": "APIs/SentinelHub/AsyncProcess/Examples.html",
    "href": "APIs/SentinelHub/AsyncProcess/Examples.html",
    "title": "Async API examples",
    "section": "",
    "text": "The requests below are written in Python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples.\n\nCreate an asynchronous processing request\nBefore running the example, you will have to replace placeholders &lt;your-bucket&gt;/&lt;path&gt;, &lt;your-bucket-access-key&gt;, and &lt;your-bucket-access-key-secret&gt; with your values.\nurl = 'https://sh.dataspace.copernicus.eu/api/v1/async/process'\n\nevalscript = \"\"\"\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"B08\"\n      ]\n    }],\n    output: {\n      bands: 3\n    }\n  }\n}\n\nlet viz = ColorGradientVisualizer.createWhiteGreen();\n\nfunction evaluatePixel(samples) {\n    let ndvi = index(samples.B08, samples.B04);\n    vizualizedNdvi = viz.process(ndvi);\n    return vizualizedNdvi;\n}\n\n\"\"\"\n\npayload = {\n  \"input\" : {\n    \"bounds\" : {\n      \"bbox\" : [ 426000, 3960000, 462000, 3994000 ],\n      \"properties\" : {\n        \"crs\" : \"http://www.opengis.net/def/crs/EPSG/0/32633\"\n      }\n    },\n    \"data\" : [ {\n      \"dataFilter\" : {\n        \"timeRange\" : {\n          \"from\" : \"2022-06-20T00:00:00Z\",\n          \"to\" : \"2022-06-30T23:59:59Z\"\n        }\n      },\n      \"type\" : \"S2L2A\"\n    } ]\n  },\n  \"output\" : {\n    \"resx\" : 10,\n    \"resy\" : 10,\n    \"responses\" : [ {\n      \"identifier\" : \"default\",\n      \"format\" : {\n        \"type\" : \"image/tiff\"\n      }\n    } ],\n    \"delivery\" : {\n      \"s3\" : {\n        \"url\": \"s3://&lt;your-bucket&gt;/&lt;path&gt;\",\n        \"accessKey\": \"&lt;your-bucket-access-key&gt;\",\n        \"secretAccessKey\": \"&lt;your-bucket-access-key-secret&gt;\"\n      }\n    }\n  },\n  \"evalscript\" : evalscript\n}\n\nheaders = {\n  'Content-Type': 'application/json'\n}\n\nresponse = oauth.post(url, headers=headers, json=payload)\nresponse.json()\nExtracting the asynchronous request id from the response:\nrequest_id = response.json()['id']\n\n\nGet information about your asynchronous processing request\nresponse = oauth.get(url=f\"{url}/{request_id}\")\nresponse.json()"
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical/Examples.html",
    "href": "APIs/SentinelHub/BatchStatistical/Examples.html",
    "title": "Examples of Batch Statistical Workflow",
    "section": "",
    "text": "The requests below are written in Python. To execute them you need to create an OAuth client as is explained here. It is named oauth in these examples."
  },
  {
    "objectID": "APIs/SentinelHub/BatchStatistical/Examples.html#create-a-batch-statistical-request",
    "href": "APIs/SentinelHub/BatchStatistical/Examples.html#create-a-batch-statistical-request",
    "title": "Examples of Batch Statistical Workflow",
    "section": "Create a batch statistical request",
    "text": "Create a batch statistical request\nThis request defines which data is requested and how it will be processed. In this example we'll get the statistics for a single band on a given day. To create a batch statistical request replace the input.features.s3.url field for the actual path to the GeoPackage features and the output.s3.url field for the desired path where the output data will be processed.\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\n        \"B04\",\n        \"dataMask\"\n      ]\n    }],\n    output: [\n      {\n        id: \"output_B04\",\n        bands: 1,\n        sampleType: \"FLOAT32\"\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  }\n}\nfunction evaluatePixel(samples) {\n    return {\n        output_B04: [samples.B04],\n        dataMask: [samples.dataMask]\n        }\n}\n\"\"\"\n\nrequest_payload = {\n  \"input\": {\n  \"features\":{\n      \"s3\": {\n          \"url\": \"s3://&lt;my-bucket&gt;/&lt;path-to-geopackage&gt;\",\n          \"accessKey\": \"&lt;my-s3-access-key&gt;,\n          \"secretAccessKey\": \"&lt;my-secret-access-key&gt;\n      }\n  },\n    \"data\": [\n      {\n        \"type\": \"sentinel-2-l2a\",\n        \"dataFilter\": {\n            \"mosaickingOrder\": \"leastCC\"\n        }\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n            \"from\": \"2020-06-01T00:00:00Z\",\n            \"to\": \"2020-07-31T00:00:00Z\"\n      },\n    \"aggregationInterval\": {\n        \"of\": \"P30D\"\n    },\n    \"evalscript\": evalscript,\n    \"resx\": 10,\n    \"resy\": 10\n  },\n  \"output\": {\n      \"s3\": {\n          \"url\": \"s3://&lt;my-bucket&gt;/&lt;path&gt;\",\n          \"accessKey\": \"&lt;my-s3-access-key&gt;,\n          \"secretAccessKey\": \"&lt;my-secret-access-key&gt;\n      }\n  }\n}\n\nheaders = {\n  'Content-Type': 'application/json',\n   'Accept': 'application/json'\n}\n\nurl = \"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch\"\n\nresponse = oauth.request(\"POST\", url=url, headers=headers, json=request_payload)\n\nrequest_id = response.json()['id']\nNote that in the above example we're specifying an accessKey and secretAccessKey, so Sentinel Hub can read and write to the user's bucket. You can find more details about this under the AWS access section.\nYou can download an example of a valid .gpkg (GeoPackage) file by clicking here.\n\nGet information about a batch statistical request\nresponse = oauth.request(\"GET\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}\")\n\nresponse.json()\n\n\nGet status information about a batch statistical request\nresponse = oauth.request(\"GET\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}/status\")\n\nresponse.json()\n\n\nRequest analysis of a batch statistical request (ANALYSIS)\nresponse = oauth.request(\"POST\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}/analyse\")\n\nresponse.status_code\n\n\nRequest the start of a batch statistical request (START)\nresponse = oauth.request(\"POST\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}/start\")\n\nresponse.status_code\n\n\nStop a batch statistical request (STOP)\nresponse = oauth.request(\"POST\", f\"https://sh.dataspace.copernicus.eu/api/v1/statistics/batch/{request_id}/stop\")\n\nresponse.status_code"
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html",
    "href": "APIs/SentinelHub/Statistical.html",
    "title": "Statistical API",
    "section": "",
    "text": "The Statistical API (or shortly \"Stats API\") enables you to get statistics calculated based on satellite imagery without having to download images. In your Statistical API request, you can specify your area of interest, time period, evalscript and which statistical measures should be calculated. The requested statistics are returned in the API response. Using Statistical API you can calculate the percentage of cloudy pixels for a given area of interest and time period, or calculate mean, standard deviation, and histogram of band values for a parcel in a given time period. Find more examples here.\nTo familiarise yourself with the Statistical API, we recommend checking the Requests builder, our API reference and our Statistical API webinar."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#general-approach",
    "href": "APIs/SentinelHub/Statistical.html#general-approach",
    "title": "Statistical API",
    "section": "General approach",
    "text": "General approach\nBased on parameters specified by users in requests (e.g. area of interest, time range, evalscript) the Statistical API processes satellite data in a similar way as Processing API. Instead of returning images, it calculates requested statistics and returns the results in a json format."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#statistical-api-and-evalscript",
    "href": "APIs/SentinelHub/Statistical.html#statistical-api-and-evalscript",
    "title": "Statistical API",
    "section": "Statistical API and evalscript",
    "text": "Statistical API and evalscript\nAll general rules for building evalscripts apply. However, there are some specifics when using evalscripts with the Statistical API:\n\nThe evaluatePixel() function must, in addition to other output, always return also dataMask output. This output defines which pixels are excluded from calculations. For more details and an example, see here.\nThe default value of sampleType is FLOAT32.\nThe output.bands parameter in the setup() function can be an array. This makes it possible to specify custom names for the output bands and different output dataMask for different outputs, see this example."
  },
  {
    "objectID": "APIs/SentinelHub/Statistical.html#apis-features",
    "href": "APIs/SentinelHub/Statistical.html#apis-features",
    "title": "Statistical API",
    "section": "API's features",
    "text": "API's features\n\nSplit requested timeRange into multiple time intervals\nThe Statistical API supports requesting statistics for multiple time intervals with only one request. For example, requesting the aggregationInterval and timeRange as:\n...\n\"timeRange\": {\n    \"from\": \"2020-06-01T00:00:00Z\",\n    \"to\": \"2020-07-31T00:00:00Z\"\n    },\n\"aggregationInterval\": {\n    \"of\": \"P10D\"\n}\n...\nreturns the requested statistics calculated for multiple 10-day intervals, see this example. The aggregation intervals should be at least one day long (e.g. \"P5D\", \"P30D\"). You can only use period OR time designator not both.\nIf a timeRange is not divisible by an aggregationInterval, the last (\"not full\") time interval will be dismissed by default (SKIP option). The user can instead set the lastIntervalBehavior to SHORTEN (shortens the last interval so that it ends at the end of the provided time range) or EXTEND (extends the last interval over the end of the provided time range so that all the intervals are of equal duration).\nNote that the data is mosaicked for each of the time intervals (as defined with the mosaicking parameter in an evalscript) before the statistics are calculated. To calculate statistics over time (for example, the maximum NDVI value in a month), you should set mosaicking to ORBIT or TILE and calculate the required value in an evalscript, see this example. If you use mosaicking SIMPLE, one mosaicked output for each time interval is a basis for calculating statistics.\n\n\nHistogram\nRequesting histograms is optional. A variety of histogram customisations are available. Users can specify either of the following:\n\narbitrary bins or\nwidth of bins binWidthor\nnumber of bins nBins.\n\nAlong with binWidth and nBins users can also provide values for lowEdge and/or highEdge parameters. Otherwise, their default values will be used, which correspond to min and max statistics for particular output band.\nThis example demonstrates all three options.\n\n\nPercentile calculations\nIt is possible to get values for any percentile. For example, to get values for 33%, 75%, and 90% percentile, add the \"percentiles\" parameter to your requests as:\n...\n{\n  \"percentiles\": {\n    \"k\": [33, 75, 90]\n  }\n}\n...\nSee also this example.\n\n\nExclude pixels from calculations (dataMask output)\nIt is possible to exclude certain pixels from the calculation of the statistics. The most common use cases are excluding no data and cloudy pixels.\nWith the Statistical API, this is achieved by defining a special output called \"dataMask\". This output should have value \"0\" assigned for the pixels that should be excluded from the calculations, and a value of \"1\" elsewhere. The values of the \"dataMask\" output are defined by the user in an evalscript. An illustrative example is excluding water pixels from statistics of NDVI, see this example.\nNote that the Statistical API does not automatically exclude the no data pixels from calculating the statistics. We recommend that you always exclude those unless there is a good reason not to. This is especially important when you are requesting statistics for a polygon, as it will ensure that pixels outside of the polygon (and inside of the bounding box) are excluded. To exclude no data pixels you need to pass input dataMask band to the dataMask output, e.g.:\nfunction evaluatePixel(samples) {\n    return {\n        ...,\n        dataMask: [samples.dataMask]\n        }\n}\nAll evalscripts in the examples here exclude no data pixels.\n\n\nMultiple outputs and multi bands outputs\nStatistics can be requested for multiple outputs. This is useful when we need to use different dataMasks or different sampleTypes for each output. Additionally, each output can have multiple bands. It is possible to request different statistics for each band and for each output. This example demonstrates how to do all this.\n\n\nExamples\nExamples of Statistical API\n\n\nTutorials and Other Related Materials\n\nTo get you started, we created a detailed beginner webinar on statistical API, where you can learn how to get statistics for your data, how to manipulate the evalscript to return several outputs, each with its own statistical information, how to make use of powerful aggregations, exclude pixels from the calculation, make custom histograms and visualize your statistics in Python."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L2A.html",
    "href": "APIs/SentinelHub/Data/S2L2A.html",
    "title": "Sentinel-2 L2A",
    "section": "",
    "text": "General information about Sentinel-2 mission can be found here. Sentinel Hub offers Sentinel-2 Level 2A products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L2A.html#about-sentinel-2-l2a-data",
    "href": "APIs/SentinelHub/Data/S2L2A.html#about-sentinel-2-l2a-data",
    "title": "Sentinel-2 L2A",
    "section": "",
    "text": "General information about Sentinel-2 mission can be found here. Sentinel Hub offers Sentinel-2 Level 2A products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L2A.html#accessing-sentinel-2-l2a-data",
    "href": "APIs/SentinelHub/Data/S2L2A.html#accessing-sentinel-2-l2a-data",
    "title": "Sentinel-2 L2A",
    "section": "Accessing Sentinel-2 L2A Data",
    "text": "Accessing Sentinel-2 L2A Data\nTo access data you need to send a POST request to our process API. The requested data will be returned as the response to your request. Each POST request can be tailored to get you exactly the data you require. To do this requires setting various parameters which depend on the datasource you are querying. This chapter will help you understand the parameters for S2L2A data. To see examples of such requests go here, and for an overview of all API parameters see the API Reference.\n\nData type identifier: sentinel-2-l2a\nUse sentinel-2-l2a (previously S2L2A) as the value of the input.data.type parameter in your API requests. This is mandatory and will ensure you get Sentinel-2 L2A data.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object of the S2L2A process API.\n\nmosaickingOrder\nSets the order of overlapping tiles from which the output result is mosaicked. Note that tiles will in most cases come from the same orbit/acquisition. The tiling is done by ESA for easier distribution.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nmostRecent\nselected by default. The pixel will be selected from the tile, which was acquired most recently\nin case there are more tiles available with the same timestamp (some tiles are processed by many ground stations, some are reprocessed, etc.), the one, which was downloaded from SciHub later will be used.\n\n\nleastRecent\nsimilar to mostRecent but in reverse order\n\n\n\nleastCC\npixel is selected from tile with the least cloud coverage metadata\nnote that \"per tile\" information is used here, each covering about a 12,000 sq. km area, so this information is only an estimate .\n\n\n\n\n\nmaxCloudCoverage\nSets the upper limit for cloud coverage in percent based on the precomputed cloud coverage estimate for each Sentinel-2 tile as present in the tile metadata. Satellite data will therefore not be retrieved for tiles with a higher cloud coverage estimate. For example, by setting the value to 20, only tiles with at most 20% cloud coverage will be used. Note that this parameter is set per tile and might not be directly applicable to the chosen area of interest.\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the S2L2A process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing when the pixel resolution is greater than the source resolution (e.g. 5m/px with a 10m/px source)\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nAs above except when the resolution is lower.\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\n\nA visual representation of upsampling results using various algorithms is available here.\n\n\nAvailable Bands and Data\nThis chapter will explain the bands and data which can be set in the evalscript input object. Any string listed in the column Name can be an element of the input.bands array in your evalscript.\n\n\n\nName\nDescription\nResolution\n\n\n\n\nB01\nCoastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\n60m\n\n\nB02\nBlue, 492.4 nm (S2A), 492.1 nm (S2B)\n10m\n\n\nB03\nGreen, 559.8 nm (S2A), 559.0 nm (S2B)\n10m\n\n\nB04\nRed, 664.6 nm (S2A), 665.0 nm (S2B)\n10m\n\n\nB05\nVegetation red edge, 704.1 nm (S2A), 703.8 nm (S2B)\n20m\n\n\nB06\nVegetation red edge, 740.5 nm (S2A), 739.1 nm (S2B)\n20m\n\n\nB07\nVegetation red edge, 782.8 nm (S2A), 779.7 nm (S2B)\n20m\n\n\nB08\nNIR, 832.8 nm (S2A), 833.0 nm (S2B)\n10m\n\n\nB8A\nNarrow NIR, 864.7 nm (S2A), 864.0 nm (S2B)\n20m\n\n\nB09\nWater vapour, 945.1 nm (S2A), 943.2 nm (S2B)\n60m\n\n\nB11\nSWIR, 1613.7 nm (S2A), 1610.4 nm (S2B)\n20m\n\n\nB12\nSWIR, 2202.4 nm (S2A), 2185.7 nm (S2B)\n20m\n\n\nAOT\nAerosol Optical Thickness map, based on Sen2Cor processor\n10m\n\n\nSCL\nScene classification data, based on Sen2Cor processor, codelist\n20m\n\n\nSNW\nSnow probability, based on Sen2Cor processor\n20m\n\n\nCLD\nCloud probability, based on Sen2Cor processor\n20m\n\n\nsunAzimuthAngles\nSun azimuth angle\n5000m\n\n\nsunZenithAngles\nSun zenith angle\n5000m\n\n\nviewAzimuthMean\nViewing azimuth angle\n5000m\n\n\nviewZenithMean\nViewing zenith angle\n5000m\n\n\ndataMask\nThe mask of data/no data pixels (more).\nN/A*\n\n\n\n*dataMask has no source resolution as it is calculated for each output pixel.\n\n\n\n\n\n\nNote\n\n\n\nThe cirrus band B10 is excluded as it does not contain any \"bottom of the atmosphere\" information (Source: Sen2Cor Configuration and User Manual).\n\n\n\n\nUnits\nThe data values for each band in your custom script are presented in the units as specified here. In case more than one unit is available for a given band, you may optionally set the value of input.units in your evalscript setup function to one of the values in the Sentinel Hub Units column. Doing so will present data in that unit. The Sentinel Hub units parameter combines the physical quantity and corresponding units of measurement values. As such, some names more closely resemble physical quantities, others resemble units of measurement.\nThe Source Format specifies how and with what precision the digital numbers (DN) from which the unit is derived are encoded. Bands requested in DN units contain exactly the pixel values of the source data (See also Harmonize Values). Note that resampling may produce interpolated values. DN is also used whenever a band is derived computationally (like dataMask); such bands can be identified by having DN units and N/A source format. DN values are typically not offered if they do not simply represent any physical quantity, in particular, when DN values require source-specific (i.e. non-global) conversion to physical quantities.\nValues in non-DN units are computed from the source (DN) values with at least float32 precision. Note that the conversion might be nonlinear, therefore the full value range and quantization step size of such a band can be hard to predict. Band values in evalscripts always behave as floating point numbers, regardless of the actual precision.\nThe Typical Range indicates what values are common for a given band and unit, however outliers can be expected.\nFor Sentinel-2 optical data, the relation between DN and REFLECTANCE (default unit) is: DN = 10000 * REFLECTANCE. See also Harmonize Values.\n\n\n\nBand\nPhysical Quantity (units)\nSentinel Hub Units\nSource Format\nTypical Range\n\n\n\n\nOptical bands\nReflectance (unitless)\nREFLECTANCE (default)\nUINT15\n0 - 0.4*\n\n\nOptical bands\nDigital numbers (unitless)\nDN\nUINT15\n0 - 4000*\n\n\nAOT\nAerosol optical thickness (unitless)\nOPTICAL_DEPTH (default) **\nUINT16\n0 - 0.6**\n\n\nAOT\nDigital numbers (unitless)\nDN**\nUINT16\n0 - 600**\n\n\nSCL\nScene classification mask (unitless)\nDN\nUINT8\n0 - No data 1 - Saturated / Defective  2 - Dark Area Pixels  3 - Cloud Shadows  4 - Vegetation  5 - Bare Soils  6 - Water  7 - Clouds low probability / Unclassified  8 - Clouds medium probability  9 - Clouds high probability  10 - Cirrus  11 - Snow / Ice\n\n\nSNW\nSnow probability (percent)\nPERCENT\nUINT8\n0 - 100\n\n\nCLD\nCloud probability (percent)\nPERCENT\nUINT8\n0 - 100\n\n\nsunAzimuthAngles\nAngle (degrees)\nDEGREES\nFLOAT32\n30 - 200\n\n\nviewAzimuthMean\nAngle (degrees)\nDEGREES\nFLOAT32\n90 - 300\n\n\nsunZenithAngles\nAngle (degrees)\nDEGREES\nFLOAT32\n15 - 80\n\n\nviewZenithMean\nAngle (degrees)\nDEGREES\nFLOAT32\n0 - 12\n\n\ndataMask\nN/A\nDN\nN/A\n0 - no data 1 - data\n\n\n\n*Higher values are expected in infrared bands. Reflectance values can easily be above 1.  ** AOT = DN / 1000.\n\nHarmonize Values\nESA updated the Sentinel-2 processing baseline to version 04.00 in January, 2022, which introduced breaking changes to the interpretation of digital numbers (DN). The optional harmonizeValues parameter gives you extra control over the values which enter your evalscript.\nharmonizeValues can be true (default) or false, and it's behavior depends on the units chosen:\n\nREFLECTANCE:\n\nharmonizeValues = true: negative reflectance values are clamped to zero. In other words, pixels with negative reflectance return zero reflectance instead.\nharmonizeValues = false: negative reflectance values can be returned.\n\nDN:\n\nharmonizeValues = true: DN values are harmonized so they are comparable with data from previous baselines. Therefore it still holds that DN = 10000 * REFLECTANCE. In addition, negative values are clamped to zero.\nharmonizeValues = false: DN values are exactly as provided in the source files themselves. The \"true\" DN value, you could say. Don't forget that values have different definitions with different processing baselines, careful with mosaicking!\n\n\n\n\n\nMosaicking\nAll mosaicking types are supported.\n\n\nScenes Object\nscenes object stores metadata, for an example see scenes object for Sentinel-2 L1C.\n\n\nCollection Specific Constraints\n\nEach Sentinel-2 satellite takes 100.6 minutes for an entire orbit, with S2A and S2B orbiting 180 degree apart. By setting a time interval to less than 50 minutes, there should be no overlap possible between different acquisitions, even near the poles.\nFor atmospheric correction, ESA's official Sen2Cor is used. In most cases the processing is done by ESA itself. On users' request we can also process some archive data using the same processor."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L2A.html#catalog-api-capabilities",
    "href": "APIs/SentinelHub/Data/S2L2A.html#catalog-api-capabilities",
    "title": "Sentinel-2 L2A",
    "section": "Catalog API Capabilities",
    "text": "Catalog API Capabilities\nTo access Sentinel 2 L2A product metadata you need to send search request to our Catalog API. The requested metadata will be returned as JSON formatted response to your request. This chapter will help with understanding Sentinel 2 L2A specific parameters for search request.\n\nCollection identifier: sentinel-2-l2a\n\n\nFilter extension\n\neo:cloud_cover cloud cover percentage\n\n\n\nDistinct extension\n\ndate"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S2L2A.html#examples",
    "href": "APIs/SentinelHub/Data/S2L2A.html#examples",
    "title": "Sentinel-2 L2A",
    "section": "Examples",
    "text": "Examples\nS2L2A examples"
  },
  {
    "objectID": "APIs/SentinelHub/Data/DEM.html#mission-information",
    "href": "APIs/SentinelHub/Data/DEM.html#mission-information",
    "title": "Digital Elevation Model (DEM) Data",
    "section": "Mission information",
    "text": "Mission information\nA DEM is a digital model or 3D1 representation of a terrain's surface. With a DEM you are able to obtain and analayse heights within your area of interest, and integrate the data in 3D applications. The data can also be used for the orthorectification of satellite imagery (e.g., Sentinel 1).\nCopernicus DEM is based on WorldDEM that is infilled on a local basis with the following DEMs: ASTER, SRTM90, SRTM30, SRTM30plus, GMTED2010, TerraSAR-X Radargrammetric DEM, ALOS World 3D-30m. We provide two instances named COPERNICUS_30 and COPERNICUS_90, with worldwide coverage. COPERNICUS_90 uses COP-DEM GLO-90, which has 90 meters resolution. COPERNICUS_30 uses COP-DEM GLO-30 Public, which has 30 meters resolution, where it's available, and for the rest is uses GLO-90. Tiles that are missing from GLO-30 Public are not yet released to the public by Copernicus Programme. Both instances are static and do not depend on the date. We return a homogeneous DEM with zeros in regions where there are no source tiles (e.g. in ocean areas). More information here."
  },
  {
    "objectID": "APIs/SentinelHub/Data/DEM.html#attribution-and-use",
    "href": "APIs/SentinelHub/Data/DEM.html#attribution-and-use",
    "title": "Digital Elevation Model (DEM) Data",
    "section": "Attribution and use",
    "text": "Attribution and use\nFor Copernicus DEM GLO-90, check the terms on page 15, where it says \"Licence for COP-DEM-GLO-90-F Global 90m Full, Free & Open. Licence for the use of the Copernicus WorldDEM™-90\".\nFor Copernicus DEM GLO-30 Public, check the license and terms here."
  },
  {
    "objectID": "APIs/SentinelHub/Data/DEM.html#accessing-dem-data",
    "href": "APIs/SentinelHub/Data/DEM.html#accessing-dem-data",
    "title": "Digital Elevation Model (DEM) Data",
    "section": "Accessing DEM Data",
    "text": "Accessing DEM Data\nTo access data you need to send a POST request to our process API. The requested data will be returned as the response to your request. Each POST request can be tailored to get you exactly the data you require. To do this requires setting various parameters which depend on the collection you are querying. This chapter will help you understand the parameters for DEM data. To see examples of such requests go here, and for an overview of all API parameters see the API Reference.\n\nData type identifier: dem\nUse dem (previously DEM) as the value of the input.data.type parameter in your API requests. This is mandatory and will ensure you get DEM data.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object of the DEM process API.\n\ndemInstance\nSets the DEM to use. Will return the default DEM (COPERNICUS_30) if no parameter is set.\n\n\n\nIdentifier\nDEM\nNotes\n\n\n\n\nCOPERNICUS_30\nCopernicus DEM GLO-30 Public and GLO-90\n30m is infilled with 90m where 30m tiles are not released\n\n\nCOPERNICUS_90\nCopernicus DEM GLO-90\nGlobal\n\n\n\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the DEM process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing when the pixel resolution is greater than the source resolution (e.g. 5m/px with a 10m/px source).\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nAs above except when the resolution is lower.\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\negm\nAn option to add geoid heights from an earth gravitational model to the orthometric heights in which case the returned values represent ellipsoidal heights relative to the WGS84 ellipsoid.  For Copernicus DEMs, we use EGM2008.\nTRUE - returned values are ellipsoid heights FALSE - returned values are orthometric heights\nFALSE\n\n\n\n\n\nAvailable Bands and Data\nInformation in this chapter is useful when defining input object in evalscript. A string listed in the column Name can be an element of the input.bands array in your evalscript.\n\n\n\nProperty name\nDescription\nResolution\n\n\n\n\nDEM\nHeights in meters\nVarious, depending on the datasource used for the generation of the DEM, see.\n\n\ndataMask\nThe mask of data/no data pixels (more).\nN/A dataMask has no source resolution as it is calculated for each output pixel.\n\n\n\n\n\nUnits\nThe data values for each band in your custom script are presented in the units as specified here. In case more than one unit is available for a given band, you may optionally set the value of input.units in your evalscript setup function to one of the values in the Sentinel Hub Units column. Doing so will present data in that unit. The Sentinel Hub units parameter combines the physical quantity and corresponding units of measurement values. As such, some names more closely resemble physical quantities, others resemble units of measurement.\nThe Source Format specifies how and with what precision the digital numbers (DN) from which the unit is derived are encoded. Bands requested in DN units contain exactly the pixel values of the source data. Note that resampling may produce interpolated values. DN is also used whenever a band is derived computationally (like dataMask); such bands can be identified by having DN units and N/A source format. DN values are typically not offered if they do not simply represent any physical quantity, in particular, when DN values require source-specific (i.e. non-global) conversion to physical quantities.\nValues in non-DN units are computed from the source (DN) values with at least float32 precision. Note that the conversion might be nonlinear, therefore the full value range and quantization step size of such a band can be hard to predict. Band values in evalscripts always behave as floating point numbers, regardless of the actual precision.\nThe Typical Range indicates what values are common for a given band and unit, however outliers can be expected.\nFor DEM, DN (digital numbers) are the default and only unit. DN values equal elevation.\n\n\n\nBand\nPhysical Quantity (units)\nSentinel Hub Units\nSource Format\nTypical Range\n\n\n\n\nDEM\nHeight (meters)\nMETERS\nFLOAT32\ntypically positive\n\n\ndataMask\nN/A\nDN\nN/A\n0 - no data 1 - data\n\n\n\n\n\nScene Object\nThe evalscript evaluatePixel scene object is not returned/is null when requesting DEM.\n\n\nCollection specific constraints\nDEM values are in meters and can be negative for areas which lie below sea level (e.g. ocean areas or much of the Netherlands). When requesting a DEM a simple way to mitigate this is to set the output format in your evalscript to sampleType: SampleType.FLOAT32 or sampleType: SampleType.INT16 if this provides sufficient precision for your use. More about output formats can be found here.\nFor output formats sampleType: SampleType.UINT8 and sampleType: SampleType.UINT16 be careful as negative values can be misinterpreted due to signedness issues as well as potential problems due to integer overflow. For example:\n\nsampleType: SampleType.UINT8 - a height of 256 meters will be encoded as 0 in such a file due to overflow. A height of -1 meter will be encoded as 255.\nsampleType: SampleType.UINT16- a height of -15 meters for instance will be encoded as 65520.\n\nOne way to handle this adjustment is to ensure there are no negative values in the output by adding a constant to DEM values, e.g. 12000 (the minimum value in DEM is not smaller than -11000 m). If you need actual DEM values (i.e. heights), the constant 12000 must be subtracted from the output values outside of Sentinel Hub.\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output:{\n        id: \"default\",\n        bands: 1,\n        sampleType: SampleType.UINT16\n    }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM + 12000]\n}"
  },
  {
    "objectID": "APIs/SentinelHub/Data/DEM.html#examples",
    "href": "APIs/SentinelHub/Data/DEM.html#examples",
    "title": "Digital Elevation Model (DEM) Data",
    "section": "Examples",
    "text": "Examples\nDEM examples"
  },
  {
    "objectID": "APIs/SentinelHub/Data/DEM.html#footnotes",
    "href": "APIs/SentinelHub/Data/DEM.html#footnotes",
    "title": "Digital Elevation Model (DEM) Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nActually, we should say \"2.5D\" to be more precise. The terrain surface embedded in 3D space is modeled in a way that precisely one height is assigned to each pixel. This brings limitations as not all 3D shapes (e.g., overhangs, vertical walls, caves) can be fully modeled.↩︎"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3SLSTR.html",
    "href": "APIs/SentinelHub/Data/S3SLSTR.html",
    "title": "Sentinel-3 SLSTR L1B",
    "section": "",
    "text": "General information about Sentinel-3 mission can be found here. Sentinel Hub offers Sentinel-3 SLSTR Level 1B products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3SLSTR.html#about-sentinel-3-slstr-l1b-data",
    "href": "APIs/SentinelHub/Data/S3SLSTR.html#about-sentinel-3-slstr-l1b-data",
    "title": "Sentinel-3 SLSTR L1B",
    "section": "",
    "text": "General information about Sentinel-3 mission can be found here. Sentinel Hub offers Sentinel-3 SLSTR Level 1B products."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3SLSTR.html#accessing-sentinel-3-slstr-data",
    "href": "APIs/SentinelHub/Data/S3SLSTR.html#accessing-sentinel-3-slstr-data",
    "title": "Sentinel-3 SLSTR L1B",
    "section": "Accessing Sentinel-3 SLSTR Data",
    "text": "Accessing Sentinel-3 SLSTR Data\nTo access data you need to send a POST request to our process API. The requested data will be returned as the response to your request. Each POST request can be tailored to get you exactly the data you require. To do this requires setting various parameters which depend on the datasource you are querying. This chapter will help you understand the parameters for S3SLSTR data. To see examples of such requests go here, and for an overview of all API parameters see the API Reference.\n\nData type identifier: sentinel-3-slstr\nUse sentinel-3-slstr (previously S3SLSTR) as the value of the input.data.type parameter in your API requests. This is mandatory and will ensure you get Sentinel-3 SLSTR L1B data.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object of the S3SLSTR process API.\n\nmosaickingOrder\nSets the order of overlapping tiles from which the output result is mosaicked. The tiling is based on ESA's Product Dissemination Units for easier distribution.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nmostRecent\nthe pixel will be selected from the most recently acquired tile\nIf there are multiple products with the same timestamp then NTC will be used over NRT. Default value.\n\n\nleastRecent\nthe pixel will be selected from the oldest acquired tile\nIf there are multiple products with the same timestamp then NTC will be used over NRT.\n\n\nleastCC\npixel is selected from tile with the least cloud coverage metadata\nNote that \"per tile\" information is used here.\n\n\n\n\n\norbitDirection\nFilters the acquisition orbit direction. For ascending orbits optical bands will typically return a black image as there is no sunlight to illuminate the earth, though you may get some usable data in regions of midnight sun. Thermal bands will return data normally as they do not depend on sunlight.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nASCENDING\nData acquired when the satellite was traveling approximately towards the Earth's North pole\nNight (not for optical bands)\n\n\nDESCENDING\nData acquired when the satellite was traveling approximately towards the Earth's South pole\nDay (for optical bands)\n\n\n\n\n\nview\nFilters the acquisition by view.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nNADIR\nthe image acquired by the nadir viewing scanner will be selected\nDefault value\n\n\nOBLIQUE\nthe image acquired by the oblique (rear) viewing scanner will be selected\n\n\n\n\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the S3SLSTR process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing, regardless of the resolution\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nNot used, use upsampling instead\nN/A\nIgnored\n\n\n\n\n\nAvailable Bands and Data\nThis chapter will explain the bands and data which can be set in the evalscript input object: Any string listed in the column Name can be an element of the input.bands array in your evalscript.\n\n\n\nName\nDescription\nWavelength centre (nm)\nResolution (m/px)\n\n\n\n\nS1\nCloud screening, vegetation monitoring, aerosol\n554.27\n500\n\n\nS2\nNDVI, vegetation monitoring, aerosol\n659.47\n500\n\n\nS3\nNDVI, cloud flagging, pixel co-registration\n868\n500\n\n\nS4\nCirrus detection over land\n1374.80\n500\n\n\nS5\nCloud clearing, ice, snow, vegetation monitoring\n1613.40\n500\n\n\nS6\nVegetation state and cloud clearing\n2255.70\n500\n\n\nS7\nSST, LST, Active fire\n3742\n1000\n\n\nS8\nSST, LST, Active fire\n10854\n1000\n\n\nS9\nSST, LST\n12022.50\n1000\n\n\nF1\nActive fire\n3742\n1000\n\n\nF2\nActive fire\n10854\n1000\n\n\ndataMask\nThe mask of data/no data pixels (more).\nN/A*\nN/A**\n\n\n\n*dataMask has no wavelength information, as it carries only boolean information on whether a pixel has data or not. See the chapter on Units for more.  **dataMask has no source resolution as it is calculated for each output pixel.\nFor more about Sentinel-3 SLSTR bands, visit this ESA website.\n\n\nUnits\nThe data values for each band in your custom script are presented in the units as specified here. In case more than one unit is available for a given band, you may optionally set the value of input.units in your evalscript setup function to one of the values in the Sentinel Hub Units column. Doing so will present data in that unit. The Sentinel Hub units parameter combines the physical quantity and corresponding units of measurement values. As such, some names more closely resemble physical quantities, others resemble units of measurement.\nThe Source Format specifies how and with what precision the digital numbers (DN) from which the unit is derived are encoded. Bands requested in DN units contain exactly the pixel values of the source data. Note that resampling may produce interpolated values. DN is also used whenever a band is derived computationally (like dataMask); such bands can be identified by having DN units and N/A source format. DN values are typically not offered if they do not simply represent any physical quantity, in particular, when DN values require source-specific (i.e. non-global) conversion to physical quantities.\nValues in non-DN units are computed from the source (DN) values with at least float32 precision. Note that the conversion might be nonlinear, therefore the full value range and quantization step size of such a band can be hard to predict. Band values in evalscripts always behave as floating point numbers, regardless of the actual precision.\nThe Typical Range indicates what values are common for a given band and unit, however outliers can be expected.\n\n\n\nBand\nPhysical Quantity (units)\nSentinel Hub Units\nSource Format\nTypical Range\nNotes\n\n\n\n\nOptical bands S1 - S6\nReflectance (unitless)\nREFLECTANCE\nUINT16\n0 - 0.4\nHigher values in infrared bands. Reflectance values can easily be above 1.\n\n\nThermal infrared bands  S7 - F2\nBrightness temperature (kelvin)\nBRIGHTNESS_TEMPERATURE\nUINT16\n250 - 320\nRoughly -20 to +50 C. Can reach outside this range in extreme environments.\n\n\ndataMask\nN/A\nDN\nN/A\n0 - no data 1 - data\n\n\n\n\n\n\nMosaicking\nAll mosaicking types are supported.\n\n\nScenes Object\nscenes object stores metadata. An example of metadata available in scenes object for Sentinel-3 SLSTR when mosaicking is ORBIT:\n\n\n\nProperty name\nValue\n\n\n\n\ntiles[i].date\n'2020-04-04T20:51:52.402Z'\n\n\ntiles[i].shId\n1873419\n\n\ntiles[i].cloudCoverage\n30.95142364501953\n\n\ntiles[i].dataPath\n'http://data.cloudferro.com/EODATA/Sentinel-3/SLSTR/SL_1_RBT/2020/04/04/S3A_SL_1_RBT____20200404T205152_20200404T205452_20200406T015620_0179_056_371_0540_LN2_O_NT_004.SEN3'\n\n\n\nProperties of a scenes object can differ depending on the selected mosaicking and in which evalscript function the object is accessed. Working with metadata in evalscript user guide explains all details and provides examples."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3SLSTR.html#catalog-api-capabilities",
    "href": "APIs/SentinelHub/Data/S3SLSTR.html#catalog-api-capabilities",
    "title": "Sentinel-3 SLSTR L1B",
    "section": "Catalog API Capabilities",
    "text": "Catalog API Capabilities\nTo access Sentinel 3 SLSTR product metadata you need to send search request to our Catalog API. The requested metadata will be returned as JSON formatted response to your request.\n\nCollection identifier: sentinel-3-slstr\n\n\nFilter extension\n\neo:cloud_cover cloud cover percentage\nsat:orbit_state (possible values)\n\n\n\nDistinct extension\n\ndate\nsat:orbit_state"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S3SLSTR.html#examples",
    "href": "APIs/SentinelHub/Data/S3SLSTR.html#examples",
    "title": "Sentinel-3 SLSTR L1B",
    "section": "Examples",
    "text": "Examples\nS3SLSTR examples"
  },
  {
    "objectID": "APIs/SentinelHub/Data/Zarr.html",
    "href": "APIs/SentinelHub/Data/Zarr.html",
    "title": "Zarr",
    "section": "",
    "text": "Zarr data can be ingested by Sentinel Hub users using Zarr Import API."
  },
  {
    "objectID": "APIs/SentinelHub/Data/Zarr.html#about-zarr-data",
    "href": "APIs/SentinelHub/Data/Zarr.html#about-zarr-data",
    "title": "Zarr",
    "section": "",
    "text": "Zarr data can be ingested by Sentinel Hub users using Zarr Import API."
  },
  {
    "objectID": "APIs/SentinelHub/Data/Zarr.html#accessing-data",
    "href": "APIs/SentinelHub/Data/Zarr.html#accessing-data",
    "title": "Zarr",
    "section": "Accessing data",
    "text": "Accessing data\nZarr data is accessed using Sentinel Hub APIs, just like any other data you are used to. In all cases collection id is needed, which can be obtained using the Zarr Import API.\n\nData type identifier\nUse zarr-&lt;collectionId&gt; for accessing as the value of the input.data.type parameter in your API requests. For example, set it to: zarr-123e4567-e89b-12d3-a456-426614174000 for Zarr collection with id 123e4567-e89b-12d3-a456-426614174000. Note that each Zarr collection in Sentinel Hub contains data from a single Zarr group.\n\n\nRequest resolution limit\nThe maximum meters per pixel limit is set by the service and is approximately 3 times the resolution of the actual ingested data.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object.\n\nmosaickingOrder\nSets the sensing time order of preference.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nmostRecent\n- In case of SIMPLE mosaicking, the values for most recent sensing time will be returned.  - For ORBIT and TILE mosaicking, samples in the evalscript will have values sorted by descending sensing times.\n\n\n\nleastRecent\nSimilar to mostRecent but in reverse order.\n\n\n\n\nNote that mosaicking works differently for Zarrs than for other collections.\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing when the pixel resolution is greater than the source resolution (e.g. 5m/px with a 10m/px source)\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nAs above except when the resolution is lower.\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\n\n\n\nAvailable Data Arrays\nSince Zarr collections contains your ingested data, this means that the available arrays (or bands) are the ones that the Zarr group contains. The band names to use in your evalscript are the ingested arrays names and can be listed using the Zarr Import API.\n\n\nData mask and mosaicking\nA Zarr collection only contains data arrays of a single Zarr group. Zarr metadata does not contain cover geometries (other than the envelope), thus all data arrays are considered to cover the full Zarr envelope. Thus, the value of dataMask is always 1 inside the Zarr's envelope and 0 outside. Areas for which an array has no data chunks are filled with the no data value.\nConsequently, mosaicking works differently than for other collections:\n\nTimeless (two-dimensional) Zarrs contain data for a single (unspecified) sensing time. This data will be returned for both SIMPLE and TILE mosaicking.\nThree-dimensional Zarrs contain data for multiple sensing times. The data returned will be:\n\nFor SIMPLE mosaicking, only the data for a single sensing time. As explained above, the data is considered to cover the full Zarr envelope, thus there are no missing areas where data from other sensing times would be mosaicked in.\nFor TILE mosaicking, an array of tiles corresponding to sensing times.\n\nORBIT mosaicking is not supported because Zarrs do not contain orbit metadata.\n\n\n\nUnits\nThe only units available are digital numbers (DN) so any unit conversions, if necessary, are the responsability of your evalscript."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S1GRD.html",
    "href": "APIs/SentinelHub/Data/S1GRD.html",
    "title": "Sentinel-1 GRD",
    "section": "",
    "text": "General information about Sentinel-1 mission can be found here. Sentinel Hub offers Sentinel-1 Level 1 Ground Range Detected products. For spatio-temporal availability refer to “Packed or Unpacked, SAFE with Cloud optimized GeoTIFF” in this table."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S1GRD.html#about-sentinel-1-grd-data",
    "href": "APIs/SentinelHub/Data/S1GRD.html#about-sentinel-1-grd-data",
    "title": "Sentinel-1 GRD",
    "section": "",
    "text": "General information about Sentinel-1 mission can be found here. Sentinel Hub offers Sentinel-1 Level 1 Ground Range Detected products. For spatio-temporal availability refer to “Packed or Unpacked, SAFE with Cloud optimized GeoTIFF” in this table."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S1GRD.html#processing-chain",
    "href": "APIs/SentinelHub/Data/S1GRD.html#processing-chain",
    "title": "Sentinel-1 GRD",
    "section": "Processing Chain",
    "text": "Processing Chain\nThe following describes the way Sentinel-1 GRD data is processed in Sentinel Hub. For information on how to set processing parameters, see Processing Options.\n\nOriginal or multilooked source chosen (depending on the resolution level; multilooking is done in ground range. Also see.)\nCalibration to the chosen backscatter coefficient and thermal noise removal applied.\n(Optional) Speckle filtering on the source data (see the example).\n(Optional) Radiometric terrain correction using area integration is performed. The Mapzen or Copernicus DEM is used (see the example).\n(Optional) Orthorectification using Range-Doppler terrain correction using the Mapzen or Copernicus DEM.\n\nNotes:\n\nThe orbit files used are the ones bundled in the products themselves. We find these more than sufficient for GRD use. Non-realtime products typically contain restituted orbit information.\nThe areas of border noise are not displayed by Sentinel Hub.\nRadiometric terrain correction can only be performed if orthorectification is enabled. The DEM oversampling parameter is by default set to 2 and can be user adjusted. For low resolution requests (many meters per pixel) increasing it to 3, for example, can be worthwhile to reduce artifacts. Integer values are recommended. See also the S1GRD API Reference.\nThe DEM, if used, is resampled using bilinear interpolation, and the same DEM is used for both radiometric terrain correction and orthorectification, provided both are enabled."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S1GRD.html#accessing-sentinel-1-grd-data",
    "href": "APIs/SentinelHub/Data/S1GRD.html#accessing-sentinel-1-grd-data",
    "title": "Sentinel-1 GRD",
    "section": "Accessing Sentinel-1 GRD Data",
    "text": "Accessing Sentinel-1 GRD Data\nTo access data you need to send a POST request to our process API. The requested data will be returned as the response to your request. Each POST request can be tailored to get you exactly the data you require. To do this requires setting various parameters which depend on the data collection you are querying. This chapter will help you understand the parameters for S1GRD data. To see examples of such requests go here, and for an overview of all API parameters see the S1GRD API Reference.\n\nData type identifier: sentinel-1-grd\nUse sentinel-1-grd (previously S1GRD) as the value of the input.data.type parameter in your API requests. This is mandatory and will ensure you get Sentinel-1 GRD data.\n\n\nFiltering Options\nThis chapter will explain the input.data.dataFilter object of the S1GRD process API.\n\nmosaickingOrder\nThe same as for S2L1C.\n\n\nresolution (pixel spacing)\n\n\n\nValue\nDescription\n\n\n\n\nHIGH\n10m/px for IW and 25m/px for EW\n\n\nMEDIUM\n40m/px for IW and EW\n\n\n\nA full table of resolutions is available (here)\n\n\nacquisitionMode\nSentinel-1 operates in four different acquisition modes (more).\n\n\n\nValue\nDescription\nPolarization options\n\n\n\n\nSM\nStripmap mode (more).\nHH+HV, VV+VH, HH, VV\n\n\nIW\nInterferometric Wide (IW) swath mode (more).\nHH+HV, VV+VH, HH, VV\n\n\nEW\nExtra Wide (EW) swath mode (more).\nHH+HV, VV+VH, HH, VV\n\n\nWV\nWave mode (more).\nHH, VV\n\n\n\n\n\npolarization\nThis table contains information about the polarization two letter code used by ESA and the product's contained polarizations.\n\n\n\nValue\nDescription\nNotes\n\n\n\n\nSH\nHH\n\n\n\nSV\nVV\n\n\n\nDH\nHH+HV\nTypical for EW acquisitions\n\n\nDV\nVV+VH\nTypical for IW acquisitions\n\n\nHH\nPartial Dual, HH only\nHH+HV was acquired, only HH is available in this product\n\n\nHV\nPartial Dual, HV only\nHH+HV was acquired, only HV is available in this product\n\n\nVV\nPartial Dual, VV only\nVV+VH was acquired, only VV is available in this product\n\n\nVH\nPartial Dual, VH only\nVV+VH was acquired, only VH is available in this product\n\n\n\n\n\norbitDirection\n\n\n\nValue\nDescription\n\n\n\n\nASCENDING\nData acquired when the satellite was traveling approx. towards the Earth's North pole.\n\n\nDESCENDING\nData acquired when the satellite was traveling approx. towards the Earth's South pole.\n\n\n\n\n\ntimeliness\n\n\n\nValue\n\n\n\n\nNRT10m\n\n\nNRT1h\n\n\nNRT3h\n\n\nFast24h\n\n\nOffline\n\n\nReprocessing\n\n\nArchNormal\n\n\n\n\n\n\nProcessing Options\nThis chapter will explain the input.data.processing object of the S1GRD process API.\n\n\n\nParameter\nDescription\nValues\nDefault\n\n\n\n\nupsampling\nDefines the interpolation used for processing, regardless of the resolution\nNEAREST - nearest neighbour interpolation  BILINEAR - bilinear interpolation  BICUBIC - bicubic interpolation\nNEAREST\n\n\ndownsampling\nNot used, use upsampling instead\nN/A\nIgnored\n\n\nbackCoeff [1]\nBackscatter coefficient\nBETA0SIGMA0_ELLIPSOID GAMMA0_ELLIPSOID GAMMA0_TERRAIN\nGAMMA0_ELLIPSOID\n\n\northorectify [2]\nEnables/disables orthorectification\nTRUE - OrthorectifiedFALSE - non-Orthorectified\nFALSE\n\n\ndemInstance\nThe DEM used for orthorectification\nCOPERNICUS - Copernicus DEM 10m and 30m [4][5]  COPERNICUS_30 - Copernicus DEM 30m [5]  COPERNICUS_90 - Copernicus DEM 90m\nCOPERNICUS\n\n\nradiometricTerrainOversampling\nSets the DEM oversampling parameter for radiometric terrain correction. Integer values recommended.\n1 to 4\n2\n\n\nspeckleFilter\nDefines the speckle filtering method and parameters to use.\nSee Speckle Filtering\nNONE\n\n\n\n[1]: gamma0_ellipsoid and sigma0_ellipsoid use an ellipsoid earth model. Radiometric terrain correction can be enabled by setting the backscatter coefficient to gamma0_terrain; orthorectification must be enabled in this case.\n[2]: For orthorectification, we use the DEM instance specified in the demInstance field or the default DEM instance if this is not set. The Copernicus DEM is generally of higher quality and recommended in most cases. The non-orthorectified products use a simple earth model as provided in the products themselves. This may be sufficient for very flat target areas and is faster to process.\n[4]: It has 10m resolution inside 39 European states including islands and 30m elsewhere. The 30m DEM is used exclusively if the request resolution is lower (more zoomed out) than 120m/px.\n[5]: The Copernicus 30m DEM has global coverage if used for the processing of Sentinel-1 data.\n\nSpeckle Filtering\nSpeckle filtering is applied right after calibration and noise removal and done on source data. To enable speckle filtering, add the speckle filter object with the correct type and parameters to your processing options, as shown in this example).\nAvailable filters:\n\nThe NONE filter, which as the name implies, does nothing, and is equivalent to not having the filter defined at all.\n\n\"speckleFilter\": {\n   \"type\": \"NONE\"\n}\n\nThe LEE speckle filter. Window sizes from 1 to 7 are supported in each dimension. Odd valued window sizes are recommended. Processing time rapidly increases as window size increases. Note also that the effect of the filter depends on the resolution/zoom level; it is most pronounced at native resolution and gets reduced as you zoom out. We therefore suggest you use it at or near native resolution and switch it off at low resolution to save processing time. The effect of the filter is negligible if greatly zoomed out. An example with a 5x5 window:\n\n\"speckleFilter\": {\n   \"type\": \"LEE\",\n   \"windowSizeX\": 5,\n   \"windowSizeY\": 5\n}\n\n\n\n\n\n\nNote\n\n\n\nAs an alternative or in addition to this, you can also perform multitemporal averaging to reduce speckle.\n\n\n\n\n\nAvailable Bands and Data\nInformation in this chapter is useful when defining input object in evalscript. Any string listed in the column Name can be an element of the input.bands array in your evalscript.\n\n\n\nName\nDescription\n\n\n\n\nVV\nPresent when the product polarization type is one of SV, DV or VV.\n\n\nVH\nPresent when the product polarization type is VH or DV.\n\n\nHV\nPresent when the product polarization type is HV or DH.\n\n\nHH\nPresent when the product polarization type is one of SH, DH or HH.\n\n\nlocalIncidenceAngle\nThe local incidence angle for each output pixel. Only available if orthorectification is enabled.\n\n\nscatteringArea\nThe normalized scattering area for each output pixel. Used for conversion of beta0 to terrain corrected gamma0. Only available if radiometric terrain correction is performed.\n\n\nshadowMask\nFlags output pixels which are in or near radar shadow. Is true if the nearest GRD source pixel is at most one GRD pixel away from a GRD pixel with a scatteringArea of less than 0.05. Only available if radiometric terrain correction is performed.\n\n\ndataMask\nThe mask of data/nodata pixels (more).\n\n\n\n\n\nUnits\nThe data values for each band in your custom script are presented in the units as specified here. In case more than one unit is available for a given band, you may optionally set the value of input.units in your evalscript setup function to one of the values in the Sentinel Hub Units column. Doing so will present data in that unit. The Sentinel Hub units parameter combines the physical quantity and corresponding units of measurement values. As such, some names more closely resemble physical quantities, others resemble units of measurement.\nThe Source Format specifies how and with what precision the digital numbers (DN) from which the unit is derived are encoded. Bands requested in DN units contain exactly the pixel values of the source data. Note that resampling may produce interpolated values. DN is also used whenever a band is derived computationally (like dataMask); such bands can be identified by having DN units and N/A source format. DN values are typically not offered if they do not simply represent any physical quantity, in particular, when DN values require source-specific (i.e. non-global) conversion to physical quantities.\nValues in non-DN units are computed from the source (DN) values with at least float32 precision. Note that the conversion might be nonlinear, therefore the full value range and quantization step size of such a band can be hard to predict. Band values in evalscripts always behave as floating point numbers, regardless of the actual precision.\nThe Typical Range indicates what values are common for a given band and unit, however outliers can be expected.\nFor Sentinel-1, data values are linear power in the chosen backscatter coefficient. To specify the backscatter coefficient, set BETA0, SIGMA0_ELLIPSOID, GAMMA0_ELLIPSOID (default) or GAMMA0_TERRAIN as the value of input.data.processing.backCoeff in your request. The default is GAMMA0_ELLIPSOID.\n\n\n\nBand\nPhysical Quantity (units)\nSentinel Hub Units\nSource Format\nTypical Range\nNotes\n\n\n\n\nPolarization VV, HH, VH, HV\nLinear power in the chosen backscatter coefficient (unitless)\nLINEAR_POWER\nUINT16\n0 - 0.5\nCan reach very high values (such as 1000); for visualizing a large dynamic range consider converting to decibels: decibel = 10 * log10 (linear).\n\n\nlocalIncidenceAngle\nAngle (degrees)\nDN\nN/A\n0 - 180\nComputed for each output pixel. Requires orthorectification.\n\n\nscatteringArea\nNormalized area (unitless)\nDN\nN/A\n0 - 2\nCan reach high values on foreslopes. Requires radiometric terrain correction.\n\n\nshadowMask\nN/A\nDN\nN/A\n0 - likely not radar shadow  1 - likely in/near radar shadow\nRequires radiometric terrain correction.\n\n\ndataMask\nN/A\nDN\nN/A\n0 - no data 1 - data\n\n\n\n\n\n\nScenes Object\nscenes object stores metadata. An example of metadata available in scenes object for Sentinel-1 GRD when mosaicking is ORBIT:\n\n\n\nProperty name\nValue\n\n\n\n\ndateFrom\n'2019-04-02T00:00:00Z'\n\n\ndateTo\n'2019-04-02T23:59:59Z'\n\n\ntiles[i].date\n'2019-04-02T17:05:39Z'\n\n\ntiles[i].shId\n881338\n\n\ntiles[i].dataPath\n's3://sentinel-s1-l1c/GRD/2019/4/2/IW/DV/S1A_IW_GRDH_1SDV_20190402T170539_20190402T170604_026614_02FC31_7D8E'\n\n\n\nProperties of a scenes object can differ depending on the selected mosaicking and in which evalscript function the object is accessed. Working with metadata in evalscript user guide explains all details and provide examples.\n\n\nMosaicking\nSIMPLE and ORBIT mosaicking types are supported."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S1GRD.html#collection-specific-constraints",
    "href": "APIs/SentinelHub/Data/S1GRD.html#collection-specific-constraints",
    "title": "Sentinel-1 GRD",
    "section": "Collection specific constraints",
    "text": "Collection specific constraints\n\nNoise: All products on both services have thermal noise reduction applied.\nDecibel units: For decibel outputs, a conversion is necessary within your evalscript, see an example here. We offer pre-defined evalscripts, which return S1GRD values in decibel units, as products in the Configuration Utility for your convenience.\nOrbit state vectors: We currently use the orbit state vectors provided in the products themselves as we find these sufficient for GRD use."
  },
  {
    "objectID": "APIs/SentinelHub/Data/S1GRD.html#catalog-api-capabilities",
    "href": "APIs/SentinelHub/Data/S1GRD.html#catalog-api-capabilities",
    "title": "Sentinel-1 GRD",
    "section": "Catalog API Capabilities",
    "text": "Catalog API Capabilities\nTo access Sentinel-1 GRD product metadata you need to send search request to our Catalog API. The requested metadata will be returned as JSON formatted response to your request. This chapter will help with understanding Sentinel 1 GRD specific parameters for search request.\n\nCollection identifier: sentinel-1-grd\n\n\nFilter extension\n\nsar:instrument_mode (possible values)\nsat:orbit_state (possible values)\ns1:polarization (possible values)\ns1:resolution (possible values)\ns1:timeliness (possible values)\n\n\n\nDistinct extension\n\ndate\nsar:instrument_mode\nsat:orbit_state\ns1:polarization"
  },
  {
    "objectID": "APIs/SentinelHub/Data/S1GRD.html#examples",
    "href": "APIs/SentinelHub/Data/S1GRD.html#examples",
    "title": "Sentinel-1 GRD",
    "section": "Examples",
    "text": "Examples\nS1 GRD examples"
  },
  {
    "objectID": "APIs/SentinelHub/Zarr.html",
    "href": "APIs/SentinelHub/Zarr.html",
    "title": "Zarr Import API",
    "section": "",
    "text": "Zarr Import API is only available for users with Copernicus Service accounts. Please refer to our FAQ on account typology change and Submit an account change request to our Copernicus Data Space Ecosystem Support Team to request your Copernicus Service account accordingly."
  },
  {
    "objectID": "APIs/SentinelHub/Zarr.html#overview",
    "href": "APIs/SentinelHub/Zarr.html#overview",
    "title": "Zarr Import API",
    "section": "Overview",
    "text": "Overview\nZarr Import API (or shortly \"Zarr\") enables you to import your own Zarr data in Sentinel Hub and access it just like any other data when some conditions are met.\nThese are:\n\nStore your raster data in the Zarr format on your own S3 bucket in the supported region.\nZarr data must conform to Sentinel Hub data constraints.\nConfigure the bucket's permissions so that Sentinel Hub can read them."
  },
  {
    "objectID": "APIs/SentinelHub/Zarr.html#data-constraints",
    "href": "APIs/SentinelHub/Zarr.html#data-constraints",
    "title": "Zarr Import API",
    "section": "Data constraints",
    "text": "Data constraints\nSince Zarr is a generic data format, there are additional constraints in order to ingest the data to Sentinel Hub:\n\nData must be stored as a single Zarr group that contains coordinate arrays and data arrays.\nData array names should be valid JavaScript identifiers so they can be safely used in evalscripts; valid identifiers are case-sensitive, can contain Unicode letters, $, _, and digits (0-9), but may not start with a digit, and should not be one of the reserved JavaScript keywords.\nData arrays must have two or three dimensions. There must be exactly two spatial coordinate arrays, named either x and y or lat and lon, and an optional time coordinate array.\nData arrays must be stored in row-major order (\"order\": \"C\", i.e., the last dimension varies fastest). The ordering of the dimensions has to be [time, lat, lon] or [time, y, x] for 3 dimensional data, and [lat, lon] or [y, x] for 2 dimensional data.\nAll data, including the spatial and the optional time coordinate arrays, must consist of 32-bit or 64-bit integers and floats (Zarr data types u4, i4, i8, f4, f8).\nThe chunk size in the two spatial dimensions must be less than or equal to 3072, but does not need to be the same for all data arrays.\nFor 3 dimensional data:\n\nthe time array must include the units attribute in its zattrs, which has to be in the format &lt;unit&gt; since &lt;instant&gt;. Where supported units are days/hours/minutes/seconds/millis/micros/nanos and instant should either be in the format ISO8601 or should follow the definition of the time:units field of the CF time coordinate convention. As an example, unix epoch could be encoded as seconds since 1970-01-01 00:00:00,\nthe chunk size in time dimension must be the same for all data arrays and must be less than or equal to 50.\n\nData must not cross any of the two poles.\nData must use an equidistant spatial grid, that is, the two spatial coordinate arrays must be equidistant. The time coordinate array can be non-equidistant.\nThe projection needs to be one of: WGS84 (EPSG:4326), WebMercator (EPGS:3857), any UTM zone (EPSG:32601-32660, 32701-32760), or Europe LAEA (EPSG:3035).\nSubgroups within the Zarr group will be ignored, but may be ingested separately.\n\nPlease refer to Zarr specification for explanation of various Zarr format properties."
  },
  {
    "objectID": "APIs/SentinelHub/Zarr.html#bucket-settings",
    "href": "APIs/SentinelHub/Zarr.html#bucket-settings",
    "title": "Zarr Import API",
    "section": "Bucket settings",
    "text": "Bucket settings\nIf you do not yet have a bucket at Copernicus Data Space Ecosystem, please follow these steps to get one.\nYou will have to configure your bucket to allow read access to Sentinel Hub. To do this, update your bucket policy to include the following statement (don’t forget to replace &lt;bucket_name&gt; with your actual bucket name):\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Sentinel Hub permissions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::ddf4c98b5e6647f0a246f0624c8341d9:root\"\n            },\n            \"Action\": [\n                \"s3:GetBucketLocation\",\n                \"s3:ListBucket\",\n                \"s3:GetObject\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;\",\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}\nA python script to set a bucket policy can be downloaded here."
  },
  {
    "objectID": "APIs/SentinelHub/Zarr.html#creating-zarr-collections",
    "href": "APIs/SentinelHub/Zarr.html#creating-zarr-collections",
    "title": "Zarr Import API",
    "section": "Creating Zarr collections",
    "text": "Creating Zarr collections\nEach Zarr collection will correspond to a single Zarr group. When creating a collection, you need to provide:\n\nthe S3 bucket where you data is located,\nthe path in the bucket where the Zarr group resides, that is, the directory containing the .zgroup file,\nthe CRS in which your data is defined,\na name for the collection."
  },
  {
    "objectID": "APIs/SentinelHub/Zarr.html#ingesting-the-arrays",
    "href": "APIs/SentinelHub/Zarr.html#ingesting-the-arrays",
    "title": "Zarr Import API",
    "section": "Ingesting the arrays",
    "text": "Ingesting the arrays\nAfter a collection is created, the ingestion will start automatically. The service will try to ingest every data array found in the group in the given S3 bucket and path. If the Zarr data does not fulfill any of the above constraints, the ingestion will either fail entirely or the offending data arrays will be skipped.\nZarr service automatically configures collection bands named after the data arrays of the Zarr group, that is, the folder names of the arrays. For example, in a Zarr file that contains B1 and B2 array folders, the resulting arrays will be named B1 and B2.\nThe no data value will be read from data arrays' metadata, that is, from the fill_value property inside the array's .zarray file.\n\nQuerying ingestion status\nQuerying a collection will return the status of the ingestion as well as an error message if something went wrong. If the returned status is INGESTED you can start using your new zarr data with Sentinel Hub services."
  },
  {
    "objectID": "APIs/SentinelHub/Zarr.html#reingesting-the-zarr-collection",
    "href": "APIs/SentinelHub/Zarr.html#reingesting-the-zarr-collection",
    "title": "Zarr Import API",
    "section": "Reingesting the Zarr collection",
    "text": "Reingesting the Zarr collection\nWhen reingesting the Zarr, the data already ingested cannot be changed, but new chunks can be added to the existing data arrays and the temporal array can be expanded accordingly."
  },
  {
    "objectID": "APIs/SentinelHub/Zarr.html#examples",
    "href": "APIs/SentinelHub/Zarr.html#examples",
    "title": "Zarr Import API",
    "section": "Examples",
    "text": "Examples\nZarr Import API Examples"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/TimeSeries.html",
    "href": "APIs/SentinelHub/UserGuides/TimeSeries.html",
    "title": "Time series",
    "section": "",
    "text": "Processing API uses a timeRange parameter, where a user can select from-to dates. When such a request is ran, only one image is returned. timeRange is used to specify the scenes that are going to be considered for mosaicking (for example all the scenes from April 1 to June 1). Which one will be chosen for the output depends on the mosaicking type and order specified. If the user specified SIMPLE mosaicking order to be mostRecent, the first image considered for mosaicking would be the most recent image available from April 1 to June 1. If a user selected a mosaicking type TILE, and requested second samples (sample[1]), the samples of the second available scene in the specified time range would be returned. Learn more about mosaicking here and mosaicking orders here.\nIf you would like to return all the scenes in a given time range, the recommended approach is to first search for all the available scenes using our Catalog service API, which you can use to view detailed geospatial information, such as the acquisition date and time, for each of the available scenes of your specified BBOX, collection and time range. You can control your Catalog search by specifying fields, limits and other properties. See the Catalog API examples to learn how to do so. It's also possible to search the available scenes using the OGC WFS request, which might be a bit easier to use, but gives you much less search control. See a WFS request example here.\nWhen you have a list of the available scenes, you can then request each by using a separate Processing API call. To do so, limit time-range to only allow for the desired time frame, which matches the acquisition time of your scene."
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/TimeSeries.html#working-with-time-series",
    "href": "APIs/SentinelHub/UserGuides/TimeSeries.html#working-with-time-series",
    "title": "Time series",
    "section": "",
    "text": "Processing API uses a timeRange parameter, where a user can select from-to dates. When such a request is ran, only one image is returned. timeRange is used to specify the scenes that are going to be considered for mosaicking (for example all the scenes from April 1 to June 1). Which one will be chosen for the output depends on the mosaicking type and order specified. If the user specified SIMPLE mosaicking order to be mostRecent, the first image considered for mosaicking would be the most recent image available from April 1 to June 1. If a user selected a mosaicking type TILE, and requested second samples (sample[1]), the samples of the second available scene in the specified time range would be returned. Learn more about mosaicking here and mosaicking orders here.\nIf you would like to return all the scenes in a given time range, the recommended approach is to first search for all the available scenes using our Catalog service API, which you can use to view detailed geospatial information, such as the acquisition date and time, for each of the available scenes of your specified BBOX, collection and time range. You can control your Catalog search by specifying fields, limits and other properties. See the Catalog API examples to learn how to do so. It's also possible to search the available scenes using the OGC WFS request, which might be a bit easier to use, but gives you much less search control. See a WFS request example here.\nWhen you have a list of the available scenes, you can then request each by using a separate Processing API call. To do so, limit time-range to only allow for the desired time frame, which matches the acquisition time of your scene."
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Transparency.html",
    "href": "APIs/SentinelHub/UserGuides/Transparency.html",
    "title": "Transparency",
    "section": "",
    "text": "Parts of the image can be made fully or partially transparent by including the fourth output channel, also known as the alpha channel. The value 0 in the alpha channel makes a pixel fully transparent, while the maximum value in the alpha channel makes it fully opaque (not transparent). Values in between will make the pixel proportionally transparent. Maximum value in alpha channel depends on an image bit depth which is in SH specified by sampleType:\n\nfor sampleType AUTO or FLOAT32: values in alpha channel should be from the interval [0, 1]\nfor sampleType UINT8: values in alpha channel should be from the interval [0, 255]\nfor sampleType UINT16: values in alpha channel should be from the interval [0, 65535]\n\nOutput file formats which support transparency are PNG and TIFF. Note that the JPEG format does not support alpha channel.\n\n\nNo-data pixels are marked by the value 0 in the dataMask band. In the evalscript below, we return value 0 in the fourth band for such pixels, which made them transparent. This evalscript can be used as part of any request for Sentinel-2 data and it will display a true color image with transparent background.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    if (samples.dataMask == 1){\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 1]\n    } else if (samples.dataMask == 0) {\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 0]\n    }\n}\nIn the example above we see that the value of dataMask band is exactly the value we want to use for the alpha channel (i.e. fourth channel) of the output. We can thus simplify the evalscript and return dataMask as the fourth band for all pixels.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, samples.dataMask]\n}\nExamine in EO Browser\nElegant! This will work whenever you request sampleType AUTO or FLOAT32. However, for other sampleTypes, you will have to scale the output values to achieve the same transparency. Let us check how to do this in the examples below.\n\n\nWhen using sampleType UINT16 the range of output values in an image becomes [0, 65535] and we must return value 65535 in the alpha channel for pixels which should not be transparent. The above example, if using sampleType UINT16, would be:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT16\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 65535, samples.B03 * 3.5 * 65535, samples.B02 * 3.5 * 65535, samples.dataMask * 65535]\n}\n\n\n\nThe same logic applies also for sampleType UINT8 except that the range of output values in this case is [0, 255]. The same evalscript as above but for sampleType UINT8 is:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT8\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 255, samples.B03 * 3.5 * 255, samples.B02 * 3.5 * 255, samples.dataMask * 255]\n}\n\n\n\n\nTo use some other condition for turning pixels transparent, simply return the condition in the fourth channel, while also outputting four bands in the function setup(). In the example below, we are returning the Sentinel-2 L1C NDVI index larger than 0.6 as transparent. We also leave the no-data pixels non-transparent and thus do not need to use the the dataMask input band.\n//VERSION=3\nfunction setup () {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"B08\"],\n    output: {bands: 4}\n  }\n}\nfunction evaluatePixel(samples, scenes) {\n  var NDVI = (samples.B08 - samples.B04) / (samples.B08 + samples.B04)\n  return [samples.B04 * 2.5, samples.B03 * 2.5, samples.B02 * 2.5, NDVI &lt; 0.6]\n}\nExamine in EO Browser\n\n\n\n  \n      \n         Data Mask\n                \n  \n  \n      \n        Time Series"
  },
  {
    "objectID": "APIs/SentinelHub/UserGuides/Transparency.html#transparency-and-background-color",
    "href": "APIs/SentinelHub/UserGuides/Transparency.html#transparency-and-background-color",
    "title": "Transparency",
    "section": "",
    "text": "Parts of the image can be made fully or partially transparent by including the fourth output channel, also known as the alpha channel. The value 0 in the alpha channel makes a pixel fully transparent, while the maximum value in the alpha channel makes it fully opaque (not transparent). Values in between will make the pixel proportionally transparent. Maximum value in alpha channel depends on an image bit depth which is in SH specified by sampleType:\n\nfor sampleType AUTO or FLOAT32: values in alpha channel should be from the interval [0, 1]\nfor sampleType UINT8: values in alpha channel should be from the interval [0, 255]\nfor sampleType UINT16: values in alpha channel should be from the interval [0, 65535]\n\nOutput file formats which support transparency are PNG and TIFF. Note that the JPEG format does not support alpha channel.\n\n\nNo-data pixels are marked by the value 0 in the dataMask band. In the evalscript below, we return value 0 in the fourth band for such pixels, which made them transparent. This evalscript can be used as part of any request for Sentinel-2 data and it will display a true color image with transparent background.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    if (samples.dataMask == 1){\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 1]\n    } else if (samples.dataMask == 0) {\n        return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, 0]\n    }\n}\nIn the example above we see that the value of dataMask band is exactly the value we want to use for the alpha channel (i.e. fourth channel) of the output. We can thus simplify the evalscript and return dataMask as the fourth band for all pixels.\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5, samples.B03 * 3.5, samples.B02 * 3.5, samples.dataMask]\n}\nExamine in EO Browser\nElegant! This will work whenever you request sampleType AUTO or FLOAT32. However, for other sampleTypes, you will have to scale the output values to achieve the same transparency. Let us check how to do this in the examples below.\n\n\nWhen using sampleType UINT16 the range of output values in an image becomes [0, 65535] and we must return value 65535 in the alpha channel for pixels which should not be transparent. The above example, if using sampleType UINT16, would be:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT16\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 65535, samples.B03 * 3.5 * 65535, samples.B02 * 3.5 * 65535, samples.dataMask * 65535]\n}\n\n\n\nThe same logic applies also for sampleType UINT8 except that the range of output values in this case is [0, 255]. The same evalscript as above but for sampleType UINT8 is:\n//VERSION=3\nfunction setup () {\n    return {\n        input: [\"B04\", \"B03\", \"B02\", \"dataMask\"],\n        output: {bands: 4, sampleType: \"UINT8\"}\n    }\n}\n\nfunction evaluatePixel(samples, scenes) {\n    return [samples.B04 * 3.5 * 255, samples.B03 * 3.5 * 255, samples.B02 * 3.5 * 255, samples.dataMask * 255]\n}\n\n\n\n\nTo use some other condition for turning pixels transparent, simply return the condition in the fourth channel, while also outputting four bands in the function setup(). In the example below, we are returning the Sentinel-2 L1C NDVI index larger than 0.6 as transparent. We also leave the no-data pixels non-transparent and thus do not need to use the the dataMask input band.\n//VERSION=3\nfunction setup () {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"B08\"],\n    output: {bands: 4}\n  }\n}\nfunction evaluatePixel(samples, scenes) {\n  var NDVI = (samples.B08 - samples.B04) / (samples.B08 + samples.B04)\n  return [samples.B04 * 2.5, samples.B03 * 2.5, samples.B02 * 2.5, NDVI &lt; 0.6]\n}\nExamine in EO Browser\n\n\n\n  \n      \n         Data Mask\n                \n  \n  \n      \n        Time Series"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html",
    "href": "APIs/SentinelHub/OGC/WFS.html",
    "title": "Web Feature Service",
    "section": "",
    "text": "The Sentinel Hub WFS (Web Feature Service) service conforms to the WFS standard. It provides access to the geometric (vector) metadata about the available data collection tiles. As with the WMS service, WFS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WFS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WFS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;\nThe service supports many vector formats, including GML, XML, JSON and also raw HTML and plain text. Check GetCapabilities for a list of all supported formats. It supports WFS version 2.0.0."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html#wfs-request",
    "href": "APIs/SentinelHub/OGC/WFS.html#wfs-request",
    "title": "Web Feature Service",
    "section": "",
    "text": "The Sentinel Hub WFS (Web Feature Service) service conforms to the WFS standard. It provides access to the geometric (vector) metadata about the available data collection tiles. As with the WMS service, WFS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WFS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WFS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;\nThe service supports many vector formats, including GML, XML, JSON and also raw HTML and plain text. Check GetCapabilities for a list of all supported formats. It supports WFS version 2.0.0."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WFS.html#wfs-url-parameters",
    "href": "APIs/SentinelHub/OGC/WFS.html#wfs-url-parameters",
    "title": "Web Feature Service",
    "section": "WFS URL Parameters",
    "text": "WFS URL Parameters\nStandard common WFS URL parameters (parameter names are case insensitive):\n\n\n\nWFS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WFS\".\n\n\nVERSION\nWFS version standard. Optional, default: \"2.0.0\". Supported values: \"2.0.0\".\n\n\nREQUEST\nWhat is requested, valid values: DescribeFeatureType, GetFeature or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WFS URL parameters, the WFS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetFeature request URL parameters:\n\n\n\nWFS parameter\nInfo\n\n\n\n\nTYPENAMES\nMore information found below.\n\n\nMAXFEATURES\nThe maximum number of features to be returned by a single request. Default value: 100. Valid range: 0..100.\n\n\nBBOX\nThe bounding box area for which to return the features.\n\n\nSRSNAME\nThe CRS in which the BBOX is specified.\n\n\nFEATURE_OFFSET\nOffset controls the starting point within the returned features.\n\n\nOUTPUTFORMAT\nThe MIME format of the returned features.\n\n\n\nStandard DescribeFeatureType request URL parameters:\n\n\n\nWFS parameter\nInfo\n\n\n\n\nTYPENAMES\nMore information found below.\n\n\nOUTPUTFORMAT\nThe MIME format of the returned features.\n\n\n\n\nTypenames\n\n\n\nData collection\nTYPENAMES for services\n\n\n\n\nSENTINEL-2 L1C\nDSS1\n\n\nSENTINEL-2 L2A\nDSS2\n\n\nSENTINEL-1 IW\nDSS3\n\n\nSENTINEL-1 EW\nDSS3\n\n\nSENTINEL-1 EW SH\nDSS3\n\n\nSENTINEL 3 OLCI\nDSS8\n\n\nSENTINEL 3 SLSTR\nDSS9\n\n\nSENTINEL 5P\nDSS7\n\n\nBYOC\nbyoc-&lt;collectionId&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html",
    "href": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html",
    "title": "Additional Request Parameters",
    "section": "",
    "text": "WMS/WMTS/WFS/WCS services support many custom parameters which affect the generation of the service responses. In the following table, all the available custom parameters, such as preview modes, are listed. All these parameters are optional.\nFor the examples on how to use them, see this documentation.\nNote that atmospheric correction is not a parameter anymore, as we now only support L2A atmospheric correction. Read more about it here.\n\n\n\nCustom parameter\nInfo\nDefault value\nValid value range\nAvailable for\n\n\n\n\nMAXCC\nThe maximum allowable cloud coverage in percent. Cloud coverage is a product average and not viewport accurate hence images may have more cloud cover than specified here.\n100.0\n0.0 - 100.0\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nPRIORITY\nThe priority by which to select and sort the overlapping valid tiles from which the output result is made. For example, using mostRecent will place newer tiles over older ones therefore showing the latest image possible. Using leastCC will place the least cloudy tiles available on top.\nmostRecent\nmostRecent, leastRecent, leastCC, leastTimeDifference, maximumViewingElevation\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nEVALSCRIPT\nThis parameter allows for a custom evaluation script or formula specifying how the output image will be generated from the input bands. See Custom evaluation script usage for details.   EVALSCRIPT parameter has to be BASE64 encoded before it is passed to the service.\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nEVALSCRIPTURL\nThis parameter allows for a custom evaluation script or formula to be passed as an URL parameter, where the script itself is located (it should be on HTTPS).\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nPREVIEW\nSee Preview modes for details.\n0\n0, 1, 2\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nGEOMETRY\nOutputs imagery only within the given geometry and cropped to the geometry's minimum bounding box.\n\none WKT string, one WKB hex string, or a list of coordinate pairs representing a polygon (pairs separated by semicolons, components by comma, i.e. 1 1, 2 2;...) Coordinates should be specified using the CRS of the request (i.e. same CRS as BBOX).\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nQUALITY\nUsed only when requesting JPEGs.\n90\n0 - 100; where 0 is the lowest and 100 the highest quality\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nUPSAMPLING\nSets the image upsampling method. Used when the requested resolution is higher than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nDOWNSAMPLING\nSets the image downsampling method. Used when the requested resolution is lower than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC, BOX\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nWARNINGS\nEnables or disables the display of in-image warnings, like \"No data available for the specified area\".\nYES\nYES, NO\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\n\n\n\nPreview modes make it possible to receive data from across all zoom levels. Sentinel Hub is optimised for full resolution data access as this is what most users need. There are, however, some cases when lower resolution previews of the data make sense as well. This is done by adding the URL parameter PREVIEW. Optional, default=\"0\". Supported values:\n\n\n\nValues\nInfo\n\n\n\n\nPREVIEW=0\nOnly high resolution data from Sentinel-2 is used. This corresponds to real world distances up to 200m/pixel. This is the default.\n\n\nPREVIEW=1\nAllows zooming further out, up to a point. Up to 200m/pixel it displays the same data as PREVIEW=0. In addition to this it uses lower resolution data for real world distances up to 1500m/pixel.   With resolutions between 200m/pixel and 1500m/pixel cloud filtering is no longer applied.\n\n\nPREVIEW=2\nAllows any zoom level but is limited to a maximum of one month of data when most zoomed out. Up to 1500m/pixel it displays the same data as PREVIEW=1. With resolutions lower than 1500m/pixel (more zoomed out) it limits the data to one month prior to the \"TO\" date.   With resolutions less than 200m/pixel (more zoomed out) cloud filtering is no longer applied.\n\n\n\n\n\n\nSatellite images sometimes seem washed out or foggy, as atmosphere absorbs and scatters light on its way to the ground. We can correct for this to get clearer images using atmospheric correction. ESA provides a Sen2Cor processor, that applies atmospheric correction to the input Sentinel-2 L1C data with global coverage. The resulting product is called S2L2A data. To use Atmospheric correction, use the Sentinel-2 L2A (S2L2A) data collection.\nBelow, you can see the difference atmospheric correction makes. The first image of Marseille was made in EO Browser using S2L1C data, and the lower image was made using S2L2A atmospheric correction."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html#additional-request-parameters",
    "href": "APIs/SentinelHub/OGC/AdditionalRequestParameters.html#additional-request-parameters",
    "title": "Additional Request Parameters",
    "section": "",
    "text": "WMS/WMTS/WFS/WCS services support many custom parameters which affect the generation of the service responses. In the following table, all the available custom parameters, such as preview modes, are listed. All these parameters are optional.\nFor the examples on how to use them, see this documentation.\nNote that atmospheric correction is not a parameter anymore, as we now only support L2A atmospheric correction. Read more about it here.\n\n\n\nCustom parameter\nInfo\nDefault value\nValid value range\nAvailable for\n\n\n\n\nMAXCC\nThe maximum allowable cloud coverage in percent. Cloud coverage is a product average and not viewport accurate hence images may have more cloud cover than specified here.\n100.0\n0.0 - 100.0\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nPRIORITY\nThe priority by which to select and sort the overlapping valid tiles from which the output result is made. For example, using mostRecent will place newer tiles over older ones therefore showing the latest image possible. Using leastCC will place the least cloudy tiles available on top.\nmostRecent\nmostRecent, leastRecent, leastCC, leastTimeDifference, maximumViewingElevation\nWMS/WMTS/WFS/WCS (when REQUEST = \"GetMap\", \"GetTile\", \"GetCoverage\", \"GetFeature\", \"GetFeatureInfo\" or \"GetIndex\")\n\n\nEVALSCRIPT\nThis parameter allows for a custom evaluation script or formula specifying how the output image will be generated from the input bands. See Custom evaluation script usage for details.   EVALSCRIPT parameter has to be BASE64 encoded before it is passed to the service.\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nEVALSCRIPTURL\nThis parameter allows for a custom evaluation script or formula to be passed as an URL parameter, where the script itself is located (it should be on HTTPS).\n\n\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nPREVIEW\nSee Preview modes for details.\n0\n0, 1, 2\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nGEOMETRY\nOutputs imagery only within the given geometry and cropped to the geometry's minimum bounding box.\n\none WKT string, one WKB hex string, or a list of coordinate pairs representing a polygon (pairs separated by semicolons, components by comma, i.e. 1 1, 2 2;...) Coordinates should be specified using the CRS of the request (i.e. same CRS as BBOX).\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nQUALITY\nUsed only when requesting JPEGs.\n90\n0 - 100; where 0 is the lowest and 100 the highest quality\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nUPSAMPLING\nSets the image upsampling method. Used when the requested resolution is higher than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nDOWNSAMPLING\nSets the image downsampling method. Used when the requested resolution is lower than the source resolution.\nNEAREST\nNEAREST, BILINEAR, BICUBIC, BOX\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\nWARNINGS\nEnables or disables the display of in-image warnings, like \"No data available for the specified area\".\nYES\nYES, NO\nWMS/WMTS/WCS (when REQUEST = \"GetMap\", \"GetTile\" or \"GetCoverage\")\n\n\n\n\n\nPreview modes make it possible to receive data from across all zoom levels. Sentinel Hub is optimised for full resolution data access as this is what most users need. There are, however, some cases when lower resolution previews of the data make sense as well. This is done by adding the URL parameter PREVIEW. Optional, default=\"0\". Supported values:\n\n\n\nValues\nInfo\n\n\n\n\nPREVIEW=0\nOnly high resolution data from Sentinel-2 is used. This corresponds to real world distances up to 200m/pixel. This is the default.\n\n\nPREVIEW=1\nAllows zooming further out, up to a point. Up to 200m/pixel it displays the same data as PREVIEW=0. In addition to this it uses lower resolution data for real world distances up to 1500m/pixel.   With resolutions between 200m/pixel and 1500m/pixel cloud filtering is no longer applied.\n\n\nPREVIEW=2\nAllows any zoom level but is limited to a maximum of one month of data when most zoomed out. Up to 1500m/pixel it displays the same data as PREVIEW=1. With resolutions lower than 1500m/pixel (more zoomed out) it limits the data to one month prior to the \"TO\" date.   With resolutions less than 200m/pixel (more zoomed out) cloud filtering is no longer applied.\n\n\n\n\n\n\nSatellite images sometimes seem washed out or foggy, as atmosphere absorbs and scatters light on its way to the ground. We can correct for this to get clearer images using atmospheric correction. ESA provides a Sen2Cor processor, that applies atmospheric correction to the input Sentinel-2 L1C data with global coverage. The resulting product is called S2L2A data. To use Atmospheric correction, use the Sentinel-2 L2A (S2L2A) data collection.\nBelow, you can see the difference atmospheric correction makes. The first image of Marseille was made in EO Browser using S2L1C data, and the lower image was made using S2L2A atmospheric correction."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/Examples.html",
    "href": "APIs/SentinelHub/OGC/Examples.html",
    "title": "Examples of OGC API",
    "section": "",
    "text": "Below are examples for all our OGC APIs. To run the examples yourself, replace &lt;INSTANCE_ID&gt; in the URLs with your own configuration instance id and paste the url in any web browser. Your configuration must be based on the \"Simple WMS template\", which can be found when you create new configuration in the Dashboard in \"Configuration Utility\" tab.\nIf you want to check interactive example use this link.\n\nWMS #1\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetMap&BBOX=3238005,5039853,3244050,5045897&LAYERS=NATURAL-COLOR&MAXCC=20&WIDTH=320&HEIGHT=320&FORMAT=image/jpeg&TIME=2018-03-29/2018-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2018-03-29/2018-05-29\n\n\n\n\n\nResult\n\n\n\n\nWMS #2\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wms/&lt;INSTANCE_ID&gt;?REQUEST=GetMap&BBOX=3238005,5039853,3244050,5045897&FORMAT=image/jpeg&LAYERS=NATURAL-COLOR&MAXCC=20&WIDTH=320&HEIGHT=320&TIME=2017-01-29/2017-02-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2017-01-29/2017-02-29\n\n\n\n\n\nResult\n\n\n\n\nWCS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;?SERVICE=WCS&REQUEST=GetCoverage&COVERAGE=NATURAL-COLOR&BBOX=3238005,5039853,3244050,5045897&MAXCC=20&WIDTH=320&HEIGHT=320&FORMAT=image/jpeg&TIME=2019-03-29/2019-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nNATURAL-COLOR\n\n\nFORMAT\nimage/jpeg\n\n\nMAXCC\n20\n\n\nWIDTH\n320\n\n\nHEIGHT\n320\n\n\nTIME\n2019-03-29/2019-05-29\n\n\n\n\n\nResult\n\n\n\n\nWMTS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wmts/&lt;INSTANCE_ID&gt;?REQUEST=GetTile&BBOX=3238005,5039853,3244050,5045897&RESOLUTION=10&TILEMATRIXSET=PopularWebMercator512&LAYER=FALSE-COLOR&MAXCC=20&TILEMATRIX=14&TILEROW=3065&TILECOL=4758&TIME=2018-03-29/2018-05-29\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nLAYERS\nFALSE-COLOR\n\n\nMAXCC\n20\n\n\nRESOLUTION\n10\n\n\nTILEMATRIXSET\nPopularWebMercator512\n\n\nTILEMATRIX\n14\n\n\nTILEROW\n3065\n\n\nTILECOL\n4758\n\n\nTIME\n2018-03-29/2018-05-29\n\n\n\n\n\nResult\n\n\n\n\nWFS\n\nURL\nhttps://sh.dataspace.copernicus.eu/ogc/wfs/&lt;INSTANCE_ID&gt;?REQUEST=GetFeature&srsName=EPSG:3857&TYPENAMES=DSS2&BBOX=3238005,5039853,3244050,5045897&TIME=2019-02-11/2019-02-12\n\n\nParameters\n\n\n\nParameters\nOptions\n\n\n\n\nREQUEST\nGetFeature\n\n\nsrsName\nEPSG:3857\n\n\nTYPENAMES\nDSS2\n\n\nBBOX\n3238005,5039853,3244050,5045897\n\n\nTIME\n2019-02-11/2019-02-12\n\n\n\n\n\nResult\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\n&lt;wfs:FeatureCollection xsi:schemaLocation=\"http://www.opengis.net/wfs/2.0 http://schemas.opengis.net/wfs/2.0/wfs.xsd http://www.opengis.net/gml/3.2 http://schemas.opengis.net/gml/3.2.1/gml.xsd\"\n    xmlns:sh=\"https://www.sentinel-hub.com/\" xmlns:gml=\"http://www.opengis.net/gml/3.2\" xmlns:wfs=\"http://www.opengis.net/wfs/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n  &lt;wfs:boundedBy&gt;\n    &lt;gml:Box srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n      &lt;gml:coordinates&gt;\n        3137112.369571343,4944408.712920986 3285542.013115577,5093151.414429454\n      &lt;/gml:coordinates&gt;\n    &lt;/gml:Box&gt;\n  &lt;/wfs:boundedBy&gt;\n  &lt;wfs:member&gt;\n    &lt;DSS2&gt;\n      &lt;gml:boundedBy&gt;\n        &lt;gml:Box srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n          &lt;gml:coordinates&gt;\n            3137112.369571343,4944408.712920986 3285542.013115577,5093151.414429454\n          &lt;/gml:coordinates&gt;\n        &lt;/gml:Box&gt;\n      &lt;/gml:boundedBy&gt;\n      &lt;id&gt;S2A_OPER_MSI_L2A_TL_SGS__20190212T133228_A019023_T35TPF_N02.11&lt;/id&gt;\n      &lt;date&gt;2019-02-12&lt;/date&gt;\n      &lt;time&gt;09:08:52&lt;/time&gt;\n      &lt;path&gt;s3://sentinel-s2-l2a/tiles/35/T/PF/2019/2/12/0&lt;/path&gt;\n      &lt;crs&gt;EPSG:32635&lt;/crs&gt;\n      &lt;mbr&gt;600000,4490220 709800,4600020&lt;/mbr&gt;\n      &lt;cloudCoverPercentage&gt;97.48&lt;/cloudCoverPercentage&gt;\n      &lt;geometryProperty&gt;\n        &lt;gml:MultiPolygon srsName='urn:ogc:def:crs:EPSG::3857'&gt;\n          &lt;gml:polygonMember&gt;\n            &lt;gml:Polygon&gt;\n              &lt;gml:outerBoundaryIs&gt;\n                &lt;gml:LinearRing&gt;\n                  &lt;gml:coordinates&gt;\n                    3139096.254297407,5093151.414429454 3137112.369571343,4947176.295365512 3272770.2640233915,4944408.712920986 3273149.797764646,4946283.966865066 3273655.8785869186,4947972.618733139 3274080.280822489,4949071.057870209 3275105.522264074,4952896.767191993 3275390.8923655148,4953708.980760984 3275718.486013052,4955098.598468996 3282365.302587746,4979008.234912587\n                    3285542.013115577,5089991.454384799 3139096.254297407,5093151.414429454\n                  &lt;/gml:coordinates&gt;\n                &lt;/gml:LinearRing&gt;\n              &lt;/gml:outerBoundaryIs&gt;\n            &lt;/gml:Polygon&gt;\n          &lt;/gml:polygonMember&gt;\n        &lt;/gml:MultiPolygon&gt;\n      &lt;/geometryProperty&gt;\n    &lt;/DSS2&gt;\n  &lt;/wfs:member&gt;\n&lt;/wfs:FeatureCollection&gt;"
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html",
    "href": "APIs/SentinelHub/OGC/WCS.html",
    "title": "Web Coverage Service",
    "section": "",
    "text": "The Sentinel Hub WCS (Web Coverage Service) service conforms to the WCS standard. Provides access to the same bands product and additional informational layers as the WMS service except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. In addition to raster products, the WCS service can also return the vector features of the Sentinel-2 tiles' metadata. As with the WMS service, WCS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WCS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WCS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request (with addition of vector output formats, when \"TILE\" is selected as the COVERAGE) and supports the standard WCS requests: GetCoverage, DescribeCoverage and GetCapabilities. It supports WCS versions 1.0.0 and 1.1.2."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html#wcs-request",
    "href": "APIs/SentinelHub/OGC/WCS.html#wcs-request",
    "title": "Web Coverage Service",
    "section": "",
    "text": "The Sentinel Hub WCS (Web Coverage Service) service conforms to the WCS standard. Provides access to the same bands product and additional informational layers as the WMS service except only one layer can be specified at once, even when only raw Sentinel-2 bands are used. In addition to raster products, the WCS service can also return the vector features of the Sentinel-2 tiles' metadata. As with the WMS service, WCS is also only available via a user-preconfigured custom server instance URL.\nSee our OGC API Webinar, which will guide you through different OGC services, including WCS, help you understand the structure, show you how to run the requests in different environments and how they can be integrated with QGIS, ArcGIS and web applications.\nThe base URL for the WCS service:\nhttps://sh.dataspace.copernicus.eu/ogc/wcs/&lt;INSTANCE_ID&gt;\nThe service supports the same output formats as the WMS request (with addition of vector output formats, when \"TILE\" is selected as the COVERAGE) and supports the standard WCS requests: GetCoverage, DescribeCoverage and GetCapabilities. It supports WCS versions 1.0.0 and 1.1.2."
  },
  {
    "objectID": "APIs/SentinelHub/OGC/WCS.html#wcs-url-parameters",
    "href": "APIs/SentinelHub/OGC/WCS.html#wcs-url-parameters",
    "title": "Web Coverage Service",
    "section": "WCS URL Parameters",
    "text": "WCS URL Parameters\nStandard common WCS URL parameters (parameter names are case insensitive):\n\n\n\nWCS parameter\nInfo\n\n\n\n\nSERVICE\nRequired, must be \"WCS\".\n\n\nVERSION\nWCS version standard. Optional, default: \"1.1.2\". Supported values: \"1.0.0\" and \"1.1.2\".\n\n\nREQUEST\nWhat is requested, valid values: GetCoverage, DescribeCoverage or GetCapabilities. Required.\n\n\nTIME\n(when REQUEST = GetTile) The time range for which to return the results. The result is based on all scenes between the specified times conforming to the cloud coverage criteria and stacked based on priority setting - e.g. most recent on top. It is written as two time values in ISO8601 format separated by a slash, for example: TIME=2016-01-01T09:02:44Z/2016-02-01T11:00:00Z. Reduced accuracy times, where parts of the time string are omitted, are also supported. For example, TIME=2016-07-15/2016-07-15 will be interpreted as \"TIME=2016-07-15T00:00:00Z/2016-07-15T23:59:59Z\" and TIME=2016-07/2016-08 will be interpreted as \"TIME=2016-07-01T00:00:00Z/2016-08-31T23:59:59Z\"  Optional, default: none (the last valid image is returned).  Note: Requesting a single value for TIME parameter is deprecated. Sentinel Hub interpreted it as a time interval [given time - 6 months, given time]. For vast majority of cases this resulted in unnecessary long processing time thus we strongly encourage you to always use the smallest possible time range instead.\n\n\n\nIn addition to the standard WCS URL parameters, the WCS service also supports many custom URL parameters. See Custom service URL parameters for details.\nStandard GetCoverage request URL parameters:\n\n\n\nWCS parameter\nInfo\n\n\n\n\nCOVERAGE\nThe preconfigured (in the instance) layer for which to generate the output image, or \"TILE\" to return the vector format features.\n\n\nFORMAT\nThe returned image format. Optional, default: \"image/png\", other options: \"image/jpeg\", \"image/tiff\". Detailed information about supported values.\n\n\n\nStandard DescribeCoverage request URL parameters:\n\n\n\nWCS parameter\nInfo\n\n\n\n\nComing soon..."
  },
  {
    "objectID": "APIs/SentinelHub/Evalscript.html",
    "href": "APIs/SentinelHub/Evalscript.html",
    "title": "Evalscript (custom script)",
    "section": "",
    "text": "An evalscript (or \"custom script\") is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return. It is a required part of any process, batch processing or OGC request.\nEvalscripts can use any JavaScript function or language structures, along with certain utility functions we provide for your convenience. For running evalscripts we use the Chrome V8 JavaScript engine.\nIn the Evalscript V3 section you will find a technical documentation with detailed explanations of parameters and functions you can use in your evalscripts.\n\nExamples\nExamples of various evalscritps can be found on our Custom Scripts Repository.\n\n\nTutorials and Other Related Materials\n\nA PDF tutorial on writing simple evalscripts for beginners: Custom scripts tutorial\nA webinar on writing evalscripts for beginners: Custom Scripts, September 28, 2020\nA webinar on multi-temporal scripts and data fusion: Multi-temporal Scripts and Data Fusion, March 3, 2021\nA blog on good scripting practices: Custom Scripts: Faster, Cheaper, Better!, November 18, 2019\nA blog post on color maps: PUCK - Perceptually Uniform Color Maps in Satellite Imagery, January 28, 2021\nA blog post on sampleType: SampleType: what’s all the fuss about?, February 15, 2022\nMore blog posts and useful links can be found on our Sentinel Hub website."
  },
  {
    "objectID": "APIs/S3.html",
    "href": "APIs/S3.html",
    "title": "Access to EO data via S3",
    "section": "",
    "text": "S3 API is one of the main access methods for EO data. It is suitable for Third Party applications that require high-performance parallel access and scalability. Moreover, any user who wants to connect from an external infrastructure to the Copernicus Data Space Ecosystem collection can do so through the S3 protocol."
  },
  {
    "objectID": "APIs/S3.html#object-storage-endpoints",
    "href": "APIs/S3.html#object-storage-endpoints",
    "title": "Access to EO data via S3",
    "section": "Object Storage endpoints",
    "text": "Object Storage endpoints\nAccess to EO data hosted on object storage is using an API compatible with S3.\nS3 is an object storage service with which you can retrieve data over HTTPS using REST API.\nThere are multiple S3 endpoints for accessing the EO Data. The default S3 endpoint address is: https://eodata.dataspace.copernicus.eu/\nThis endpoint will provide access to EO data which is stored on the Object Storage. A Global Service Load Balancer (GSLB) directs the request to either CloudFerro Cloud or OpenTelekom Cloud (OTC) S3 endpoint. The decision is based on the location of the DNS resolver. (Global Service Load Balancer)\nUsers who want to make sure they are forwarded to OTC S3 endpoint have to use the following URL: https://eodata.ams.dataspace.copernicus.eu/"
  },
  {
    "objectID": "APIs/S3.html#registration",
    "href": "APIs/S3.html#registration",
    "title": "Access to EO data via S3",
    "section": "Registration",
    "text": "Registration\nTo generate the necessary credentials, you must have a registered account on dataspace.copernicus.eu. If you don’t have an account, you can register here."
  },
  {
    "objectID": "APIs/S3.html#generate-secrets",
    "href": "APIs/S3.html#generate-secrets",
    "title": "Access to EO data via S3",
    "section": "Generate secrets",
    "text": "Generate secrets\nIn order to obtain secrets, visit page and log in with the Copernicus Data Space Ecosystem account for which the keys are to be generated. After successfully logging in, indicate the expiration date of the secrets using the “Add Credentials” button and click “Confirm”.\n\n\n\nAdd Credentials\n\n\n\n\n\nDisplay Credentials\n\n\nNote that the Secret Key will be displayed only once, and you cannot view it again after clicking the Close button. Copy your secret key and keep it in a safe place."
  },
  {
    "objectID": "APIs/S3.html#example-access-using-s3cmd",
    "href": "APIs/S3.html#example-access-using-s3cmd",
    "title": "Access to EO data via S3",
    "section": "Example access using s3cmd",
    "text": "Example access using s3cmd\nThe example shown below assumes the use of a Linux environment.\nWith the access and secret key and the endpoint eodata.dataspace.copernicus.eu, you can use any tool to handle access via S3. Below is an example of how to access EO Data using the s3cmd.\nFirst, we recommend creating a configuration file. You can create it with tools like vi/vim or nano:\nvi .s3cfg\nvim .s3cfg\nnano .s3cfg\nCopy the following content to your configuration file with your access and secret key:\n[default]\naccess_key = &lt;access_key&gt;\nhost_base = eodata.dataspace.copernicus.eu\nhost_bucket = eodata.dataspace.copernicus.eu\nhuman_readable_sizes = False\nsecret_key = &lt;secret_key&gt;\nuse_https = true\ncheck_ssl_certificate = true\nThen you can run any s3cmd command pointing to the previously created configuration file with option -c:\ns3cmd -c ~/.s3cfg ls\nBelow is an example of downloading a product from the EO data repository using s3cmd:\ns3cmd -c ~/.s3cfg get s3://eodata/Sentinel-1/SAR/SLC/2016/12/28/S1A_IW_SLC__1SDV_20161228T044442_20161228T044509_014575_017AE8_4C26.SAFE/measurement/s1a-iw2-slc-vv-20161228t044442-20161228t044508-014575-017ae8-005.tiff\nIf the objects in the repository are archives, for example, such as S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE use the resursive option ––recursive or -r to download whole product.\nExample with the recursive option:\ns3cmd -c ~/.s3cfg -r get s3://eodata/Sentinel-1/SAR/SLC/2019/10/13/S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE/"
  },
  {
    "objectID": "APIs/S3.html#example-script-to-download-product-using-boto3",
    "href": "APIs/S3.html#example-script-to-download-product-using-boto3",
    "title": "Access to EO data via S3",
    "section": "Example script to download product using boto3",
    "text": "Example script to download product using boto3\nimport boto3\nimport os\n\nsession = boto3.session.Session()\ns3 = boto3.resource(\n    's3',\n    endpoint_url='https://eodata.dataspace.copernicus.eu',\n    aws_access_key_id=access_key,\n    aws_secret_access_key=secret_key,\n    region_name='default'\n)  # generated secrets\n\ndef download(bucket, product: str, target: str = \"\") -&gt; None:\n    \"\"\"\n    Downloads every file in bucket with provided product as prefix\n\n    Raises FileNotFoundError if the product was not found\n\n    Args:\n        bucket: boto3 Resource bucket object\n        product: Path to product\n        target: Local catalog for downloaded files. Should end with an `/`. Default current directory.\n    \"\"\"\n    files = bucket.objects.filter(Prefix=product)\n    if not list(files):\n        raise FileNotFoundError(f\"Could not find any files for {product}\")\n    for file in files:\n        os.makedirs(os.path.dirname(file.key), exist_ok=True)\n        if not os.path.isdir(file.key):\n            bucket.download_file(file.key, f\"{target}{file.key}\")\n\n# path to the product to download\ndownload(s3.Bucket(\"eodata\"), \"Sentinel-1/SAR/SLC/2019/10/13/S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE/\")"
  },
  {
    "objectID": "APIs/openEO/Processes.html",
    "href": "APIs/openEO/Processes.html",
    "title": "openEO Processes",
    "section": "",
    "text": "A process in openEO is an operation that performs a specific task on a set of parameters and returns a result. An example is computing a statistical operation, such as mean or median, on selected EO data. A process is similar to a function or method in programming languages.\nThe following is the list of Processes currently supported in openEO for performing several operations in your datacube."
  },
  {
    "objectID": "APIs/openEO/Glossary.html",
    "href": "APIs/openEO/Glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "The following glossary provides an introduction to the key technical terms commonly used when working with the openEO API."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#general-terms",
    "href": "APIs/openEO/Glossary.html#general-terms",
    "title": "Glossary",
    "section": "General terms",
    "text": "General terms\n\nEO: Earth Observation\nAPI: Application Programming Interface (wikipedia), a (standardized) communication protocol, for example between a client application and back-end service\nclient: Software tool, framework or environment that an end-user directly interacts with. For example: a Jupyter notebook, a Python script/application, an RStudio session, a JavaScript based web app, etc.\nback-end: server; computer infrastructure (one or more physical computers or virtual machines) used for storing EO data and processing it. Additionally, here, industry and researchers can analyse large amounts of EO data."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#processes",
    "href": "APIs/openEO/Glossary.html#processes",
    "title": "Glossary",
    "section": "Processes",
    "text": "Processes\nA process is an operation that performs a specific task on a set of parameters and returns a result. An example is computing a statistical operation, such as mean or median, on selected EO data. A process is similar to a function or method in programming languages.\nA pre-defined process is a process provided by the back-end, typically one of the processes centrally defined by openeo.org.\nA user-defined process is a process defined by the user. It can directly be part of another process graph or be stored as custom process on a back-end. Internally it is a process graph with optional additional metadata.\nA process graph chains specific process calls from the set of pre-defined and user-defined processes together. A process graph itself is a (user-defined) process again. Similarly to scripts in the context of programming, process graphs organize and automate the execution of one or more processes that could alternatively be executed individually.\nProcess graphs can be parameterized by using placeholders (parameters) instead of actual values in various places of the process graph. This turns them into so-called user-defined processes that can reused in a flexible way in other process graphs. It also simplifies sharing and reusing openEO workflows across users.\nUser-defined processes can for example be shared in the openEO algorithm plaza. You can find more information in this page"
  },
  {
    "objectID": "APIs/openEO/Glossary.html#eo-data-collections",
    "href": "APIs/openEO/Glossary.html#eo-data-collections",
    "title": "Glossary",
    "section": "EO data (Collections)",
    "text": "EO data (Collections)\nIn the Earth Observation domain, different terms are used to describe EO data(sets). Within openEO, a granule (sometimes also called item or asset in the specification) typically refers to a limited area and a single overpass leading to a very short observation period (seconds) or a temporal aggregation of such data (e.g. for 16-day MODIS composites). A collection is a sequence of granules sharing the same product specification. It typically corresponds to the series of products derived from data acquired by a sensor on board of a satellite and having the same mode of operation.\nThe CEOS OpenSearch Best Practice Document v1.2 lists the following synonyms used by other organizations:\n\ngranule: dataset (ESA, ISO 19115), granule (NASA), product (ESA, CNES), scene (JAXA)\ncollection: dataset series (ESA, ISO 19115), collection (CNES, NASA), dataset (JAXA), product (JAXA)\n\nIn openEO, a back-end offers a set of collections to be processed. All collections can be requested using a client and are described using the STAC (SpatioTemporal Asset Catalog) metadata specification as STAC collections. A user can load (a subset of) a collection using a special process, which returns a (spatial) datacube. All further processing is then applied to the datacube on the back-end."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#spatial-datacubes",
    "href": "APIs/openEO/Glossary.html#spatial-datacubes",
    "title": "Glossary",
    "section": "Spatial datacubes",
    "text": "Spatial datacubes\nA spatiotemporal datacube is a multidimensional array with one or more spatial or temporal dimensions. In the EO domain, it is common to be implicit about the temporal dimension and just refer to them as spatial datacubes in short. Special cases are raster and vector datacubes. Learn more about datacubes in the datacube documentation."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#vector-data",
    "href": "APIs/openEO/Glossary.html#vector-data",
    "title": "Glossary",
    "section": "Vector data",
    "text": "Vector data\nIn general, vector data represent specific things (also called “features”) in a space, e.g. on the surface of the Earth. It comprises of individual points stored as coordinate pairs that indicate a physical location in the world. These points can be joined, in a particular order, to form lines or joined into closed areas to form polygons.\nA coordinate represents a specific point in space.\nA feature is a thing that usually has a geometry (e.g. the outline of an agricultural field, a forest or an urban area) and it may have additional properties assigned (e.g. a name, a color or a population). In rare cases features may not have a geometry, which is often referred to as an “empty geometry”.\nGeometries consist of one or more coordinates that may be connected and then form a specific type of geometry, e.g. two points can be connected to a straight line and four straight lines can be connected to rectangle.\nCommonly used types of geometries are: - Point - LineString (connected straight line pieces) - Polygon (connected straight line pieces forming a closed ring, possibly with holes - for example a triangle or rectangle)\nFurther more, these base geometries can be grouped to form, for example, so-called “multi-point” or “multi-polygon” geometries. It’s important to note that these multi-geometries act as single entities with regard to their associated properties.\nFeatures and geometries are specified by the OGC in the Simple Feature Access specification (and ISO 19125). See the specification for more details."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#user-defined-function-udf",
    "href": "APIs/openEO/Glossary.html#user-defined-function-udf",
    "title": "Glossary",
    "section": "User-defined function (UDF)",
    "text": "User-defined function (UDF)\nThe abbreviation UDF stands for user-defined function. With this concept, users are able to upload custom code and have it executed e.g. for every pixel of a scene, or applied to a particular dimension or set of dimensions, allowing custom server-side calculations. See the section on UDFs for more information."
  },
  {
    "objectID": "APIs/openEO/Glossary.html#data-processing-modes",
    "href": "APIs/openEO/Glossary.html#data-processing-modes",
    "title": "Glossary",
    "section": "Data Processing modes",
    "text": "Data Processing modes\nProcesses can run in three different ways:\n\nResults can be pre-computed by creating a batch job. They are submitted to the back-end’s processing system, but will remain inactive until explicitly put into the processing queue. They will run only once and store results after execution. Results can be downloaded. Batch jobs are typically time consuming and user interaction is not possible although log files are generated for them. This is the only mode that allows to get an estimate about time, volume and costs beforehand.\nProcesses can also be executed on-demand (i.e. synchronously). Results are delivered with the request itself and no job is created. Only lightweight computations, for example previews, should be executed using this approach as timeouts are to be expected for long-polling HTTP requests.\nThe third way of data processing in openEO is client-side processing. The client-side processing functionality allows to test and use openEO with its processes locally, i.e. without any connection to an openEO back-end. It relies on the projects openeo-pg-parser-networkx, which provides an openEO process graph parsing tool, and openeo-processes-dask, which provides an Xarray and Dask implementation of most openEO processes."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html",
    "href": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html",
    "title": "Usecase showcasing Regional Benchmarking service of Anomaly Identification",
    "section": "",
    "text": "With the OpenEO-based Regional Benchmarking service you can check the crop growth on a field and compare it with a similar fields. It gives you an idea of whether your field is performing better or worse than other fields.\nIn this example, we have compared several fields with similar croptype available in our area of interest. The area of interest is derived as WFS from DLV service filtered by a croptype(here, croptype = ‘Zomergerst’). Nevertheless, if users have their polygons/parcels, they can use them with a note that they should be of similar crop type.\n# importing necessary packages\nimport openeo\nimport rasterio\nfrom rasterio.plot import show\n# Acquire more information about the service\nservice = \"Anomaly_Detection\"\nnamespace = \"vito\"\n\neoconn = openeo.connect('https://openeo.vito.be').authenticate_oidc()\neoconn.describe_process(service, namespace=namespace)\n\nAuthenticated using refresh token.\nAs mentioned earlier, though, in this example, we used parcels from a WFS; these parameters are specific to them. User can use their polygons/parcels based on their requirements.\n# Specific parameters\ncroptype = 'Zomergerst'\n\n# Bounding Box\nwest = 5.17\neast = 5.3\nsouth = 51.1\nnorth = 52.246\n# reading the json file (user can use this function if they have their features stored as json file)\n\nimport json\ndef read_json_str(json_txt: str) -&gt; dict:\n    field = json.loads(json_txt)\n    return field"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#parse-the-data",
    "href": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#parse-the-data",
    "title": "Usecase showcasing Regional Benchmarking service of Anomaly Identification",
    "section": "Parse the data",
    "text": "Parse the data\nHere, we tried in parsing WFS provided by https://lv.vlaanderen.be/en as parcels with their crop types.\n\n# requesting data over a region for a specific crop type\n\nimport urllib\nimport requests\n\nurl = f\"https://geo.api.vlaanderen.be/Landbgebrperc/wfs?service=WFS&request=getfeature&cql_filter=LBLHFDTLT='{croptype}'&outputformat=json&typename=Lbgebrperc&SRSName=urn:x-ogc:def:crs:EPSG:4326\"\nreq = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n\nwfs_request_url = requests.Request('GET', url,headers={'User-Agent': 'Mozilla/5.0'}).prepare().url\ndata = req.json()\n\nBefore proceeding forward, we want to ensure that the filtered data likes in the area of interest. Thus the following cell includes the method to display the parsed data as a dataframe and map.\n\nimport shapely\nimport geopandas as gpd\nfrom shapely.geometry import box\n\n\ndataframe = gpd.GeoDataFrame.from_features(data[\"features\"],crs='EPSG:4326')\narea=dataframe.to_crs(epsg=3857).area\ndataframe=dataframe[area&gt;200]\n\n# filter data within the bounding box\nbbox = box(west,south,east,north)\ndataframe = dataframe[dataframe.within(bbox)]\n\ndataframe = dataframe.head()\n# converting dataframe to geojson string\ngeojson_str = dataframe.to_json()\n\ndataframe\n\n\n\n\n\n\n\n\ngeometry\nUIDN\nOIDN\nALVID\nHFDTLT\nLBLHFDTLT\nGEWASGROEP\nPM\nLBLPM\n\n\n\n\n19\nPOLYGON ((5.17759388 51.13236902, 5.17754339 5...\n4092306\n1228344\n1211525956\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n47\nPOLYGON ((5.24743582 51.10311003, 5.24843201 5...\n1882791\n1021017\n1319447853\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n57\nPOLYGON ((5.17872085 51.17170835, 5.17848342 5...\n4340847\n1667648\n2074973981\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n82\nPOLYGON ((5.21847254 51.27816026, 5.21847592 5...\n4355462\n1639446\n2070875228\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n129\nPOLYGON ((5.2909333 51.20048401, 5.29085554 51...\n4367507\n1523096\n1860308032\n322\nZomergerst\nGranen, zaden en peulvruchten\n\n\n\n\n\n\n\n\n\n\n# plot the polygons\nimport folium\nmap = folium.Map( tiles=\"open street map\", zoom_start=12,location=[51.243,5.18])\npoints = folium.features.GeoJson(dataframe.to_crs('EPSG:4326').to_json())\nmap.add_child(points)\nmap.fit_bounds(map.get_bounds(), padding=(30, 30))\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#apply-anomaly-detection-service",
    "href": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#apply-anomaly-detection-service",
    "title": "Usecase showcasing Regional Benchmarking service of Anomaly Identification",
    "section": "Apply Anomaly Detection service",
    "text": "Apply Anomaly Detection service\n\n#parameters mandatory for this openeo-based service\naoi=read_json_str(geojson_str)\ndate = [\"2020-03-06\", \"2020-06-30\"]\n\n#accessing the openeo service\nanomaly = eoconn.datacube_from_process(service, namespace=namespace, date=date\n                                       , polygon=aoi)\n\n/home/pratixa/.local/lib/python3.6/site-packages/openeo/metadata.py:252: UserWarning: No cube:dimensions metadata\n  complain(\"No cube:dimensions metadata\")\n\n\n\n# synchronous download or batch process\nanomaly.download('RegionalBenchmarking_AD.json')\n\n# # batch processing\n# batch_job = anomaly.create_job(out_format = \"json\", title=\"Croptype\")\n# batch_job.start_and_wait()\n# results = batch_job.get_results()\n# results.download_files()\n\nThe service calculates the CropSAR fAPAR curve for each field and the regional average fAPAR curve calculated from comparable fields in the region during a given time period."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#visualize-and-compare-the-final-result",
    "href": "APIs/openEO/openeo-community-examples/python/Anomaly_Detection/Anomaly_Detection.html#visualize-and-compare-the-final-result",
    "title": "Usecase showcasing Regional Benchmarking service of Anomaly Identification",
    "section": "Visualize and compare the final result",
    "text": "Visualize and compare the final result\n\nimport matplotlib.pyplot as plt\nimport json\n\ndata_json = json.load(open('RegionalBenchmarking_AD.json', 'r'))\n\n\nfrom matplotlib.pyplot import figure\nimport matplotlib.dates as mdates\n\nfigure(figsize=(18,9), dpi=300)\nfor i in data_json:\n    x_Axis = [key for key, value in data_json[i].items()]\n    y_Axis = [value for key, value in data_json[i].items()]\n    plt.plot(x_Axis,y_Axis, label = i)\n\nax = plt.gca()\nn = 7  # Keeps every 7th label\n[l.set_visible(False) for (i,l) in enumerate(ax.get_xticklabels()) if i % n != 0]\nplt.xlabel('variable')\nplt.xticks(rotation=90)\nplt.ylabel('value')\nplt.tight_layout()\nplt.legend()\nplt.show()\n\n\n\n\nThrough the visualized curved you can study the croptype behaviour of the field in comparision with the Regional average."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html",
    "href": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html",
    "title": "Publishing an openEO workflow as a User-Defined-Process (UDP)",
    "section": "",
    "text": "In this notebook, we want to show how to create an openEO User Defined Process(UDP). Here, we make use of an apply_dimension process that applies a process to all values along a dimension of a data cube.\nThe notebook involves a section on creating a concrete datacube, inspecting netCDF downloads, and developing a parameterized version stored as a UDP.\nimport json\nimport openeo\nimport xarray\nimport matplotlib.pyplot as plt\nfrom utils import *\n\nfrom openeo.processes import array_create, array_concat, ProcessBuilder\nfrom openeo.api.process import Parameter\nIf you have a local JupyterLab instance running, you need to install the following libraries first: openeo, xarray, ipyleaflet, shapely and matplotlib:\npip install openeo xarray shapely ipyleaflet matplotlib\nMake sure to restart the kernel and refresh the webpage.\n# Set some defaults for plots\nplt.rcParams[\"figure.figsize\"] = [5.0, 3.0]\nplt.rcParams[\"figure.dpi\"] = 75\nConnect to the openEO Platform backend (at openeo.cloud) and authenticate with OIDC.\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#inspect-raw-data",
    "href": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#inspect-raw-data",
    "title": "Publishing an openEO workflow as a User-Defined-Process (UDP)",
    "section": "Inspect raw data",
    "text": "Inspect raw data\nLoad initial data cube with raw S1_GRD_SIGMA0_ASCENDING data for a certain spatio-temporal extent.\n\ncenter = [46.49, 11.35]\nzoom = 15\n\neoMap = openeoMap(center, zoom)\neoMap.map\n\n\n\n\n\nbbox = eoMap.getBbox()\nprint(\"west\", bbox[0], \"\\neast\", bbox[2], \"\\nsouth\", bbox[1], \"\\nnorth\", bbox[3])\n\nwest 11.3409 \neast 11.353779 \nsouth 46.48772 \nnorth 46.493924\n\n\n\nspatial_extent = {\n    \"west\": bbox[0],\n    \"east\": bbox[2],\n    \"south\": bbox[1],\n    \"north\": bbox[3],\n    \"crs\": 4326,\n}\ntemporal_extent = [\"2023-05-01\", \"2023-07-01\"]\n\n\ns1_raw = connection.load_collection(\n    collection_id=\"SENTINEL1_GRD_SIGMA0\",\n    temporal_extent=temporal_extent,\n    spatial_extent=spatial_extent,\n    bands=[\"VH\", \"VV\"],\n)\n\nLet’s download this data cube synchronously as a netCDF file.\nThis download command triggers the actual processing on the back-end: it sends the process graph to the back-end and waits for the result. It is a synchronous operation (the download() call blocks until the result is fully downloaded) and because we work on a small spatio-temporal extent, this should only take a couple of seconds.\n\n%%time\ns1_raw.download(\"s1sar-raw.nc\")\n\nCPU times: user 36 ms, sys: 12 ms, total: 48 ms\nWall time: 1min 3s\n\n\nHowever, batch job-based execution is preferred when it is relatively larger spatial/temporal extent and the process may take some time to process.\n\nds = xarray.load_dataset(\"s1sar-raw.nc\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (t: 10, x: 102, y: 72)\nCoordinates:\n  * t        (t) datetime64[ns] 2023-05-03 2023-05-10 ... 2023-06-20 2023-06-27\n  * x        (x) float64 6.796e+05 6.796e+05 6.797e+05 ... 6.806e+05 6.806e+05\n  * y        (y) float64 5.152e+06 5.152e+06 5.152e+06 ... 5.151e+06 5.151e+06\nData variables:\n    crs      |S1 b''\n    VH       (t, y, x) float32 0.3498 0.2405 0.2339 ... 0.003244 0.003791\n    VV       (t, y, x) float32 0.356 0.356 0.809 ... 0.08211 0.01796 0.02538\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platformxarray.DatasetDimensions:t: 10x: 102y: 72Coordinates: (3)t(t)datetime64[ns]2023-05-03 ... 2023-06-27standard_name :tlong_name :taxis :Tarray(['2023-05-03T00:00:00.000000000', '2023-05-10T00:00:00.000000000',\n       '2023-05-15T00:00:00.000000000', '2023-05-22T00:00:00.000000000',\n       '2023-05-27T00:00:00.000000000', '2023-06-03T00:00:00.000000000',\n       '2023-06-08T00:00:00.000000000', '2023-06-15T00:00:00.000000000',\n       '2023-06-20T00:00:00.000000000', '2023-06-27T00:00:00.000000000'],\n      dtype='datetime64[ns]')x(x)float646.796e+05 6.796e+05 ... 6.806e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([679635., 679645., 679655., 679665., 679675., 679685., 679695., 679705.,\n       679715., 679725., 679735., 679745., 679755., 679765., 679775., 679785.,\n       679795., 679805., 679815., 679825., 679835., 679845., 679855., 679865.,\n       679875., 679885., 679895., 679905., 679915., 679925., 679935., 679945.,\n       679955., 679965., 679975., 679985., 679995., 680005., 680015., 680025.,\n       680035., 680045., 680055., 680065., 680075., 680085., 680095., 680105.,\n       680115., 680125., 680135., 680145., 680155., 680165., 680175., 680185.,\n       680195., 680205., 680215., 680225., 680235., 680245., 680255., 680265.,\n       680275., 680285., 680295., 680305., 680315., 680325., 680335., 680345.,\n       680355., 680365., 680375., 680385., 680395., 680405., 680415., 680425.,\n       680435., 680445., 680455., 680465., 680475., 680485., 680495., 680505.,\n       680515., 680525., 680535., 680545., 680555., 680565., 680575., 680585.,\n       680595., 680605., 680615., 680625., 680635., 680645.])y(y)float645.152e+06 5.152e+06 ... 5.151e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5151615., 5151605., 5151595., 5151585., 5151575., 5151565., 5151555.,\n       5151545., 5151535., 5151525., 5151515., 5151505., 5151495., 5151485.,\n       5151475., 5151465., 5151455., 5151445., 5151435., 5151425., 5151415.,\n       5151405., 5151395., 5151385., 5151375., 5151365., 5151355., 5151345.,\n       5151335., 5151325., 5151315., 5151305., 5151295., 5151285., 5151275.,\n       5151265., 5151255., 5151245., 5151235., 5151225., 5151215., 5151205.,\n       5151195., 5151185., 5151175., 5151165., 5151155., 5151145., 5151135.,\n       5151125., 5151115., 5151105., 5151095., 5151085., 5151075., 5151065.,\n       5151055., 5151045., 5151035., 5151025., 5151015., 5151005., 5150995.,\n       5150985., 5150975., 5150965., 5150955., 5150945., 5150935., 5150925.,\n       5150915., 5150905.])Data variables: (3)crs()|S1b''crs_wkt :PROJCS[\"WGS 84 / UTM zone 32N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 9.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32632\"]]spatial_ref :PROJCS[\"WGS 84 / UTM zone 32N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 9.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32632\"]]array(b'', dtype='|S1')VH(t, y, x)float320.3498 0.2405 ... 0.003244 0.003791long_name :VHunits :grid_mapping :crsarray([[[0.3497991 , 0.240497  , 0.23386185, ..., 0.00583607,\n         0.01114625, 0.01180739],\n        [0.21625957, 0.22582962, 0.27404746, ..., 0.01413637,\n         0.01605362, 0.02861624],\n        [0.21343715, 0.15391256, 0.1240928 , ..., 0.01913997,\n         0.02732791, 0.06749884],\n        ...,\n        [0.00975169, 0.00683461, 0.00614753, ..., 0.00683165,\n         0.00199292, 0.01335612],\n        [0.00809784, 0.00810335, 0.0087291 , ..., 0.00491569,\n         0.00386301, 0.01294566],\n        [0.00524675, 0.01154147, 0.0111153 , ..., 0.0089683 ,\n         0.00496414, 0.00955531]],\n\n       [[0.05656133, 0.07117188, 0.12068269, ..., 0.03960535,\n         0.02495288, 0.01579268],\n        [0.09063352, 0.06542234, 0.06321717, ..., 0.074268  ,\n         0.04379695, 0.02947565],\n        [0.08322202, 0.05983272, 0.06086417, ..., 0.06582635,\n         0.04827164, 0.05478774],\n...\n        [0.02081406, 0.01660735, 0.00927989, ..., 0.00631161,\n         0.00305758, 0.01555643],\n        [0.01103931, 0.01278648, 0.0059051 , ..., 0.00733566,\n         0.00785622, 0.01034456],\n        [0.01053969, 0.01614342, 0.01426238, ..., 0.00684131,\n         0.00470488, 0.00610361]],\n\n       [[0.11626446, 0.10056856, 0.11683535, ..., 0.02819041,\n         0.01466341, 0.0131486 ],\n        [0.0842052 , 0.09308649, 0.08042921, ..., 0.0202127 ,\n         0.01330222, 0.02162029],\n        [0.11007892, 0.10168418, 0.07600641, ..., 0.01328301,\n         0.06286687, 0.09713611],\n        ...,\n        [0.02943419, 0.03480869, 0.03886167, ..., 0.00179048,\n         0.01113027, 0.00225721],\n        [0.01721563, 0.02312371, 0.05103515, ..., 0.00179926,\n         0.00703626, 0.00816311],\n        [0.01056776, 0.01323224, 0.01524322, ..., 0.01825097,\n         0.00324418, 0.00379148]]], dtype=float32)VV(t, y, x)float320.356 0.356 ... 0.01796 0.02538long_name :VVunits :grid_mapping :crsarray([[[0.35600373, 0.3559536 , 0.80896807, ..., 0.3317161 ,\n         0.16445988, 0.04160649],\n        [0.61769664, 0.5578946 , 0.5050262 , ..., 0.22054403,\n         0.10073389, 0.06029705],\n        [0.84790504, 0.6570914 , 0.58305556, ..., 0.16478802,\n         0.05791532, 0.0579203 ],\n        ...,\n        [0.1073544 , 0.10243879, 0.09812227, ..., 0.02534649,\n         0.00922628, 0.01754627],\n        [0.05122279, 0.06052506, 0.06034074, ..., 0.02414759,\n         0.01439755, 0.01660094],\n        [0.04778335, 0.05747797, 0.06184885, ..., 0.02491218,\n         0.02271986, 0.01123959]],\n\n       [[0.4726906 , 0.47493017, 0.82746756, ..., 0.22725   ,\n         0.10644101, 0.04749625],\n        [0.39489403, 0.413578  , 0.57773596, ..., 0.22964555,\n         0.12250378, 0.06308025],\n        [0.4349608 , 0.4983854 , 0.8121271 , ..., 0.14484774,\n         0.11491019, 0.10635231],\n...\n        [0.10983685, 0.09603946, 0.08231169, ..., 0.07407534,\n         0.02241934, 0.17368278],\n        [0.05511827, 0.04872738, 0.0588784 , ..., 0.10989355,\n         0.01494858, 0.09516722],\n        [0.03997884, 0.03643978, 0.03698706, ..., 0.09584986,\n         0.01911887, 0.03895752]],\n\n       [[0.54582274, 0.8157599 , 1.0333498 , ..., 0.10145897,\n         0.07532571, 0.0363849 ],\n        [0.5309309 , 0.97571516, 1.3032748 , ..., 0.1301856 ,\n         0.08703941, 0.06910698],\n        [0.2805328 , 0.6426719 , 0.9920144 , ..., 0.13717869,\n         0.18444583, 0.2799541 ],\n        ...,\n        [0.07433109, 0.08866205, 0.08638017, ..., 0.01586673,\n         0.04167084, 0.0467084 ],\n        [0.06121723, 0.12546135, 0.15904632, ..., 0.01122087,\n         0.02190844, 0.06850047],\n        [0.08498283, 0.09475873, 0.06337849, ..., 0.08210503,\n         0.01796073, 0.02538092]]], dtype=float32)Indexes: (3)tPandasIndexPandasIndex(DatetimeIndex(['2023-05-03', '2023-05-10', '2023-05-15', '2023-05-22',\n               '2023-05-27', '2023-06-03', '2023-06-08', '2023-06-15',\n               '2023-06-20', '2023-06-27'],\n              dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Index([679635.0, 679645.0, 679655.0, 679665.0, 679675.0, 679685.0, 679695.0,\n       679705.0, 679715.0, 679725.0,\n       ...\n       680555.0, 680565.0, 680575.0, 680585.0, 680595.0, 680605.0, 680615.0,\n       680625.0, 680635.0, 680645.0],\n      dtype='float64', name='x', length=102))yPandasIndexPandasIndex(Index([5151615.0, 5151605.0, 5151595.0, 5151585.0, 5151575.0, 5151565.0,\n       5151555.0, 5151545.0, 5151535.0, 5151525.0, 5151515.0, 5151505.0,\n       5151495.0, 5151485.0, 5151475.0, 5151465.0, 5151455.0, 5151445.0,\n       5151435.0, 5151425.0, 5151415.0, 5151405.0, 5151395.0, 5151385.0,\n       5151375.0, 5151365.0, 5151355.0, 5151345.0, 5151335.0, 5151325.0,\n       5151315.0, 5151305.0, 5151295.0, 5151285.0, 5151275.0, 5151265.0,\n       5151255.0, 5151245.0, 5151235.0, 5151225.0, 5151215.0, 5151205.0,\n       5151195.0, 5151185.0, 5151175.0, 5151165.0, 5151155.0, 5151145.0,\n       5151135.0, 5151125.0, 5151115.0, 5151105.0, 5151095.0, 5151085.0,\n       5151075.0, 5151065.0, 5151055.0, 5151045.0, 5151035.0, 5151025.0,\n       5151015.0, 5151005.0, 5150995.0, 5150985.0, 5150975.0, 5150965.0,\n       5150955.0, 5150945.0, 5150935.0, 5150925.0, 5150915.0, 5150905.0],\n      dtype='float64', name='y'))Attributes: (2)Conventions :CF-1.9institution :openEO platform\n\n\nWe got these observations dates:\n\nds.coords[\"t\"].values\n\narray(['2023-05-03T00:00:00.000000000', '2023-05-10T00:00:00.000000000',\n       '2023-05-15T00:00:00.000000000', '2023-05-22T00:00:00.000000000',\n       '2023-05-27T00:00:00.000000000', '2023-06-03T00:00:00.000000000',\n       '2023-06-08T00:00:00.000000000', '2023-06-15T00:00:00.000000000',\n       '2023-06-20T00:00:00.000000000', '2023-06-27T00:00:00.000000000'],\n      dtype='datetime64[ns]')\n\n\nA quick plot for visual inspection.\n\nds[\"VH\"].isel(t=0).plot(vmin=0, vmax=0.5)\n\n&lt;matplotlib.collections.QuadMesh at 0x7ff7a5f59850&gt;\n\n\n\n\n\nThis section presented a straightforward example of retrieving and analyzing a S1_GRD_SIGMA0_ASCENDING data cube from the backend within a defined area of interest during a specified time frame."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#collect-statistics",
    "href": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#collect-statistics",
    "title": "Publishing an openEO workflow as a User-Defined-Process (UDP)",
    "section": "Collect statistics",
    "text": "Collect statistics\nAs part of more detailed processing within the openEO platform, we’ll gather temporal statistics using the apply_dimension process and a collection of statistical measures (minimum, maximum, quantiles, …).\n\ndef get_stats(data: ProcessBuilder) -&gt; ProcessBuilder:\n    \"\"\"\n    Collect stats for `data` (to be interpreted as an array of values along the \"t\" dimension).\n    We should return a new array with the stats.\n    \"\"\"\n    # Put some scalar stats (`min`, `max`, ... return a scalar value) in a new array\n    scalar_stats = array_create(\n        [\n            data.min(),\n            data.max(),\n            data.mean(),\n            data.sd(),\n        ]\n    )\n    # The `quantiles` process returns an array on its own\n    quantile_stats = data.quantiles([0.1, 0.5, 0.9])\n\n    # Combine everything in a single array\n    return array_concat(array1=scalar_stats, array2=quantile_stats)\n\n\ns1_stats = s1_raw.apply_dimension(\n    process=get_stats,\n    dimension=\"t\",\n    target_dimension=\"bands\",\n)\n# Rename band labels, pairing original band names with stat names\ns1_stats = s1_stats.rename_labels(\n    \"bands\",\n    [\n        f\"{b}_{s}\"\n        for b in s1_raw.metadata.band_names\n        for s in [\"min\", \"max\", \"mean\", \"sd\", \"q10\", \"q50\", \"q90\"]\n    ],\n)\n\n\n# %%time\n# s1_stats.download(\"s1grd-stats.nc\")\n\n# let's try batch job based execution in this process\n\njob = s1_stats.execute_batch(\n    title=\"Sentinel1_GRD_Statistics\", outputfile=\"S1grd-stats.nc\"\n)\n\n\n# # Alternatively if you want to seperately save process metadata\n# s1_stats = s1_stats.save_result(format=\"netcdf\")\n# job = s1_stats.execute_batch(title=\"Sentinel 1 Statistics\")\n\n# # fetch your results\n\n# results = job.get_results()\n# results.download_files(\"output/batch_job\")\n\n0:00:00 Job 'vito-j-231106d381904baaae522c536de54d94': send 'start'\n0:00:20 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:00:26 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:00:33 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:00:42 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:00:52 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:01:05 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:01:21 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:01:41 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:02:05 Job 'vito-j-231106d381904baaae522c536de54d94': queued (progress N/A)\n0:02:36 Job 'vito-j-231106d381904baaae522c536de54d94': finished (progress N/A)\n\n\n\nassets = job.get_results().get_assets()\nprint(assets[0].href)\n\nhttps://openeo.vito.be/openeo/1.1/jobs/j-231106d381904baaae522c536de54d94/results/assets/MjUyNTRjNGRiMTkzMGNhNzQwNjg0OTJmM2NhOWIyZjM0N2JhMWU3ZTI0ZTAzY2U0OTMzOTlmZWE1NmVhOTQzN0BlZ2kuZXU%3D/2b1da7b8285e21cfcb5367297761fd95/openEO.nc?expires=1699889359\n\n\n\nds = xarray.load_dataset(\"S1grd-stats.nc\").drop_vars(\"crs\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (x: 102, y: 72)\nCoordinates:\n  * x        (x) float64 6.796e+05 6.796e+05 6.797e+05 ... 6.806e+05 6.806e+05\n  * y        (y) float64 5.152e+06 5.152e+06 5.152e+06 ... 5.151e+06 5.151e+06\nData variables: (12/14)\n    VH_min   (y, x) float32 0.05656 0.07117 0.1168 ... 0.003244 0.003747\n    VH_max   (y, x) float32 0.3573 0.2405 0.2681 ... 0.01825 0.009648 0.01772\n    VH_mean  (y, x) float32 0.1938 0.1531 0.1831 ... 0.01131 0.006023 0.008333\n    VH_sd    (y, x) float32 0.1234 0.05839 0.05198 ... 0.002023 0.004678\n    VH_q10   (y, x) float32 0.05941 0.07411 0.1172 ... 0.003359 0.003751\n    VH_q50   (y, x) float32 0.133 0.1501 0.1768 ... 0.00909 0.005713 0.006541\n    ...       ...\n    VV_max   (y, x) float32 1.072 0.8158 1.447 3.338 ... 0.1091 0.03152 0.07446\n    VV_mean  (y, x) float32 0.5529 0.5677 0.9432 ... 0.05799 0.02198 0.0379\n    VV_sd    (y, x) float32 0.2939 0.1981 0.2196 ... 0.03274 0.007118 0.0214\n    VV_q10   (y, x) float32 0.2752 0.3114 0.7015 ... 0.02147 0.009028 0.01147\n    VV_q50   (y, x) float32 0.4215 0.5806 0.868 1.512 ... 0.06002 0.02159 0.0371\n    VV_q90   (y, x) float32 1.067 0.8109 1.411 3.236 ... 0.1078 0.03147 0.0742\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platform - Geotrellis backend: 0.18.0a1\n    description:  \n    title:        xarray.DatasetDimensions:x: 102y: 72Coordinates: (2)x(x)float646.796e+05 6.796e+05 ... 6.806e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([679635., 679645., 679655., 679665., 679675., 679685., 679695., 679705.,\n       679715., 679725., 679735., 679745., 679755., 679765., 679775., 679785.,\n       679795., 679805., 679815., 679825., 679835., 679845., 679855., 679865.,\n       679875., 679885., 679895., 679905., 679915., 679925., 679935., 679945.,\n       679955., 679965., 679975., 679985., 679995., 680005., 680015., 680025.,\n       680035., 680045., 680055., 680065., 680075., 680085., 680095., 680105.,\n       680115., 680125., 680135., 680145., 680155., 680165., 680175., 680185.,\n       680195., 680205., 680215., 680225., 680235., 680245., 680255., 680265.,\n       680275., 680285., 680295., 680305., 680315., 680325., 680335., 680345.,\n       680355., 680365., 680375., 680385., 680395., 680405., 680415., 680425.,\n       680435., 680445., 680455., 680465., 680475., 680485., 680495., 680505.,\n       680515., 680525., 680535., 680545., 680555., 680565., 680575., 680585.,\n       680595., 680605., 680615., 680625., 680635., 680645.])y(y)float645.152e+06 5.152e+06 ... 5.151e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5151615., 5151605., 5151595., 5151585., 5151575., 5151565., 5151555.,\n       5151545., 5151535., 5151525., 5151515., 5151505., 5151495., 5151485.,\n       5151475., 5151465., 5151455., 5151445., 5151435., 5151425., 5151415.,\n       5151405., 5151395., 5151385., 5151375., 5151365., 5151355., 5151345.,\n       5151335., 5151325., 5151315., 5151305., 5151295., 5151285., 5151275.,\n       5151265., 5151255., 5151245., 5151235., 5151225., 5151215., 5151205.,\n       5151195., 5151185., 5151175., 5151165., 5151155., 5151145., 5151135.,\n       5151125., 5151115., 5151105., 5151095., 5151085., 5151075., 5151065.,\n       5151055., 5151045., 5151035., 5151025., 5151015., 5151005., 5150995.,\n       5150985., 5150975., 5150965., 5150955., 5150945., 5150935., 5150925.,\n       5150915., 5150905.])Data variables: (14)VH_min(y, x)float320.05656 0.07117 ... 0.003747long_name :VH_minunits :grid_mapping :crsarray([[0.05656133, 0.07117188, 0.11683535, ..., 0.00583607, 0.01081081,\n        0.00508684],\n       [0.07500888, 0.06542234, 0.06321717, ..., 0.01094758, 0.01196851,\n        0.01167572],\n       [0.07982897, 0.05711685, 0.05155696, ..., 0.01328301, 0.027206  ,\n        0.02724834],\n       ...,\n       [0.00846185, 0.00683461, 0.00614753, ..., 0.00179048, 0.00129333,\n        0.00225721],\n       [0.00809784, 0.00810335, 0.0053619 , ..., 0.00179926, 0.00333473,\n        0.00225653],\n       [0.00524675, 0.01053381, 0.01038756, ..., 0.00545653, 0.00324418,\n        0.00374676]], dtype=float32)VH_max(y, x)float320.3573 0.2405 ... 0.009648 0.01772long_name :VH_maxunits :grid_mapping :crsarray([[0.35734206, 0.240497  , 0.26810205, ..., 0.03960535, 0.04652854,\n        0.03217617],\n       [0.27547497, 0.22582962, 0.27438593, ..., 0.074268  , 0.0501226 ,\n        0.05067734],\n       [0.21343715, 0.15391256, 0.20813324, ..., 0.06582635, 0.06727563,\n        0.09713611],\n       ...,\n       [0.03269713, 0.03480869, 0.03886167, ..., 0.01295399, 0.01236935,\n        0.02895651],\n       [0.03411233, 0.02388769, 0.05103515, ..., 0.01585265, 0.01147545,\n        0.01942277],\n       [0.02799423, 0.03830879, 0.03787919, ..., 0.01825097, 0.00964783,\n        0.01771976]], dtype=float32)VH_mean(y, x)float320.1938 0.1531 ... 0.006023 0.008333long_name :VH_meanunits :grid_mapping :crsarray([[0.19379085, 0.15306295, 0.18312563, ..., 0.02910196, 0.0209428 ,\n        0.01723359],\n       [0.14099422, 0.14379239, 0.18332611, ..., 0.0316726 , 0.02414871,\n        0.02805693],\n       [0.12428942, 0.1015469 , 0.10913865, ..., 0.02867122, 0.04174799,\n        0.06203262],\n       ...,\n       [0.02315117, 0.02049922, 0.01756792, ..., 0.00845076, 0.00658812,\n        0.01444702],\n       [0.01737622, 0.01484519, 0.01687199, ..., 0.00770858, 0.00725461,\n        0.01071056],\n       [0.01501316, 0.01779779, 0.02084686, ..., 0.01131313, 0.00602277,\n        0.00833274]], dtype=float32)VH_sd(y, x)float320.1234 0.05839 ... 0.004678long_name :VH_sdunits :grid_mapping :crsarray([[0.1234301 , 0.05839253, 0.05198416, ..., 0.01116493, 0.01174154,\n        0.00802417],\n       [0.07352218, 0.0530638 , 0.0823708 , ..., 0.01750424, 0.01386139,\n        0.01197202],\n       [0.05126064, 0.02968998, 0.04590503, ..., 0.01585866, 0.01459462,\n        0.018599  ],\n       ...,\n       [0.00902716, 0.010062  , 0.01015026, ..., 0.00390621, 0.00422678,\n        0.00737783],\n       [0.00868381, 0.00717187, 0.01325622, ..., 0.00384475, 0.00265791,\n        0.00501948],\n       [0.00654324, 0.00838748, 0.0088279 , ..., 0.00490586, 0.0020231 ,\n        0.00467761]], dtype=float32)VH_q10(y, x)float320.05941 0.07411 ... 0.003751long_name :VH_q10units :grid_mapping :crsarray([[0.05940933, 0.07411155, 0.11722008, ..., 0.00716483, 0.01084435,\n        0.0057589 ],\n       [0.07568569, 0.06818876, 0.06493837, ..., 0.01126646, 0.01207127,\n        0.01214764],\n       [0.08016828, 0.05738844, 0.05248768, ..., 0.01339516, 0.02721819,\n        0.02920248],\n       ...,\n       [0.00859083, 0.00720239, 0.006311  , ..., 0.00196476, 0.00136329,\n        0.00259918],\n       [0.00819345, 0.00810346, 0.00541622, ..., 0.0021109 , 0.00338756,\n        0.00268728],\n       [0.00577605, 0.01063458, 0.01046034, ..., 0.00556804, 0.00335882,\n        0.00375124]], dtype=float32)VH_q50(y, x)float320.133 0.1501 ... 0.005713 0.006541long_name :VH_q50units :grid_mapping :crsarray([[0.13300729, 0.15007433, 0.17675401, ..., 0.03204274, 0.01529548,\n        0.01519107],\n       [0.09407672, 0.13539955, 0.17731631, ..., 0.03274555, 0.0182677 ,\n        0.02632112],\n       [0.10193632, 0.10380882, 0.10318546, ..., 0.02546695, 0.03829441,\n        0.06536277],\n       ...,\n       [0.02484563, 0.01899279, 0.01615147, ..., 0.00888117, 0.00703254,\n        0.01407467],\n       [0.01674017, 0.01109307, 0.01389441, ..., 0.00752113, 0.00739714,\n        0.01085477],\n       [0.01335989, 0.01628395, 0.02012532, ..., 0.00908964, 0.00571314,\n        0.00654103]], dtype=float32)VH_q90(y, x)float320.3566 0.2373 ... 0.009549 0.01733long_name :VH_q90units :grid_mapping :crsarray([[0.35658777, 0.23734617, 0.26467803, ..., 0.03950901, 0.0454438 ,\n        0.03181273],\n       [0.26955342, 0.22517808, 0.27435207, ..., 0.0703794 , 0.04949003,\n        0.05011839],\n       [0.21303499, 0.15208827, 0.20175149, ..., 0.06331098, 0.06683476,\n        0.09504365],\n       ...,\n       [0.03268131, 0.0345371 , 0.03776738, ..., 0.01293681, 0.01228781,\n        0.02810093],\n       [0.03357601, 0.02388243, 0.04815632, ..., 0.01540591, 0.01140328,\n        0.01917945],\n       [0.02728007, 0.0370444 , 0.03717419, ..., 0.01816397, 0.00954943,\n        0.01732791]], dtype=float32)VV_min(y, x)float320.2706 0.3071 ... 0.008148 0.01124long_name :VV_minunits :grid_mapping :crsarray([[0.27061334, 0.3071222 , 0.695984  , ..., 0.10145897, 0.06688334,\n        0.02374299],\n       [0.22295584, 0.20867158, 0.395954  , ..., 0.09766635, 0.06968673,\n        0.05215759],\n       [0.2805328 , 0.3170197 , 0.28509635, ..., 0.10177591, 0.05791532,\n        0.0579203 ],\n       ...,\n       [0.05919972, 0.04508727, 0.04939938, ..., 0.01586673, 0.00922628,\n        0.01754627],\n       [0.01951935, 0.04062539, 0.0460576 , ..., 0.01122087, 0.01439755,\n        0.01660094],\n       [0.03997884, 0.03643978, 0.03698706, ..., 0.02123374, 0.00814751,\n        0.01123959]], dtype=float32)VV_max(y, x)float321.072 0.8158 ... 0.03152 0.07446long_name :VV_maxunits :grid_mapping :crsarray([[1.0719821 , 0.8157599 , 1.4465231 , ..., 0.33690315, 0.19723721,\n        0.07042488],\n       [0.8385794 , 0.97571516, 1.3032748 , ..., 0.2828829 , 0.12840499,\n        0.11779951],\n       [0.84790504, 0.66477776, 0.9920144 , ..., 0.2696955 , 0.18787171,\n        0.2799541 ],\n       ...,\n       [0.15173328, 0.21506543, 0.2475289 , ..., 0.07407534, 0.10700826,\n        0.17368278],\n       [0.12819055, 0.31527394, 0.30131364, ..., 0.10989355, 0.06801304,\n        0.09516722],\n       [0.22751552, 0.40916196, 0.44688013, ..., 0.10911988, 0.03151594,\n        0.07445894]], dtype=float32)VV_mean(y, x)float320.5529 0.5677 ... 0.02198 0.0379long_name :VV_meanunits :grid_mapping :crsarray([[0.5528725 , 0.5677464 , 0.943177  , ..., 0.18943602, 0.10289548,\n        0.04630637],\n       [0.5078519 , 0.53124654, 0.6385149 , ..., 0.16875158, 0.10148996,\n        0.07470229],\n       [0.55347466, 0.5266556 , 0.5807746 , ..., 0.16240971, 0.12200638,\n        0.15296336],\n       ...,\n       [0.09600382, 0.10248156, 0.10659529, ..., 0.0411635 , 0.0423783 ,\n        0.06334069],\n       [0.06717557, 0.10029311, 0.11722443, ..., 0.04212674, 0.03074012,\n        0.05524332],\n       [0.09754252, 0.12261887, 0.12331397, ..., 0.05799466, 0.02197856,\n        0.03790025]], dtype=float32)VV_sd(y, x)float320.2939 0.1981 ... 0.007118 0.0214long_name :VV_sdunits :grid_mapping :crsarray([[0.29392862, 0.19808702, 0.21960482, ..., 0.08753916, 0.04366262,\n        0.0147506 ],\n       [0.20480074, 0.21877526, 0.280819  , ..., 0.06148675, 0.01930615,\n        0.02179322],\n       [0.20626569, 0.12942038, 0.19957876, ..., 0.05477447, 0.04675601,\n        0.07778829],\n       ...,\n       [0.02826963, 0.04480741, 0.05676578, ..., 0.02299318, 0.03381887,\n        0.04750483],\n       [0.03085829, 0.07947312, 0.07652301, ..., 0.03100377, 0.01888482,\n        0.02674902],\n       [0.05362873, 0.10700163, 0.1192916 , ..., 0.0327389 , 0.00711785,\n        0.021403  ]], dtype=float32)VV_q10(y, x)float320.2752 0.3114 ... 0.009028 0.01147long_name :VV_q10units :grid_mapping :crsarray([[0.2751771 , 0.31138933, 0.7014966 , ..., 0.10362278, 0.06716368,\n        0.02494995],\n       [0.22528493, 0.22181997, 0.39913344, ..., 0.09886947, 0.07085913,\n        0.05229818],\n       [0.2871844 , 0.32297683, 0.2972333 , ..., 0.10357276, 0.0590695 ,\n        0.06047119],\n       ...,\n       [0.05939193, 0.04718   , 0.05108054, ..., 0.01605947, 0.0092452 ,\n        0.0176414 ],\n       [0.02235149, 0.04143558, 0.04733969, ..., 0.01158348, 0.01445265,\n        0.01682445],\n       [0.0407593 , 0.0385436 , 0.03947324, ..., 0.02146513, 0.00902846,\n        0.01147327]], dtype=float32)VV_q50(y, x)float320.4215 0.5806 ... 0.02159 0.0371long_name :VV_q50units :grid_mapping :crsarray([[0.42152   , 0.5805598 , 0.86803246, ..., 0.14398697, 0.09079412,\n        0.04239713],\n       [0.556627  , 0.50202835, 0.5410211 , ..., 0.15162778, 0.09911549,\n        0.06609362],\n       [0.48160863, 0.5312781 , 0.56976897, ..., 0.14168528, 0.1205292 ,\n        0.12686422],\n       ...,\n       [0.09715581, 0.0989629 , 0.08927221, ..., 0.03616992, 0.03204508,\n        0.04744019],\n       [0.05867583, 0.08330473, 0.10578761, ..., 0.03562438, 0.02128811,\n        0.06257379],\n       [0.08331519, 0.09137604, 0.07936722, ..., 0.06001542, 0.02159299,\n        0.03710367]], dtype=float32)VV_q90(y, x)float321.067 0.8109 ... 0.03147 0.0742long_name :VV_q90units :grid_mapping :crsarray([[1.0667812 , 0.81092757, 1.4112619 , ..., 0.33638445, 0.19395947,\n        0.07008593],\n       [0.82598644, 0.95338386, 1.2640164 , ..., 0.27755916, 0.12781487,\n        0.11575763],\n       [0.8462007 , 0.6643335 , 0.97402567, ..., 0.26723295, 0.18752912,\n        0.2781414 ],\n       ...,\n       [0.14797401, 0.20554605, 0.23791873, ..., 0.07333827, 0.10493214,\n        0.16572711],\n       [0.12596807, 0.2962927 , 0.2870869 , ..., 0.10658363, 0.06703736,\n        0.09342997],\n       [0.21806926, 0.3837865 , 0.41725355, ..., 0.10779288, 0.03146961,\n        0.07420164]], dtype=float32)Indexes: (2)xPandasIndexPandasIndex(Index([679635.0, 679645.0, 679655.0, 679665.0, 679675.0, 679685.0, 679695.0,\n       679705.0, 679715.0, 679725.0,\n       ...\n       680555.0, 680565.0, 680575.0, 680585.0, 680595.0, 680605.0, 680615.0,\n       680625.0, 680635.0, 680645.0],\n      dtype='float64', name='x', length=102))yPandasIndexPandasIndex(Index([5151615.0, 5151605.0, 5151595.0, 5151585.0, 5151575.0, 5151565.0,\n       5151555.0, 5151545.0, 5151535.0, 5151525.0, 5151515.0, 5151505.0,\n       5151495.0, 5151485.0, 5151475.0, 5151465.0, 5151455.0, 5151445.0,\n       5151435.0, 5151425.0, 5151415.0, 5151405.0, 5151395.0, 5151385.0,\n       5151375.0, 5151365.0, 5151355.0, 5151345.0, 5151335.0, 5151325.0,\n       5151315.0, 5151305.0, 5151295.0, 5151285.0, 5151275.0, 5151265.0,\n       5151255.0, 5151245.0, 5151235.0, 5151225.0, 5151215.0, 5151205.0,\n       5151195.0, 5151185.0, 5151175.0, 5151165.0, 5151155.0, 5151145.0,\n       5151135.0, 5151125.0, 5151115.0, 5151105.0, 5151095.0, 5151085.0,\n       5151075.0, 5151065.0, 5151055.0, 5151045.0, 5151035.0, 5151025.0,\n       5151015.0, 5151005.0, 5150995.0, 5150985.0, 5150975.0, 5150965.0,\n       5150955.0, 5150945.0, 5150935.0, 5150925.0, 5150915.0, 5150905.0],\n      dtype='float64', name='y'))Attributes: (4)Conventions :CF-1.9institution :openEO platform - Geotrellis backend: 0.18.0a1description :title :\n\n\n\nds[[\"VH_mean\", \"VV_mean\"]].to_array().plot.imshow(col=\"variable\", vmin=0, vmax=1)\n\n&lt;xarray.plot.facetgrid.FacetGrid at 0x7ff79de13e50&gt;"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#build-s1-sar-stats-udp",
    "href": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#build-s1-sar-stats-udp",
    "title": "Publishing an openEO workflow as a User-Defined-Process (UDP)",
    "section": "Build S1 SAR stats UDP",
    "text": "Build S1 SAR stats UDP\nSuppose we want to save the above-described algorithm as a User-Defined-Process(UDP). Therefore, in this section, we define the input parameters, define the earlier workflow and then save it as a process.\nThe only limitation of this approach, is that your workflow needs to be defined as a single process graph. So workflows that require multiple openEO invocations or complex parameter preprocessing won’t work yet. However, thanks to the flexibility of openEO and the ability to include custom code as a UDF, a lot of algorithms can already be defined in a single openEO graph.\n\nimport openeo\nfrom openeo.api.process import Parameter\nfrom openeo.processes import array_create, array_concat\n\nLet us define the UDP parameters to allow specifying the spatio-temporal extent.\nTo make a service available to users, we might want to replace certain fixed values in your process graph with parameters that can be set by the user of your process. This provides you with a parameterised UDP.\n\ntemporal_extent = Parameter(\n    name=\"temporal_extent\",\n    description=\"The time window to calculate the stats for.\",\n    schema={\"type\": \"array\", \"subtype\": \"temporal-interval\"},\n    default=[\"2023-05-01\", \"2023-07-30\"],\n)\nspatial_extent = Parameter(\n    name=\"spatial_extent\",\n    description=\"The spatial extent to calculate the stats for.\",\n    schema={\"type\": \"object\", \"subtype\": \"bounding-box\"},\n    default={\"west\": 8.82, \"south\": 44.40, \"east\": 8.92, \"north\": 44.45},\n)\n\n\ns1_raw = connection.load_collection(\n    collection_id=\"S1_GRD_SIGMA0_ASCENDING\",\n    temporal_extent=temporal_extent,\n    spatial_extent=spatial_extent,\n    bands=[\"VH\", \"VV\"],\n)\n\n# Unlike above, where we defined the `apply_dimension` process\n# through a regular python function, we do it here compactily with a single \"lambda\".\ns1_stats = s1_raw.apply_dimension(\n    process=lambda data: array_concat(\n        array1=array_create([data.min(), data.max(), data.mean(), data.sd()]),\n        array2=data.quantiles([0.1, 0.5, 0.9]),\n    ),\n    dimension=\"t\",\n    target_dimension=\"bands\",\n)\n# Rename band labels, pairing original band names with stat names\ns1_stats = s1_stats.rename_labels(\n    \"bands\",\n    [\n        f\"{b}_{s}\"\n        for b in s1_stats.metadata.band_names\n        for s in [\"min\", \"max\", \"mean\", \"sd\", \"q10\", \"q50\", \"q90\"]\n    ],\n)\n\nStore this parameterized data cube as a UDP\n\nudp_sar = connection.save_user_defined_process(\n    user_defined_process_id=\"s1_stats\",\n    process_graph=s1_stats,\n    parameters=[temporal_extent, spatial_extent],\n    summary=\"S1 SAR stats\",\n    description=\"Calculate S1 SAR stats (min, max, mean, sd, q10, q50, q90). This service can cost an approximate of 3-5 credits per sq km. This cost is based on resource consumpltion only and added-value cost has not been included.\",\n    public=True,\n)\n\nWhen saving a process, please note that saved processes are private by default, nonetheless can be used multiple times by an individual. Therefore, to share with a large audience, you will need a public URL that can be achieved once the process is saved as public.\n\npublic_url, _ = [\n    l[\"href\"] for l in udp_sar.describe()[\"links\"] if l[\"rel\"] == \"canonical\"\n]"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#use-the-saved-udp-in-the-python-client",
    "href": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#use-the-saved-udp-in-the-python-client",
    "title": "Publishing an openEO workflow as a User-Defined-Process (UDP)",
    "section": "Use the saved UDP in the Python Client",
    "text": "Use the saved UDP in the Python Client\nNow, let’s evaluate our freshly created user-defined processes “s1_stats”. We can use datacube_from_process() to create a DataCube from this process and only have to provide concrete temporal and spatial extents\nNote: Since the spatial_extent and temporal_extent variable were re-assigned as a paramter definition, you might have lost their value, so please don’t forget to re-define your interested extent in the cell below.\n\nsar = connection.datacube_from_process(\n    \"s1_stats\",\n    namespace=public_url,\n    temporal_extent=[\"2023-05-01\", \"2023-07-30\"],\n    spatial_extent={\"west\": 8.82, \"south\": 44.40, \"east\": 8.92, \"north\": 44.45},\n)\n\n\nsar.download(\"sar_udp.nc\")\n\n\nds = xarray.load_dataset(\"sar_udp.nc\").drop_vars(\"crs\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (x: 798, y: 558)\nCoordinates:\n  * x        (x) float64 4.857e+05 4.857e+05 4.857e+05 ... 4.936e+05 4.936e+05\n  * y        (y) float64 4.922e+06 4.922e+06 4.922e+06 ... 4.916e+06 4.916e+06\nData variables: (12/14)\n    VH_min   (y, x) float32 0.007442 0.01634 0.02477 ... 0.0002788 0.0003386\n    VH_max   (y, x) float32 0.03604 0.0584 0.08822 ... 0.003115 0.006632\n    VH_mean  (y, x) float32 0.01978 0.03318 0.05122 ... 0.001801 0.003237\n    VH_sd    (y, x) float32 0.009419 0.01686 0.0247 ... 0.0009503 0.00193\n    VH_q10   (y, x) float32 0.007442 0.01634 0.02477 ... 0.0002788 0.0003386\n    VH_q50   (y, x) float32 0.01642 0.02946 0.04615 ... 0.001851 0.003168\n    ...       ...\n    VV_max   (y, x) float32 0.2145 0.352 0.4421 ... 0.02347 0.02271 0.04126\n    VV_mean  (y, x) float32 0.09626 0.1365 0.1872 ... 0.01012 0.01103 0.01548\n    VV_sd    (y, x) float32 0.05409 0.09378 0.1112 ... 0.006371 0.006519 0.01286\n    VV_q10   (y, x) float32 0.03823 0.0581 0.09845 ... 0.003309 0.002925\n    VV_q50   (y, x) float32 0.08684 0.1051 0.1579 ... 0.008462 0.009489 0.01156\n    VV_q90   (y, x) float32 0.2145 0.352 0.4421 ... 0.02347 0.02271 0.04126\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platformxarray.DatasetDimensions:x: 798y: 558Coordinates: (2)x(x)float644.857e+05 4.857e+05 ... 4.936e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([485665., 485675., 485685., ..., 493615., 493625., 493635.])y(y)float644.922e+06 4.922e+06 ... 4.916e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([4921875., 4921865., 4921855., ..., 4916325., 4916315., 4916305.])Data variables: (14)VH_min(y, x)float320.007442 0.01634 ... 0.0003386long_name :VH_minunits :grid_mapping :crsarray([[7.4415309e-03, 1.6343007e-02, 2.4772413e-02, ..., 5.5835072e-02,\n        4.0328607e-02, 3.1856596e-02],\n       [9.0845078e-03, 1.8613091e-02, 3.0874813e-02, ..., 5.9993275e-02,\n        5.3687811e-02, 4.7377892e-02],\n       [1.0651190e-02, 1.9190351e-02, 3.1387392e-02, ..., 8.2894199e-02,\n        7.3106125e-02, 4.1296154e-02],\n       ...,\n       [3.2187731e-05, 4.6482327e-04, 4.1350679e-04, ..., 3.3551207e-04,\n        1.4962933e-04, 7.3057665e-05],\n       [1.5885655e-05, 3.9615774e-05, 1.2235668e-04, ..., 3.0250914e-04,\n        7.5182226e-04, 1.5585287e-04],\n       [1.5885615e-05, 4.6827008e-05, 2.3712554e-04, ..., 1.6382546e-04,\n        2.7883082e-04, 3.3861815e-04]], dtype=float32)VH_max(y, x)float320.03604 0.0584 ... 0.006632long_name :VH_maxunits :grid_mapping :crsarray([[0.03604072, 0.05839535, 0.08822469, ..., 0.32693267, 0.2599725 ,\n        0.16062291],\n       [0.06696388, 0.10971747, 0.14447221, ..., 0.31547707, 0.19647637,\n        0.10249937],\n       [0.10121775, 0.13220015, 0.14859372, ..., 0.24435118, 0.16842037,\n        0.11494572],\n       ...,\n       [0.00431482, 0.00388348, 0.00630981, ..., 0.00496825, 0.01302709,\n        0.0066534 ],\n       [0.00336156, 0.00744628, 0.00588296, ..., 0.00518299, 0.00960913,\n        0.00696922],\n       [0.00348909, 0.00444956, 0.00253593, ..., 0.00662928, 0.00311544,\n        0.0066321 ]], dtype=float32)VH_mean(y, x)float320.01978 0.03318 ... 0.003237long_name :VH_meanunits :grid_mapping :crsarray([[0.01978468, 0.03317526, 0.05122132, ..., 0.1278438 , 0.11206219,\n        0.07862695],\n       [0.02983127, 0.05295548, 0.07390182, ..., 0.1544519 , 0.11919038,\n        0.08003806],\n       [0.04661358, 0.07003686, 0.08838344, ..., 0.1496976 , 0.11252023,\n        0.07457688],\n       ...,\n       [0.00155804, 0.00161588, 0.00264122, ..., 0.00329824, 0.00361542,\n        0.00206712],\n       [0.00155148, 0.00217963, 0.00238249, ..., 0.00290533, 0.00317651,\n        0.00251921],\n       [0.00116949, 0.00165877, 0.00139102, ..., 0.00218505, 0.00180075,\n        0.00323711]], dtype=float32)VH_sd(y, x)float320.009419 0.01686 ... 0.00193long_name :VH_sdunits :grid_mapping :crsarray([[0.00941931, 0.01685729, 0.02469561, ..., 0.08591115, 0.06487104,\n        0.03994398],\n       [0.01842893, 0.03180607, 0.03907879, ..., 0.07538059, 0.04117164,\n        0.01954442],\n       [0.03133715, 0.03918692, 0.04057009, ..., 0.05113091, 0.03679396,\n        0.02576428],\n       ...,\n       [0.00141927, 0.00125762, 0.0018592 , ..., 0.00169285, 0.00433611,\n        0.00202067],\n       [0.00116786, 0.00235026, 0.0020393 , ..., 0.00185387, 0.00289492,\n        0.0024544 ],\n       [0.00133604, 0.0017832 , 0.00104416, ..., 0.00226273, 0.00095033,\n        0.00192955]], dtype=float32)VH_q10(y, x)float320.007442 0.01634 ... 0.0003386long_name :VH_q10units :grid_mapping :crsarray([[7.4415309e-03, 1.6343007e-02, 2.4772413e-02, ..., 5.5835072e-02,\n        4.0328607e-02, 3.1856596e-02],\n       [9.0845078e-03, 1.8613091e-02, 3.0874813e-02, ..., 5.9993275e-02,\n        5.3687811e-02, 4.7377892e-02],\n       [1.0651190e-02, 1.9190351e-02, 3.1387392e-02, ..., 8.2894199e-02,\n        7.3106125e-02, 4.1296154e-02],\n       ...,\n       [3.2187731e-05, 4.6482327e-04, 4.1350679e-04, ..., 3.3551207e-04,\n        1.4962933e-04, 7.3057665e-05],\n       [1.5885655e-05, 3.9615774e-05, 1.2235668e-04, ..., 3.0250914e-04,\n        7.5182226e-04, 1.5585287e-04],\n       [1.5885615e-05, 4.6827008e-05, 2.3712554e-04, ..., 1.6382546e-04,\n        2.7883082e-04, 3.3861815e-04]], dtype=float32)VH_q50(y, x)float320.01642 0.02946 ... 0.003168long_name :VH_q50units :grid_mapping :crsarray([[0.01641532, 0.02945656, 0.04615069, ..., 0.09937736, 0.09957799,\n        0.06773166],\n       [0.02633959, 0.05312615, 0.07025553, ..., 0.1448748 , 0.11684266,\n        0.08433955],\n       [0.04026382, 0.06566416, 0.09043089, ..., 0.12782589, 0.10272062,\n        0.07347739],\n       ...,\n       [0.0014457 , 0.0012235 , 0.00271203, ..., 0.00357926, 0.00242533,\n        0.00159997],\n       [0.00157032, 0.00178378, 0.00173404, ..., 0.003209  , 0.00216497,\n        0.00176098],\n       [0.00079205, 0.00095888, 0.00126258, ..., 0.00131919, 0.00185058,\n        0.0031679 ]], dtype=float32)VH_q90(y, x)float320.03604 0.0584 ... 0.006632long_name :VH_q90units :grid_mapping :crsarray([[0.03604072, 0.05839535, 0.08822469, ..., 0.32693267, 0.2599725 ,\n        0.16062291],\n       [0.06696388, 0.10971747, 0.14447221, ..., 0.31547707, 0.19647637,\n        0.10249937],\n       [0.10121775, 0.13220015, 0.14859372, ..., 0.24435118, 0.16842037,\n        0.11494572],\n       ...,\n       [0.00431482, 0.00388348, 0.00630981, ..., 0.00496825, 0.01302709,\n        0.0066534 ],\n       [0.00336156, 0.00744628, 0.00588296, ..., 0.00518299, 0.00960913,\n        0.00696922],\n       [0.00348909, 0.00444956, 0.00253593, ..., 0.00662928, 0.00311544,\n        0.0066321 ]], dtype=float32)VV_min(y, x)float320.03823 0.0581 ... 0.002925long_name :VV_minunits :grid_mapping :crsarray([[3.82329002e-02, 5.81044294e-02, 9.84530300e-02, ...,\n        3.23727041e-01, 3.41812849e-01, 2.77307868e-01],\n       [5.36972843e-02, 1.16618790e-01, 1.23972796e-01, ...,\n        3.44944984e-01, 3.67321134e-01, 2.42612064e-01],\n       [8.68130922e-02, 1.28296837e-01, 2.05426112e-01, ...,\n        2.49633417e-01, 1.32964298e-01, 9.90427136e-02],\n       ...,\n       [4.80704126e-04, 8.40302615e-04, 8.09344347e-04, ...,\n        3.48369405e-03, 5.71828044e-04, 3.22331092e-03],\n       [2.80205859e-03, 2.71117990e-03, 1.38480763e-03, ...,\n        4.25597979e-03, 1.65972699e-04, 4.20906581e-03],\n       [2.71791941e-03, 4.16423287e-03, 2.36033788e-03, ...,\n        3.97732435e-03, 3.30928364e-03, 2.92523764e-03]], dtype=float32)VV_max(y, x)float320.2145 0.352 ... 0.02271 0.04126long_name :VV_maxunits :grid_mapping :crsarray([[0.21453455, 0.35201532, 0.44206226, ..., 0.7745028 , 0.7224579 ,\n        0.58535093],\n       [0.19568719, 0.3464168 , 0.5093019 , ..., 0.9756379 , 0.802884  ,\n        0.6578531 ],\n       [0.25700998, 0.40784222, 0.5935021 , ..., 1.0759932 , 0.7719225 ,\n        0.54108393],\n       ...,\n       [0.01855026, 0.0191953 , 0.02520283, ..., 0.04316558, 0.04142256,\n        0.03178509],\n       [0.01793688, 0.01629219, 0.02929817, ..., 0.02198837, 0.02662462,\n        0.03337206],\n       [0.02471384, 0.02900133, 0.03170837, ..., 0.02347184, 0.02271392,\n        0.04125684]], dtype=float32)VV_mean(y, x)float320.09626 0.1365 ... 0.01103 0.01548long_name :VV_meanunits :grid_mapping :crsarray([[0.09625705, 0.13647287, 0.18718082, ..., 0.5496613 , 0.51692694,\n        0.4102068 ],\n       [0.09961063, 0.1633609 , 0.2353696 , ..., 0.6605072 , 0.56492525,\n        0.41471007],\n       [0.14946699, 0.25105995, 0.3585353 , ..., 0.6142653 , 0.45950067,\n        0.3498352 ],\n       ...,\n       [0.00574651, 0.00542928, 0.00741474, ..., 0.01460892, 0.01497063,\n        0.0144419 ],\n       [0.0078292 , 0.00740209, 0.00846404, ..., 0.01040112, 0.01174255,\n        0.01500158],\n       [0.00813532, 0.00973692, 0.00984371, ..., 0.01012099, 0.01102888,\n        0.01548478]], dtype=float32)VV_sd(y, x)float320.05409 0.09378 ... 0.01286long_name :VV_sdunits :grid_mapping :crsarray([[0.05409231, 0.09378087, 0.11117973, ..., 0.17954879, 0.14689186,\n        0.10922512],\n       [0.0447595 , 0.07611188, 0.11615117, ..., 0.22754364, 0.17713465,\n        0.14189446],\n       [0.06593374, 0.08556262, 0.11674429, ..., 0.25365794, 0.22763157,\n        0.141367  ],\n       ...,\n       [0.00583977, 0.00600125, 0.0081784 , ..., 0.01263162, 0.01270936,\n        0.01037051],\n       [0.00507251, 0.00514195, 0.00953319, ..., 0.00733791, 0.0082898 ,\n        0.01043584],\n       [0.0070393 , 0.00821903, 0.0096691 , ..., 0.00637131, 0.00651885,\n        0.01285903]], dtype=float32)VV_q10(y, x)float320.03823 0.0581 ... 0.002925long_name :VV_q10units :grid_mapping :crsarray([[3.82329002e-02, 5.81044294e-02, 9.84530300e-02, ...,\n        3.23727041e-01, 3.41812849e-01, 2.77307868e-01],\n       [5.36972843e-02, 1.16618790e-01, 1.23972796e-01, ...,\n        3.44944984e-01, 3.67321134e-01, 2.42612064e-01],\n       [8.68130922e-02, 1.28296837e-01, 2.05426112e-01, ...,\n        2.49633417e-01, 1.32964298e-01, 9.90427136e-02],\n       ...,\n       [4.80704126e-04, 8.40302615e-04, 8.09344347e-04, ...,\n        3.48369405e-03, 5.71828044e-04, 3.22331092e-03],\n       [2.80205859e-03, 2.71117990e-03, 1.38480763e-03, ...,\n        4.25597979e-03, 1.65972699e-04, 4.20906581e-03],\n       [2.71791941e-03, 4.16423287e-03, 2.36033788e-03, ...,\n        3.97732435e-03, 3.30928364e-03, 2.92523764e-03]], dtype=float32)VV_q50(y, x)float320.08684 0.1051 ... 0.009489 0.01156long_name :VV_q50units :grid_mapping :crsarray([[0.08684144, 0.10507031, 0.15785766, ..., 0.5336267 , 0.4663303 ,\n        0.41561162],\n       [0.08269721, 0.1327595 , 0.201277  , ..., 0.68295944, 0.514695  ,\n        0.4009375 ],\n       [0.12596725, 0.24027355, 0.34175518, ..., 0.5718068 , 0.4059891 ,\n        0.34461385],\n       ...,\n       [0.00349785, 0.00344953, 0.0037301 , ..., 0.01074719, 0.01242693,\n        0.01454905],\n       [0.00563643, 0.00465483, 0.00359291, ..., 0.00712057, 0.01076274,\n        0.01551143],\n       [0.0061425 , 0.00736981, 0.00503082, ..., 0.00846156, 0.00948913,\n        0.01156005]], dtype=float32)VV_q90(y, x)float320.2145 0.352 ... 0.02271 0.04126long_name :VV_q90units :grid_mapping :crsarray([[0.21453455, 0.35201532, 0.44206226, ..., 0.7745028 , 0.7224579 ,\n        0.58535093],\n       [0.19568719, 0.3464168 , 0.5093019 , ..., 0.9756379 , 0.802884  ,\n        0.6578531 ],\n       [0.25700998, 0.40784222, 0.5935021 , ..., 1.0759932 , 0.7719225 ,\n        0.54108393],\n       ...,\n       [0.01855026, 0.0191953 , 0.02520283, ..., 0.04316558, 0.04142256,\n        0.03178509],\n       [0.01793688, 0.01629219, 0.02929817, ..., 0.02198837, 0.02662462,\n        0.03337206],\n       [0.02471384, 0.02900133, 0.03170837, ..., 0.02347184, 0.02271392,\n        0.04125684]], dtype=float32)Indexes: (2)xPandasIndexPandasIndex(Index([485665.0, 485675.0, 485685.0, 485695.0, 485705.0, 485715.0, 485725.0,\n       485735.0, 485745.0, 485755.0,\n       ...\n       493545.0, 493555.0, 493565.0, 493575.0, 493585.0, 493595.0, 493605.0,\n       493615.0, 493625.0, 493635.0],\n      dtype='float64', name='x', length=798))yPandasIndexPandasIndex(Index([4921875.0, 4921865.0, 4921855.0, 4921845.0, 4921835.0, 4921825.0,\n       4921815.0, 4921805.0, 4921795.0, 4921785.0,\n       ...\n       4916395.0, 4916385.0, 4916375.0, 4916365.0, 4916355.0, 4916345.0,\n       4916335.0, 4916325.0, 4916315.0, 4916305.0],\n      dtype='float64', name='y', length=558))Attributes: (2)Conventions :CF-1.9institution :openEO platform\n\n\n\nds[[\"VH_mean\", \"VV_mean\"]].to_array().plot.imshow(col=\"variable\", vmin=0, vmax=1)\n\n&lt;xarray.plot.facetgrid.FacetGrid at 0x7ff79ddb2550&gt;\n\n\n\n\n\nFurthermore, you can directly can open the saved process directly by visiting the link:\nhttps://editor.openeo.cloud/?wizard=UDP&wizard~process=s1_stats&discover=0"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#use-the-saved-udp-in-the-openeo-platform-editor",
    "href": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#use-the-saved-udp-in-the-openeo-platform-editor",
    "title": "Publishing an openEO workflow as a User-Defined-Process (UDP)",
    "section": "Use the saved UDP in the openEO Platform Editor",
    "text": "Use the saved UDP in the openEO Platform Editor\nAlternatively, we can also switch into the openEO Platform Editor to run the newly created UDP in a graphical web interface. Open https://editor.openeo.cloud?discover=0 in your web browser. It opens the editor, connects you to openEO Platform and asks you to login. Once you’ve logged in, you can explore the offerings of openEO Platform and the data associcated with your user account, including batch jobs and UDPs (“Custom Processes” in the Editor).\nThe easiest way to run your UDP is to use the Wizard: 1. In the menu bar at the top you’ll find the “Wizard”. Click it to open. 2. You’ll see a list of wizards, choose the “Run UDP” wizard. 3. It will show all your UDPs, choose the one you just created. 4. You’ll now be asked to fill the parameters that you defined for your UDP. 5. After providing the parameters, you can click “Next” at the right bottom. 6. It will now open a list that allows to select the processing mode of your UDP: 1. Batch Jobs 2. Synchronous Processing 3. Web Services 4. Don’t execute\nSelect “Synchronous Processing” (for small tasks, recommended for this tutorial) or “Batch Jobs” (for larger tasks). 7. Click “Create” and the Editor will send your processing task to the backend. Once completed the result will be shown or downloaded.\n\n\n\nimage.png\n\n\nThere are two other ways to interact with your UDP: 1. On the left side the UDP is listed in the “Processes” list. You can type your UDP name into the search area to find it. You could then drag and drop it in the Visual Model Builder and use it as part of other workflows. 2. In the lower part of the Editor, there’s a tab with the title “Custom Processes”. Here you can view, update and delete your UDPs."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#publishing-your-service-online",
    "href": "APIs/openEO/openeo-community-examples/python/Sentinel1_Stats/Sentinel1_Stats.html#publishing-your-service-online",
    "title": "Publishing an openEO workflow as a User-Defined-Process (UDP)",
    "section": "Publishing your service online",
    "text": "Publishing your service online\nOnce the UDP defined above is saved within the openEO platform, a user also has the option to add this service to the openEO Marketplace. To register a User Defined Process (UDP), you must have a public URL for your service. You’ll also need to provide the saved process ID, which can be located within the public URL.\nA detailed documentation on the process can be followed here: https://documentation.dataspace.copernicus.eu/Applications/PlazaDetails/ManageService.html#register-and-publish-your-service"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ForestFire/ForestFire.html",
    "href": "APIs/openEO/openeo-community-examples/python/ForestFire/ForestFire.html",
    "title": "Wildfire mapping using Sentinel-2",
    "section": "",
    "text": "In this notebook, we want to show a use case of mapping wildfire using Sentinel-2 following the method discussed in the work of Nolde et al. (2020). Here, we want to replicate only a part of the workflow. Thus, it involves calculating cloud-free differences in NDVI for pre and post-fire data and comparing them.\nimport scipy\nimport numpy as np\n\nimport openeo\nfrom openeo.extra.spectral_indices import compute_indices\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport matplotlib.patches as mpatches\nimport rasterio\nfrom rasterio.plot import show\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\nFor this usecase we select an area in Jaen/Spain where fire was noted on 2017/08/03 (source: https://emergency.copernicus.eu/mapping/list-of-components/EMSR219)\nextent = {\"west\": -2.6910, \"south\": 38.2239, \"east\": -2.5921, \"north\": 38.3002}\nAs locations with forest fire often have cloud cover, which hinders the calculation of forest fire-affected areas, we want to get a cloud-free pre-event datacube. Thus, let us define a simple Python function to pre-process pre-event NDVI. Here we use the concept of BAP which means the best available cloud-free pixels right before or right after the forest fire event, this is obtained via cloud masking and temporal reduction with “first” in post event datacube and “last” in pre event datacube.ent date.\nHence: * We first create a cloud mask with an SCL band where we filter out pixels which have a cloud effect; * Subsequently, a Gaussian kernel is created since the cloud masks are frequently noisy and may not completely encompass the cloud region; * Next, we apply a smoothing function to the selected mask coupled with a morphometric dilation to increase and smooth the mask area. Here, for dilation, we select 11 pixels; * Following this, a binary mask is produced by applying a threshold of 0.1. This implies that to be classified as cloud-free pixels, the pixels that have undergone smoothing and dilation should exhibit a value below 0.1. * Once the required mask is generated, it is applied to the data cube; * Finally, once the masked datacube is available, we want to select each cloud-free pixel as near the forest fire date as possible. To achieve this, we reduce the time dimension (reduce_dimension) based on the “last” criterion, which selects the nearest cloud-free pixel to the event date.\n# define a function to identify cloud-free pixels in the available data-cube\n\n\ndef getBAP(scl, data, reducer=\"first\"):\n    mask = (scl == 3) | (scl == 8) | (scl == 9) | (scl == 10)\n\n    # mask is a bit noisy, so we apply smoothening\n    # 2D gaussian kernel\n    g = scipy.signal.windows.gaussian(11, std=1.6)\n    kernel = np.outer(g, g)\n    kernel = kernel / kernel.sum()\n\n    # Morphological dilation of mask: convolution + threshold\n    mask = mask.apply_kernel(kernel)\n    mask = mask &gt; 0.1\n\n    data_masked = data.mask(mask)\n\n    # now select Best Available Pixel based on the mask\n    return data_masked.reduce_dimension(reducer=reducer, dimension=\"t\")"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ForestFire/ForestFire.html#using-normalized-difference-vegetation-index-ndvi",
    "href": "APIs/openEO/openeo-community-examples/python/ForestFire/ForestFire.html#using-normalized-difference-vegetation-index-ndvi",
    "title": "Wildfire mapping using Sentinel-2",
    "section": "Using Normalized Difference Vegetation Index (NDVI)",
    "text": "Using Normalized Difference Vegetation Index (NDVI)\n\nPre-event NDVI\nLet us load Sentinel-2 L2A as our pre-event datacube to calculate NDVI.\n\n# load S2 pre-collection\ns2pre = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2017-05-03\", \"2017-08-03\"],\n    spatial_extent=extent,\n    bands=[\"B04\", \"B08\", \"B12\"],\n    max_cloud_cover=90,\n)\n\ns2pre_scl = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2017-05-03\", \"2017-08-03\"],\n    spatial_extent=extent,\n    bands=[\"SCL\"],\n    max_cloud_cover=90,\n)\n\n# calculate ndvi\nndvi_pre = s2pre.ndvi()\n\n\n# Create a Pre-event cloud free mosiac\nndvi_pre = getBAP(s2pre_scl, ndvi_pre, reducer=\"last\")\n\n\nndvi_pre.download(\"NDVI.tiff\")\n\nDuring the forest fire, we want to know the location of the forest fire as soon as possible. However, it means that the images are often filled with smoke and clouds right after the fire events, which hinders its performance with many cloud-covered pixels where we cannot map the forest fire.\nTherefore, here, we want to show two modes of operation:\n(i) NRT mode and \n(ii) Post-event mode. \nIn NRT mode, we try to map based on the first available image right after the forest fire event. In post-event mode, we perform pre-processing similar to the pre-event data to obtain cloud-free images. The NRT mode is generally used for the first-response and quick actions, whereas the post mode is used for scientific studies.\n\n\nNear Real Time(NRT) Mode NDVI\n\n# load S2 Near-real-time(NRT) collection\ns2nrt = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2017-08-03\", \"2017-08-08\"],\n    spatial_extent=extent,\n    bands=[\"B04\", \"B08\", \"B12\"],\n    max_cloud_cover=90,\n)\n\ns2nrt_scl = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2017-08-03\", \"2017-08-08\"],\n    spatial_extent=extent,\n    bands=[\"SCL\"],\n    max_cloud_cover=90,\n)\n\nndvi_nrt = s2nrt.ndvi()\nndvi_nrt = getBAP(s2nrt_scl, ndvi_nrt, reducer=\"first\")\n\nNow, we have both pre and post event NDVI data we calculate dNDVI (differential NDVI) to find locations where forest fire has occured.\n\n# download NDVI for NRT mode for comparison\nndvi_nrt.download(\"NRT_NDVI.tiff\")\n\n\n# download signal of fire in near real time\nfire_nrt = ndvi_pre - ndvi_nrt\nfire_nrt.download(\"NRT_Fire.tiff\")\n\n\n\nPost-event NDVI\nIn post-event mode, similar to pre-event data, we collect long-term image time series and prepare the data to calculate cloud-free NDVI pixels. Notably, here we use the reducer as “first” mainly because this is a post-event time series, and we would like to obtain a cloud-free pixel with NDVI as soon as possible from the forest fire event, therefore selecting the first available cloud-free pixel ensures that we get the earliest cloud-free pixel.\n\n# load S2 post collection\ns2post = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2017-08-03\", \"2017-11-03\"],\n    spatial_extent=extent,\n    bands=[\"B04\", \"B08\", \"B12\"],\n    max_cloud_cover=90,\n)\n\ns2post_scl = connection.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=[\"2017-08-03\", \"2017-11-03\"],\n    spatial_extent=extent,\n    bands=[\"SCL\"],\n    max_cloud_cover=90,\n)\n\n# calculate post ndvi mosaic\nndvi_post = s2post.ndvi()\nndvi_post = getBAP(s2post_scl, ndvi_post, reducer=\"first\")\n\n\n# download NDVI for post-event mode for comparison\nndvi_post.download(\"Post_NDVI.tiff\")\n\n\nfire_mosiac = ndvi_pre - ndvi_post\nfire_mosiac.download(\"Mosiac_Fire.tiff\")\n\n\n\nPlot the NDVI\n\nndvi = rasterio.open(\"NDVI.tiff\")\nndvi_nrt = rasterio.open(\"NRT_NDVI.tiff\")\nndvi_mosiac = rasterio.open(\"Post_NDVI.tiff\")\n\nf, axarr = plt.subplots(1, 3, dpi=100, figsize=(18, 6))\nim = show(ndvi.read(1), vmin=0, vmax=1, transform=ndvi.transform, ax=axarr[0])\naxarr[0].set_title(\"Pre Event NDVI\")\n\nim = show(ndvi_nrt.read(1), vmin=0, vmax=1, transform=ndvi_nrt.transform, ax=axarr[1])\naxarr[1].set_title(\"Post Event NDVI (NRT)\")\n\nim = show(\n    ndvi_mosiac.read(1), vmin=0, vmax=1, transform=ndvi_mosiac.transform, ax=axarr[2]\n)\naxarr[2].set_title(\"Post Event NDVI (Mosiac)\")\nplt.tight_layout()\n\n\n\n\nAs we can see there is a drop in NDVI at the locations with forest fire (see end of page for ground truth). This shows that with the adopted approach we can identify locations with forest fire.\nMoreover, we can also observe that in the NDVI NRT mode and NDVI Mosiac mode there is not much difference, the reason could be because the cloud cover was not present in the NRT image. This shows that if there is no cloud cover, both modes operate similarly. Now, based on these image we calculated the difference in NDVI which is the likely locations of forest fire; let’s visualize them, too.\n\nfire_nrt = rasterio.open(\"NRT_Fire.tiff\")\nfire_mosiac = rasterio.open(\"Mosiac_Fire.tiff\")\n\ncmap = matplotlib.colors.ListedColormap([\"black\", \"firebrick\"])\nvalues = [\"Absence\", \"Presence\"]\ncolors = [\"black\", \"firebrick\"]\n\nf, axarr = plt.subplots(1, 2, dpi=100, figsize=(12, 6))\n\nim = show(\n    fire_nrt.read(1) &gt; 0.5,\n    vmin=0,\n    vmax=1,\n    transform=fire_nrt.transform,\n    ax=axarr[0],\n    cmap=cmap,\n)\naxarr[0].set_title(\"Forest Fire NRT mode\")\n\nim = show(\n    fire_mosiac.read(1) &gt; 0.5,\n    vmin=0,\n    vmax=1,\n    transform=fire_mosiac.transform,\n    ax=axarr[1],\n    cmap=cmap,\n)\naxarr[1].set_title(\"Forest Fire Post Mode\")\npatches = [\n    mpatches.Patch(color=colors[i], label=\"Fire {l}\".format(l=values[i]))\n    for i in range(len(values))\n]\nf.legend(handles=patches, bbox_to_anchor=(0.95, 0.2), loc=1)\nplt.tight_layout()\n\n\n\n\nHere, we can see that the burnt area is quite nicely mapped in both modes and compared to the ground truth image shown at the end of this notebook, the burned area mapping is quite accurate. Moreover, this can still be improved with the NBR data, as suggested by Nolde et al.(2020). Let’s try the same with NBR."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ForestFire/ForestFire.html#with-normalized-burn-rationbr",
    "href": "APIs/openEO/openeo-community-examples/python/ForestFire/ForestFire.html#with-normalized-burn-rationbr",
    "title": "Wildfire mapping using Sentinel-2",
    "section": "With Normalized Burn Ratio(NBR)",
    "text": "With Normalized Burn Ratio(NBR)\nThis whole process can also be done with NBR as the paper suggests that NBR produces higher accuracy, but due to the unavailability of SWIR band in medium-resolution satellites, they opted to use NDVI.\nQuoted: “Optionally, the system can utilize the Normalized Burn Ratio (NBR) index ([40], see Equations (3) and (4)) instead of the NDVI. This index features superior capabilities for burnt area discrimination compared to the NDVI”\nThus, further in this notebook, we also showcase the same process as above with NBR. In this case, all processing steps are the same except for the calculation of NBR instead of NDVI.\n\nnbr_pre = compute_indices(s2pre, indices=[\"NBR\"])\nnbr_pre = getBAP(s2pre_scl, nbr_pre, reducer=\"last\")\n\n\nnbr_pre.download(\"NBR.tiff\")\n\n\nNRT mode for NBR\n\nnbr_nrt = compute_indices(s2nrt, indices=[\"NBR\"])\nnbr_nrt = getBAP(s2nrt_scl, nbr_nrt, reducer=\"first\")\n\n\nnbr_nrt.download(\"NRT_NBR.tiff\")\n\n\n# download signal of fire in near real-time\nfire_nrt_nbr = nbr_pre - nbr_nrt\nfire_nrt_nbr.download(\"NRT_NBR_Fire.tiff\")\n\n\n\nPost-event mode for NBR\n\nnbr_post = compute_indices(s2post, indices=[\"NBR\"])\nnbr_post = getBAP(s2post_scl, nbr_post, reducer=\"first\")\n\n\nnbr_post.download(\"Post_NBR.tiff\")\n\n\nfire_nrt_mosiac = nbr_pre - nbr_post\nfire_nrt_mosiac.download(\"Mosiac_NBR_Fire.tiff\")\n\n\n\nPlot the NBR\nNow we have the NBR and its difference which can be treated as a proxy of forest fire. Let’s visualize them, first the NBR alone and then the mapped forest fire from it.\n\nnbr = rasterio.open(\"NBR.tiff\")\nnbr_nrt = rasterio.open(\"NRT_NBR.tiff\")\nnbr_mosiac = rasterio.open(\"Post_NBR.tiff\")\n\nf, axarr = plt.subplots(1, 3, dpi=100, figsize=(18, 6))\nim = show(nbr.read(1), vmin=0, vmax=1, transform=nbr.transform, ax=axarr[0])\naxarr[0].set_title(\"Pre Event NBR\")\n\nim = show(nbr_nrt.read(1), vmin=0, vmax=1, transform=nbr_nrt.transform, ax=axarr[1])\naxarr[1].set_title(\"Post Event NBR (NRT)\")\n\nim = show(\n    nbr_mosiac.read(1), vmin=0, vmax=1, transform=nbr_mosiac.transform, ax=axarr[2]\n)\naxarr[2].set_title(\"Post Event NBR (Mosiac)\")\nplt.tight_layout()\n\n\n\n\nAs we can see, the location of the forest fire is quite prominent in the post-event NBR images compared to that of the pre-event NBR images. This shows that the approach with NBR has better visibility of forest fire signals than the NDVI-based approach. Now, let’s see how the final output of the forest fire area looks with the NBR difference image.\n\nfire_nbr_nrt = rasterio.open(\"NRT_NBR_Fire.tiff\")\nfire_nbr_mosiac = rasterio.open(\"Mosiac_NBR_Fire.tiff\")\n\ncmap = matplotlib.colors.ListedColormap([\"black\", \"firebrick\"])\nvalues = [\"Absence\", \"Presence\"]\ncolors = [\"black\", \"firebrick\"]\n\nf, axarr = plt.subplots(1, 2, dpi=100, figsize=(12, 6))\n\nim = show(\n    fire_nbr_nrt.read(1) &gt; 0.5,\n    vmin=0,\n    vmax=1,\n    transform=fire_nbr_nrt.transform,\n    ax=axarr[0],\n    cmap=cmap,\n)\naxarr[0].set_title(\"Forest Fire NRT mode\")\n\nim = show(\n    fire_nbr_mosiac.read(1) &gt; 0.5,\n    vmin=0,\n    vmax=1,\n    transform=fire_nbr_mosiac.transform,\n    ax=axarr[1],\n    cmap=cmap,\n)\naxarr[1].set_title(\"Forest Fire Mosiac Mode\")\npatches = [\n    mpatches.Patch(color=colors[i], label=\"Fire {l}\".format(l=values[i]))\n    for i in range(len(values))\n]\nf.legend(handles=patches, bbox_to_anchor=(0.95, 0.2), loc=1)\nplt.tight_layout()\n\n\n\n\nWe can see here with the use of NBR, the final forest fire area map looks much more complete and less noisy/pixelated compared to the NDVI-based approach. In general, we can see that both NDVI and NBR-based approaches are good for mapping wildfires in near real-time as well as post-event analysis basis. This data can further be used for planning, mitigation and management of forest fire prevention."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/ForestFire/ForestFire.html#ground-truth",
    "href": "APIs/openEO/openeo-community-examples/python/ForestFire/ForestFire.html#ground-truth",
    "title": "Wildfire mapping using Sentinel-2",
    "section": "Ground Truth",
    "text": "Ground Truth\nAs a validation of this workflow, we have a map provided by Copernicus Emergency Management Service (CEMS) is shown below:"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RVI/RVI.html",
    "href": "APIs/openEO/openeo-community-examples/python/RVI/RVI.html",
    "title": "Calculate Radar Vegetation Index(RVI) using Sentinel-1 GRD collection",
    "section": "",
    "text": "In this notebook, we want to study the health condition of vegetation using radar. Thus, we will use the Sentinel-1 GRD collection available within the Copernicus Data Space Ecosystem. The Radar Vegetation Index (RVI) is a measure used in remote sensing and agriculture to assess the health and condition of vegetation using radar data.\nRVI has been used in several research studies, especially for predicting the growth level of crop vegetation over time and many more. However, here, we will stick to a simple example of calculating RVI.\nThe formula adopted in this notebook is as follows:\n\\[\\mathrm{RVI}=\\frac{4 \\sigma^0_{VH}}{\\sigma^0_{VV}+\\sigma^0_{VH}}\\],\nwhere \\(\\sigma^0_{VH}\\), \\(\\sigma^0_{VV}\\) and \\(\\sigma^0_{VH}\\) are the polarised backscattering coefficients,\nReference: * https://www.mdpi.com/2076-3417/9/4/655 * https://forum.step.esa.int/t/creating-radar-vegetation-index/12444/18\nimport openeo\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nimport xarray as xr\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RVI/RVI.html#load-the-collection",
    "href": "APIs/openEO/openeo-community-examples/python/RVI/RVI.html#load-the-collection",
    "title": "Calculate Radar Vegetation Index(RVI) using Sentinel-1 GRD collection",
    "section": "Load the collection",
    "text": "Load the collection\n\ns1 = connection.load_collection(\n    \"SENTINEL1_GRD\",\n    temporal_extent=[\"2017-05-03\", \"2017-08-03\"],\n    spatial_extent={\"west\": 5.15, \"south\": 51.20, \"east\": 5.25, \"north\": 51.35},\n    bands=[\"VV\", \"VH\"],\n)\n\nGiven that the “gamma0-terrain” coefficient is not currently supported in the openEO backend implementation of the Copernicus Data Space Ecosystem at the time of preparing this notebook, we use the “sigma0-ellipsoid” coefficient for SAR backscattering computation.\n\ns1 = s1.sar_backscatter(coefficient=\"sigma0-ellipsoid\")\n\nLet’s apply the formula mentioned above:\n\nrvi = (4 * s1.band(\"VH\")) / (s1.band(\"VV\") + s1.band(\"VH\"))\n\n\nrvi.download(\"RVI.nc\")"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RVI/RVI.html#lets-plot-the-rvi-result",
    "href": "APIs/openEO/openeo-community-examples/python/RVI/RVI.html#lets-plot-the-rvi-result",
    "title": "Calculate Radar Vegetation Index(RVI) using Sentinel-1 GRD collection",
    "section": "Let’s plot the RVI result",
    "text": "Let’s plot the RVI result\nIn the above process, we download RVI data over a specified time period. Now, let us plot the summary of the RVI for a pixel over the temporal period for the selected region. For example, it showcases the mean value calculated over the given temporal period. Furthermore, let us also, visualise the mean NDVI timeseries for this area plotted with time across RVI value.\n\nds = xr.load_dataset(\"RVI.nc\")\ndata = ds[[\"var\"]].to_array(dim=\"bands\")\n\n\nfig = plt.figure(figsize=(10, 5), dpi=90)\ngs = gridspec.GridSpec(1, 2, width_ratios=[2, 3])\n\n# Plot the image\nax0 = plt.subplot(gs[0])\ndata.mean(dim=\"t\")[0].plot.imshow(vmin=0, vmax=1, ax=ax0)\nax0.set_title(\"Mean RVI\")\n\n# Plot the timeseries\nax1 = plt.subplot(gs[1])\nax1.plot(data.t.to_numpy(), data.mean(dim=(\"x\", \"y\"))[0])\nax1.set_title(\"RVI timeseries\")\n\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n\n\n\nSo, looking at the plot, it looks like the vegetation has increased over time."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RVI/RVI.html#using-awesome-spectral-indices",
    "href": "APIs/openEO/openeo-community-examples/python/RVI/RVI.html#using-awesome-spectral-indices",
    "title": "Calculate Radar Vegetation Index(RVI) using Sentinel-1 GRD collection",
    "section": "Using Awesome Spectral Indices",
    "text": "Using Awesome Spectral Indices\nThe openEO Python client has a spectral indices feature to simplify building process graphs with indices like RVI. It builds on the Awesome Spectral Indices project and allows specifying indices through their name instead of having to deal with formulas.\nHowever, please note that this API is experimental and may undergo changes. Furthermore, there might be cases where it is not supported for certain collections when executed directly in the openEO web editor.\nFor example, with the compute_indices help,,r you just have to specify “DpRVIVV” (Dual-Polarized Radar Vegetation Index VV) as follows:\n\nfrom openeo.extra.spectral_indices import compute_indices\n\n\nindices = compute_indices(\n    s1,\n    indices=[\"DpRVIVV\"],\n)\n\n\nindices.download(\"RVI_direct.nc\")\n\n\nds_indices = xr.load_dataset(\"RVI_direct.nc\")\ndata = ds_indices[[\"DpRVIVV\"]].to_array(dim=\"bands\")\n\n\nfig = plt.figure(figsize=(10, 5), dpi=90)\ngs = gridspec.GridSpec(1, 2, width_ratios=[2, 3])\n\n# Plot the image\nax0 = plt.subplot(gs[0])\ndata.mean(dim=\"t\")[0].plot.imshow(vmin=0, vmax=1, ax=ax0)\nax0.set_title(\"Mean RVI\")\n\n# Plot the timeseries\nax1 = plt.subplot(gs[1])\nax1.plot(ds_indices.t.to_numpy(), data.mean(dim=(\"x\", \"y\"))[0])\nax1.set_title(\"RVI timeseries\")\n\nplt.xticks(rotation=45)\nplt.tight_layout()"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/SurfaceSoilMoisture/SoilMoisture.html",
    "href": "APIs/openEO/openeo-community-examples/python/SurfaceSoilMoisture/SoilMoisture.html",
    "title": "Surface Soil Moisture (SSM)",
    "section": "",
    "text": "In this notebook, we follow the concept presented in https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-1/soil_moisture_estimation/ to estimate the soil moisture content using the concept of change detection over three year of time interval as a openEO workflow.\nReferences: * https://eo4society.esa.int/projects/s1-for-surface-soil-moisture/ * https://www.sciencedirect.com/science/article/pii/S2352340921006296?via%3Dihub\nTherefore the surface soil moisture is calculated using the following formula:\n\\[SSM=\\frac{\\sigma_0-dry_{ref }}{wet_{ref }-dry_{ref }}\\]\nwhere, \\(\\sigma_{0}\\) = Current backscatter intensity\n\\(dry_{ref}\\) = historic minimum backscatter in past 3 years\n\\(wet_{ref}\\) = historic maximum backscatter in past 3 years\nimport openeo\nimport openeo.processes \n\nconnection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\nLet us define the area of interest.\n# defining area of interest\nspatial_extent = {\"west\": 139.194, \"south\": -35.516, \"east\": 139.535, \"north\":  -35.284}\nLet us start by creating a reference cube with a time interval of 3 years, followed by a datacube representing the current situation for approximately a month.\n#Reference Cube\ns1_ref = connection.load_collection(\n    \"SENTINEL1_GRD\",\n    temporal_extent=[\"2017-02-02\",\"2020-02-02\"],\n    spatial_extent=spatial_extent,\n    bands=[\"VV\"],\n)\ns1_ref = s1_ref.sar_backscatter(coefficient=\"sigma0-ellipsoid\")\n#Current DateCube\ns1_cur = connection.load_collection(\n    \"SENTINEL1_GRD\",\n    temporal_extent=[\"2020-02-02\", \"2020-02-28\"],\n    spatial_extent=spatial_extent,\n    bands=[\"VV\"],\n)\ns1_cur = s1_cur.sar_backscatter(coefficient=\"sigma0-ellipsoid\")\nAs we need maximum and minimum values for the reference period, we reduce the temporal dimension to derive spatially variable minimum and maximum values. For the current observation datacube, we select the most recent image, representing the latest available image available within the selected time period.\ns1_cur = s1_cur.reduce_dimension(dimension='t',reducer='last')\ndry_ref = s1_ref.reduce_dimension(dimension='t',reducer='min')\nwet_ref = s1_ref.reduce_dimension(dimension='t',reducer='max')\n#calculate Surface Soil Moisture\nSSM = (s1_cur-dry_ref)/(wet_ref-dry_ref)\nFurthermore, to filter wet and urban areas from our soil moisture dataset, we reduce the temporal dimension of our datacube by using a mean reducer to get an average reference datacube. This is followed by normalising the backscatter values by Log with base 10.\naverage_ref = s1_ref.reduce_dimension(dimension='t',reducer='mean')\naverage_ref = average_ref.apply(process=lambda data: 10 * openeo.processes.log(data, base=10))\nWe create a mask to filter out values above -6dB (probably urban area) and below -17dB (probably water bodies), following the thresholds suggested in https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-1/soil_moisture_estimation/ .\nVV = average_ref.band(\"VV\")\nmask = ((VV &gt; -6) | (VV &lt; -17))\n\n#now let us apply the mask\nSSM = SSM.mask(mask)\nThis generates a final SSM datacube after applying urban and permanent water body mask.\n# Let's download the data\nSSM.execute_batch(title=\"Surface Soil Moisture Australia\", outputfile=\"SoilMoisture.nc\")\n\n0:00:00 Job 'j-24022621028b46459728273e37b8d71a': send 'start'\n0:00:12 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:00:18 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:00:24 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:00:33 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:00:43 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:00:55 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:01:11 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:01:30 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:01:54 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:02:24 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:03:03 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:03:50 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:04:48 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:05:49 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:06:49 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:07:49 Job 'j-24022621028b46459728273e37b8d71a': created (progress N/A)\n0:08:50 Job 'j-24022621028b46459728273e37b8d71a': finished (progress N/A)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/SurfaceSoilMoisture/SoilMoisture.html#let-us-plot-the-result",
    "href": "APIs/openEO/openeo-community-examples/python/SurfaceSoilMoisture/SoilMoisture.html#let-us-plot-the-result",
    "title": "Surface Soil Moisture (SSM)",
    "section": "Let us plot the result",
    "text": "Let us plot the result\n\nimport matplotlib.pyplot as plt\nimport xarray as xr\n\n\nds = xr.load_dataset(\"SoilMoisture.nc\")\n\n\ndata = ds[[\"VV\"]].to_array(dim=\"bands\")\n\n\nfig, axes = plt.subplots(ncols=1, figsize=(8, 8), dpi=100, sharey=True)\ndata[0].plot.imshow(ax=axes, vmax=0.6, vmin=0)\naxes.set_title(\"Surface Soil Moisture\")\n\nText(0.5, 1.0, 'Surface Soil Moisture')\n\n\n\n\n\nAs suggested here, to avoid the effect of outliers, the soil moisture ranges from 0 to 0.6 is plotted. Here the white colour represents the masked-out area, including permanent water bodies and urban areas."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/BasicSentinelMerge/sentinel_merge.html",
    "href": "APIs/openEO/openeo-community-examples/python/BasicSentinelMerge/sentinel_merge.html",
    "title": "Creating multi-mission, multi-temporal datacube",
    "section": "",
    "text": "import openeo\n\nThis notebooks shows how to combine timeseries data from two popular missions, Sentinel-1 and Sentinel-2 in a single datacube for further processing. It can be considered a basic template for many use cases.\nThe uses precomputed backscatter if available, and falls back to compute backscatter on the fly, which works globally, but also consumes more credits.\nWe also create 10-daily composites, and apply linear interpolation to avoid gaps. Specific methods may of course require different cloud masking and preprocessing options.\n\nc=openeo.connect(\"openeo.dataspace.copernicus.eu\")\nc.authenticate_oidc()\n\nsentinel2 = c.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent = [\"2022-06-04\", \"2022-08-04\"],\n    bands = [\"B02\", \"B03\", \"B04\",\"SCL\"],\n    max_cloud_cover=95\n)\n\nsentinel2 = sentinel2.process(\n            \"mask_scl_dilation\",\n            data=sentinel2,\n            scl_band_name=\"SCL\",\n            kernel1_size=17, kernel2_size=77,\n            mask1_values=[2, 4, 5, 6, 7],\n            mask2_values=[3, 8, 9, 10, 11],\n            erosion_kernel_size=3)\n\nsentinel2 = sentinel2.aggregate_temporal_period(\"dekad\",reducer=\"median\")\\\n    .apply_dimension(dimension=\"t\", process=\"array_interpolate_linear\")\n\n\nAuthenticated using refresh token.\n\n\nSome openEO backends offer precomputed Sentinel-1 backscatter. We inspect the backend metadata to check if such a collection is available, otherwise we start from raw GRD and compute it on the fly.\n\nS1_collection = \"SENTINEL1_GRD\"\nif \"SENTINEL1_GRD_SIGMA0\" in c.list_collection_ids():\n    S1_collection = \"SENTINEL1_GRD_SIGMA0\"\n\nS1_collection\n\n'SENTINEL1_GRD'\n\n\n\n\nsentinel1 = c.load_collection(\n    S1_collection,\n    temporal_extent = [\"2022-06-04\", \"2022-08-04\"],\n    bands = [\"VV\",\"VH\"]\n)\n\nif S1_collection == \"SENTINEL1_GRD\":\n    sentinel1 = sentinel1.sar_backscatter(\n        coefficient='sigma0-ellipsoid',\n        local_incidence_angle=False,\n        elevation_model='COPERNICUS_30')\n\nsentinel1 = sentinel1.aggregate_temporal_period(\"dekad\",reducer=\"median\")\\\n    .apply_dimension(dimension=\"t\", process=\"array_interpolate_linear\")\n\nNow we can simply combine both cubes. Resampling is performed implicitly if needed, but explicit resampling can also be specified.\n\nmerged = sentinel2.merge_cubes(sentinel1)\n\nThe next block receives the combined Sentinel-1 and Sentinel-2 input, and transforms it using whatever method. This can be for instance a neural network based on PyTorch.\nThis example uses blocks of 128x128 pixels, with an 8 pixel overlap. Sizes for the time and bands dimensions are not specified, which means they will be fully included.\nThe UDF in this example also shows how to print statements to the logging, this is an easy way to get a better sense of the XArray data that is passed in. More information on UDF’s can be found in the documentation.\n\nmy_udf = openeo.UDF(\"\"\"\nfrom openeo.udf import XarrayDataCube\nfrom openeo.udf.debug import inspect\n\ndef apply_datacube(cube: XarrayDataCube, context: dict) -&gt; XarrayDataCube:\n    array = cube.get_array()\n    inspect(array,level=\"ERROR\",message=\"inspecting input cube\")\n    array.values = 0.0001 * array.values\n    return cube\n\"\"\")\n\nfused = merged.apply_neighborhood(my_udf, size=[\n        {'dimension': 'x', 'value': 112, 'unit': 'px'},\n        {'dimension': 'y', 'value': 112, 'unit': 'px'}\n    ], overlap=[\n        {'dimension': 'x', 'value': 8, 'unit': 'px'},\n        {'dimension': 'y', 'value': 8, 'unit': 'px'}\n    ])\n\n\nspatial_extent = {'west': 4.45, 'east': 4.70, 'south': 51.16, 'north': 51.22, 'crs': 'epsg:4326'}\njob=fused.filter_bbox(spatial_extent).execute_batch(\"result.nc\", title=\"Sentinel composite\", filename_prefix=\"merged_cube\")\n\n0:00:00 Job 'j-beec61e8511149d19cc3b6627a19888a': send 'start'\n0:00:11 Job 'j-beec61e8511149d19cc3b6627a19888a': created (progress N/A)\n0:00:16 Job 'j-beec61e8511149d19cc3b6627a19888a': created (progress N/A)\n0:00:23 Job 'j-beec61e8511149d19cc3b6627a19888a': created (progress N/A)\n0:00:31 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:00:42 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:00:55 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:01:10 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:01:30 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:01:54 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:02:24 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:03:01 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:03:48 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:04:46 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:05:47 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:06:47 Job 'j-beec61e8511149d19cc3b6627a19888a': running (progress N/A)\n0:07:47 Job 'j-beec61e8511149d19cc3b6627a19888a': finished (progress N/A)\n\n\nWhen the job is finished, are downloaded as netCDF and can be inspected using XArray or a desktop viewer like QGis.\n\nimport xarray as xr\nxr.open_dataset(\"result.nc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (t: 7, x: 1762, y: 706)\nCoordinates:\n  * t        (t) datetime64[ns] 2022-06-01 2022-06-11 ... 2022-07-21 2022-08-01\n  * x        (x) float64 6.013e+05 6.013e+05 6.013e+05 ... 6.189e+05 6.189e+05\n  * y        (y) float64 5.676e+06 5.676e+06 5.676e+06 ... 5.669e+06 5.669e+06\nData variables:\n    crs      |S1 ...\n    B02      (t, y, x) float64 ...\n    B03      (t, y, x) float64 ...\n    B04      (t, y, x) float64 ...\n    SCL      (t, y, x) float64 ...\n    VV       (t, y, x) float64 ...\n    VH       (t, y, x) float64 ...\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platform - Geotrellis backend: 0.14.1a1\n    description:  \n    title:        xarray.DatasetDimensions:t: 7x: 1762y: 706Coordinates: (3)t(t)datetime64[ns]2022-06-01 ... 2022-08-01standard_name :tlong_name :taxis :Tarray(['2022-06-01T00:00:00.000000000', '2022-06-11T00:00:00.000000000',\n       '2022-06-21T00:00:00.000000000', '2022-07-01T00:00:00.000000000',\n       '2022-07-11T00:00:00.000000000', '2022-07-21T00:00:00.000000000',\n       '2022-08-01T00:00:00.000000000'], dtype='datetime64[ns]')x(x)float646.013e+05 6.013e+05 ... 6.189e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([601265., 601275., 601285., ..., 618855., 618865., 618875.])y(y)float645.676e+06 5.676e+06 ... 5.669e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5675665., 5675655., 5675645., ..., 5668635., 5668625., 5668615.])Data variables: (7)crs()|S1...crs_wkt :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]]spatial_ref :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]][1 values with dtype=|S1]B02(t, y, x)float64...long_name :B02units :grid_mapping :crs[8707804 values with dtype=float64]B03(t, y, x)float64...long_name :B03units :grid_mapping :crs[8707804 values with dtype=float64]B04(t, y, x)float64...long_name :B04units :grid_mapping :crs[8707804 values with dtype=float64]SCL(t, y, x)float64...long_name :SCLunits :grid_mapping :crs[8707804 values with dtype=float64]VV(t, y, x)float64...long_name :VVunits :grid_mapping :crs[8707804 values with dtype=float64]VH(t, y, x)float64...long_name :VHunits :grid_mapping :crs[8707804 values with dtype=float64]Indexes: (3)tPandasIndexPandasIndex(DatetimeIndex(['2022-06-01', '2022-06-11', '2022-06-21', '2022-07-01',\n               '2022-07-11', '2022-07-21', '2022-08-01'],\n              dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Float64Index([601265.0, 601275.0, 601285.0, 601295.0, 601305.0, 601315.0,\n              601325.0, 601335.0, 601345.0, 601355.0,\n              ...\n              618785.0, 618795.0, 618805.0, 618815.0, 618825.0, 618835.0,\n              618845.0, 618855.0, 618865.0, 618875.0],\n             dtype='float64', name='x', length=1762))yPandasIndexPandasIndex(Float64Index([5675665.0, 5675655.0, 5675645.0, 5675635.0, 5675625.0, 5675615.0,\n              5675605.0, 5675595.0, 5675585.0, 5675575.0,\n              ...\n              5668705.0, 5668695.0, 5668685.0, 5668675.0, 5668665.0, 5668655.0,\n              5668645.0, 5668635.0, 5668625.0, 5668615.0],\n             dtype='float64', name='y', length=706))Attributes: (4)Conventions :CF-1.9institution :openEO platform - Geotrellis backend: 0.14.1a1description :title :\n\n\nYou can also inspect the result in the openEO editor:"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html",
    "title": "Best available pixel composite",
    "section": "",
    "text": "In this notebook a monthly composite image is created based on the Best Available Pixel (BAP) method in OpenEO. This is a scientifically sound method of generating composites, which minimizes the mixing of pixels from different observations. Also for each pixel, all bands will be taken from a single observation. As a result, the spectral signature in the composite is observed rather than being a combination of multiple observations.\nWe refer to the scientific references for a full discussion of this method, but can generally recommend it both for its correctness and performance. We do still observe some residual cloud (shadow) in certain cases, which can be attributed to the quality of the SCL band.\nThe BAP score is a weighted average of three (four) scores:\nThe final BAP score is a weighted average of the three aforementioned scores. The weights are 1, 0.5 and 0.8 for the Distance-to-Cloud, Coverage and Date Score respectively.\nThe current implementation and the various parameters are still subject to change, so please do evaluate the correctness when using this method in your project."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#loading-sentinel-2-scene-classification",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#loading-sentinel-2-scene-classification",
    "title": "Best available pixel composite",
    "section": "Loading Sentinel-2 scene classification",
    "text": "Loading Sentinel-2 scene classification\nThe score is calculated based on the ‘SCL’ band only. This is very efficient because it’s a lower resolution (20m) band, which is relatively quick to read. All other bands are read based on the score, which allows openEO to avoid loading data that is not used in the composite.\nFirst a sample period and region are defined. It’s is necessary to specify your region of interest as a Polygon.\n\nimport geopandas as gpd\n\ngdf = gpd.read_file('test_area.geojson')\ngdf = gdf.to_crs(epsg=4326)\narea = eval(gdf.to_json())\n\n\ntemporal_extent = [\"2022-07-01\", \"2022-07-31\"]\nmax_cloud_cover = 70\nspatial_resolution = 20\nblock_size = 256\n\n\nimport openeo\nimport numpy as np\n\nfrom openeo.processes import if_, is_nan\n\n\nc=openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nLoad in the SCL band from Sentinel-2 which will be used to calculate all cloud-related scores.\n\nscl = c.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent=temporal_extent,\n    bands=[\"SCL\"],\n    max_cloud_cover=90\n).resample_spatial(spatial_resolution).filter_spatial(area)\n\nscl = scl.apply(lambda x: if_(is_nan(x), 0, x))\n\nCreate a binary, which gives 1 if a pixel is classified as cloud by SCL, an 0 otherwise.\n\nclassification = scl.band(\"SCL\")\nbinary = (classification == 3) | (classification == 8) | (classification == 9) | (classification == 10)\nbinary = binary.add_dimension(name=\"bands\", label=\"score\", type=\"bands\")"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#coverage-score",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#coverage-score",
    "title": "Best available pixel composite",
    "section": "Coverage score",
    "text": "Coverage score\nFirst of all, the coverage score is calculated, which is equal to 1 - the percentage of pixels in the spatial_extent that are classified as cloud in SCL.\n\nA polygon is created that is slighty larger than the original spatial_extent\nThe cloud coverage percentage is calculated by taking the average of the cloud binary (defined above), by using the aggregate_spatial process\nSince the aggregate_spatial process results in vectordata, the data is rasterized again to the original dimensions, using the (experimental) vector_to_raster process\nThe coverage score is then equal to 1 - the cloud coverage percentage. I.e. a smaller cloud coverage percentage indicates a larger score\n\n\ncloud_coverage = (1 - binary).aggregate_spatial(geometries = area, reducer = 'mean')\ncoverage_score = cloud_coverage.vector_to_raster(scl)  # This rasterizes the vectorcube and results in the same spatial dimensions as the scl cube\ncoverage_score = coverage_score.rename_labels('bands', ['score'])"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#date-score",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#date-score",
    "title": "Best available pixel composite",
    "section": "Date Score",
    "text": "Date Score\nBoth the date and distance-to-cloud score are calculated via a UDF.\n\nfrom openeo.api.process import Parameter\n\nlabel = Parameter('label')\n\ndef day_of_month_calc(input):    \n    day = lambda x:15 + x.process(\"date_difference\",date1=x.process(\"date_replace_component\",date=label,value=15,component=\"day\"),date2=label,unit=\"day\") \n    return input.array_apply(day)  \n\ndef date_score(day):\n    return day.subtract(15).multiply(0.2).multiply(day.subtract(15).multiply(0.2)).multiply(-0.5).exp().multiply(0.07978845)  # Until 'power' and 'divide' are fixed, use this workaround\n\nday_of_month = scl.apply_neighborhood(\n        day_of_month_calc,\n        size=[{'dimension': 'x', 'unit': 'px', 'value': 1}, {'dimension': 'y', 'unit': 'px', 'value': 1},\n              {'dimension': 't', 'value': \"month\"}],\n        overlap=[]\n    )\n\ndate_score = (1.0 * day_of_month).apply(date_score)\ndate_score = date_score.rename_labels('bands', ['score'])\n\n/home/vverelst/anaconda3/envs/ndvi-comp/lib/python3.9/site-packages/openeo/api/process.py:22: UserWarning: Parameter without description: using name as description.\n  warnings.warn(\"Parameter without description: using name as description.\")"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#distance-to-cloud-score",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#distance-to-cloud-score",
    "title": "Best available pixel composite",
    "section": "Distance to Cloud Score",
    "text": "Distance to Cloud Score\nFinally, the Distance to Cloud Score is calculated by applying a Gaussian kernel to the binary. The kernel size, defined below, indicates the maximum distance from a cloud, above which a pixel is automatically assigned score 1. In case of a kernel size of 151, the maximum distance is 150 pixels. The kernel size is 151 for a resolution of 20m and will be rescaled accordingly.\n\nfrom scipy.signal.windows import gaussian\n\nkernel_size = int(150 * 20 / spatial_resolution) + 1\ngaussian_1d = gaussian(M=kernel_size, std=1)\ngaussian_kernel= np.outer(gaussian_1d, gaussian_1d)\ngaussian_kernel /= gaussian_kernel.sum()\n\ndtc_score = 1 - binary.apply_kernel(gaussian_kernel)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#aggregating-scores",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#aggregating-scores",
    "title": "Best available pixel composite",
    "section": "Aggregating Scores",
    "text": "Aggregating Scores\nThen, the scores are aggregated together, by using a weighted average. As for now the coverage score is excluded. To make sure that pixels which contain no data (SCL score 0) are not selected, they are explicitly masked out of the final score. B01 score is excluded.\n\nweights = [1, 0.8, 0.5]\nscore = (weights[0] * dtc_score + weights[1] * date_score + weights[2] * coverage_score) / sum(weights)\nscore = score.mask(classification == 0)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#masking-and-compositing",
    "href": "APIs/openEO/openeo-community-examples/python/RankComposites/bap_composite.html#masking-and-compositing",
    "title": "Best available pixel composite",
    "section": "Masking and Compositing",
    "text": "Masking and Compositing\nNext, a mask is created. This serves to mask every pixel, except the one with the highest score, for each month.\n\ndef max_score_selection(score):\n    max_score = score.max()\n    return score.array_apply(lambda x:x!=max_score)\n\nrank_mask = score.apply_neighborhood(\n        max_score_selection,\n        size=[{'dimension': 'x', 'unit': 'px', 'value': 1}, {'dimension': 'y', 'unit': 'px', 'value': 1},\n              {'dimension': 't', 'value': \"month\"}],\n        overlap=[]\n    )\n\nrank_mask = rank_mask.band('score')\n\nNext, some bands of interest from Sentinel-2 are loaded. They are then masked by the BAP mask constructed above. Then they are aggregated per month, to obtain a composite image per month. By using the “first” process as an aggregator, the situation where there are potentially more than one days in a month selected by the algorithm is immediately handled.\n\nrgb_bands = c.load_collection(\n    \"SENTINEL2_L2A\",\n    temporal_extent = temporal_extent,\n    bands = [\"B02\", \"B03\",\"B04\"],\n    max_cloud_cover=max_cloud_cover\n).filter_spatial(area)\n\ncomposite = rgb_bands.mask(rank_mask).mask(binary).aggregate_temporal_period(\"month\",\"first\")\n\nNext, the final results are downloaded and a composite image for the month of June is shown as an example.\n\ncomposite.execute_batch('./results/composite.nc')\n\n0:00:00 Job 'j-24040317819d4f538774bae276a158fc': send 'start'\n0:00:14 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:00:20 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:00:27 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:00:35 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:00:46 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:00:59 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:01:16 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:01:36 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:02:01 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:02:32 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:03:10 Job 'j-24040317819d4f538774bae276a158fc': running (progress N/A)\n0:03:58 Job 'j-24040317819d4f538774bae276a158fc': finished (progress N/A)\n\n\n\n    \n    \n        \n    \n    \n\n\n\nimport xarray as xr\ncomposite_ds = xr.open_dataset('./results/composite.nc')\ncomposite_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 915kB\nDimensions:  (t: 1, x: 292, y: 260)\nCoordinates:\n  * t        (t) datetime64[ns] 8B 2022-07-01\n  * x        (x) float64 2kB 6.101e+05 6.101e+05 6.101e+05 ... 6.13e+05 6.13e+05\n  * y        (y) float64 2kB 5.645e+06 5.645e+06 ... 5.642e+06 5.642e+06\nData variables:\n    crs      |S1 1B ...\n    B02      (t, y, x) float32 304kB ...\n    B03      (t, y, x) float32 304kB ...\n    B04      (t, y, x) float32 304kB ...\nAttributes:\n    Conventions:  CF-1.9\n    institution:  openEO platform - Geotrellis backend: 0.29.0a1\n    description:  \n    title:        xarray.DatasetDimensions:t: 1x: 292y: 260Coordinates: (3)t(t)datetime64[ns]2022-07-01standard_name :tlong_name :taxis :Tarray(['2022-07-01T00:00:00.000000000'], dtype='datetime64[ns]')x(x)float646.101e+05 6.101e+05 ... 6.13e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([610095., 610105., 610115., ..., 612985., 612995., 613005.])y(y)float645.645e+06 5.645e+06 ... 5.642e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5644805., 5644795., 5644785., ..., 5642235., 5642225., 5642215.])Data variables: (4)crs()|S1...crs_wkt :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]]spatial_ref :PROJCS[\"WGS 84 / UTM zone 31N\", GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\", SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\", AUTHORITY[\"EPSG\",\"9807\"]], PARAMETER[\"central_meridian\", 3.0], PARAMETER[\"latitude_of_origin\", 0.0], PARAMETER[\"scale_factor\", 0.9996], PARAMETER[\"false_easting\", 500000.0], PARAMETER[\"false_northing\", 0.0], UNIT[\"m\", 1.0], AXIS[\"Easting\", EAST], AXIS[\"Northing\", NORTH], AUTHORITY[\"EPSG\",\"32631\"]][1 values with dtype=|S1]B02(t, y, x)float32...long_name :B02units :grid_mapping :crs[75920 values with dtype=float32]B03(t, y, x)float32...long_name :B03units :grid_mapping :crs[75920 values with dtype=float32]B04(t, y, x)float32...long_name :B04units :grid_mapping :crs[75920 values with dtype=float32]Indexes: (3)tPandasIndexPandasIndex(DatetimeIndex(['2022-07-01'], dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Index([610095.0, 610105.0, 610115.0, 610125.0, 610135.0, 610145.0, 610155.0,\n       610165.0, 610175.0, 610185.0,\n       ...\n       612915.0, 612925.0, 612935.0, 612945.0, 612955.0, 612965.0, 612975.0,\n       612985.0, 612995.0, 613005.0],\n      dtype='float64', name='x', length=292))yPandasIndexPandasIndex(Index([5644805.0, 5644795.0, 5644785.0, 5644775.0, 5644765.0, 5644755.0,\n       5644745.0, 5644735.0, 5644725.0, 5644715.0,\n       ...\n       5642305.0, 5642295.0, 5642285.0, 5642275.0, 5642265.0, 5642255.0,\n       5642245.0, 5642235.0, 5642225.0, 5642215.0],\n      dtype='float64', name='y', length=260))Attributes: (4)Conventions :CF-1.9institution :openEO platform - Geotrellis backend: 0.29.0a1description :title :\n\n\n\nimport numpy as np\nrgb_array=composite_ds.to_array(dim=\"bands\").sel(bands=[\"B04\",\"B03\",\"B02\"]).astype(np.float32)/10000\nrgb_array\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (bands: 3, t: 1, y: 260, x: 292)&gt; Size: 911kB\narray([[[[nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         ...,\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan]]],\n\n\n       [[[nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         ...,\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan]]],\n\n\n       [[[nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         ...,\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)\nCoordinates:\n  * t        (t) datetime64[ns] 8B 2022-07-01\n  * x        (x) float64 2kB 6.101e+05 6.101e+05 6.101e+05 ... 6.13e+05 6.13e+05\n  * y        (y) float64 2kB 5.645e+06 5.645e+06 ... 5.642e+06 5.642e+06\n  * bands    (bands) object 24B 'B04' 'B03' 'B02'xarray.DataArraybands: 3t: 1y: 260x: 292nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nanarray([[[[nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         ...,\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan]]],\n\n\n       [[[nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         ...,\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan]]],\n\n\n       [[[nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         ...,\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan],\n         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)Coordinates: (4)t(t)datetime64[ns]2022-07-01standard_name :tlong_name :taxis :Tarray(['2022-07-01T00:00:00.000000000'], dtype='datetime64[ns]')x(x)float646.101e+05 6.101e+05 ... 6.13e+05standard_name :projection_x_coordinatelong_name :x coordinate of projectionunits :marray([610095., 610105., 610115., ..., 612985., 612995., 613005.])y(y)float645.645e+06 5.645e+06 ... 5.642e+06standard_name :projection_y_coordinatelong_name :y coordinate of projectionunits :marray([5644805., 5644795., 5644785., ..., 5642235., 5642225., 5642215.])bands(bands)object'B04' 'B03' 'B02'array(['B04', 'B03', 'B02'], dtype=object)Indexes: (4)tPandasIndexPandasIndex(DatetimeIndex(['2022-07-01'], dtype='datetime64[ns]', name='t', freq=None))xPandasIndexPandasIndex(Index([610095.0, 610105.0, 610115.0, 610125.0, 610135.0, 610145.0, 610155.0,\n       610165.0, 610175.0, 610185.0,\n       ...\n       612915.0, 612925.0, 612935.0, 612945.0, 612955.0, 612965.0, 612975.0,\n       612985.0, 612995.0, 613005.0],\n      dtype='float64', name='x', length=292))yPandasIndexPandasIndex(Index([5644805.0, 5644795.0, 5644785.0, 5644775.0, 5644765.0, 5644755.0,\n       5644745.0, 5644735.0, 5644725.0, 5644715.0,\n       ...\n       5642305.0, 5642295.0, 5642285.0, 5642275.0, 5642265.0, 5642255.0,\n       5642245.0, 5642235.0, 5642225.0, 5642215.0],\n      dtype='float64', name='y', length=260))bandsPandasIndexPandasIndex(Index(['B04', 'B03', 'B02'], dtype='object', name='bands'))Attributes: (0)\n\n\n\nxr.plot.imshow(rgb_array,vmin=0,vmax=0.18,rgb=\"bands\",col='t',col_wrap=2)\n\n&lt;xarray.plot.facetgrid.FacetGrid at 0x7f4c657b48b0&gt;\n\n\n/home/vverelst/anaconda3/envs/ndvi-comp/lib/python3.9/site-packages/matplotlib/cm.py:489: RuntimeWarning: invalid value encountered in cast\n  xx = (xx * 255).astype(np.uint8)"
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Heatwave/HeatwaveNL.html",
    "href": "APIs/openEO/openeo-community-examples/python/Heatwave/HeatwaveNL.html",
    "title": "Heatwave in the Netherlands",
    "section": "",
    "text": "As an impact of global warming, an increase in temperature has been reported, which can lead to potential health risks and environmental stress. Several research studies have been presented over the years, such as in this paper, where they explain the change in Land surface temperature over several regions.\nThus, in this notebook, we want to showcase a tool for mapping heatwaves using Sentinel-3 products. For this, we focused on the Netherlands and used specific conditions proposed by the “National Heatwave Plan” in the Netherlands. The condition implies:\nMoreover, in De Bilt, a municipality in the province of Utrecht had a temperature of 25°C at least five days in a row, with at least three days hotter than 30 °C\nhttps://nltimes.nl/2023/09/08/dutch-heat-record-broken-third-day-row-warm-sunny-weekend-ahead\nimport openeo\nimport json\nfrom pathlib import Path\nimport folium\nconnection = openeo.connect(\n    \"openeo-staging.dataspace.copernicus.eu\"\n).authenticate_oidc()\n\nAuthenticated using refresh token.\nLet us load 5 month data for the area of interest\ndef read_json(filename: str) -&gt; dict:\n    with open(filename) as input:\n        field = json.load(input)\n    return field\n\n\ndate = [\"2023-06-01\", \"2023-10-30\"]\naoi = read_json(\"Netherlands_polygon.geojson\")\nm = folium.Map([52.2, 5], zoom_start=7)\nfolium.GeoJson(aoi).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\nlst = connection.load_collection(\n    \"SENTINEL3_SLSTR_L2_LST\",\n    temporal_extent=date,\n    spatial_extent=aoi,\n    bands=[\"LST\"],\n)\n# apply cloud masking\n\nmask = connection.load_collection(\n    \"SENTINEL3_SLSTR_L2_LST\",\n    temporal_extent=date,\n    spatial_extent=aoi,\n    bands=[\"confidence_in\"],\n)\n\nmask = mask &gt;= 16384\n\nlst.mask(mask)\nNext, we define a User Defined Function (UDF) that takes in the datacube and checks whether both specified conditions are satisfied. Given that the unit of the Land Surface Temperature (LST) layer is Kelvin, the conditions are applied accordingly. If the values meet the designated threshold and continue for more than two days, a new resulting array is generated and returned.\nPlease note that, here we gave 298.15 and 303.15 Kelvin as two thresholds since we chose a relatively small region. You can change match your requirement.\nudf = openeo.UDF(\n    \"\"\"\nimport xarray\nimport numpy as np\nfrom openeo.udf import inspect\n\ndef apply_datacube(cube: xarray.DataArray, context: dict) -&gt; xarray.DataArray:\n    \n    array = cube.values\n    inspect(data=[array.shape], message = \"Array dimensions\")\n    res_arr=np.zeros(array.shape)\n    for i in range(array.shape[0]-4):\n        ar_sub=np.take(array,  range(i, i+5), axis=0)\n        res_arr[i]=(np.all(ar_sub&gt;295,axis=0)) & (np.nansum(ar_sub&gt;300,axis=0)&gt;2)\n    return xarray.DataArray(res_arr, dims=cube.dims, coords=cube.coords)\n\"\"\"\n)\nheatwave_loc = lst.apply_dimension(process=udf, dimension=\"t\")\nNow let us use sum as the reducer to count the total number of times each pixels had a heat wave in the Netherlands during June-September 2023.\nheatwave_loc = heatwave_loc.reduce_dimension(reducer=\"sum\", dimension=\"t\")\nSince the workflow covers an entire country, we assume that the processing might take a longer time and the default amount of CPU and memory resources assigned might not be sufficient. Therefore, we can use the job configuration capabilities provided in openEO to execute the workflow when using batch job-based methods.\nYou can find more information on Job configuration on this page.\njob_options = {\n    \"executor-memory\": \"3G\",\n    \"executor-memoryOverhead\": \"4G\",\n    \"executor-cores\": \"2\",\n}\n# execute using batch job\nheatwave_job = heatwave_loc.execute_batch(\n    title=\"Heatwave Locations in the Netherlands\",\n    outputfile=\"Heatwave_NL.nc\"\n)\nprint(f\" The total openEO credits consumed when executing heatwave workflow is \n        {heatwave_job.describe()['costs']} \n        credits.\"\n     )\n\n The total openEO credits consumed when executing heatwave workflow is 6.0 credits.\nHowever, please note that the cost mentioned above was incurred during the preparation of this notebook and could change over time."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/Heatwave/HeatwaveNL.html#lets-plot-the-results",
    "href": "APIs/openEO/openeo-community-examples/python/Heatwave/HeatwaveNL.html#lets-plot-the-results",
    "title": "Heatwave in the Netherlands",
    "section": "Let’s plot the results",
    "text": "Let’s plot the results\n\nimport matplotlib.pyplot as plt\nimport xarray as xr\n\n\nheatwave = xr.load_dataset(\"Heatwave_NL.nc\")\n\n\ndata = heatwave[[\"LST\"]].to_array(dim=\"bands\")\n\n\nfig, axes = plt.subplots(ncols=1, figsize=(8, 8), dpi=100, sharey=True)\ndata[0].plot.imshow(vmin=0, vmax=5, ax=axes, cmap=\"hot\")\naxes.set_title(\"# of Days with Heatwave in 2023\")\n\nText(0.5, 1.0, '# of Days with Heatwave in 2023')\n\n\n\n\n\nThe above plot shows the number of days with a heatwave in the area of interest in the specified time interval."
  },
  {
    "objectID": "APIs/openEO/openeo-community-examples/python/FloodNDWI/flood_ndwi.html",
    "href": "APIs/openEO/openeo-community-examples/python/FloodNDWI/flood_ndwi.html",
    "title": "Comparitive study of before and after flash flood in Cologne using NDWI service available in EOplaza",
    "section": "",
    "text": "In this notebook, we tried in performing comparative study between pre and post image for Cologne during 2021 flood. A simple technique to subtract pre and post image is done to know the change in water content due to flood in that region. Refernce: https://labo.obs-mip.fr/multitemp/the-ndwi-applied-to-the-recent-flooding-in-the-central-us/\n\n# import necessary packages\nimport openeo\nfrom openeo.api.process import Parameter\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport rasterio\nimport numpy as np\n\n# connect with the backend\neoconn = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\nUser can choose among different backend available here to connect to the backend. Rrgarding the authentication process OpenID connect (oidc) is recommended, but not always straightforward to use. In cases where you are unable to connect with the backend use basic authentication method explained here.\n\n# function to load geojson file\ndef read_json(path: Path) -&gt; dict:\n    with open(path) as input:\n        field = json.load(input)\n        input.close()\n    return field\n\nSince this is an already published service available service, they need not be concerned with selecting the backend. They can directly execute the process by providing time and area of interest.\n\nbefore_date = [\"2021-05-12\",\"2021-05-12\"]\nafter_date = [\"2021-06-18\", \"2021-06-18\"]\naoi = read_json(\"cologne_all.geojson\")\n\n# Create a processing graph from the NDWI process using an active openEO connection\nbefore_ndwi = eoconn.datacube_from_process(\"NDWI\", namespace=\"vito\", date=before_date\n                                        ,polygon=aoi)\n# Create a processing graph from the NDWI process using an active openEO connection\nafter_ndwi = eoconn.datacube_from_process(\"NDWI\", namespace=\"vito\", date=after_date\n                                        ,polygon=aoi)\n\n/home/pratixa/.local/lib/python3.6/site-packages/openeo/metadata.py:252: UserWarning: No cube:dimensions metadata\n  complain(\"No cube:dimensions metadata\")\n\n\nAs you can see a userwarning for missing data pops up which might not be an issue in normal case but here we wish to further evaluate our result in our process thus defining metadata is needed.\nNot all the available service requires updating metadata. If a service lack metadata then performing further computation on output of the service could be an issue. In such case user can update the metadata based on it’s status.\n\n# check available information is available in metadata or not\nbefore_ndwi.metadata\n\n\n    \n    \n        \n    \n    \n\n\n\n# updating our metadata\nfrom openeo.metadata import CollectionMetadata\n\nbefore_ndwi.metadata = CollectionMetadata({\"cube:dimensions\":{\"t\":{\"type\":\"temporal\"}}})\nafter_ndwi.metadata = CollectionMetadata({\"cube:dimensions\":{\"t\":{\"type\":\"temporal\"}}})\n\nOnce the metadata is updated you can perform further operations like subtraction or sum etc as done for this use case.\nSince now we have details on temporal dimension we can perform dimension reduction. As we loaded our collection for specific time intervals, it can include multiple time dimensions. Thus reduce_dimension applies a reducer to a data cube dimension by collapsing all the pixel values along the time dimension into an output value computed by the reducer.\nIt is then followed by subtracting our before datacube from the later.\n\n# compute the change between pre and post image\nmerging_cubes = after_ndwi.merge_cubes(-before_ndwi)\ndifferenced_cube = merging_cubes.reduce_dimension(dimension=\"t\",reducer='sum')\n\nOnce the process is completed, you can also save it as your process using save_user_defined_process that can later be used for a similar task. Otherwise, you can download the result either by direct download (in case of the small spatial extent with few processing) or perform create a batch job in case it is a heavy task over a large extent.\n\n# download your result either using synchronous method or batch\n# synchronous download\ndifferenced_cube.download(\"changed_ndwi.tiff\")\n# \n# # Or perform batch processing if area is comparatively large\n# batch_job = Rrescaled_chunks.create_job(out_format = \"GTiff\", title=\"changed_ndwi\")\n# batch_job.start_and_wait()\n# results = batch_job.get_results()\n# results.download_files()"
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html",
    "href": "APIs/openEO/R_Client/R.html",
    "title": "Getting started with R client",
    "section": "",
    "text": "This Getting Started guide will give you just a simple overview of the capabilities of the openEO R client library."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#installation",
    "href": "APIs/openEO/R_Client/R.html#installation",
    "title": "Getting started with R client",
    "section": "Installation",
    "text": "Installation\nBefore you install the R client module into your R environment, please make sure that you have at least R version 3.6. Older versions might also work, but were not tested.\nStable releases can be installed from CRAN:\ninstall.packages(\"openeo\")\n\n\n\n\n\n\nInstalling the development version\n\n\n\n\n\nIf you want to install the development version, you can install from GitHub. It may contain more features, but may also be unstable.\nYou need to have the package ‘devtools’ installed. If it is not installed use install.packages(\"devtools\").\nNow you can use install_github from the devtools package to install the development version:\n\ndevtools::install_github(repo=\"Open-EO/openeo-r-client\", dependencies=TRUE, ref=\"develop\")\nIf this gives you an error, something went wrong with the installation so please check the requirements again.\n\n\n\nIf you have troubles installing the package, feel free to to create a ticket or leave an issue at the GitHub project.\nNow that the installation was successfully finished, we can load the package and connect to openEO compliant back-ends. In the following chapters we quickly walk through the main features of the R client."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#exploring-a-back-end",
    "href": "APIs/openEO/R_Client/R.html#exploring-a-back-end",
    "title": "Getting started with R client",
    "section": "Exploring a back-end",
    "text": "Exploring a back-end\nFor this tutorial we will use the openEO instance of Copernicus Data Space Ecosystem, which is available at https://openeo.dataspace.copernicus.eu.\nFirst we need to establish a connection to the back-end.\n\nlibrary(openeo)\nconnection = connect(host = \"https://openeo.dataspace.copernicus.eu\")\nThe capabilities of the back-end and the collections are generally publicly available, unless the data collections are proprietary and licensing issues prevent the back-end provider from publishing the collection. For the publicly available information you do not need to have an account on the back-end for reading them.\n\nCollections\nCollections represent the basic data the back-end provides (e.g. Sentinel 1 collection) and are therefore often used as input data for job executions (more info on collections). With the following code snippet you can get all available collection names and their description. The collection list and its entries have their own implementations of the print function. The collection list object is coerced into a data.frame only for printing purposes and the collection for the collection some key information are printed.\nTo get the collection list can be indexed by the collections ID to get the more details about the overview information. With the describe_collection function you can get an even more detailed information about the collection.\n\n# Dictionary of the full metadata of the \"COPERNICUS/S2\" collection (dict)\ns2 = describe_collection(\"SENTINEL2_L2A\") # or use the collection entry from the list, e.g. collections$`COPERNICUS/S2`\nprint(s2)\nIn general all metadata objects are based on lists, so you can use str() to get the structure of the list and address fields by the $ operator.\n\n\n\n\n\n\nTip\n\n\n\n\n\nIf the package is used with RStudio the metadata can also be nicely rendered as a web page in the viewer panel by running collection_viewer(x=\"SENTINEL2_L2A\").\n\n\n\n\n\nProcesses\nProcesses in openEO are tasks that can be applied to (EO) data. The input of a process might be the output of another process, so that several connected processes form a new (user-defined) process itself. Therefore, a process resembles the smallest unit of task descriptions in openEO (more details on processes). The following code snippet shows how to get the available processes.\n# List of available openEO processes with full metadata\nprocesses = list_processes()\n\n# List of available openEO processes by identifiers (string)\nprint(names(processes))\n\n# print metadata of the process with ID \"load_collection\"\nprint(processes$load_collection)\nThe list_processes() method returns a list of process metadata objects that the back-end provides. Each process list entry is a more complex list object (called ‘ProcessInfo’) and contains the process identifier and additional metadata about the process, such as expected arguments and return types.\n\n\n\n\n\n\nTip\n\n\n\n\n\nAs for the collection, processes can also be rendered as a web page in the viewer panel, if RStudio is used. In order to open the viewer use process_viewer() with either a particular process (process_viewer(\"load_collection\")) or you can pass on all processes (process_viewer(processes)). When all processes are chosen, there is also a search bar and a category tree.\n\n\n\nFor other graphical overviews of the openEO processes, there is an online documentation for general process descriptions and the openEO Hub for back-end specific process descriptions."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#authentication",
    "href": "APIs/openEO/R_Client/R.html#authentication",
    "title": "Getting started with R client",
    "section": "Authentication",
    "text": "Authentication\nIn the code snippets above we did not need to log in since we just queried publicly available back-end information. However, to run non-trivial processing queries one has to authenticate so that permissions, resource usage, etc. can be managed properly.\nTo authenticate your account on the backend of the Copernicus Data Space Ecosystem, it is necessary for you to complete the registration process. Once registered, the OIDC (OpenID Connect) authentication method will be employed to verify your identity using an external service.\nThe following code snippet shows how to log in via OIDC authentication if the back-end supports the simplified authentication method:\n\nlogin()\nThe following code snippet shows how to log in via OIDC authentication if the simplified authentication method doesn’t work and you need to provide a client ID and secret:\n\n# get supported OIDC providers which the back-end supports\noidc_providers = list_oidc_providers()\n\nlogin(provider = oidc_providers$some_provider,\n      config = list(\n        client_id= \"...\",\n        secret = \"...\"))\nCalling this method opens your system web browser, with which you can authenticate yourself on the back-end authentication system. After that the website will give you the instructions to go back to the R client, where your connection has logged your account in. This means, that every call that comes after that via the connection variable is executed by your user account."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#creating-a-user-defined-process",
    "href": "APIs/openEO/R_Client/R.html#creating-a-user-defined-process",
    "title": "Getting started with R client",
    "section": "Creating a (user-defined) process",
    "text": "Creating a (user-defined) process\nNow that we know how to discover the back-end and how to authenticate, lets continue by creating a new batch job to process some data.\nFirst we need to create a process builder object that carries all the available predefined openEO processes of the connected back-end as attached R functions with the parameters stated in the process metadata.\n\np = processes()\nThe functions of the builder return process nodes, which represent a particular result in the workflow. As one of the first steps we need to select the source data collection.\ndatacube = p$load_collection(\n  id = \"SENTINEL1_GRD\",\n  spatial_extent=list(west = 16.06, south = 48.06, east = 16.65, north = 48.35),\n  temporal_extent=c(\"2017-03-01\", \"2017-04-01\"),\n  bands=c(\"VV\", \"VH\")\n)\nThis results in a process node that represents a datacube and contains the “SENTINEL1_GRD” data restricted to the given spatial extent, the given temporal extent and the given bands .\n\n\n\n\n\n\nSample Data Retrieval\n\n\n\n\n\nIn order to get a better understanding about the processing mechanisms and the data structures used in openEO Platform, it helps to check the actual data from time to time. The function get_sample aids the user in downloading data for a very small spatial extent. It is automatically loaded into R so that you can directly inspect it with stars. Read the vignette on “Sample Data Retrieval” for more details.\n\n\n\nHaving the input data ready, we want to apply a process on the datacube. Therefore, we can call the process directly on the datacube object, which then returns a datacube with the process applied.\n\nmin_reducer = function(data,context) { \n  return(p$min(data = data))\n}\n\nreduced = p$reduce_dimension(data = datacube, reducer = min_reducer, dimension=\"t\")\nThe datacube is now reduced by the time dimension named t, by taking the minimum value of the timeseries values. Now the datacube has no time dimension left. Other so called “reducer” processes exist, e.g. for computing maximum and mean values.\n\n\n\n\n\n\nNote\n\n\n\nEverything applied to the datacube at this point is neither executed locally on your machine nor executed on the back-end. It just defines the input data and process chain the back-end needs to apply when it sends the datacube to the back-end and executes it there.\n\n\nAfter applying all processes you want to execute, we need to tell the back-end to export the datacube, for example as GeoTiff:\n\nformats = list_file_formats()\n\nresult = p$save_result(data = reduced, format = formats$output$`GTIFF-ZIP`)\nThe first line retrieves the back-ends offered input and output formats. The second line creates the result node, which stores the data as a zipped GeoTiff."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#batch-job-management",
    "href": "APIs/openEO/R_Client/R.html#batch-job-management",
    "title": "Getting started with R client",
    "section": "Batch Job Management",
    "text": "Batch Job Management\nAfter you have finished working on your (user-defined) process, we can now send it to the back-end and start the execution. In openEO, an execution of a (user-defined) process is called a (batch job). Therefore, we need to create a job at the back-end using our datacube, giving it the title Example Title.\n\njob = create_job(graph=result,title = \"Example Title\")\nThe create_job method sends all necessary information to the back-end and creates a new job, which gets returned. After this, the job is just created, but has not started the execution at the back-end yet. It needs to be queued for processing explicitly:\n\nstart_job(job = job)\nAfter the job was executed, status updates can be fetched by using the list_jobs() function. This function returns a list of job descriptions, which can be indexed with the jobs ID to limit the search results. But remember that only list_jobs() refreshes this list. So, to monitor a job you have to iteratively call the job (describe_job()) or the job list list_jobs().\n\njobs = list_jobs()\njobs # printed as a tibble or data.frame, but the object is a list\n\n# or use the job id (in this example 'cZ2ND0Z5nhBFNQFq') as index to get a particular job overview\njobs$cZ2ND0Z5nhBFNQFq\n\n# alternatively request detailed information about the job\ndescribe_job(job = job)\nWhen the job is finished, calling download_results() will download the results of a job. Using list_results() will return an overview about the created files and their download link or it states the error message, in case of an error.\n\n# list the processed results\nlist_results(job = job)\n\n# download all the files into a folder on the file system\ndownload_results(job = job, folder = \"/some/folder/on/filesystem\")\n\n\n\n\n\n\nNote\n\n\n\nThe printing behavior and the actual data structure might differ!\n\n\nNow you know the general workflow of job executions."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#full-example",
    "href": "APIs/openEO/R_Client/R.html#full-example",
    "title": "Getting started with R client",
    "section": "Full Example",
    "text": "Full Example\nIn this chapter we will show a full example of an earth observation use case using the R client. Instead of batch job processing, we compute the image synchronously. Synchronous processing means the result is directly returned in the response, which usually works only for smaller amounts of data.\nHere, we want to produce a monthly RGB composite of Sentinel 1 backscatter data over the area of Vienna, Austria for three months in 2017. This can be used for classification and crop monitoring.\nIn the following code example, we use inline code comments to describe what we are doing.\nlibrary(openeo)\nlibrary(tibble)\n\n\n# connect  to the back-end and login either via explicit call of login, or use your credentials in the connect function\nconnection = login(connect(host = \"https://openeo.dataspace.copernicus.eu\"))\n\n# get the process collection to use the predefined processes of the back-end\np = processes()\n\n# get the collection list to get easier access to the collection ids, via auto completion\ncollections = list_collections()\n\n# get the formats\nformats = list_file_formats()\n\n# load the initial data collection and limit the amount of data loaded\n# note: for the collection id and later the format you can also use the its character value\ndata = p$load_collection(id = collections$`SENTINEL1_GRD`,\n                         spatial_extent = list(west=16.06, \n                                               south=48.06,\n                                               east=16.65,\n                                               north=48.35),\n                         temporal_extent = c(\"2017-03-01\", \"2017-06-01\"),\n                         bands = c(\"VV\"))\n\n# create three monthly sub data sets, which will be merged back into a single data cube later\nmarch = p$filter_temporal(data = data,\n                          extent = c(\"2017-03-01\", \"2017-04-01\"))\n\napril = p$filter_temporal(data = data,\n                          extent = c(\"2017-04-01\", \"2017-05-01\"))\n\nmay = p$filter_temporal(data = data,\n                        extent = c(\"2017-05-01\", \"2017-06-01\"))\n\n# The aggregation function for the following temporal reducer\nagg_fun_mean = function(data, context) {\n  mean(data)\n}\n\nmarch_reduced = p$reduce_dimension(data = march,\n                                   reducer = agg_fun_mean,\n                                   dimension = \"t\")\n\napril_reduced = p$reduce_dimension(data = april,\n                                   reducer = agg_fun_mean,\n                                   dimension = \"t\")\n\nmay_reduced = p$reduce_dimension(data = may,\n                                 reducer = agg_fun_mean,\n                                 dimension = \"t\")\n\n# Each band is currently called VV. We need to rename at least the label of one dimension, \n# because otherwise identity of the data cubes is assumed. The bands dimension consists \n# only of one label, so we can rename this to be able to merge those data cubes.\nmarch_renamed = p$rename_labels(data = march_reduced,\n                                dimension = \"bands\",\n                                target = c(\"R\"),\n                                source = c(\"VV\"))\n\napril_renamed = p$rename_labels(data = april_reduced,\n                                dimension = \"bands\",\n                                target = c(\"G\"),\n                                source = c(\"VV\"))\n\nmay_renamed = p$rename_labels(data = may_reduced,\n                              dimension = \"bands\",\n                              target = c(\"B\"),\n                              source = c(\"VV\"))\n\n# combine the individual data cubes into one\n# this is done one by one, since the dimensionalities have to match between each of the data cubes\nmerge_1 = p$merge_cubes(cube1 = march_renamed,cube2 = april_renamed)\nmerge_2 = p$merge_cubes(cube1 = merge_1, cube2 = may_renamed)\n\n# rescale the the back scatter measurements into 8Bit integer to view the results as PNG\nrescaled = p$apply(data = merge_2,\n        process = function(data,context) {\n          p$linear_scale_range(x=data, inputMin = -20,inputMax = -5, outputMin = 0, outputMax = 255)\n        })\n\n# export shall be format PNG\n# look at the format description\nformats$output$PNG\n\n# store the results using the format and set the create options\nresult = p$save_result(data = rescaled,format = formats$output$PNG, options = list(red=\"R\",green=\"G\",blue=\"B\"))\n\n# create a job\njob = create_job(graph = result, title = \"S1 Example R\", description = \"Getting Started example on openeo.org for R-client\")\n\n# then start the processing of the job and turn on logging (messages that are captured on the back-end during the process execution)\nstart_job(job = job, log = TRUE)\nNow the resulting PNG file of the RGB backscatter composite is stored as a PNG file in the current working directory. It looks like this:"
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#user-defined-functions",
    "href": "APIs/openEO/R_Client/R.html#user-defined-functions",
    "title": "Getting started with R client",
    "section": "User Defined Functions",
    "text": "User Defined Functions\nIf your use case can not be accomplished with the default processes of openEO, you can define a user defined function.\nIn general the processing workflow works by uploading the Python or R script into the users file directory on the back-end and reference the script via its URL or by its relational name (e.g. /scripts/script1.R) in the function run_udf. The latter function is a predefined openEO process that the back-end might provide, if UDFs are supported.\nFind out more about UDFs in the respective Python UDF and R UDF repositories with their documentation and examples."
  },
  {
    "objectID": "APIs/openEO/R_Client/R.html#useful-links",
    "href": "APIs/openEO/R_Client/R.html#useful-links",
    "title": "Getting started with R client",
    "section": "Useful links",
    "text": "Useful links\nAdditional information and resources about the openEO R Client Library:\n\nDocumentation\nVignettes\nCode Repository\nfor function documentation, use R’s ? function or see the online documentation"
  },
  {
    "objectID": "APIs/openEO/job_config.html",
    "href": "APIs/openEO/job_config.html",
    "title": "Job Configuration",
    "section": "",
    "text": "Jobs running on the cloud get assigned a default amount of CPU and memory resources. This may not always be enough for your job, for instance, when using UDFs. Also, for very large jobs, you may want to optimise your resource settings for cost optimisation.\nThe example below shows how to start a job with all options set to their default values. It is important to highlight that default settings are subject to change by the backend whenever needed.\nThis is a short overview of the various options:"
  },
  {
    "objectID": "APIs/openEO/job_config.html#validity-of-signed-urls-in-batch-job-results",
    "href": "APIs/openEO/job_config.html#validity-of-signed-urls-in-batch-job-results",
    "title": "Job Configuration",
    "section": "Validity of signed URLs in batch job results",
    "text": "Validity of signed URLs in batch job results\nBatch job results are accessible to the user via signed URLs stored in the result assets. Within the platform, these URLs have a validity (expiry time) of 7 days. Within these 7 days, the results of a batch job can be accessed by any person with the URL. Each time a user requests the results from the job endpoint (GET /jobs/{job_id}/results), a freshly signed URL (valid for 7 days) is created for the result assets.\n\nLearning more\nThe topic of resource optimisation is a complex one, and here we just give a short summary. The goal of openEO is to hide most of these details from the user, but we realize that advanced users sometimes want to have a bit more insight, so in the spirit of being open, we give some hints.\nTo learn more about these options, we point to the piece of code that handles this.\nMost memory related options are translated to Apache Spark configuration settings, which are documented here."
  },
  {
    "objectID": "APIs/openEO/Collections.html",
    "href": "APIs/openEO/Collections.html",
    "title": "Data collections",
    "section": "",
    "text": "In the Earth Observation domain, different terms are used to describe EO data(sets). In openEO, it is referred to as a “Collection”. Thus, a collection is a sequence of granules sharing the same product specification. It typically corresponds to the series of products derived from data acquired by a sensor on board of a satellite and having the same mode of operation.\nIn openEO, a back-end offers a set of collections to be processed. A user can load (a subset of) a collection using the load_collection process, which returns a raster data cube.\nThe following are the list of data collections available currently in the Copernicus Data Space Ecosystem backend through openEO."
  },
  {
    "objectID": "APIs/openEO/fair.html",
    "href": "APIs/openEO/fair.html",
    "title": "FAIR data & open science",
    "section": "",
    "text": "One of the key goals of openEO, is to support FAIR principles and open science. The implementation in the Copernicus dataspace makes it easier to comply with these principles, by incorporating these principles in the implementation, so that users are automatically a step closer to generating FAIR-compliant open data. If your project has requirements related to these topics, this should serve as a good starting point.\nThese are a few examples:\n\nF2 Rich metadata openEO generates rich STAC metadata, that includes processing info, complete raster metadata, band information, etcetera.\nR1.2 Detailed provenance In result metadata derived-from links link back to all input products to provide provenance.\nR1.3 use of domain relevant (meta)data standard openEO generates STAC metadata, so this one is included by default. For the data formats, it supports well known options such as Cloud optimized Geotiff, netCDF with CF conventions, GeoParquet, and many more.\n\nThis is a concrete example of STAC metadata generated by openEO:"
  },
  {
    "objectID": "APIs/openEO/fair.html#fair",
    "href": "APIs/openEO/fair.html#fair",
    "title": "FAIR data & open science",
    "section": "",
    "text": "One of the key goals of openEO, is to support FAIR principles and open science. The implementation in the Copernicus dataspace makes it easier to comply with these principles, by incorporating these principles in the implementation, so that users are automatically a step closer to generating FAIR-compliant open data. If your project has requirements related to these topics, this should serve as a good starting point.\nThese are a few examples:\n\nF2 Rich metadata openEO generates rich STAC metadata, that includes processing info, complete raster metadata, band information, etcetera.\nR1.2 Detailed provenance In result metadata derived-from links link back to all input products to provide provenance.\nR1.3 use of domain relevant (meta)data standard openEO generates STAC metadata, so this one is included by default. For the data formats, it supports well known options such as Cloud optimized Geotiff, netCDF with CF conventions, GeoParquet, and many more.\n\nThis is a concrete example of STAC metadata generated by openEO:"
  },
  {
    "objectID": "APIs/openEO/fair.html#open-science",
    "href": "APIs/openEO/fair.html#open-science",
    "title": "FAIR data & open science",
    "section": "Open Science",
    "text": "Open Science\nWith respect to open science, the main benefit of openEO is that your workflows can be stored in a standardized notation, in the form of openEO ‘process graphs’. This gives scientists a novel way of exchanging algorithms, without having to exchange a complex code base. The key element is that openEO code or process graphs are often a lot easier to understand, because much of the boilerplate logic is handled by the backend rather than by the user code.\nThis also has consequences for replicating work: the same process graph can be executed on different backends, or evaluated against different datasets. This allows to evaluate whether an algorithm is broadly applicable, or only works in a very specific environment.\nA rendering of a very simple process graph that simply extracts Sentinel-2 data is shown below. While the example is simple, the underlying steps needed to generate an analysis ready datacube from raw Sentinel-2 L2A products are already quite complex, and most equivalent code will be a lot harder to understand and analyze."
  },
  {
    "objectID": "APIs/STAC.html",
    "href": "APIs/STAC.html",
    "title": "STAC product catalogue",
    "section": "",
    "text": "STAC (SpatioTemporal Asset Catalog) is a relatively new web service specification for catalogs that is increasingly used and supported. STAC data have become a de-facto standard in the EO community, also being onboarded to OGC at the moment. STAC items are provided for all online products, as well as for products generated by users within the Copernicus Data Space Ecosystem.\nThe Copernicus Data Space Ecosystem STAC API was implemented as a web service interface to query over a group of STAC collections held in a database. All fields included in Data Space API are consistent with the STAC Specification.\nThe service implements the STAC API version v1.0.0. The version exposed in the Copernicus Data Space Ecosystem is still subject to change as the quality of STAC metadata is still improving. Nevertheless, it already supports basic product search."
  },
  {
    "objectID": "APIs/STAC.html#endpoint-url",
    "href": "APIs/STAC.html#endpoint-url",
    "title": "STAC product catalogue",
    "section": "Endpoint URL",
    "text": "Endpoint URL\nThe Copernicus Data Space Ecosystem STAC API Catalog can be accessed using the following URL:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac"
  },
  {
    "objectID": "APIs/STAC.html#available-collections",
    "href": "APIs/STAC.html#available-collections",
    "title": "STAC product catalogue",
    "section": "Available Collections",
    "text": "Available Collections\nThe data are organized in so-called collections corresponding to various satellites.\nThe following collections are currently available via STAC API:\n\nCopernicus Sentinel Mission\n\nSENTINEL-1\nSENTINEL-2\nSENTINEL-3\nSENTINEL-5P\nSENTINEL-6\nSENTINEL-1-RTC (Sentinel-1 Radiometric Terrain Corrected)\n\nComplementary data\n\nGLOBAL-MOSAICS (Sentinel-1 and Sentinel-2 Global Mosaics)\nSMOS (Soil Moisture and Ocean Salinity)\nENVISAT (ENVISAT- Medium Resolution Imaging Spectrometer - MERIS)\nLANDSAT-5\nLANDSAT-7\nLANDSAT-8\nCOP-DEM (Copernicus DEM)\nTERRAAQUA (Terra MODIS and Aqua MODIS)\nS2GLC (S2GLC 2017)"
  },
  {
    "objectID": "APIs/STAC.html#stac-collections-search",
    "href": "APIs/STAC.html#stac-collections-search",
    "title": "STAC product catalogue",
    "section": "STAC Collections Search",
    "text": "STAC Collections Search\nSTAC Collections endpoint lets users get information about collections available in the Copernicus Data Space Ecosystem catalogue.\nTo access the information about all STAC API Collections:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections\n\n\n\nTo access the information about a specified STAC API Collection (e.g. SENTINEL-2):\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-2"
  },
  {
    "objectID": "APIs/STAC.html#stac-items-search",
    "href": "APIs/STAC.html#stac-items-search",
    "title": "STAC product catalogue",
    "section": "STAC Items Search",
    "text": "STAC Items Search\nSearch for items is possible among all collections Items Search in all STAC Collections or in one specified collection only Items Search in a STAC Collection.\n\n\n\n\n\n\nNote\n\n\n\nTo accelerate the query performance, it is recommended to search for Items within one specified collection, e.g.:\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-3/items\n\n\n\nItems Search in a STAC Collection\n\nSearch for items in a collection\nTo list items in a given collection:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items\n\n\n\nBy default, the catalogue will limit the number of shown items to 20. It can be changed by filtering with the limit option as described below Limit option.\n\n\nSearch for a specific item\nTo list a specific item in a collection:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items/S1A_IW_SLC__1SDV_20221231T100709_20221231T100736_046574_0594DE_0A58.SAFE\n\n\n\n\n\nSearch for items by attributes\nTo list items with a given attribute:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items?datetime=2022-12-31T09:59:31.293Z/\n\n\n\nCurrently, those attributes are supported:\n\nbbox\ndatetime\nids(Items Ids)\n\n\nSearch Items by bbox\nAttribute bbox will list all products from a given collection within the Area of Interest (AOI). This attribute requires between 4 and 6 values (coordinates) where a comma separates each coordinate.\nTo search for items by bbox:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items?bbox=-80.673805,-0.52849,-78.060341,1.689651\n\n\n\n\n\nSearch Items by datetime\nAttribute datetime will list all products within a specified time interval.\nTo search for items within specified datetime:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items?datetime=2021-12-31T09:59:31.293Z/2023-12-31T09:59:31.293Z\n\n\n\nAttribute datetime can search for several different formats:\n\n2022-12-31T00:00:00Z\n2022-12-31T00:00:00\n2022-12-31T16:00:00-08:00\n2022-12-31T00:00:00+01:00\n2022-12-31T00:00:00.000Z\n2022-12-31T00:00:00.000\n\ndatatime intervals:\n\n/2021-12-31T23:59:59Z (open start interval)\n2021-12-31T23:59:59Z/ (open end interval)\n2022-12-30T00:00:00Z/2022-12-31T23:59:59Z (closed interval)\n\nPlease note that those are example values and might not return anything if input.\n\n\nSearch Items by ids\nTo search for products by their Ids:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-2/items?ids=S2A_MSIL2A_20150715T094306_N0204_R036_T33SXA_20150715T094315.SAFE,S2A_MSIL2A_20150715T112846_N0204_R037_T29RLH_20150715T112845.SAFE\n\n\n\n\n\n\nSearch Items by two or more attributes\nTo list items by two or more attributes:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items?bbox=-80.673805,-0.52849,-78.060341,1.689651&datetime=2014-10-13T23:28:54.650Z\n\n\n\n\n\nLimit option\nThe limit option allows users to increase or decrease the number of items shown. \nThe default value is set to 20.\nThe acceptable arguments for this option: Integer &lt;0,1000&gt;\nTo list a limited number of items:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items?datetime=2022-12-31T09:59:31.293Z/&limit=10\n\n\n\n\n\nSortby option\nThe sortby option allows users to define the fields by which to sort results.\nThe acceptable arguments for this option are:\n\nend_datetime\nstart_datetime\ndatetime\n\nTo set the sort order, the prefix should be added to the sort parameter:\n\n+ for ascending (in https standard + sign should be encoded with %2B)\n- for descending\n\nIf no prefix is provided, ascending order is assumed.\nTo sort items within a specified collection:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items?datetime=2021-12-31T09:59:31.293Z/&sortby=-start_datetime\n\n\n\n\n\nPage option\nThe page option determines the page of results.\nThe acceptable arguments for this option: Integer &lt;1,100&gt;\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items?datetime=2022-12-31T09:59:31.293Z/&page=32\n\n\n\n\n\n\nItems Search in all STAC Collections\nIf users would like to list items from any collection, they can use search option, which will search all collections.\nTo list items in any collection:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/search?\n\n\n\nThis endpoint enables searching with simple filtering by:\n\ncollectionId\nids(Items Ids)\ndatetime\nbbox\n\nAlso, the following options are supported:\n\nlimit\nsortby\npage\n\n\nSearch by attributes\nListing by attributes and using the limit option works the same way as before:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/search?ids=S2A_MSIL2A_20150715T094306_N0204_R036_T33SXA_20150715T094315.SAFE,S2A_MSIL2A_20150715T112846_N0204_R037_T29RLH_20150715T112845.SAFE&datetime=2015-07-15T00:00:00.000Z/&limit=10\n\n\n\nCurrently those attributes are available:\n\nbbox\ndatetime\nids(Items Ids)\n\n\n\nSearch items for many collections\nUsing /search option allows the user to list more than one collection.\nTo list more than one collection:\n\nHTTPS Request\n\n\nhttps://catalogue.dataspace.copernicus.eu/stac/search?collections=SENTINEL-1,SENTINEL-2"
  },
  {
    "objectID": "APIs/OpenSearch.html",
    "href": "APIs/OpenSearch.html",
    "title": "OpenSearch Catalog web service",
    "section": "",
    "text": "The OpenSearch catalogue allows you to search through Copernicus data using a standardized web service. The OpenSearch specification can be consulted for technical details of the standard. This web service returns results as GeoJSON feature collections. Each feature in the collection represents an earth observation ‘product’, referencing where the actual data can be found.\nWe remark that this version does not implement the OGC OpenSearch standards, and a migration from other APIs named OpenSearch may require significant modifications. It mainly offers compatibility for existing users of a similar API on the CreoDIAS and Wekeo platforms and with client-side tools and workflows that have implemented support for this API."
  },
  {
    "objectID": "APIs/OpenSearch.html#using-opensearch-interface-to-query-data-catalogue",
    "href": "APIs/OpenSearch.html#using-opensearch-interface-to-query-data-catalogue",
    "title": "OpenSearch Catalog web service",
    "section": "Using OpenSearch interface to query Data Catalogue",
    "text": "Using OpenSearch interface to query Data Catalogue\nSince offset is not a recommended form of searching repository pages, we had to implement a limit to a maximum of 200k. The requests over the limit will be rejected with the code 400. Therefore, we encourage you to limit your inquiries by geographic or temporal area.\nAll queries may be executed as simple HTTPS-Get calls by typing the query in the web browser address line, using any HTTPS client, e.g., curl or wget, or from inside the users’ program. The database is accessible free and anonymously (open for anonymous access for everyone; no authorization is used). It may be accessed both from the internal network (virtual machines in Creodias) and from outside, e.g. your home computer. Note that the actual EO data are restricted to authorized users; only the Data Catalogue is open.\n\nGeneral Rules\nThe queries produce results in JSON format. Base URL:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n3149838d-0bdb-4ca8-980b-02258a1c08ac\n[]\n{'collection': 'SENTINEL-3', 'status': 'ONLINE...\n\n\n1\nFeature\nb584d0b4-d422-48a6-b8db-e9371c985cbe\n[]\n{'collection': 'SENTINEL-3', 'status': 'ONLINE...\n\n\n2\nFeature\nd636272d-9835-4f8e-9cd4-617ffc404024\n[]\n{'collection': 'SENTINEL-3', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMost queries are case-sensitive.\n\n\n\n\nCollections\nThe data are organized in so-called collections corresponding to various satellites. A query may search for data in all collections or one particular collection only. If only one satellite is in the field of interest, the second approach is faster and more efficient than filtering the general query. For example, to find the ten most recent Sentinel-2 products with cloud cover below 10%, the query should look like:\n\nCLI\n\n\n$ wget -O - \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10\"\n\n\n\nwhile if the collection field is missing in the URL, the products from all the satellites are returned:\n\nCLI\n\n\n$ wget -O - \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10\"\n\n\n\nAs for today, the following collections are defined and may be used:\n\nCopernicus Sentinel Mission\n\nSentinel1 or SENTINEL-1\nSentinel2 or SENTINEL-2\nSentinel3 or SENTINEL-3\nSentinel5P or SENTINEL-5P\nSentinel6 or SENTINEL-6\nSentinel1RTC or SENTINEL-1-RTC (Sentinel-1 Radiometric Terrain Corrected)\n\nComplementary data\n\nGLOBAL-MOSAICS (Sentinel-1 and Sentinel-2 Global Mosaics)\nSMOS (Soil Moisture and Ocean Salinity)\nENVISAT or Envisat (ENVISAT- Medium Resolution Imaging Spectrometer - MERIS)\nLandsat5 or LANDSAT-5\nLandsat7 or LANDSAT-7\nLandsat8 or LANDSAT-8\nCOP-DEM (Copernicus DEM)\nTERRAAQUA (Terra MODIS and Aqua MODIS)\nS2GLC (S2GLC 2017)\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that collection names vary slightly from satellite names, as they are used in the EO Data repository. For example, the collection is named Sentinel2, while in the repository, its data are located within /eodata/Sentinel-2/…. branch of the repository tree.\n\n\n\n\nOutput sorting and limiting\nBy default, a maximum of 20 products are returned. You may change the limit (beware of long execution time for queries about thousands of products) using the phrase:\n\nmaxRecords=nnn\n\nIf the query is very general and the number of matching products is large, the following pages of products can be retrieved using:\n\npage=nnn\n\nIt is also possible to alter the sequence in which the products are displayed by using a phrase similar to:\n\nsortParam=startDate\n\nThis will sort the output by observation date. The following orderings can be implemented:\n\nstartDate - the date when the observation was made (start)\ncompletionDate - the date when the observation was made (end)\npublished - the date when the product got published in our repository\nupdated - the date when the product got updated in our repository\n\nEach of these orders can be accompanied by:\n\nsortOrder=ascending or sortOrder=descending\n\nFor example, the query\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n6d96149e-6b5d-4ae4-8135-cb30b7501b39\n[]\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\ne6ed6849-1517-4a1f-b51f-cbbd25f4cd5d\n[]\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n00fd2b8e-694c-5efd-94d7-236adbd9af74\n{'type': 'Polygon', 'coordinates': [[[157.1876...\n{'collection': 'SENTINEL-2', 'status': 'OFFLIN...\n\n\n\n\n\n\n\n\n\n\nThe above request will return 20 products from July 2021, whereas the next query will return the next 20:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20&page=2\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?startDate=2021-07-01T00:00:00Z&completionDate=2021-07-31T23:59:59Z&sortParam=startDate&maxRecords=20&page=2\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n7b2ef7f2-2839-5002-b5a3-257d06f96318\n{'type': 'Polygon', 'coordinates': [[[158.1844...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\n8a1b03c3-27dd-5643-8a13-6a55523df7ba\n{'type': 'Polygon', 'coordinates': [[[156.7053...\n{'collection': 'SENTINEL-2', 'status': 'OFFLIN...\n\n\n2\nFeature\n8b77768a-74d7-4996-9c30-3fe43e79f90d\n{'type': 'Polygon', 'coordinates': [[[157.1876...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\n\n\nFormal queries\nThe formal query is invoked as a sub-phrase sequence, separated by &. The result is a conjunction of all sub-phrases. It is impossible to use an alternative in the question. The query must be specified as a formal query.\nAn example of a formal query - about cloudless (cloud cover lower or equal to 10%) products for a specific location:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2021-06-21T00:00:00Z&completionDate=2021-09-22T23:59:59Z&lon=21.01&lat=52.22\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2021-06-21T00:00:00Z&completionDate=2021-09-22T23:59:59Z&lon=21.01&lat=52.22\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n5fe10705-3b67-59ca-bd14-64d9edd61b63\n{'type': 'Polygon', 'coordinates': [[[21.95587...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\n5733d277-4d5d-40e5-ab6d-44b1d5b52cf3\n{'type': 'Polygon', 'coordinates': [[[21.95587...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n86500fef-db1e-55fc-812f-e1e96010b3d4\n{'type': 'Polygon', 'coordinates': [[[21.96013...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\nThe queries are in the form param=value or param=[minvalue,maxvalue]. Most of the parameters are common for all collections. Still, some are specific for some of them (e.g. cloudCover applies to optical satellites, but polarisation applies to radar ones), or just a single one.\n\n\nGeography and time-frame\nThe common set of parameters are:\n\nstartDate, completionDate - the date limits of the observation. The time may also be specified, e.g. 2021-10-01T21:37:00Z\npublishedAfter, publishedBefore - the date limits when the product was published in our repository\nlon, lat - geographical position, expressed in military style (EPSG:4326, as a decimal fraction of degrees, positive for eastern latitude and northern longitude)\nradius - a region of interest, defined as a circle with centre in point determined by the longitude and latitude with radius expressed in meters (it won’t work with point manually selected in EOFinder/Data Explorer)\ngeometry - region of interest, defined as WKT string (POINT, POLYGON, etc.)\nbox - a region of interest, defined as the rectangle with given (west, south, east, north) values. It should be defined this way: &box=west,south,east,north\n\nFor example, the query can be:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?productType=S2MSI1C&cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=4,51,4.5,52\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?productType=S2MSI1C&cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=4,51,4.5,52\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n3c58022f-4be0-5a8d-b671-4da46dafb7dd\n{'type': 'Polygon', 'coordinates': [[[4.064181...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\ne6c08c26-60a9-59aa-bc7e-222875703aef\n{'type': 'Polygon', 'coordinates': [[[4.064090...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n5fff7c82-7c4f-50d9-ac21-c1f40855ad74\n{'type': 'Polygon', 'coordinates': [[[4.436811...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\nor\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=-21,23,-24,15\n\n\n\n\nCode\njson = requests.get(\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?cloudCover=[0,10]&startDate=2022-06-11T00:00:00Z&completionDate=2022-06-22T23:59:59Z&maxRecords=10&box=-21,23,-24,15\").json()\npd.DataFrame.from_dict(json['features']).head(3)\n\n\n\n\n\n\n\n\n\ntype\nid\ngeometry\nproperties\n\n\n\n\n0\nFeature\n8e81c47e-58a1-53b1-812c-f5920d70ca48\n{'type': 'Polygon', 'coordinates': [[[-48.1934...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n1\nFeature\n16e54669-fc91-5667-9125-b0db7247cf34\n{'type': 'Polygon', 'coordinates': [[[-7.34594...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n2\nFeature\n64eeed3a-4d69-5861-81c8-49102a93f169\n{'type': 'Polygon', 'coordinates': [[[58.59901...\n{'collection': 'SENTINEL-2', 'status': 'ONLINE...\n\n\n\n\n\n\n\n\n\n\n\n\nVolatile features\nSome terrain-like feature masks are not permanent but describe a single scene only. The most commonly used feature is cloudiness, or cloudCover, which is defined for most of the products coming from optical sensors. For example:\n\ncloudCover=[0,10]\n\nThis parameter selects only those scenes, which are covered by clouds by no more than 10%.\n\n\n\n\n\n\nCaution\n\n\n\nTo be meaningful, the cloudiness must be provided with each product, while in many products is missing. If the cloudiness is unknown for the scene, it is marked by a value of 0 or -1. cloudCover=0 is therefore ambiguous: it may either mean a totally cloudless sky or a cloudy scene for which cloud cover had not been estimated during original data processing.\n\n\n\n\nSatellite features\n\ninstrument - meaningful only for satellites equipped with multiple instruments. The possible values are satellite specific.\nproductType - the actual types possible are specific for every satellite.\nsensorMode - also satellite and sensor specific. E.g. (for Sentinel-1): sensorMode=EW\norbitDirection - ASCENDING or DESCENDING. For most heliosynchronous satellites descending orbits means the day scenes, while ascending means night ones. For many optical satellites (e.g. Sentinel-2) only day scenes are published.\nresolution - expected spatial resolution of the product defined in meters.\nstatus:\n\n\n\nONLINE\nOFFLINE\nALL\n\n\nSome additional parameters are strictly satellite-specific, e.g. polarisation, which is defined only for Sentinel-1.\nFor every satellite (collection) its set of query-able parameters may be obtained by a query such as:\n\nHTTPS RequestPython\n\n\nhttps://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/describe.xml\n\n\n\n\nCode\nurl = 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel1/describe.xml'\nresponse = requests.get(url)\n\nroot = ET.fromstring(response.content)\n\nfor child in root:\n    if child.tag.endswith('ShortName') or child.tag.endswith('Description'):\n        print(f\"{child.tag}: {child.text}\")\n\n\n{http://a9.com/-/spec/opensearch/1.1/}ShortName: Sentinel-1\n{http://a9.com/-/spec/opensearch/1.1/}Description: Sentinel-1 Collection\n\n\n\n\n\nThe resulting XML file provides a complete list of the collection parameters, with their brief descriptions."
  }
]