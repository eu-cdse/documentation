---
title: On-Demand Production API
---

On-Demand Production API provides access to two sets of data processing workflows: 

* production of the Sentinel-1/2/3 products from Level-0 data to Level-1 and Level-2. The production workflows use the IPF processors and the versions are aligned with the Production Service. The service allows generation of products using different versions of the processors and parameters than the ones used in the systematic production. This allows reprocessing of the historical data with the recent IPF version which enables creation of coherent timeseries
* processing of additional products using custom processors or workflows based on SNAP graphs. Available workflows include the Sentinel-1 backscatter and interferometric coherence  

Both production and processing workflows are available through the OData API described below, and the [Data Workspace](https://dataspace.copernicus.eu/analyse/data-workspace){target="blank"} which provided a graphical user interface to the service.
Basic interaction with the On-Demand Production service is following: 

* user sends a request including the name of the workflow (the processor to be executed), the identifier of the reference product (product from which the processing should start or product which should be reprocessed) and workflow options (parameters) specific to the selected workflow
* system runs the requested workflows and the result is made available for retrieval 

Access to the On-Demand Production service is subject to [Quotas and Limitations](https://documentation.dataspace.copernicus.eu/Quotas.html){target="blank"}. 

* "Concurrent Processing" - number of products which can be processed simultaneously. If the users submits more orders to the system, the orders will be queued and gradually processed
* "Processed Products per month" - number of orders which can be submitted in the current calendar month (count of ordered products from the first day of the current month)

## On-Demand Production

The production of the Copernicus products is done using the recent IPF (Instrument Processing Facility) processor sets, used by the Production Services.
Users can request production of any Sentinel-1 or Sentinel-3 product using the existing output product as reference. Using the metadata of the reference product, the service identifies the necessary Level-0 and Auxiliary products to run the IPF. The input products are retrieved from the Copernicus LTA (Long Term Archive) and submitted to a processing engine.
The output of the production is stored in the temporary data storage and available to download for a period of 14 days.
Initially the production workflows are available for Sentinel-1 and Sentinel-3. The Sentinel-2 workflows will follow.

### Sentinel-1

All Sentinel-1 workflows start from Level-0 RAW products.  

**Available workflows** 

|Workflow name|Input product type|Output product type|
|--|--|--|
|Sentinel-1-L0-EW_GRDM_1S|EW_RAW__0|EW_GRDM_1S|
|Sentinel-1-L0-EW_OCN__2S|EW_RAW__0|EW_OCN__2S|
|Sentinel-1-L0-EW_SLC__2S|EW_RAW__0|EW_SLC__2S|
|Sentinel-1-L0-IW_GRDH_1S|IW_RAW__0|IW_GRDH_1S|
|Sentinel-1-L0-IW_OCN__2S|IW_RAW__0|IW_OCN__2S|
|Sentinel-1-L0-IW_SLC__1S|IW_RAW__0|IW_SLC__1S|
|Sentinel-1-L0-S1_GRDH_1S|S1_RAW__0|S1_GRDH_1S|
|Sentinel-1-L0-S1_OCN__2S|S1_RAW__0|S1_OCN_2S|
|Sentinel-1-L0-S1_SLC__1S|S1_RAW__0|S1_SLC__1S|
|Sentinel-1-L0-S2_GRDH_1S|S2_RAW__0|S2_GRDH_1S|
|Sentinel-1-L0-S2_OCN__2S|S2_RAW__0|S2_OCN__2S|
|Sentinel-1-L0-S2_SLC__1S|S2_RAW__0|S2_SLC__1S|
|Sentinel-1-L0-S3_GRDH_1S|S3_RAW__0|S3_GRDH_1S|
|Sentinel-1-L0-S3_OCN__2S|S3_RAW__0|S3_OCN__2S|
|Sentinel-1-L0-S3_SLC__1S|S3_RAW__0|S3_SLC__1S|
|Sentinel-1-L0-S4_GRDH_1S|S4_RAW__0|S4_GRDH_1S|
|Sentinel-1-L0-S4_OCN__2S|S4_RAW__0|S4_OCN__2S|
|Sentinel-1-L0-S4_SLC__1S|S4_RAW__0|S4_SLC__1S|
|Sentinel-1-L0-S5_GRDH_1S|S5_RAW__0|S5_GRDH_1S|
|Sentinel-1-L0-S5_OCN__2S|S5_RAW__0|S5_OCN__2S|
|Sentinel-1-L0-S5_SLC__1S|S5_RAW__0|S5_SLC__1S|
|Sentinel-1-L0-S6_GRDH_1S|S6_RAW__0|S6_GRDH_1S|
|Sentinel-1-L0-S6_OCN__2S|S6_RAW__0|S6_OCN__2S|
|Sentinel-1-L0-S6_SLC__1S|S6_RAW__0|S6_SLC__1S|
|Sentinel-1-L0-WV_OCN__2S|WV_RAW__0|WV_OCN__2S|
|Sentinel-1-L0-WV_SLC__1S|WV_RAW__0|WV_SLC__1S|

**Workflow options for Sentinel-1** 

|Option name|Description|Values|
|--|--|--|
|DEM|Identifier of the digital elevation model to use for processing.|"coarse", "getasse30v1", "getasse30v2"|
|output_storage|Location of output product.|“TEMPORARY”|

### Sentinel-3

The Sentinel-3 workflows run from Level-0 products.

**Available workflows** 

|Workflow name|Input product type|Output product type|
|--|--|--|
|Sentinel-3-L0-OL_1_EFR|OL_0_EFR___|OL_1_EFR___|
|Sentinel-3-L0-OL_1_ERR|OL_0_EFR___|OL_1_ERR___|
|Sentinel-3-L0-OL_2_LFR|OL_0_EFR___|OL_2_LFR___|
|Sentinel-3-L0-OL_2_LRR|OL_0_EFR___|OL_2_LRR___|
|Sentinel-3-L0-SL_1_RBT|SL_0_SLT___|SL_1_RBT___|
|Sentinel-3-L0-SL_2_FRP|SL_0_SLT___|SL_2_FRP___|
|Sentinel-3-L0-SL_2_LST|SL_0_SLT___|SL_2_LST___|
|Sentinel-3-L0-SR_1_SRA|SR_0_SRA___|SR_1_SRA___|
|Sentinel-3-L0-SR_2_LAN|SR_0_SRA___, MW_0_MWR___|SR_2_LAN___|
|Sentinel-3-L0-SY_2_AOD|OL_0_EFR___, SL_0_SLT___|SY_2_AOD___|
|Sentinel-3-L0-SY_2_SYN|OL_0_EFR___, SL_0_SLT___|SY_2_SYN___|
|Sentinel-3-L0-SY_2_VG1|OL_1_EFR___, SL_1_RBT___|SY_2_VG1___|
|Sentinel-3-L0-SR_2_LAN_LI|SR_0_SRA___, MW_0_MWR___|SR_2_LAN_LI|
|Sentinel-3-L0-SR_2_LAN_HY|SR_0_SRA___, MW_0_MWR___|SR_2_LAN_HY|
|Sentinel-3-L0-SR_2_LAN_SI|SR_0_SRA___, MW_0_MWR___|SR_2_LAN_SI|

**Workflow options for Sentinel-3** 

|Option name|Description|Values|
|--|--|--|
|Baseline|Version number of the processor and static auxiliary files.|dependent on the specific workflow|
|Mode|Timeliness condition : NTC (Non-Time Critical), STC (Short-Time Critical).|“NTC”, “STC”|
|output_storage|Location of output product.|“TEMPORARY”|


## On-Demand Processing 

On-demand processing capability for CARD-BS and CARD-COH6/12 is available in the Copernicus Data Space Ecosystem. This service is offered via a limited pool of resources, shared across all users, and can be used to process the data free of charge. This is suitable for users who need to process smaller batches of products. There is no guarantee that processing will be completed in a specific time. For commercial use, the [price list](https://creodias.eu/pricing/eo-data-hub-services/){target="blank"} is available in the CREODIAS portal. The service is available via an On-Demand Processing API and Data Workspace.

## OnDemand Production API with OData interface

The OnDemand Processing API allows the users to interact with the service to issue and control the orders. It provides functionalities like creation, update, cancellation, pausing and monitoring of orders. This allows the users to have better control over the workflow execution process.
The API is based on the Production Interface Delivery Point ICD, extended to provide more flexibility and additional functionality.

## General information

This documentation provides an overview of the OnDemand Processing (ODP) API based on the Open Data Protocol (OData) standard. The ODP API complements the Catalogue API used for accessing data and metadata from the Copernicus data catalogue.
Access to the API is limited by the Authentication service. Quotas are assigned according to the user typology and include limits on the number of concurrent orders and available processing workflows.
The API allows the discovery of all available workflows that can be run in the Copernicus Data Space Ecosystem platform, indicating which data types can be processed and what the available parameters and output modes are.

### API Endpoint

The **ODP API endpoint is [https://odp.dataspace.copernicus.eu/odata/v1](https://odp.dataspace.copernicus.eu/odata/v1){target="blank"}**.

**OpenAPI documentation is located at [https://odp.dataspace.copernicus.eu/odata/docs](https://odp.dataspace.copernicus.eu/odata/docs){target="blank"}**

### API Operations

The ODP API supports the following operations: 

* GET: This operation retrieves data and metadata from the ODP. The GET operation supports various query options to filter, order, and limit the data retrieved
* POST: This operation creates new entities in the ODP. The POST operation requires a payload in JSON format that specifies the properties of the new entity
* PATCH: This operation is used to update existing entities in the ODP. The PATCH operation requires a JSON payload that specifies the entity's properties to update
* DELETE: This operation deletes existing entities from the ODP. The DELETE operation requires the URL of the entity to be deleted 

### API Resources

The ODP API provides access to the following resources:  

* Workflow: predefined processor which creates a single output product or series of products based on the input parameters provided by the user. Typical inputs are the name of the source product and parameters specific to the processing chain
* Production Order: request for production using a Workflow chosen by the user
* Batch Order: request to produce multiple products using a chosen Workflow
* Order Item: single processing job within and a Production Order or Batch Order

### Authentication

To access the ODP API, you need an authorization token, as only authorized users are allowed to interact with the processing service.
To get the token, you can use the following script:

````
export KEYCLOAK_TOKEN=$(curl -d 'client_id=cdse-public' \
-d 'username=<LOGIN>' \
-d 'password=<PASSWORD>' \
-d 'grant_type=password' \
'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' | \
python -m json.tool | grep "access_token" | awk -F\" '{print $4}')
````

Once you have your token, you can execute a request to the API, including the token in the request header. For example, to list available Workflows, you can use the following command:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" "https://odp.dataspace.copernicus.eu/odata/v1/Workflows"
````

More information on the tokens and authentication can be found here: [https://documentation.dataspace.copernicus.eu/APIs/OData.html#product-download](https://documentation.dataspace.copernicus.eu/APIs/OData.html#product-download){target="blank"}

## Querying the API

### Workflows
#### Listing available Workflows
To list all processing Workflows available to the user:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/Workflows"
````

To search for specific Workflows you can use filters on the attributes. To find workflow named “coh”:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/Workflows?$filter=Name%20eq%20coh"
````

In a similar way to find all Workflows suitable for processing Sentinel-1 SLC products:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/Workflows?$filter=contains(InputProductType,'SLC')"
````

Details of the Workflow in the response list the parameters which are needed to create a new Production Order:

````
        {
            "Id": "47",
            "Name": "card_coh12_public",
            "DisplayName": "Sentinel-1: Coherence (12 days)",
            "Documentation": null,
            "Description": "The Sentinel-1 CARD COH12 (Copernicus Analysis Ready
             Data Coherence) processor generates a Sentinel-1 Level 2 product describing 
             the coherence of a pair of images - 12 days apart. 
             Concurrently, a terrain-correction (using DEM) is performed. This processor 
             provided by the Joint Research Centre is based on a GPT graph that can be run 
             with ESA SNAP.",
            "InputProductType": "SLC",
            "InputProductTypes": [
                "SLC",
                "S1_SLC__1S",
                "S2_SLC__1S",
                "S3_SLC__1S",
                "S4_SLC__1S",
                "S5_SLC__1S",
                "S6_SLC__1S",
                "IW_SLC__1S",
                "EW_SLC__1S",
                "WV_SLC__1S"
            ],
            "OutputProductType": "CARD-COH12",
            "WorkflowVersion": "3.1.0"
        }
````

### Production Orders

#### Create a new Production Order
To submit a new processing job, you need to use the POST method and send the parameters as a JSON message according to the requirements of a specific Workflows:

````
curl -X POST -H 'Content-Type:application/json' \
-H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder/OData.CSC.Order" \
-d '<json_message>'
````

Production orders accept the following general parameters: 

* WorkflowName: the  identifier of the workflow – “Name” attribute in the /Workflows response
* InputProductReference: information about the input data to be used by the processor
  * Reference: identifier of a single input product or multiple products (example – mosaicking processors)
  * ContentDate: time period which should be used by the Workflows (example - time-series based processors)
* WorkflowOptions: parameters specific to the Workflows (example – DEM version, cloud coverage)
* Priority: priority of the order in the users job queue. Orders with higher priority will be processed first
* NotificationEndpoint: (not used) URL of the endpoint which should receive the information once the order is completed (done or failed)
* Name: non-unique name for the order to help identify the orders 

The structure of the JSON message:

````
{
  "WorkflowName": "string",
  "InputProductReference": {
    "Reference": "string",
    "ContentDate": {
      "Start": "YYYY-MM-DDTHH:mm:ss.SSSZ",
      "End": "YYYY-MM-DDTHH:mm:ss.SSSZ"
    }
  },
  "WorkflowOptions": [
    {
      "Name": "string",
      "Value": "string"
    }
  ],
  "Priority": 0,
  "NotificationEndpoint": "string",
  "Name": "string"
}
````

Example: to submit an order for the Sentinel-1 CARD Backscatter product:

````
curl -X POST -H 'Content-Type:application/json' \
-H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder/OData.CSC.Order" \
-d '{ \
  "WorkflowName": "card_bs",
  "InputProductReference": {
    "Reference": "S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE"
  },
  "Priority": 1,
  "Name": "card_bs_order_1"
}'
````

Sample response after successful submission of the order:

````
{
  "@odata.context": "$metadata#OData.CSC.Order",
  "value": {
    "Id": "9999999",
    "Status": "queued",
    "StatusMessage": "queued",
    "SubmissionDate": "2023-04-05T10:03:25.474Z",
    "Name": "S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE",
    "EstimatedDate": "2023-04-05T10:33:16.161Z",
    "InputProductReference": {
      "Reference": S1A_IW_GRDH_1SDV_20230404T162838_20230404T162903_047949_05C333_B4FC.SAFE",
      "ContentDate": null
    },
    "WorkflowOptions": [],
    "WorkflowName": "card_bs",
    "WorkflowId": null,
    "Priority": 1
  }
}
````

#### Check list of Production Orders
To list all Production Orders requested by the user:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders"
````

When looking for completed orders for a specific processor:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders?$filter=WorkflowName%20eq%20coh%20and%20Status%20eq%20completed"
````

#### Check the status of a single Production Order
To check details of the single order using the order Id:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrders(<order_id>)"
````

#### Cancel a Production Order
To cancel an existing order:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(<order_id>)/OData.CSC.Cancel"
````

The orders that are in the queue and have not yet been processed will be removed instantly. For the orders in processing, the Order Items (single item within a Production Order) being processed will complete but the remaining part of the Order will be cancelled.

#### Display details of the result
The order generates a new product which can be downloaded from the public repository or private storage. To check the details of the result:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(<order_id>)/Product"
````

#### Download the result
Once the order is successfully processed, the status changes to complete, and the result is ready for download. The user may choose to instruct the service to put the results in a specified location (mandatory if custom parameters have been passed to the Workflow), and standard results (for Workflows like CARD-BS or CARD-COH12) are stored in the CDSE public repository and can be retrieved through the API.  
To download the result:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/ProductionOrder(<order_id>)/Product/$value" \
-o result.zip
````

### Batch Orders
#### Create a new Batch Order
In a way similar to a single Production Order, you can request processing of multiple input products as a Batch Order. The Batch Order will run a selected Workflow with the same parameters for all inputs and output the results to the same location. Using Batch Orders makes it easier to process time series or large AOIs.  
Batch Order endpoint uses the same mechanism as described for the Production Order:

````
curl -X POST -H 'Content-Type:application/json' \
-H "Authorization: Bearer $KEYCLOAK_TOKEN" \ 
"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder/OData.CSC.Order" \
-d '<json_message>'
````

Batch Orders accept the following general parameters: 

* WorkflowName: the  identifier of the workflow – “Name” attribute in the /Workflows response
* IdentifierList: information about the input data to be used by the processor - identifiers of products
* WorkflowOptions: parameters specific to the Workflows (example – DEM version, cloud coverage)
* Priority: priority of the order in the users job queue. Orders with higher priority will be processed first
* Callback: (not used) URL of the endpoint which should receive the information once the order is completed (done or failed)
* Name: non-unique name for the order to help identify the orders
* BatchSize: maximum number of items in the batch
* BatchVolume: maximum size of output data 

The structure of the JSON message:

````
{
  "Name": "string",
  "Priority": 0,
  "WorkflowName": "string",
  "Callback": "string",
  "WorkflowOptions": [
    {
      "Name": "string",
      "Value": "string"
    }
  ],
  "IdentifierList": [
    "string"
  ],
  "BatchSize": 0,
  "BatchVolume": 0
}
````

#### Check list of Batch Orders
To list all Production Orders requested by the user:

````
curl -X POST -H 'Content-Type:application/json' \
-H "Authorization: Bearer $KEYCLOAK_TOKEN" \ 
"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder"
````

When looking for batch orders for a specific processor (in example 'coh'):

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder?$filter=WorkflowName%20eq%20%coh"
````

#### Check the status of a single Batch Order
To check details of the single order using the order Id:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(<batch_order_id>)"
````

#### List products generated in a Batch Order
When the batch order is processed, for each input product an output is generated. To list the output of a batch:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(<batch_order_id>)/Products"
````

#### Display details of the results
Each item in the batch is an individual Production Order. To check the details of the single result:

````
curl -H "Authorization: Bearer $KEYCLOAK_TOKEN" \
"https://odp.dataspace.copernicus.eu/odata/v1/BatchOrder(<batch_order_id>)/Product(<order_id>)"
````
