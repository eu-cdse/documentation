---
title: Access to EO data via S3
---

S3 API is one of the main access methods for EO data. It is suitable for Third Party applications that require high-performance parallel access and scalability. Moreover, any user who wants to connect from an external infrastructure to the Copernicus Data Space Ecosystem collection can do so
through the S3 protocol.

## Object Storage endpoints

Access to EO data hosted on object storage is using an API compatible with S3. 

S3 is an object storage service with which you can retrieve data over HTTPS using REST API.

There are multiple S3 endpoints for accessing the EO Data. The default S3 endpoint address is:
[https://eodata.dataspace.copernicus.eu/](https://eodata.dataspace.copernicus.eu/)
 
This endpoint will provide access to EO data which is stored on the Object Storage. A Global Service Load Balancer (GSLB) directs the request to either CloudFerro Cloud or OpenTelekom Cloud (OTC) S3 endpoint. The decision is based on the location of the DNS resolver. ([Global Service Load Balancer](https://documentation.dataspace.copernicus.eu/ResearchNetwork.html#global-service-load-balancer){target="_blank"})

Users who want to make sure they are forwarded to OTC S3 endpoint have to use the following URL:
[https://eodata.ams.dataspace.copernicus.eu/](https://eodata.ams.dataspace.copernicus.eu/)

## Registration

To generate the necessary credentials, you must have a registered account on dataspace.copernicus.eu. If you don't have an account, you can register [here](https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/auth?client_id=cdse-public&response_type=code&scope=openid&redirect_uri=https%3A//dataspace.copernicus.eu/account/confirmed/1).

## Generate secrets

In order to obtain secrets, <a href="https://eodata-s3keysmanager.dataspace.copernicus.eu/">visit page</a> and log in with the Copernicus Data Space Ecosystem account for which the keys are to be generated. After successfully logging in, indicate the expiration date of the secrets using the "Add Credentials" button and click "Confirm".

![](_images/s3_cdse_1.png)

![](_images/s3_cdse_2.png)

Note that the Secret Key will be displayed only once, and you cannot view it again after clicking the Close button. Copy your secret key and keep it in a safe place.


## Example access using s3cmd

The example shown below assumes the use of a Linux environment.

With the access and secret key and the endpoint `eodata.dataspace.copernicus.eu`, you can use any tool to handle access via S3. Below is an example of how to access EO Data using the s3cmd.

First, we recommend creating a configuration file. You can create it with tools like vi/vim or nano:
```
vi .s3cfg
vim .s3cfg
nano .s3cfg
```
Copy the following content to your configuration file with your access and secret key:
```
[default]
access_key = <access_key>
host_base = eodata.dataspace.copernicus.eu
host_bucket = eodata.dataspace.copernicus.eu
human_readable_sizes = False
secret_key = <secret_key>
use_https = true
check_ssl_certificate = true
```
Then you can run any s3cmd command pointing to the previously created configuration file with option `-c`:
```
$ s3cmd -c .s3cfg ls s3://eodata/
```
Below is an example of downloading a product from the EO data repository using s3cmd:
```
$ s3cmd -c ~/.s3cfg get s3://eodata/Sentinel-1/SAR/SLC/2016/12/28/S1A_IW_SLC__1SDV_20161228T044442_20161228T044509_014575_017AE8_4C26.SAFE/measurement/s1a-iw2-slc-vv-20161228t044442-20161228t044508-014575-017ae8-005.tiff
```
If the objects in the repository are archives, for example, such as `S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE` use the resursive option `––recursive` or `-r` to download whole product.

Example with the recursive option:
```
$ s3cmd -c ~/.s3cfg -r get s3://eodata/Sentinel-1/SAR/SLC/2019/10/13/S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE/
```

Request type using command s3cmd get with --recursive option can be broken down as follows:

- Single Request to Initiate: The initial command with --recursive is a single request to initiate the process of downloading files recursively.
- Multiple Requests for Each File: Despite the initial command being a single request to start the recursive download, S3 treats each file download as a separate request. Therefore, if downloaded product have 100 files in the package, S3 will count this as 100 requests (one for each file downloaded).

So, while s3cmd is executed in a single command, the --recursive option will cause that each downloaded file is counted as an individual request in terms of quota count.

## Example script to download product using boto3

```
import boto3
import os

session = boto3.session.Session()
s3 = boto3.resource(
	's3',
	endpoint_url='https://eodata.dataspace.copernicus.eu',
	aws_access_key_id=access_key,
	aws_secret_access_key=secret_key,
	region_name='default'
)  # generated secrets

def download(bucket, product: str, target: str = "") -> None:
	"""
	Downloads every file in bucket with provided product as prefix

	Raises FileNotFoundError if the product was not found

	Args:
		bucket: boto3 Resource bucket object
		product: Path to product
		target: Local catalog for downloaded files. Should end with an `/`. Default current directory.
	"""
	files = bucket.objects.filter(Prefix=product)
	if not list(files):
		raise FileNotFoundError(f"Could not find any files for {product}")
	for file in files:
		os.makedirs(os.path.dirname(file.key), exist_ok=True)
		if not os.path.isdir(file.key):
			bucket.download_file(file.key, f"{target}{file.key}")

# path to the product to download
download(s3.Bucket("eodata"), "Sentinel-1/SAR/SLC/2019/10/13/S1B_IW_SLC__1SDV_20191013T155948_20191013T160015_018459_022C6B_13A2.SAFE/")
```

## Example script to download product using python

```
#!/usr/bin/env python3

import os
import json
import requests
import boto3
from tqdm import tqdm
import time
import argparse

# Set up command line argument parser
parser = argparse.ArgumentParser(
    description="Script to download EO product using OData and S3 protocol.",
    epilog="Example usage: python script.py -u <username> -p <password> <eo_product_name>"
)
parser.add_argument('-u', '--username', type=str, help='Username for authentication (required)')
parser.add_argument('-p', '--password', type=str, help='Password for authentication (required)')
parser.add_argument('eo_product_name', type=str, help='Name of the Earth Observation product to be downloaded (required)')
args = parser.parse_args()

# Prompt for missing credentials
if not args.username:
    args.username = input("Enter username: ")
if not args.password:
    args.password = input("Enter password: ")

# Configuration parameters
config = {
    "auth_server_url": "https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token",
    "odata_base_url": "https://catalogue.dataspace.copernicus.eu/odata/v1/Products",
    "s3_endpoint_url": "https://eodata.dataspace.copernicus.eu",
}

def get_access_token(config, username, password):
    """
    Retrieve an access token from the authentication server.
    This token is used for subsequent API calls.
    """
    auth_data = {
        "client_id": "cdse-public",
        "grant_type": "password",
        "username": username,
        "password": password,
    }
    response = requests.post(config["auth_server_url"], data=auth_data, verify=True, allow_redirects=False)
    if response.status_code == 200:
        return json.loads(response.text)["access_token"]
    else:
        print(f"Failed to retrieve access token. Status code: {response.status_code}")
        exit(1)

def get_eo_product_details(config, headers, eo_product_name):
    """
    Retrieve EO product details using the OData API to determine the S3 path.
    """
    odata_url = f"{config['odata_base_url']}?$filter=Name eq '{eo_product_name}'"
    response = requests.get(odata_url, headers=headers)
    if response.status_code == 200:
        eo_product_data = response.json()["value"][0]
        return eo_product_data["Id"], eo_product_data["S3Path"]
    else:
        print(f"Failed to retrieve EO product details. Status code: {response.status_code}")
        exit(1)

def get_temporary_s3_credentials(headers):
    """
    Create temporary S3 credentials by calling the S3 keys manager API.
    """
    credentials_response = requests.post("https://s3-keys-manager.cloudferro.com/api/user/credentials", headers=headers)
    if credentials_response.status_code == 200:
        s3_credentials = credentials_response.json()
        print("Temporary S3 credentials created successfully.")
        print(f"access: {s3_credentials['access_id']}")
        print(f"secret: {s3_credentials['secret']}")
        return s3_credentials
    else:
        print(f"Failed to create temporary S3 credentials. Status code: {credentials_response.status_code}")
        print("Product download aborted.")
        exit(1)

def format_filename(filename, length=40):
    """
    Format a filename to a fixed length, truncating if necessary.
    """
    if len(filename) > length:
        return filename[:length - 3] + '...'
    else:
        return filename.ljust(length)

def download_file_s3(s3, bucket_name, s3_key, local_path, failed_downloads):
    """
    Download a file from S3 with a progress bar.
    Track failed downloads in a list.
    """
    try:
        file_size = s3.head_object(Bucket=bucket_name, Key=s3_key)['ContentLength']
        formatted_filename = format_filename(os.path.basename(local_path))
        with tqdm(total=file_size, unit='B', unit_scale=True, desc=formatted_filename, ncols=80, bar_format='{desc:.40}|{bar:20}| {percentage:3.0f}% {n_fmt}/{total_fmt}B') as pbar:
            def progress_callback(bytes_transferred):
                pbar.update(bytes_transferred)

            s3.download_file(bucket_name, s3_key, local_path, Callback=progress_callback)
    except Exception as e:
        print(f"Failed to download {s3_key}. Error: {e}")
        failed_downloads.append(s3_key)

def traverse_and_download_s3(s3_resource, bucket_name, base_s3_path, local_path, failed_downloads):
    """
    Traverse the S3 bucket and download all files under the specified prefix.
    """
    bucket = s3_resource.Bucket(bucket_name)
    files = bucket.objects.filter(Prefix=base_s3_path)

    for obj in files:
        s3_key = obj.key
        relative_path = os.path.relpath(s3_key, base_s3_path)
        local_path_file = os.path.join(local_path, relative_path)
        local_dir = os.path.dirname(local_path_file)
        os.makedirs(local_dir, exist_ok=True)
        download_file_s3(s3_resource.meta.client, bucket_name, s3_key, local_path_file, failed_downloads)

def main():
    # Step 1: Retrieve the access token
    access_token = get_access_token(config, args.username, args.password)

    # Step 2: Set up headers for API calls
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Accept": "application/json"
    }

    # Step 3: Get EO product details (including S3 path)
    eo_product_id, s3_path = get_eo_product_details(config, headers, args.eo_product_name)
    bucket_name, base_s3_path = s3_path.lstrip('/').split('/', 1)

    # Step 4: Get temporary S3 credentials
    s3_credentials = get_temporary_s3_credentials(headers)

    # Step 5: Set up S3 client and resource with temporary credentials
    time.sleep(5)  # Ensure the key pair is installed
    s3_resource = boto3.resource('s3',
                                 endpoint_url=config["s3_endpoint_url"],
                                 aws_access_key_id=s3_credentials["access_id"],
                                 aws_secret_access_key=s3_credentials["secret"])

    # Step 6: Create the top-level folder and start download
    top_level_folder = args.eo_product_name
    os.makedirs(top_level_folder, exist_ok=True)
    failed_downloads = []
    traverse_and_download_s3(s3_resource, bucket_name, base_s3_path, top_level_folder, failed_downloads)

    # Step 7: Print final status
    if not failed_downloads:
        print("Product download complete.")
    else:
        print("Product download incomplete:")
        for failed_file in failed_downloads:
            print(f"- {failed_file}")

    # Step 7: Delete the temporary S3 credentials
    delete_response = requests.delete(f"https://s3-keys-manager.cloudferro.com/api/user/credentials/access_id/{s3_credentials['access_id']}", headers=headers)
    if delete_response.status_code == 204:
        print("Temporary S3 credentials deleted successfully.")
    else:
        print(f"Failed to delete temporary S3 credentials. Status code: {delete_response.status_code}")

if __name__ == "__main__":
    main()
```

## Accessing EOData via AWS CLI

In this section, you will access EOData resources using a Linux OS using **AWS Command Line Interface (AWS CLI)**.

### Prerequirements

**Check for system updates:**
```
$ sudo apt-get update -y
```
**Install prerequirements:**
```
$ sudo apt-get install unzip groff less -y
```
**Generate S3 credentials at CDSE:**

In order to access EOData via S3 you must obtain secrets (**access** and **secret** key). Please visit following <a href="https://eodata-s3keysmanager.dataspace.copernicus.eu/">page</a> and log in with Copernicus Data Space Ecosystem account for which the keys are to be generated.

If you dont have an account, you can register via following <a href="https://documentation.dataspace.copernicus.eu/Registration.html">link</a>.

### Install or update the AWS CLI

To update your current installation of AWS CLI, download a new installer each time you update to overwrite previous versions. Follow these steps from the command line to install the AWS CLI on Linux.
```
$ curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
```
Verify if client is installed:
```
$ aws --version
aws-cli/2.13.32 Python/3.11.6 Linux/5.15.0-75-generic exe/x86_64.ubuntu.22 prompt/off
```
### Configuration

Enter the following command:
```
$ aws configure
```
You will be prompted for providing certain connection details. Below are the values which you should use during the configuration. Replace **access_key** and **secret_key** with appropriate keys you obtained previously.

```
AWS Access Key ID [None]: <access_key>
AWS Secret Key ID [None]: <secret_key>
Default region name [None]: default
Default output format [None]: text
```

### List and download products

Now you can use AWS CLI commands (documentation available via following link: https://aws.amazon.com/cli/)

**Specify the CDSE endpoint:**

Use following line to specify endpoint.
```
export AWS_ENDPOINT_URL=https://eodata.dataspace.copernicus.eu/
```
**List available buckets:**

```
$ aws s3 ls s3://eodata/
eouser@aws-cli:~$ aws s3 ls s3://eodata/
                           PRE C3S/
                           PRE CAMS/
                           PRE CEMS/
                           PRE CLMS/
                           PRE CMEMS/
                           PRE Envisat/
                           PRE Envisat-ASAR/
                           PRE Global-Mosaics/
                           PRE Jason-3/
                           PRE Landsat-5/
                           PRE Landsat-7/
                           PRE Landsat-8/
                           PRE SMOS/
                           PRE Sentinel-1/
                           PRE Sentinel-1-COG/
                           PRE Sentinel-1-RTC/
                           PRE Sentinel-2/
                           PRE Sentinel-3/
                           PRE Sentinel-5P/
                           PRE Sentinel-6/
                           PRE auxdata/
```
**Downloading products:**

In order to download products from repository follow the steps. 

Below example is downloading product from Sentinel-2 named "S2A_MSIL2A_20240115T235221_N0510_R130_T55HGS_20240116T021554.SAFE" and saving it at user's home location.
```
$ aws s3 cp s3://eodata/Sentinel-2/MSI/L2A/2024/01/15/S2A_MSIL2A_20240115T235221_N0510_R130_T55HGS_20240116T021554.SAFE/ /home/eouser/S2A_MSIL2A_20240115T235221_N0510_R130_T55HGS_20240116T021554.SAFE

download: s3://eodata/Sentinel-2/MSI/L2A/2024/01/15/S2A_MSIL2A_20240115T235221_N0510_R130_T55HGS_20240116T021554.SAFE/ to ./S2A_MSIL2A_20240115T235221_N0510_R130_T55HGS_20240116T021554.SAFE
```

After this operation, you should downloaded product in specified path.
